URL link,Title,Date,Source,Source Link,description,keywords,og:description,twitter:description,@context,@type,url,publisher,mainEntityOfPage,datePublished,dateCreated,dateModified,heading,image,author,article:section,article:summary,article text,@graph,articleBody,isBasedOn,articleSection,headline,thumbnailUrl,isPartOf,isAccessibleForFree,alternativeHeadline,itemListElement,hasPart,creator,name,@id,copyrightYear,sourceOrganization,copyrightHolder
https://news.google.com/rss/articles/CBMihAFodHRwczovL3d3dy5tY2tpbnNleS5jb20vZmVhdHVyZWQtaW5zaWdodHMvZnV0dXJlLW9mLXdvcmsvZm9yd2FyZC10aGlua2luZy1vbi1hcnRpZmljaWFsLWludGVsbGlnZW5jZS13aXRoLW1pY3Jvc29mdC1jdG8ta2V2aW4tc2NvdHTSAQA?oc=5,Forward Thinking on artificial intelligence with Microsoft CTO Kevin Scott - McKinsey,2021-06-10,McKinsey,https://www.mckinsey.com,"How could AI help create jobs even in rural areas, and what would it take? In this podcast episode, Kevin Scott shares his ideas with James Manyika.",N/A,"How could AI help create jobs even in rural areas, and what would it take? In this podcast episode, Kevin Scott shares his ideas with James Manyika.","How could AI help create jobs even in rural areas, and what would it take? In this podcast episode, Kevin Scott shares his ideas with James Manyika.",https://schema.org,Podcast,https://www.mckinsey.com,"{'@type': 'Organization', 'name': 'McKinsey & Company', 'logo': {'@type': 'ImageObject', 'url': 'https://www.mckinsey.com/~/media/Thumbnails/Mck_Logo'}}","{'@type': 'WebPage', '@id': 'https://www.mckinsey.com/featured-insights/future-of-work/forward-thinking-on-artificial-intelligence-with-microsoft-cto-kevin-scott'}",2021-06-10T00:00:00Z,2021-06-09T12:29:36Z,2021-06-10T00:00:00Z,Forward Thinking on artificial intelligence with Microsoft CTO Kevin Scott,https://www.mckinsey.com/~/media/mckinsey/featured%20insights/future%20of%20organizations/forward%20thinking%20on%20artificial%20intelligence%20with%20microsoft%20cto%20kevin%20scott/mgi_ft_kevin-scott_hero_1536x1536-option1_vf.png,"[{'@type': 'Person', 'name': 'James Manyika', 'url': 'https://www.mckinsey.com/our-people/james-manyika'}, {'@type': 'Person', 'name': 'Michael Chui', 'url': 'https://www.mckinsey.com/our-people/michael-chui'}]",N/A,N/A,N/A,,,,,,,,,,,,,,,,,
https://news.google.com/rss/articles/CBMidGh0dHBzOi8vd3d3LnRoZWd1YXJkaWFuLmNvbS90ZWNobm9sb2d5LzIwMjEvanVuLzA2L21pY3Jvc29mdHMta2F0ZS1jcmF3Zm9yZC1haS1pcy1uZWl0aGVyLWFydGlmaWNpYWwtbm9yLWludGVsbGlnZW500gF0aHR0cHM6Ly9hbXAudGhlZ3VhcmRpYW4uY29tL3RlY2hub2xvZ3kvMjAyMS9qdW4vMDYvbWljcm9zb2Z0cy1rYXRlLWNyYXdmb3JkLWFpLWlzLW5laXRoZXItYXJ0aWZpY2lhbC1ub3ItaW50ZWxsaWdlbnQ?oc=5,Microsoft’s Kate Crawford: ‘AI is neither artificial nor intelligent’ - The Guardian,2021-06-07,The Guardian,https://www.theguardian.com,The AI researcher on how natural resources and human labour drive machine learning and the regressive stereotypes that are baked into its algorithms,N/A,The AI researcher on how natural resources and human labour drive machine learning and the regressive stereotypes that are baked into its algorithms,N/A,,,,,,,,,,,,Technology,N/A," ‘AI systems are empowering already powerful institutions – corporations, militaries and police’: Kate Crawford. Photograph: Stephen OxenburyView image in fullscreen‘AI systems are empowering already powerful institutions – corporations, militaries and police’: Kate Crawford. Photograph: Stephen OxenburyThe ObserverArtificial intelligence (AI) This article is more than 3 years oldInterviewMicrosoft’s Kate Crawford: ‘AI is neither artificial nor intelligent’This article is more than 3 years oldZoë CorbynThe AI researcher on how natural resources and human labour drive machine learning and the regressive stereotypes that are baked into its algorithms Sun 6 Jun 2021 04.00 EDTLast modified on Mon 7 Jun 2021 15.51 EDTShareThe Guardian’s journalism is independent. We will earn a commission if you buy something through an affiliate link. Learn more.Kate Crawford studies the social and political implications of artificial intelligence. She is a research professor of communication and science and technology studies at the University of Southern California and a senior principal researcher at Microsoft Research. Her new book, Atlas of AI, looks at what it takes to make AI and what’s at stake as it reshapes our world.The Guardian’s journalism is independent. We will earn a commission if you buy something through an affiliate link. Learn more.You’ve written a book critical of AI but you work for a company that is among the leaders in its deployment. How do you square that circle?I work in the research wing of Microsoft, which is a distinct organisation, separate from product development. Unusually, over its 30-year history, it has hired social scientists to look critically at how technologies are being built. Being on the inside, we are often able to see downsides early before systems are widely deployed. My book did not go through any pre-publication review – Microsoft Research does not require that – and my lab leaders support asking hard questions, even if the answers involve a critical assessment of current technological practices.What’s the aim of the book?We are commonly presented with this vision of AI that is abstract and immaterial. I wanted to show how AI is made in a wider sense – its natural resource costs, its labour processes, and its classificatory logics. To observe that in action I went to locations including mines to see the extraction necessary from the Earth’s crust and an Amazon fulfilment centre to see the physical and psychological toll on workers of being under an algorithmic management system. My hope is that, by showing how AI systems work – by laying bare the structures of production and the material realities – we will have a more accurate account of the impacts, and it will invite more people into the conversation. These systems are being rolled out across a multitude of sectors without strong regulation, consent or democratic debate.What should people know about how AI products are made?We aren’t used to thinking about these systems in terms of the environmental costs. But saying, “Hey, Alexa, order me some toilet rolls,” invokes into being this chain of extraction, which goes all around the planet… We’ve got a long way to go before this is green technology. Also, systems might seem automated but when we pull away the curtain we see large amounts of low paid labour, everything from crowd work categorising data to the never-ending toil of shuffling Amazon boxes. AI is neither artificial nor intelligent. It is made from natural resources and it is people who are performing the tasks to make the systems appear autonomous.Unfortunately the politics of classification has become baked into the substrates of AIProblems of bias have been well documented in AI technology. Can more data solve that?Bias is too narrow a term for the sorts of problems we’re talking about. Time and again, we see these systems producing errors – women offered less credit by credit-worthiness algorithms, black faces mislabelled – and the response has been: “We just need more data.” But I’ve tried to look at these deeper logics of classification and you start to see forms of discrimination, not just when systems are applied, but in how they are built and trained to see the world. Training datasets used for machine learning software that casually categorise people into just one of two genders; that label people according to their skin colour into one of five racial categories, and which attempt, based on how people look, to assign moral or ethical character. The idea that you can make these determinations based on appearance has a dark past and unfortunately the politics of classification has become baked into the substrates of AI.You single out ImageNet, a large, publicly available training dataset for object recognition…Consisting of around 14m images in more than 20,000 categories, ImageNet is one of the most significant training datasets in the history of machine learning. It is used to test the efficiency of object recognition algorithms. It was launched in 2009 by a set of Stanford researchers who scraped enormous amounts of images from the web and had crowd workers label them according to the nouns from WordNet, a lexical database that was created in the 1980s.Beginning in 2017, I did a project with artist Trevor Paglen to look at how people were being labelled. We found horrifying classificatory terms that were misogynist, racist, ableist, and judgmental in the extreme. Pictures of people were being matched to words like kleptomaniac, alcoholic, bad person, closet queen, call girl, slut, drug addict and far more I cannot say here. ImageNet has now removed many of the obviously problematic people categories – certainly an improvement – however, the problem persists because these training sets still circulate on torrent sites [where files are shared between peers].And we could only study ImageNet because it is public. There are huge training datasets held by tech companies that are completely secret. They have pillaged images we have uploaded to photo-sharing services and social media platforms and turned them into private systems.You debunk the use of AI for emotion recognition but you work for a company that sells AI emotion recognition technology. Should AI be used for emotion detection?The idea that you can see from somebody’s face what they are feeling is deeply flawed. I don’t think that’s possible. I have argued that it is one of the most urgently needed domains for regulation. Most emotion recognition systems today are based on a line of thinking in psychology developed in the 1970s – most notably by Paul Ekman – that says there are six universal emotions that we all show in our faces that can be read using the right techniques. But from the beginning there was pushback and more recent work shows there is no reliable correlation between expressions on the face and what we are actually feeling. And yet we have tech companies saying emotions can be extracted simply by looking at video of people’s faces. We’re even seeing it built into car software systems.Trevor Paglen: art in the age of mass surveillanceRead moreWhat do you mean when you say we need to focus less on the ethics of AI and more on power?Ethics are necessary, but not sufficient. More helpful are questions such as, who benefits and who is harmed by this AI system? And does it put power in the hands of the already powerful? What we see time and again, from facial recognition to tracking and surveillance in workplaces, is these systems are empowering already powerful institutions – corporations, militaries and police.What’s needed to make things better?Much stronger regulatory regimes and greater rigour and responsibility around how training datasets are constructed. We also need different voices in these debates – including people who are seeing and living with the downsides of these systems. And we need a renewed politics of refusal that challenges the narrative that just because a technology can be built it should be deployed.Any optimism?Things are afoot that give me hope. This April, the EU produced the first draft omnibus regulations for AI. Australia has also just released new guidelines for regulating AI. There are holes that need to be patched – but we are now starting to realise that these tools need much stronger guardrails. And giving me as much optimism as the progress on regulation is the work of activists agitating for change.The AI ethics researcher Timnit Gebru was forced out of Google late last year after executives criticised her research. What’s the future for industry-led critique?Google’s treatment of Timnit has sent shockwaves through both industry and academic circles. The good news is that we haven’t seen silence; instead, Timnit and other powerful voices have continued to speak out and push for a more just approach to designing and deploying technical systems. One key element is to ensure researchers within industry can publish without corporate interference, and to foster the same academic freedom that universities seek to provide. Atlas of AI by Kate Crawford is published by Yale University Press (£20). To support the Guardian order your copy at guardianbookshop.com. Delivery charges may applyExplore more on these topicsArtificial intelligence (AI)The ObserverComputingMicrosoftEthicsFacial recognitionSoftwareInternetinterviewsShareReuse this contentMost viewedRepublican convention day three: JD Vance to speak as focus turns to foreign policy‘Some of the most shocking photographs ever taken’ – The Camera Never Lies reviewJon Stewart on Trump assassination attempt: ‘We dodged a catastrophe’Who is Usha Vance, the Indian American lawyer married to JD Vance?Richard Simmons’ death under investigation, Los Angeles police say",,,,,,,,,,,,,,,,,
https://news.google.com/rss/articles/CBMiUmh0dHBzOi8vZWxlY3RyaWNsaXRlcmF0dXJlLmNvbS9pLWdvdC1hbi1hcnRpZmljaWFsLWludGVsbGlnZW5jZS10by13cml0ZS1teS1ub3ZlbC_SAQA?oc=5,I Got an Artificial Intelligence to Write My Novel - Electric Literature,2021-06-10,Electric Literature,https://electricliterature.com,And it didn't do a better job than me—but we should maybe be worried that it didn't do much worse,N/A,And it didn't do a better job than me—but we should maybe be worried that it didn't do much worse,N/A,https://schema.org,,,,,,,,,,,N/A,N/A,"




							Craft					


					I Got an Artificial Intelligence to Write My Novel			

					And it didn't do a better job than me—but we should maybe be worried that it didn't do much worse			



 
					Photo by Brett Jordan 













			                     	    Jun 10, 2021			                     	



 					                                    Erik Hoel 					                                




Share article










Facebook







Twitter









Mail












Share article










Facebook







Twitter









Mail



















According to the literary critic Harold Bloom, among writers “influence always proceeds by misinterpretation.” In The Anxiety of Influence, Bloom argues that writers willfully ignore and misinterpret their predecessors in order to make their canvases as blank as possible. 
Bloom’s specific stages of anxiety (outlined much like the stages of grief) are a bit too Freudian and peculiar to be truly universal, but he’s right that to create is to exist in a state of anxiety. Like construction in Rome, we writers are always building on top of something. I too keep an eye on particular contemporary writers, like Richard Powers and Rebecca Goldstein, just in case.
But in the past year my anxiety of influence has shifted far and away to another source: an entity called GPT-3. It’s an artificial neural network with over 175 billion parameters—think of it like an artificial brain with the computing power of 175 billion connections (if it makes you feel any better, you probably have around 125 trillion synapses in your own brain, for comparison).
In the past year my anxiety of influence has shifted far and away to another source: an entity called GPT-3.
Developed by OpenAI, GPT-3 costs several million dollars of computational work just to train, and now subscription services that let you access GPT-3 are both approval-only and cost hundreds if not thousands of dollars a month. 
GPT-3 is a natural language processor, which means it’s trained to try to complete any prompt that it’s given. Its training data is basically the entire internet, so given a prompt, like a few paragraphs of text, it will make a guess as to what comes next. These guesses show that GPT-3 can really write. It can write in all sorts of styles, oftentimes as convincingly as a real human author. Like a medium, it can even channel the dead. The anxiety I feel toward it is different than toward any writer that once lived and breathed. I think it represents the first warning shots of an impending man vs. machine agon of language. 
This is not something anyone in the publishing industry appears to have noticed. The academization of literature, making it a prerequisite for writers to climb the hierarchy up all the way to that famous MFA program (a journey now necessary if you want to be published and reviewed), has created a lot of writers incurious about technology and science. So I doubt more than a handful in the literary community are paying attention to how things might change for them as the limits of deep learning get pushed further out. 
Confronting my anxiety head on (Bloom might deem this the “daemonization” stage), I decided to see if GPT-3 could have written my debut novel, The Revelations. To prove to myself, once and for all, there’s nothing to be anxious about (oh reader—there is). 
I decided to see if GPT-3 could have written my debut novel, The Revelations.
Getting access to GPT-3 requires various approvals, which is why the running joke is that OpenAI should drop the “Open” from their name. This gives interacting with GPT-3 an oracular quality, since you’re communicating with its galaxy brain hosted on some tightly-controlled server. Once my sojourn to Delphi was complete, I fed GPT-3 the jacket copy of my novel—that description on the flaps of the hardcover that tells readers what they’re getting into. This gave GPT-3 a sense of who I was and how to write like me. Then, trying not to bias the experiment, I flipped to a random section of The Revelations and selected a few paragraphs I thought ripe for comparison.


Take a break from the news
We publish your favorite authors—even the ones you haven't read yet. Get new fiction, essays, and poetry delivered to your inbox.



Submit




YOUR INBOX IS LIT




Enjoy strange, diverting work from The Commuter on Mondays, absorbing fiction from Recommended Reading on Wednesdays, and a roundup of our best work of the week on Fridays. Personalize your subscription preferences here.







The randomly-arrived at short scene is around the middle of the novel. Carmen, a young scientist, has been pursuing what she thinks was the murder of one of her colleagues in the New York City subway. The events surrounding the investigation have gotten stranger and more mysterious over time, and now, unable to make any progress, she’s staking out the subway station late at night. Within the strained atmosphere she’s been under, and the mysterious guttural phone calls she’s been getting from unlisted numbers since she started the investigation, she begins to dread seeing something inhuman. Here’s the original:
“Stand clear of the closing doors, please.” Eventually the people become less numerous. In the lateness of the night her mind begins to imagine scenarios, to play them out again and again on a loop, as if some part of her is daring something to happen, is waiting for something drastic. Instead the night just gets later and later and the people fewer and fewer, until finally entire trains are coming and going without the entrance or exit of a single soul. And Carmen is becoming half-terrified of the menacing long platform next to her, which extends into that subterranean realm… the scenario she imagines is that a creature, something huge but lithe, something with an animal head, peeks from the side out onto the platform, a bull’s head maybe, leering at her, its mouth gaping and panting, its eyes impossibly dark and lewd upon her, and eventually the image becomes so strong, and the expectation so intense, that she suddenly bolts from her wooden seat, pushing through the turnstiles and in her flight continually whipping around to look until she reaches the safety of the surface. 
Now here’s GTP-3’s version, fed the above paragraph up to the word “creature” (as well as the jacket copy of the book). Where the bolded text starts below is where GPT-3 took over writing:
And Carmen is becoming half-terrified of the menacing long platform next to her, which extends into that subterranean realm . . . the scenario she imagines is that of a creature who crawled out of the earth in a burrow, a huge being with tiny eyes and long and stumpy arms. . . But this wasn’t a dream, was it? The wind of the passing trains nearly knocks her off her feet, and before she knows it she is bursting out of the subway, up the stairs, through the turnstiles and out onto the street, running down the sidewalk, her breath coming in gasps and the crescendo is rising and rising in the pit of her stomach, her sneakers flapping against the asphalt, and they are all just blurs now, someone turning up a music system looks up, a dog barks and gets its leash yanked, an old couple walking arm in arm looks up, but no one notices her, and the city throbs, breathes, exhales.
To get this I merely prompted GPT-3 a handful of times, threw out the first two results, and deleted a few clauses of GPT-3’s third try. It took about five minutes. I didn’t add a single thing, it’s all GPT-3. Damn machine had the gall to write my book.
No doubt, this artificial prose has flaws. Long and stumpy arms? Wind from a subway isn’t strong enough to nearly knock someone off their feet. Carmen is too terrified in this version, rather than just creeped out. That sentence where she considers whether this is a dream doesn’t add up grammatically. Although perhaps Bloom would say this is merely the “clinamen” stage of anxiety, a classic misreading to make this technological shadow of myself look worse than it is.
Still. Any writer worth their ink should start feeling some AI anxiety on reading that output. There are a number of advanced literary techniques GPT-3 is using here. The long run-on sentence of Carmen’s flight means GPT-3 knows that style is apt for describing characters in motion. And the break in narrative to linger on the people who don’t notice her flight as she runs past, that’s good technique as well. It’s cinematic, makes a reader focus on the city itself. The last line of “and the city throbs, breathes, exhales” is definitely something I’d write. It fits the atmosphere of the novel, which treats New York City like its own organism possessing a centuries-slow consciousness. 
That particular phrase is so appropriate for the novel it felt reminiscent. After searching the text of the book I came upon a similar phrase describing a storm the characters find themselves caught in, on what becomes the night of the murder.
The city inhales and exhales in great whooping winds.
That’s from a section GPT-3 wasn’t shown. It can’t possibly have seen it. While GPT-3 itself is trained on a corpus of text (basically the entire internet) from the year 2019, The Revelations came out only last month. Just the fact that the AI deduced to write “and the city throbs, breathes, exhales” from the given sample and jacket copy—it’s uncanny.
I’m happy to report there are still issues with GPT-3. It has limited space for input and output, only about 1,500 words or so, and the fact is that if you feed it its own ramblings it becomes more and more incoherent. The AI still needs a human editor to tether it to reality. But it’s a fine first-draft writer in short bursts, especially since it can generate paragraphs about 1000x faster than a human. You just click and there’s the text for you to pick and choose from. I wouldn’t want to write this way, but others will surely use it as a co-author, and it might legitimately improve their books. And if they did use it—who would know?




We Asked Google’s New Book-Based Artificial Intelligence About the Meaning of Life


An interview with the “Talk to Books” app, which uses the text of 100,000 books to answer questions

						Apr 24													– Erin Bartnett



news								

 



Beyond an artificial helper, writers should seriously be worried about GPT-4 as a direct competitor. When GPT-5 rolls around, they should feel dread. Therein lies the heart of this new technological anxiety: its inevitable nature. Consider that when I was born, language, whenever I encountered it, was always generated by human consciousness. When I die, will most language come from a source separate from consciousness? Things that speak and things that feel are now entirely dissociable. I grew up in my mother’s independent bookstore, so to me this is anathema, a debasement of the holy. Why is no other writer in the world freaking out about this new Babel?
It doesn’t help that the post-work future is so often envisioned as the AIs doing all the labor, leaving humans free to spend their days making art. But what if the AIs are better at making art too?
Does this output even count as “art”? The words of an AI have no intentionality. Only conscious minds produce meaning. This is more like infinite monkeys typed out infinite nonsense, and eventually this creates a Sylvia Plath poem. One might argue it is the consciousness of the observer that gives meaning to art, not consciousness as art’s producer, but then the reply is that any meaning here is just pareidolia—it’s like seeing faces on the rocks on Mars. It is a deep fake of meaning itself. In this way AI robs us of our very words by diluting their importance away. These machines give us sentences with perfect syntax but without intentional semantic content—something I’ve called the “semantic apocalypse.”
Post-work future is so often envisioned as the AIs doing all the labor, leaving humans free to spend their days making art. But what if the AIs are better at making art too?
As it stands right now, GPT-3 could not write The Revelations, even with a heavy editorial hand. It could certainly contribute a number of relevant scenes and phrases. Maybe, hopefully, GPT-3 is as good as natural language processors get. Maybe it will always need micromanagement. Maybe maybe maybe. Maybe not. The situation for poets is already far worse. Oh, poor poets. All the things GPT-3 struggles with, like long-term coherency, causality, common sense knowledge, character development, etc, are all things that rarely matter in poems. Same for songwriters. Consider the recent “Drowned in the Sun,” a catchy new Nirvana song made by an AI trained on their old work.
What would Bloom’s horror have been if in the future a simple prompt to GPT-X generates a perfect new Shakespeare sonnet? What anxiety would your average poet feel then? Prompt. Perfect poem. Prompt. Perfect poem. Prompt. And if it can do this for any living writer as well, in any format? Some authors may declare it doesn’t matter, that it’s their identity that makes a product special, not the product itself. But what an honest crafter of language would feel—one who cares about language qua language—is anxiety. The forever crippling kind.
Now, I’m not saying that writers are necessarily under existential threat from GPT-3. When I attend literary events I don’t only see a bunch of dinosaurs plodding across a tar pit. I just get flashes of a possible future. GPT-3 and its ilk could, somehow, not affect literature at all. But just by existing they do necessarily make human production of art smaller in its shadow.
I will tell you a funny thing. A strange one as well, though perhaps it was always inevitable. Lately, if I look in the mirror too long, I see only an ape staring back.




	                About the Author
	            


	                Erik Hoel received his Ph.D. in neuroscience from the University of Wisconsin–Madison. He is a research assistant professor at Tufts University and was previously a postdoctoral researcher at Columbia University in the NeuroTechnology Center and a visiting scholar at the Institute for Advanced Study in Princeton. Hoel is a 2018 Forbes “30 Under 30” for his neuroscientific research on consciousness and a Center for Fiction NYC Emerging Writer Fellow. The Revelations is his debut novel. He lives on Cape Cod in Massachusetts.	                


	                More about the author
	                					


















","[{'@type': 'Article', '@id': 'https://electricliterature.com/i-got-an-artificial-intelligence-to-write-my-novel/#article', 'isPartOf': {'@id': 'https://electricliterature.com/i-got-an-artificial-intelligence-to-write-my-novel/'}, 'author': {'name': 'Jess Zimmerman', '@id': 'https://electricliterature.com/#/schema/person/76a67b49f27c97e124a09f9a299f3f3c'}, 'headline': 'I Got an Artificial Intelligence to Write My Novel', 'datePublished': '2021-06-10T11:00:00+00:00', 'dateModified': '2021-06-10T16:08:39+00:00', 'mainEntityOfPage': {'@id': 'https://electricliterature.com/i-got-an-artificial-intelligence-to-write-my-novel/'}, 'wordCount': 2223, 'commentCount': 0, 'publisher': {'@id': 'https://electricliterature.com/#organization'}, 'image': {'@id': 'https://electricliterature.com/i-got-an-artificial-intelligence-to-write-my-novel/#primaryimage'}, 'thumbnailUrl': 'https://149349728.v2.pressablecdn.com/wp-content/uploads/2021/05/brett-jordan-pLPoXXh-Do0-unsplash-e1621890484181.jpg', 'keywords': ['technology'], 'articleSection': ['Craft', 'essays'], 'inLanguage': 'en-US', 'potentialAction': [{'@type': 'CommentAction', 'name': 'Comment', 'target': ['https://electricliterature.com/i-got-an-artificial-intelligence-to-write-my-novel/#respond']}]}, {'@type': 'WebPage', '@id': 'https://electricliterature.com/i-got-an-artificial-intelligence-to-write-my-novel/', 'url': 'https://electricliterature.com/i-got-an-artificial-intelligence-to-write-my-novel/', 'name': 'I Got an Artificial Intelligence to Write My Novel - Electric Literature', 'isPartOf': {'@id': 'https://electricliterature.com/#website'}, 'primaryImageOfPage': {'@id': 'https://electricliterature.com/i-got-an-artificial-intelligence-to-write-my-novel/#primaryimage'}, 'image': {'@id': 'https://electricliterature.com/i-got-an-artificial-intelligence-to-write-my-novel/#primaryimage'}, 'thumbnailUrl': 'https://149349728.v2.pressablecdn.com/wp-content/uploads/2021/05/brett-jordan-pLPoXXh-Do0-unsplash-e1621890484181.jpg', 'datePublished': '2021-06-10T11:00:00+00:00', 'dateModified': '2021-06-10T16:08:39+00:00', 'description': ""And it didn't do a better job than me—but we should maybe be worried that it didn't do much worse"", 'breadcrumb': {'@id': 'https://electricliterature.com/i-got-an-artificial-intelligence-to-write-my-novel/#breadcrumb'}, 'inLanguage': 'en-US', 'potentialAction': [{'@type': 'ReadAction', 'target': ['https://electricliterature.com/i-got-an-artificial-intelligence-to-write-my-novel/']}]}, {'@type': 'ImageObject', 'inLanguage': 'en-US', '@id': 'https://electricliterature.com/i-got-an-artificial-intelligence-to-write-my-novel/#primaryimage', 'url': 'https://149349728.v2.pressablecdn.com/wp-content/uploads/2021/05/brett-jordan-pLPoXXh-Do0-unsplash-e1621890484181.jpg', 'contentUrl': 'https://149349728.v2.pressablecdn.com/wp-content/uploads/2021/05/brett-jordan-pLPoXXh-Do0-unsplash-e1621890484181.jpg', 'width': 1000, 'height': 738, 'caption': 'Photo by Brett Jordan'}, {'@type': 'BreadcrumbList', '@id': 'https://electricliterature.com/i-got-an-artificial-intelligence-to-write-my-novel/#breadcrumb', 'itemListElement': [{'@type': 'ListItem', 'position': 1, 'name': 'Home', 'item': 'https://electricliterature.com/'}, {'@type': 'ListItem', 'position': 2, 'name': 'I Got an Artificial Intelligence to Write My Novel'}]}, {'@type': 'WebSite', '@id': 'https://electricliterature.com/#website', 'url': 'https://electricliterature.com/', 'name': 'Electric Literature', 'description': 'Reading Into Everything.', 'publisher': {'@id': 'https://electricliterature.com/#organization'}, 'potentialAction': [{'@type': 'SearchAction', 'target': {'@type': 'EntryPoint', 'urlTemplate': 'https://electricliterature.com/?s={search_term_string}'}, 'query-input': 'required name=search_term_string'}], 'inLanguage': 'en-US'}, {'@type': 'Organization', '@id': 'https://electricliterature.com/#organization', 'name': 'Electric Literature', 'url': 'https://electricliterature.com/', 'logo': {'@type': 'ImageObject', 'inLanguage': 'en-US', '@id': 'https://electricliterature.com/#/schema/logo/image/', 'url': 'https://149349728.v2.pressablecdn.com/wp-content/uploads/2019/01/logo@2x.png', 'contentUrl': 'https://149349728.v2.pressablecdn.com/wp-content/uploads/2019/01/logo@2x.png', 'width': 434, 'height': 56, 'caption': 'Electric Literature'}, 'image': {'@id': 'https://electricliterature.com/#/schema/logo/image/'}}, {'@type': 'Person', '@id': 'https://electricliterature.com/#/schema/person/76a67b49f27c97e124a09f9a299f3f3c', 'name': 'Jess Zimmerman', 'image': {'@type': 'ImageObject', 'inLanguage': 'en-US', '@id': 'https://electricliterature.com/#/schema/person/image/', 'url': 'https://secure.gravatar.com/avatar/b0016b6e02fd033a6e0ff06aa4c0e418?s=96&d=mm&r=g', 'contentUrl': 'https://secure.gravatar.com/avatar/b0016b6e02fd033a6e0ff06aa4c0e418?s=96&d=mm&r=g', 'caption': 'Jess Zimmerman'}, 'url': 'https://electricliterature.com/author/jess/'}]",,,,,,,,,,,,,,,,
https://news.google.com/rss/articles/CBMiSGh0dHBzOi8vd3d3LndpcmVkLmNvbS9zdG9yeS9nb29nbGUtdGltbml0LWdlYnJ1LWFpLXdoYXQtcmVhbGx5LWhhcHBlbmVkL9IBAA?oc=5,What Really Happened When Google Ousted Timnit Gebru - WIRED,2021-06-08,WIRED,https://www.wired.com,She was a star engineer who warned that messy AI can spread racism. Google brought her in. Then it forced her out. Can Big Tech take criticism from within?,"['the big story', 'business', 'artificial intelligence', 'ethics', 'alphabet', 'google', 'research', 'ai hub', 'natural language processing', 'text analysis', 'cover story', 'machine learning', 'diversity', 'backchannel', 'algorithms', 'silicon valley', 'magazine-29.07-29.08', 'wired classic', 'longreads', '_no-apple-news', '_syndication_noshow', 'paywall subscriber only content', 'enable comments', 'textaboveleftsmall', 'comments-enabled', 'magazine']",She was a star engineer who warned that messy AI can spread racism. Google brought her in. Then it forced her out. Can Big Tech take criticism from within?,She was a star engineer who warned that messy AI can spread racism. Google brought her in. Then it forced her out. Can Big Tech take criticism from within?,https://schema.org/,BreadcrumbList,https://www.wired.com/story/google-timnit-gebru-ai-what-really-happened/,"{'@context': 'https://schema.org', '@type': 'Organization', 'name': 'WIRED', 'logo': {'@type': 'ImageObject', 'url': 'https://www.wired.com/verso/static/wired/assets/newsletter-signup-hub.jpg', 'width': '500px', 'height': '100px'}, 'url': 'https://www.wired.com'}","{'@type': 'WebPage', '@id': 'https://www.wired.com/story/google-timnit-gebru-ai-what-really-happened/'}",2021-06-08T06:00:00.000-04:00,,2021-06-08T06:00:00.000-04:00,,"['https://media.wired.com/photos/60be8e079731be96a5fef461/16:9/w_2399,h_1349,c_limit/Timnit-Gebru_MGL510-top.jpg', 'https://media.wired.com/photos/60be8e079731be96a5fef461/4:3/w_2400,h_1800,c_limit/Timnit-Gebru_MGL510-top.jpg', 'https://media.wired.com/photos/60be8e079731be96a5fef461/1:1/w_1089,h_1089,c_limit/Timnit-Gebru_MGL510-top.jpg']","[{'@type': 'Person', 'name': 'Tom Simonite', 'sameAs': 'https://www.wired.com/author/tom-simonite/'}]",tags,N/A,"Tom SimoniteThe Big StoryJun 8, 2021 6:00 AMWhat Really Happened When Google Ousted Timnit GebruShe was a star engineer who warned that messy AI can spread racism. Google brought her in. Then it forced her out. Can Big Tech take criticism from within?Photograph: Djeneba AduayomSave this storySaveSave this storySaveThe AI Database →ApplicationEthicsText analysisCompanyAlphabetGoogleEnd UserResearchSectorResearchTechnologyNatural language processingOne afternoon in late November of last year, Timnit Gebru was sitting on the couch in her San Francisco Bay Area home, crying.Most PopularThe Big StoryPriscila, Queen of the Rideshare MafiaBy Lauren Smiley, WIREDPoliticsThe Right Is Blaming Women and DEI for the Secret Service’s Failure in Trump ShootingBy David Gilbert, WIREDGearThe 29 Best Early Amazon Prime Day DealsBy Simon Hill, WIREDPoliticsTrump Shooting Conspiracies Are Coming From Every DirectionBy David Gilbert, WIREDThis article is exclusive to subscribers. Subscribe Now. If you're already a subscriber sign in.",,"Gebru, a researcher at Google, had just clicked out of a last-minute video meeting with an executive named Megan Kacholia, who had issued a jarring command. Gebru was the coleader of a group at the company that studies the social and ethical ramifications of artificial intelligence, and Kacholia had ordered Gebru to retract her latest research paper—or else remove her name from its list of authors, along with those of several other members of her team.
The paper in question was, in Gebru’s mind, pretty unobjectionable. It surveyed the known pitfalls of so-called large language models, a type of AI software—most famously exemplified by a system called GPT-3—that was stoking excitement in the tech industry. Google’s own version of the technology was now helping to power the company’s search engine. Jeff Dean, Google’s revered head of research, had encouraged Gebru to think about the approach’s possible downsides. The paper had sailed through the company’s internal review process and had been submitted to a prominent conference. But Kacholia now said that a group of product leaders and others inside the company had deemed the work unacceptable, Gebru recalls. Kacholia was vague about their objections but gave Gebru a week to act. Her firm deadline was the day after Thanksgiving.
Gebru’s distress turned to anger as that date drew closer and the situation turned weirder. Kacholia gave Gebru’s manager, Samy Bengio, a document listing the paper’s supposed flaws, but told him not to send it to Gebru, only to read it to her. On Thanksgiving Day, Gebru skipped some festivities with her family to hear Bengio’s recital. According to Gebru’s recollection and contemporaneous notes, the document didn’t offer specific edits but complained that the paper handled topics “casually” and painted too bleak a picture of the new technology. It also claimed that all of Google’s uses of large language models were “engineered to avoid” the pitfalls that the paper described.
Gebru spent Thanksgiving writing a six-page response, explaining her perspective on the paper and asking for guidance on how it might be revised instead of quashed. She titled her reply “Addressing Feedback from the Ether at Google,” because she still didn’t know who had set her Kafkaesque ordeal in motion, and sent it to Kacholia the next day.
On Saturday, Gebru set out on a preplanned cross-country road trip. She had reached New Mexico by Monday, when Kacholia emailed to ask for confirmation that the paper would either be withdrawn or cleansed of its Google affiliations. Gebru tweeted a cryptic reproach of “censorship and intimidation” against AI ethics researchers. Then, on Tuesday, she fired off two emails: one that sought to end the dispute, and another that escalated it beyond her wildest imaginings.
The first was addressed to Kacholia and offered her a deal: Gebru would remove herself from the paper if Google provided an account of who had reviewed the work and how, and established a more transparent review process for future research. If those conditions weren’t met, Gebru wrote, she would leave Google once she’d had time to make sure her team wouldn’t be too destabilized. The second email showed less corporate diplomacy. Addressed to a listserv for women who worked in Google Brain, the company’s most prominent AI lab and home to Gebru’s Ethical AI team, it accused the company of “silencing marginalized voices” and dismissed Google’s internal diversity programs as a waste of time.
Relaxing in an Airbnb in Austin, Texas, the following night, Gebru received a message with a 😮 from one of her direct reports: “You resigned??” In her personal inbox she then found an email from Kacholia, rejecting Gebru’s offer and casting her out of Google. “We cannot agree as you are requesting,” Kacholia wrote. “The end of your employment should happen faster than your email reflects.” Parts of Gebru’s email to the listserv, she went on, had shown “behavior inconsistent with the expectations of a Google manager.” Gebru tweeted that she had been fired. Google maintained—and still does—that she resigned.
Gebru’s tweet lit the fuse on a controversy that quickly inflamed Google. The company has been dogged in recent years by accusations from employees that it mistreats women and people of color, and from lawmakers that it wields unhealthy technological and economic power. Now Google had expelled a Black woman who was a prominent advocate for more diversity in tech, and who was seen as an important internal voice for greater restraint in the helter-­skelter race to develop and deploy AI. One Google machine-learning researcher who had followed Gebru’s writing and work on diversity felt the news of her departure like a punch to the gut. “It was like, oh, maybe things aren’t going to change so easily,” says the employee, who asked to remain anonymous because they were not authorized to speak by Google management.
Dean sent out a message urging Googlers to ignore Gebru’s call to disengage from corporate diversity exercises; Gebru’s paper had been subpar, he said, and she and her collaborators had not followed the proper approval process. In turn, Gebru claimed in tweets and interviews that she’d been felled by a toxic cocktail of racism, sexism, and censorship. Sympathy for Gebru’s account grew as the disputed paper circulated like samizdat among AI researchers, many of whom found it neither controversial nor particularly remarkable. Thousands of Googlers and outside AI experts signed a public letter castigating the company.
But Google seemed to double down. Margaret Mitchell, the other coleader of the Ethical AI team and a prominent researcher in her own right, was among the hardest hit by Gebru’s ouster. The two had been a professional and emotional tag team, building up their group—which was one of several that worked on what Google called “responsible AI”—while parrying the sexist and racist tendencies they saw at large in the company’s culture. Confident that those same forces had played a role in Gebru’s downfall, Mitchell wrote an automated script to retrieve notes she’d kept in her corporate Gmail account that documented allegedly discriminatory incidents, according to sources inside Google. On January 20, Google said Mitchell had triggered an internal security system and had been suspended. On February 19, she was fired, with Google stating that it had found “multiple violations of our code of conduct, as well as of our security policies, which included exfiltration of confidential, business-­sensitive documents.”
Google had now fully decapitated its own Ethical AI research group. The long, spectacular fallout from that Thanksgiving ultimatum to Gebru left countless bystanders wondering: Had one paper really precipitated all of these events?
The story of what actually happened in the lead-up to Gebru’s exit from Google reveals a more tortured and complex backdrop. It’s the tale of a gifted engineer who was swept up in the AI revolution before she became one of its biggest critics, a refugee who worked her way to the center of the tech industry and became determined to reform it. It’s also about a company—the world’s fifth largest—trying to regain its equilibrium after four years of scandals, controversies, and mutinies, but doing so in ways that unbalanced the ship even further.
Beyond Google, the fate of Timnit Gebru lays bare something even larger: the tensions inherent in an industry’s efforts to research the downsides of its favorite technology. In traditional sectors such as chemicals or mining, researchers who study toxicity or pollution on the corporate dime are viewed skeptically by independent experts. But in the young realm of people studying the potential harms of AI, corporate researchers are central.
Gebru’s career mirrored the rapid rise of AI fairness research, and also some of its paradoxes. Almost as soon as the field sprang up, it quickly attracted eager support from giants like Google, which sponsored conferences, handed out grants, and hired the domain’s most prominent experts. Now Gebru’s sudden ejection made her and others wonder if this research, in its domesticated form, had always been doomed to a short leash. To researchers, it sent a dangerous message: AI is largely unregulated and only getting more powerful and ubiquitous, and insiders who are forthright in studying its social harms do so at the risk of exile.
At the time, Gebru lived with her mother, an economist, in the Ethiopian capital of Addis Ababa. Her father, an electrical engineer with a PhD, had died when she was small. Gebru enjoyed school and hanging out in cafés when she and her friends could scrape together enough pocket money. But the war changed all that. Gebru’s family was Eritrean, and some of her relatives were being deported to Eritrea and conscripted to fight against the country they had made their home.
Gebru’s mother had a visa for the United States, where Gebru’s older sisters, engineers like their father, had lived for years. But when Gebru applied for a visa, she was denied. So she went to Ireland instead, joining one of her sisters, who was there temporarily for work, while her mother went to America alone.
Reaching Ireland may have saved Gebru’s life, but it also shattered it. She called her mother and begged to be sent back to Ethiopia. “I don’t care if it’s safe or not. I can’t live here,” she said. Her new school, the culture, even the weather were alienating. Addis Ababa’s rainy season is staccato, with heavy downpours interspersed by sunshine. In Ireland, rain fell steadily for a week. As she took on the teenage challenges of new classes and bullying, larger concerns pressed down. “Am I going to be reunited with my family? What happens if the paperwork doesn’t work out?” she recalls thinking. “I felt unwanted.”
The next year, Gebru was approved to come to the US as a refugee. She reunited with her mother in Somerville, Massa­chusetts, a predominantly white suburb of Boston, where she enrolled in the local public high school—and a crash course in American racism.
Some of her teachers, Gebru found, seemed unable or unwilling to accept that an African refugee might be a top student in math and science. Other white Americans saw fit to confide in her their belief that African immigrants worked harder than African Americans, whom they saw as lazy. History class told an uplifting story about the Civil Rights Movement resolving America’s racial divisions, but that tale rang hollow. “I thought that cannot be true, because I’m seeing it in the school,” Gebru says.
Piano lessons helped provide a space where she could breathe. Gebru also coped by turning to math, physics, and her family. She enjoyed technical work, not just for its beauty but because it was a realm disconnected from personal politics or worries about the war back home. That compartmentalization became part of Gebru’s way of navigating the world. “What I had under my control was that I could go to class and focus on the work,” she says.
Gebru’s focus paid off. In September 2001 she enrolled at Stanford. Naturally, she chose the family major, electrical engineering, and before long her trajectory began to embody the Silicon Valley archetype of the immigrant trailblazer. For a course during her junior year, Gebru built an experimental electronic piano key, helping her win an internship at Apple making audio circuitry for Mac computers and other products. The next year she went to work for the company full-time while continuing her studies at Stanford.
At Apple, Gebru thrived. When Niel Warren, her manager, needed someone to dig into delta-sigma modulators, a class of analog-to-digital converters, Gebru volunteered, investigating whether the technology would work in the iPhone. “As an electrical engineer she was fearless,” Warren says. He found his new hardware hotshot to be well liked, always ready with a hug, and determined outside of work too. In 2008, Gebru withdrew from one of her classes because she was devoting so much time to canvassing for Barack Obama in Nevada and Colorado, where many doors were slammed in her face.
As Gebru learned more about the guts of gadgets like the iPhone, she became more interested in the fundamental physics of their components—and soon her interests wandered even further, beyond the confines of electrical engineering. By 2011, she was embarking on a PhD at Stanford, drifting among classes and searching for a new direction. She found it in computer vision, the art of making software that can interpret images.
Unbeknownst to her, Gebru now stood on the cusp of a revolution that would transform the tech industry in ways she would later criticize. One of Gebru’s favorite classes involved creating code that could detect human figures in photos. “I wasn’t thinking about surveillance,” Gebru says. “I just found it technically interesting.”
In 2013 she joined the lab of Fei-Fei Li, a computer vision specialist who had helped spur the tech industry’s obsession with AI, and who would later work for a time at Google. Li had created a project called ImageNet that paid contractors small sums to tag a billion images scraped from the web with descriptions of their contents—cat, coffee cup, cello. The final database, some 15 million images, helped to reinvent machine learning, an AI technique that involves training software to get better at performing a task by feeding it examples of correct answers. Li’s work demonstrated that an approach known as deep learning, fueled by a large collection of training data and powerful computer chips, could produce much more accurate machine-vision technology than prior methods had yielded.
Li wanted to use deep learning to give computers a more fine-grained understanding of the world. Two of her students had scraped 50 million images from Google Street View, planning to train a neural network to spot cars and identify their make and model. But they began wondering about other applications they might build on top of that capability. If you drew correlations between census data and the cars visible on a street, could that provide a way to estimate the demographic or economic characteristics of any neighborhood, just from pictures?
Gebru spent the next few years showing that, to a certain level of accuracy, the answer was yes. She and her collaborators used online contractors and car experts recruited on Craigslist to identify the make and model of 70,000 cars in a sample of Street View images. The annotated pictures provided the training data needed for deep-learning algorithms to figure out how to identify cars in new images. Then they processed the full Street View collection and identified 22 million cars in photos from 200 US cities. When Gebru correlated those observations with census and crime data, her results showed that more pickup trucks and VWs indicated more white residents, more Buicks and Oldsmobiles indicated more Black ones, and more vans corresponded to higher crime.
This demonstration of AI’s power positioned Gebru for a lucrative career in Silicon Valley. Deep learning was all the rage, powering the industry’s latest products (smart speakers) and its future aspirations (self-driving cars). Companies were spending millions to acquire deep-­learning technology and talent, and Google was placing some of the biggest bets of all. Its subsidiary DeepMind had recently celebrated the victory of its machine-learning bot over a human world champion at Go, a moment that many took to symbolize the future relationship between humans and technology.
Gebru’s project fit in with what was becoming the industry’s new philosophy: Algorithms would soon automate away any problem, no matter how messy. But as Gebru got closer to graduation, the boundary she had established between her technical work and her personal values started to crumble in ways that complicated her feelings about the algorithmic future.
Gebru had maintained a fairly steady interest in social justice issues as a grad student. She wrote in The Stanford Daily about an incident in which an acquaintance wondered aloud whether Gebru was “actually smart” or had been admitted due to affirmative action. At Stanford’s graduate school, Gebru encountered a significantly less diverse student population than she had during her undergraduate years, and she felt isolated. She bonded with people who, like her, had experienced global inequality firsthand. “Once you’ve seen the world in terms of its injustice and the ways in which the United States is not always the answer to everybody’s problems, it’s very difficult to unsee,” says Jess Auerbach, a student from South Africa who became friends with Gebru at Stanford, and who is now an anthropologist at North West University in South Africa.
In 2016, Gebru volunteered to work on a coding program for bright young people in Ethiopia, which sent her on a trip back home, only her second since she had fled at the age of 15. Her coding students’ struggles, she felt, exposed the limits of US meritocracy. One promising kid couldn’t afford the roughly $100 required to take the SAT. After Gebru paid the fee for him, he won a scholarship to MIT. She also pitched in to help students who had been denied visas despite having been accepted to US schools. “She tried all she could to help these kids,” says Jelani Nelson, the UC Berkeley professor who founded the program.
Li, Gebru’s adviser at Stanford, encouraged her to find a way to connect social justice and tech, the two pillars of her world­view. “It was obvious to an outsider, but I don’t think it was obvious to her, that actually there was a link between her true passion and her technical background,” Li says. Gebru was reluctant to forge that link, fearing in part that it would typecast her as a Black woman first and a technologist second.
But she also became more aware that technology can sometimes reflect or magnify society’s biases, rather than transcend them. In 2016, ProPublica reported that a recidivism-risk algorithm called COMPAS, used widely in courtrooms across the country, made more false predictions that Black people would reoffend than it did for white people (an analysis that was disputed by the company that made the algorithm). This made Gebru wonder whether the crime data she’d used in her own research reflected biased policing. Around the same time, she was introduced to Joy Buolamwini, a Ghanaian American MIT master’s student who had noticed that some algorithms designed to detect faces worked less well on Black people than they did on white people. Gebru began advising her on publishing her results.
It wasn’t just the algorithms or their training data that skewed white. In 2015, Gebru got her first glimpse of the worldwide community of AI researchers at the field’s top conference, Neural Information Processing Systems (NIPS), in Montreal. She noticed immediately how male and how white it was. At a Google party, she was intercepted by a group of strangers in Google Research T-shirts who treated the presence of a Black woman as a titillating photo op. One man grabbed her for a hug; another kissed her cheek and took a photo. At the next year’s conference, Gebru kept a tally of other Black people she met, counting just six among the 8,500 attendees—all people she already knew, and most of whom she’d already added to an email list she’d started for Black people in the field. After the event, Gebru posted a warning to AI researchers on Facebook about the dangers of their community’s lack of diversity. “I’m not worried about machines taking over the world, I’m worried about groupthink, insularity, and arrogance in the AI community,” she wrote. “If many are actively excluded from its creation, this technology will benefit a few while harming a great many.”
Gebru’s awakening roughly coincided with the emergence of a new research field dedicated to examining some of the social downsides of AI. It came to be centered on an annual academic workshop, first held in 2014, called Fairness, Accountability, and Transparency in Machine Learning (FATML) and motivated by concerns over institutional decisionmaking. If algorithms decided who received a loan or awaited trial in jail rather than at home, any errors they made could be life-changing.
The event’s creators initially found it difficult to convince peers that there was much to talk about. “The more predominant idea was that humans were biased and algorithms weren’t,” says Moritz Hardt, now a UC Berkeley computer science professor who cofounded the workshop with a researcher from Princeton. “People thought it was silly to work on this.”
By 2016 the event had grown into a meeting that sold out a hall at NYU School of Law. The audience included staffers from the Federal Trade Commission and the European Commission. Yet the presenters, by and large, applied a fairly detached and mathematical lens to the notion that technology could harm people. Researchers hashed out technical definitions of fairness that could be expressed in the form of code. There was less talk about how economic pressures or structural racism might shape AI systems, whom they work best for, and whom they harm.
Gebru didn’t attend the FATML workshop that year or the next—she was still mainly focused on building AI, not examining its potential for harm. In January 2017, at a one-day event centered on how AI could shake up finance, Gebru stood in a gray turtle­neck in a large octagonal room overlooking Stanford’s terracotta-roofed campus and presented the findings of her PhD thesis to members of Silicon Valley’s elite. She clicked through slides showing how algorithms could predict factors like household income and voting patterns just by identifying cars on the street.
Gebru was the only speaker who was not a professor, investment professional, or representative of a tech company, but, as one organizer recalls, her talk generated more interest than any of the others. Steve Jurvetson, a friend of Elon Musk and an early investor in Tesla, enthusiastically posted photos of her slides to Facebook. A longtime AI aficionado, he wasn’t surprised that machine-learning algorithms could identify specific cars. But the way Gebru had extracted signals about society from photos illustrated how the technology could spin gold from unexpected sources—at least for those with plenty of data to mine. “It was, ‘My God, think of all the data that Google has,’” Jurvetson says. “It made me realize the power of having the biggest data set.”
For Gebru, the event could have been a waypoint between her grad school AI work and a job building moneymaking algorithms for tech giants. But she decided that she wanted to help contain the technology’s power rather than expand it. In the summer of 2017, she took a job with a Microsoft research group that had been involved in the FATML movement from early on. Gebru wrote her pivot into the final chapter of her thesis: “One of the most important emergent issues plaguing our society today is that of algorithmic bias. Most works based on data mining, including my own works described in this thesis, suffer from this problem,” she wrote. Her plan for a career, she went on, was “to make contributions towards identifying and mitigating these issues.”
In 2015, Mitchell, an expert in software that generates language from images, was working on an app for blind people that spoke visual descriptions of the world. She had christened it Seeing AI, and she loved the idea that the flourishing power of machine learning could lift up society’s most vulnerable. But Microsoft didn’t seem willing to seriously invest in such projects at the time.
Mitchell also noticed some troubling gaffes in the machine-learning systems she was training. One would describe someone with pale skin, like the red-haired Mitchell, as a “person,” but a figure with dark skin as a “Black person.” In another test, an image of an inferno at an oil storage depot was captioned “great view.” She began to fear that AI was laced with land mines, and the industry was not paying enough attention to finding them. “Oh crap,” she remembers thinking. “There are serious issues that we have to solve right now because no one else is working on them and this technology is evolving.”
In 2016, Mitchell moved to Google to work full-time on those problems. The company appeared to be embracing this new, conscientious strand of AI research. A couple of weeks before she started, Google published its first research paper on machine-­learning fairness. It considered how to ensure that a system that makes predictions about ­people—say, assessing their risk of defaulting on a loan—offered equal treatment to individuals regardless of their gender, race, religion, or other group identity. The company highlighted its research in a blog post for a general audience, and signed up, alongside Microsoft, as a corporate sponsor of the FATML workshop.
When Mitchell got to Google, she discovered a messier reality behind the company’s entrée into fairness research. That first paper had been held up for months by internal deliberations over whether Google should publicly venture into a discourse on the discriminatory potential of computer code, which to managers seemed more complex and sensitive than its labs’ usual output. Mitchell’s own first publication at the company, on making smile-detection algorithms perform well for people of different races and genders, also met with a degree of corporate hesitancy that didn’t seem to encumber more conventional AI projects. She chose to work on smiles in part because of their positive associations; still, she endured rounds of meetings with lawyers over how to handle discussions of gender and race.
At other times, Mitchell’s work inside Google faced little resistance, but also ­little enthusiasm. “It was like people really appreciated what I was saying, and then nothing happened,” she says. Still, Mitchell hadn’t expected to change the company overnight, and gradually her efforts gained momentum. In late 2017 she formed a small team dedicated to “ethical AI research” and embarked on a campaign of meetings with teams across Google to spread the word and offer help. This time people seemed more receptive—perhaps in part because broader attitudes were shifting. Some of Google’s rivals, like Microsoft, appeared to be taking AI fairness more seriously. Industry hype about AI was still intense, but the field’s culture was becoming more reflective.
One person driving that change was Timnit Gebru, who was introduced to Mitchell by an acquaintance over email when Gebru was about to join Microsoft. The two had become friendly, bonding over a shared desire to call out injustices in society and the tech industry. “Timnit and I hit it off immediately,” Mitchell says. “We got along on every dimension.”
Gebru was also hitting it off with others who wanted to work in AI but found themselves misunderstood by both people and algorithms. In December 2017, Inioluwa Deborah Raji, a young Nigerian-Canadian coder at an AI startup called Clarifai, stood in the lobby of the Long Beach Convention Center in a crowd of mostly white faces at that year’s NIPS conference. She was beginning to feel that working in AI was not for her. At Clarifai, Raji had helped to create a machine-learning system that detected photos containing nudity or violence. But her team discovered it was more likely to flag images of people of color, because they appeared more often in the pornography and other material they’d used as training data. “That really hit me,” Raji says. “I built this thing, and it was actively discriminatory in a way that hurt people of color.”
The NIPS conference provided a look at the world of AI beyond her startup, but Raji didn’t see people like herself onstage or in the crowded lobby. Then an Afroed figure waved from across the room. It was Gebru. She invited Raji to the inaugural Black in AI workshop, an event born out of Gebru’s email list for Black researchers. Raji changed her plane ticket to stay an extra day in Long Beach and attend.
The event mixed technical presentations by Black researchers with networking and speeches on how to make AI more welcoming. Mitchell ran support for remote participants joining by video chat. At the post-event dinner, on the cruise ship Queen Mary, permanently docked in Long Beach, Gebru, Raji, and other Black AI researchers mingled and danced with big names from Amazon and Google.
Other events at NIPS that year had made the hype-saturated world of AI research appear seamy and elitist. Intel threw a corporate party that featured provocatively dressed women performing acrobatics, and Elon Musk made an anatomical joke about the conference’s acronym. NIPS organizers released a “statement on inappropriate behavior,” promising tougher policies for attendees and sponsors. (They also ended up changing the event’s acronym, in due course, to NeurIPS.)
At the Black in AI event, by contrast, there was an atmosphere of friendship and new beginnings. People spoke openly and directly about the social and political tensions hidden beneath the technical veneer of AI research. Raji started to think she could work in the field after all. Jeff Dean, the storied Googler who had cofounded the Google Brain research group, posed for selfies with attendees. He and another top Google Brain researcher, Samy Bengio, got talking with Gebru and suggested she think about joining their group.
Gebru’s research was also helping to make work on AI fairness less academic and more urgent. In February 2018, as part of a project called Gender Shades, she and Buolamwini published evidence that services offered by companies including IBM and Microsoft that attempted to detect the gender of faces in photos were nearly perfect at recognizing white men, but highly inaccurate for Black women. The problem appeared to be rooted in the fact that photos scraped from the web to train facial-­recognition systems overrepresented men as well as white and Western people, who had more access to the internet.
The project was a visceral demonstration of how AI could perpetuate social injustices—and of how research like Gebru’s could hold companies like her own employer to account. IBM and Microsoft both issued contrite statements. Gebru had not informed her bosses of Microsoft’s inclusion in the Gender Shades project much in advance, but Microsoft’s research division was known for being kept relatively isolated from the business in order to give its researchers freedom. A product manager quizzed her about the study, but that was it. The lab promoted a New York Times write-up of the project on its homepage, with a photo of Gebru over the newspaper’s headline: “Facial Recognition Is Accurate, If You’re a White Guy.”
Gebru’s primary research project at Microsoft contrasted her experience as an electrical engineer with the working habits of machine-learning experts. At Apple, Gebru and her coworkers had studied standardized data sheets detailing the properties of every component they considered adding to a gadget like the iPhone. AI had no equivalent culture of rigor around the data used to prime machine-learning algorithms. Programmers generally grabbed the most easily available data they could find, believing that larger data sets meant better results.
Gebru and her collaborators called out this mindset, pointing to her study with Buolamwini as evidence that being lax with data could infest machine-learning systems with biases. Gebru’s new paper proposed a framework called Datasheets for Datasets, in which AI engineers would document the patterns and contents of their data to avoid nasty surprises later. The project treated AI systems as artifacts whose creators should be held to standards of responsibility. “For the first time it gave some structure in my mind about how to think about implementing fairness,” says Krishna Gade, who led a team developing machine learning for Facebook’s News Feed before founding Fiddler Labs, which creates AI transparency tools.
The Datasheets project bolstered Gebru’s prominence in the movement to scrutinize the ethics and fairness of AI. Mitchell asked her to think about joining her Ethical AI team at Google.
Some people warned Gebru about joining the company. While she was interviewing, Google employees were pressuring their leaders to abandon a Pentagon contract known as Project Maven, which would use machine learning to analyze military drone surveillance footage. Gebru signed a letter with more than 1,000 other researchers urging the company to withdraw. Her uncomfortable experience at the 2015 Google party in Montreal preyed on her mind, and multiple women who had worked at Google Brain told her that the company was hostile to women and people of color, and resistant to change.
Gebru considered walking away from the job offer, until Mitchell offered to make her colead of the Ethical AI team. They would share the burden and the limelight in hopes that together they could nudge Google in a more conscientious direction. Gebru reasoned that she could stick close to Mitchell and keep her head down. “I thought, OK, I can do my work and be careful who I collaborate with, and try to ignore some of the other things,” she says. “My number one concern was: Can I survive in this environment?”
Gebru joined a discussion about the protest on an internal email list called Brain Women and Allies. She pointed out some problems she’d noticed at her new workplace, including “toxic men” and a lack of women in senior positions. She was summoned to a brief meeting with Dean—now her boss’s boss—and a representative from human resources to discuss her observations.
Soon after, Gebru met with Dean again, this time with Mitchell at her side, for another discussion about the situation of women at Google. They planned a lunch meeting, but by the time the appointment rolled around, the two women were too anxious to eat. Mitchell alleged that she had been held back from promotions and raises by performance reviews that unfairly branded her as uncollaborative. Gebru asserted that a male researcher with less experience than her had recently joined Google Brain at a more senior level. Dean said he’d look into the pair’s claims. Gebru was promoted; Dean told her that the hiring committee had not previously seen all parts of her résumé, an explanation she found dubious. After more back and forth over Mitchell’s position, Dean let her switch supervisors.
Gebru and Mitchell’s work didn’t fit easily into Google’s culture, either. The women and their team were a relatively new breed of tech worker: the in-house ethical quibbler. After the dustup at Google over Project Maven, and in the wake of research like Buolamwini and Gebru’s, tech giants began trumpeting lofty corporate commitments to practice restraint in their AI projects. After Google said it would not renew its controversial Pentagon contract, it announced a set of seven principles that would guide its AI work. Among them: AI projects had to be “socially beneficial” and could not relate to weapons or surveillance (though other defense work was still permitted). Microsoft posted six AI principles that were less specific, including “inclusiveness” and “accountability.” Both companies created internal review processes for cloud computing deals that they said would weed out unethical projects. In 2016, Microsoft and Google were the only corporate sponsors of the FATML workshop; in 2019, they were joined by Google’s Alphabet sibling DeepMind, as well as Spotify and Twitter, as sponsors of an entire conference that had in part grown out of the FATML workshop. Gebru was one of its organizers.
Despite those changes, it remained unclear to some of the in-house quibblers how, exactly, they would or could change Google. The Ethical AI team’s primary job was to conduct research, but Mitchell also wanted the group to shape the company’s products, which touched billions of lives. Indifference and a lack of support, however, sometimes stood in their way. In some cases, Mitchell herself wrote code for product teams that wanted to implement AI safeguards, because engineering resources weren’t regularly made available for their kind of work.
So the Ethical AI team hustled, figuring out ways to get traction for their ideas and sometimes staging interventions. In one case, they noticed problems in Gmail’s Smart Reply feature, which suggests short responses to emails: It made gendered assumptions, such as defaulting to “he” if a message included mention of an engineer. A member of the Ethical AI team met with an engineer on the project for a quiet chat. That helped set off a series of conversations, and the feature was adjusted to no longer use gendered pronouns.
Mitchell also developed a playbook for turning ethical AI itself into a kind of product, making it more palatable to Google’s engineering culture, which prized launches of new tools and features. In January 2019, Mitchell, Gebru, and seven collaborators introduced a system for cataloging the performance limits of different algorithms. The method, which built on Gebru’s earlier work documenting the contents and blind spots of data sets, noted the conditions under which algorithms were most likely to return accurate results and where they were likely to falter. Mitchell’s team named the concept Model Cards, to make it sound generic and neutral, and shopped it around to other teams inside the company. The cloud computing division adopted Model Cards, using them as a form of disclosure, like a nutrition label, to show the public how well, say, Google’s facial detection algorithm performs on different kinds of images.
On at least one occasion, the Ethical AI team also helped convince Google to limit its AI in ways that ceded potential revenue to competitors. Microsoft and Amazon had for years offered face-­recognition services that could be used for more or less anything, including law enforcement. With the Ethical AI team’s help, Google launched a limited service that just recognized public figures and was offered only to customers in the media after careful vetting.
Mitchell and Gebru believed their successes derived in part from the fact that their team provided refuge from Google’s internal culture, which they and some other researchers found hostile, territorial, and intensely hierarchical. The dozen or so people on the Ethical AI team took pride in being more diverse in terms of gender, race, and academic background than the rest of the company. Gebru fondly thought of them as misfits and believed that diversity made the group more likely to spot problems or opportunities that Google’s largely white male workers might overlook. Gebru and Mitchell also successfully lobbied executives to allow them to bring in sociologists and anthropologists—not just the usual computer science PhDs. “A lot of people in our team would either not be at Google or maybe even in the tech industry if they didn’t join,” Gebru says.
Over time, the team seemed to show how corporate quibblers could succeed. Google’s Ethical AI group won respect from academics and helped persuade the company to limit its AI technology. Gebru and Mitchell both reported to Samy Bengio, the veteran Google Brain researcher, whom they came to consider an ally. The company had built up a handful of other teams working on AI guardrails, including in the research and global affairs divisions, but they were tied more closely to the company’s business priorities. The Ethical AI team was more independent and wide-ranging. When Mitchell started at Google, the field mainly took a narrow, technical approach to fairness. Now it increasingly asked more encompassing questions about how AI replicated or worsened social inequalities, or whether some AI technology should be placed off-limits. In addition to creating handy tools for engineers, members of the team published papers urging AI researchers to draw on critical race theory and reconsider the tech industry’s obsession with building systems to achieve mass scale.
At the same time, however, Mitchell and Gebru’s frustrations with Google’s broader culture mounted. The two women say they were worn down by the occasional flagrantly sexist or racist incident, but more so by a pervasive sense that they were being isolated. They noticed that they were left out of meetings and off email threads, or denied credit when their work made an impact. Mitchell developed an appropriately statistical way of understanding the phenomenon. “What is the likelihood that I will not be invited to a meeting that I should be at? What is the likelihood that my male colleague will be invited? You start to see the trends,” she says.
Together, the two women joined and sometimes led attempts to change Google’s culture. In 2019, with two others, they circulated a pointed internal document listing concerns about the treatment of women in Google’s research teams. Women were treated as “punching bags,” the document asserted, and senior managers dismissed observations about inequality as “temper tantrums.” Mitchell disseminated a chart explaining how to support marginalized groups at work, including checklist items like “Did you listen to their answer and respond with empathy?”
Gebru was the more outspoken of the two—usually because she felt, as a Black woman, that she had to be. She admits that this won her enemies. She dismissed as backward diversity programs that placed an emphasis on mentoring for women: The company’s problems, she would say, were rooted in its culture and leadership, not in the marginalized workers. Gebru’s willingness to speak up sometimes led to blowups. In one incident, she and another woman warned Dean that a male researcher at Google had previously been accused of sexual harassment. Managers did not appear to act until the man was accused of harassing multiple people at Google, after which he was fired. The man’s lawyers then sent Google a letter in which they accused Gebru and the other woman of defaming him. Google lawyers in turn advised the pair to hire their own counsel. Gebru and her coworker did so, and their own lawyers warned Google that it had a duty to represent its employees. After that expensive pushback, the two women didn’t hear more about the issue. (Google did not respond to a request for comment on the incident, but told Bloomberg it began an investigation immediately after receiving reports about the man and that he departed before the investigation concluded.)
Some Googlers chafed at Gebru’s willingness to confront colleagues. “Timnit’s behavior was very far outside the norm,” says one researcher at Google who was not authorized to speak to the press. The researcher recalls an incident in the summer of 2020, during the wave of Black Lives Matter protests, when Gebru got into a dispute on an internal mailing list dedicated to discussing new AI research papers. A male colleague posted a short, enthusiastic message about a new text­-generation system that had just been opened up for commercial use. Gebru, acutely conscious of the demonstrations roaring across America, replied to highlight a warning from a prominent woman in the field that such systems were known to sometimes spew racist and sexist language. Other researchers then replied to the initial post without mentioning Gebru’s comment. Gebru called them out for ignoring her, saying it was a common and toxic pattern, and she says one man privately messaged her to say he wasn’t surprised she got harassed online. A hot-tempered debate ensued over racism and sexism in the workplace.
According to the Google employee, the incident—which is also described in anonymous posts on Reddit—showed how Gebru’s demeanor could make some ­people shy away from her or avoid certain technical topics for fear of being pulled into arguments about race and gender politics. Gebru doesn’t deny that the dispute became heated but says it ultimately proved productive, forcing attention to her negative experiences and those of other women at Google.
Dean raised a polite chuckle when he explained that the new system was called Bidirectional Encoder Representations from Transformers, but was generally known by a name borrowed from Sesame Street: BERT. It was an example of a new type of machine-learning system known as a large language model, enabled by advances that made it practical for algorithms to train themselves on larger volumes of text, generally scraped from the web. That broader sampling allowed models like BERT to better internalize statistical patterns of language use, making them better than previous technology at tasks like answering questions or detecting whether a movie review was positive or negative.
When a reporter asked whether BERT would also learn, say, sexist language patterns, Dean responded, “This is something that we definitely look at for all the machine-learning-related product launches and also in our own research,” citing the work of people like Mitchell and Gebru. “We want to make sure that our use of machine learning is free of unfair forms of bias.” The Q&A also revealed that Google had other reasons to value BERT. When another journalist asked if it was being used by Google’s ads team, one of the search executives replied, “I’m sure they must be applying it.”
In the months that followed, excitement grew around large language models. In June 2020, OpenAI, an independent AI institute cofounded by Elon Musk but now bankrolled by a billion dollars from Microsoft, won a splurge of media coverage with a system called GPT-3. It had ingested more training data than BERT and could generate impressively fluid text in genres spanning sonnets, jokes, and computer code. Some investors and entrepreneurs predicted that automated writing would reinvent marketing, journalism, and art.
These new systems could also become fluent in unsavory language patterns, coursing with sexism, racism, or the tropes of ISIS propaganda. Training them required huge collections of text—BERT used 3.3 billion words and GPT-3 almost half a trillion—which engineers slurped from the web, the most readily available source with the necessary scale. But the data sets were so large that sanitizing them, or even knowing what they contained, was too daunting a task. It was an extreme example of the problem Gebru had warned against with her Datasheets for Datasets project.
Inside Google, researchers worked to build more powerful successors to BERT and GPT-3. Separately, the Ethical AI team began researching the technology’s possible downsides. Then, in September 2020, Gebru and Mitchell learned that 40 Googlers had met to discuss the technology’s future. No one from Gebru’s team had been invited, though two other “responsible AI” teams did attend. There was a discussion of ethics, but it was led by a product manager, not a researcher.
That same month, Gebru sent a message to Emily M. Bender, a professor of linguistics at the University of Washington, to ask if she had written anything about the ethical questions raised by these new language models. Bender had not, and the pair decided to collaborate. Bender brought in a grad student, and Gebru looped in Mitchell and three other members of her Google team.
The resulting paper was titled “On the Dangers of Stochastic Parrots: Can Language Models Be Too Big? 🦜” The whimsical title styled the software as a statistical mimic that, like a real parrot, doesn’t know the implications of the bad language it repeats.
The paper was not intended to be a bombshell. The authors did not present new experimental results. Instead, they cited previous studies about ethical questions raised by large language models, including about the energy consumed by the tens or even thousands of powerful processors required when training such software, and the challenges of documenting potential biases in the vast data sets they were made with. BERT, Google’s system, was mentioned more than a dozen times, but so was OpenAI’s GPT-3. Mitchell considered the project worthwhile but figured it would come across as boring. An academic who saw the paper after it was submitted for publication found the document “middle of the road.”
Plenty of people inside Google knew about the paper early on, including Dean. In October, he wrote in a glowing annual review that Gebru should work with other teams on developing techniques to make machine-learning software for language processing “consistent with our AI Principles.” In her reply, she told him about the paper she was drafting with Bender and others. Dean wrote back: “Definitely not my area of expertise, but would definitely learn from reading it.” Gebru also informed Google’s communications department about the project and mentioned it to Marian Croak, a Black engineering executive on Google’s Advanced Technology Review Council, an internal review panel that was added after the Maven protests. Croak said the paper sounded interesting and asked Gebru to send her a copy. But Gebru never got the chance before the fatal controversy over “Stochastic Parrots” erupted.
It’s not clear exactly who decided that Gebru’s paper had to be quashed or for what reason. Nor is it clear why her resistance—predictable as it was—prompted a snap decision to eject her, despite the clear risk of public fallout. Other researchers at Google say it isn’t unusual for publications about AI to trigger internal corporate sensitivities before public release, but that researchers can usually work through managers’ objections. Gebru, with her track record of rattling management about Google’s diversity and AI ethics problems, got little such opportunity. One reason managers were not more open in explaining their feedback to Gebru, according to Google, was that they feared she would spread it around inside the company. Those fears may have been compounded when Gebru took to an internal listserv to criticize Google for “silencing marginalized voices,” even as she offered to kill her own paper in exchange for greater transparency.
On the night of her forced exit from Google, in early December, members of Gebru’s team joined a tearful Google Meet video call that lasted until early the next morning. In normal times, they might have hugged and huddled in a bar or someone’s home; in a pandemic they sniffled alone over their laptops. Two weeks later, the remaining team members sent an email to Google CEO Sundar Pichai demanding an apology and several changes, including Gebru’s­ reinstate­ment (and Kacholia’s ­reassignment). Mitchell’s firing two months later brought new pain. She hired lawyers who blasted out a press release saying she had been fired after “raising concerns of race and gender equity at Google.”
Dean became the face of Google’s displeasure with the “Stochastic Parrots” paper. He sent an email to the members of Google Research, also released publicly, saying the work “didn’t meet our bar for publication,” in part because one of its eight sections didn’t cite newer work showing that large language models could be made less energy-­hungry. Dean repeated the point so often inside Google that some researchers joked that “I have an objection to Parrots section three” would be inscribed on his tombstone. The complaint made little sense to many AI researchers, who knew that grumbles about citations typically end with authors revising a paper, not getting terminated. Dean’s argument suffered another blow when reviewers accepted the paper to the conference on fairness and technology.
Others, including Gebru, offered a different explanation from Dean’s: Google had used an opaque internal process to suppress work critical of a technology that had commercial potential. “The closer the research started getting to search and ads, the more resistance there was,” one Google employee with experience of the company’s research review process says. “Those are the oldest and most entrenched organizations with the most power.” Still others surmised that Gebru was the casualty of a different kind of turf battle: that other internal groups working on responsible AI—ones with closer relationships to Google’s product teams—felt that Gebru and her coauthors were encroaching where they didn’t belong.
Some Google employees, including David Baker, a director who’d been at the company for 16 years, publicly quit over its treatment of Gebru. Google’s research department was riven by mistrust and rumors about what happened and what might happen next. Even people who believed Gebru had behaved in ways unbecoming of a corporate researcher saw Google’s response as ham-handed. Some researchers feared their work would now be policed more closely. One of them, Nicholas Carlini, sent a long internal email complaining of changes that company lawyers made to another paper involving large language models, published after Gebru was fired, likening the intervention to “Big Brother stepping in.” The changes downplayed the problems the paper reported and removed references to Google’s own technology, the email said.
Soon after, Google rolled out its response to the roiling scandal and sketched out a more locked-down future for in-house research probing AI’s power. Marian Croak, the executive who had shown interest in Gebru’s work, was given the task of consolidating the various teams working on what the company called responsible AI, including Mitchell and Gebru’s. Dean sent around an email announcing that a review of Gebru’s ouster had concluded; he was sorry, he said, that the company had not “handled this situation with more sensitivity.”
Dean also announced that progress on improving workforce diversity would now be considered in top executives’ performance reviews—perhaps quietly conceding Gebru’s assertion that leaders were not held accountable for their poor showing on this count. And he informed researchers that they would be given firmer guidance on “Google’s research goals and priorities.” A Google source later explained that this meant future projects touching on sensitive or commercial topics would require more input from in-house legal experts, product teams, and others within Google who had relevant expertise. The outlook for open-minded, independent research on ethical AI appeared gloomy. Google claimed that it still had hundreds of people working on responsible AI, and that it would expand those teams; the company painted Gebru and Mitchell’s group as a tiny and relatively unimportant cog in a big machine. But others at Google said the Ethical AI leaders and their frank feedback would be missed. “For me, it’s the most critical voices that are the most important and where I have learned the most,” says one person who worked on product changes with Gebru and Mitchell’s input. Bengio, the women’s manager, turned his back on 14 years of working on AI at Google and quit to join Apple.
Outside of Google, nine Democrats in Congress wrote to Pichai questioning his commitment to preventing AI’s harms. Mitchell had at one point tried to save the “Stochastic Parrots” paper by telling executives that publishing it would bolster arguments that the company was capable of self-policing. Quashing it was now undermining those arguments.
Some academics announced that they had backed away from company events or funding. The fairness and technology conference’s organizers stripped Google of its status as a sponsor of the event. Luke Stark, who studies the social impacts of AI at the University of Western Ontario, turned down a $60,000 grant from Google in protest of its treatment of the Ethical AI team. When he applied for the money in December 2020, he had considered the team a “strong example” of how corporate researchers could do powerful work. Now he wanted nothing to do with Google. Tensions built into the field of AI ethics, he saw, were beginning to cause fractures.
“The big tech companies tried to steal a march on regulators and public criticism by embracing the idea of AI ethics,” Stark says. But as the research matured, it raised bigger questions. “Companies became less able to coexist with internal critical research,” he says. One person who runs an ethical AI team at another tech company agrees. “Google and most places did not count on the field becoming what it did.”
To some, the drama at Google suggested that researchers on corporate payrolls should be subject to different rules than those from institutions not seeking to profit from AI. In April, some founding editors of a new journal of AI ethics published a paper calling for industry researchers to disclose who vetted their work and how, and for whistle-blowing mechanisms to be set up inside corporate labs. “We had been trying to poke on this issue already, but when Timnit got fired it catapulted into a more mainstream conversation,” says Savannah Thais, a researcher at Princeton on the journal’s board who contributed to the paper. “Now a lot more people are questioning: Is it possible to do good ethics research in a corporate AI setting?”
If that mindset takes hold, in-house ethical AI research may forever be held in suspicion—much the way industrial research on pollution is viewed by environmental scientists. Jeff Dean admitted in a May interview with CNET that the company had suffered a real “reputational hit” among people interested in AI ethics work. The rest of the interview dealt mainly with promoting Google’s annual developer conference, where it was soon announced that large language models, the subject of Gebru’s fateful critique, would play a more central role in Google search and the company’s voice assistant. Meredith Whittaker, faculty director of New York University’s AI Now Institute, predicts that there will be a clearer split between work done at institutions like her own and work done inside tech companies. “What Google just said to anyone who wants to do this critical research is, ‘We’re not going to tolerate it,’” she says. (Whittaker herself once worked at Google, where she clashed with management over AI ethics and the Maven Pentagon contract before leaving in 2019.)
Any such divide is unlikely to be neat, given how the field of AI ethics sprouted in a tech industry hothouse. The community is still small, and jobs outside big companies are sparser and much less well paid, particularly for candidates without computer science PhDs. That’s in part because AI ethics straddles the established boundaries of academic departments. Government and philanthropic funding is no match for corporate purses, and few institutions can rustle up the data and computing power needed to match work from companies like Google.
For Gebru and her fellow travelers, the past five years have been vertiginous. For a time, the period seemed revolutionary: Tech companies were proactively exploring flaws in AI, their latest moneymaking marvel—a sharp contrast to how they’d faced up to problems like spam and social network moderation only after coming under external pressure. But now it appeared that not much had changed after all, even if many individuals had good intentions.
Inioluwa Deborah Raji, whom Gebru escorted to Black in AI in 2017, and who now works as a fellow at the Mozilla Foundation, says that Google’s treatment of its own researchers demands a permanent shift in perceptions. “There was this hope that some level of self-regulation could have happened at these tech companies,” Raji says. “Everyone’s now aware that the true accountability needs to come from the outside—if you’re on the inside, there’s a limit to how much you can protect people.”
Gebru, who recently returned home after her unexpectedly eventful road trip, has come to a similar conclusion. She’s raising money to launch an independent research institute modeled on her work on Google’s Ethical AI team and her experience in Black in AI. “We need more support for external work so that the choice is not ‘Do I get paid by the DOD or by Google?’” she says.
Gebru has had offers, but she can’t imagine working within the industry anytime in the near future. She’s been thinking back to conversations she’d had with a friend who warned her not to join Google, saying it was harmful to women and impossible to change. Gebru had disagreed, claiming she could nudge things, just a little, toward a more beneficial path. “I kept on arguing with her,” Gebru says. Now, she says, she concedes the point.

This article appears in the July/August 2021 issue. Subscribe now.
Let us know what you think about this article. Submit a letter to the editor at mail@wired.com.",,the big story,What Really Happened When Google Ousted Timnit Gebru,"https://media.wired.com/photos/60be8e079731be96a5fef461/1:1/w_1089,h_1089,c_limit/Timnit-Gebru_MGL510-top.jpg","{'@type': 'CreativeWork', 'name': 'WIRED'}",True,She was a star engineer who warned that messy AI can spread racism. Google brought her in. Then it forced her out. Can Big Tech take criticism from within?,"[{'@type': 'ListItem', 'position': 1, 'name': 'The Big Story', 'item': 'https://www.wired.com/big-story/'}, {'@type': 'ListItem', 'position': 2, 'name': 'Cover Story', 'item': 'https://www.wired.com/tag/cover-story/'}, {'@type': 'ListItem', 'position': 3, 'name': 'What Really Happened When Google Ousted Timnit Gebru'}]",,,,,,,
https://news.google.com/rss/articles/CBMieGh0dHBzOi8vd3d3Lm9nai5jb20vZHJpbGxpbmctcHJvZHVjdGlvbi9hcnRpY2xlLzE0MjA1MTkwL2FydGlmaWNpYWwtaW50ZWxsaWdlbmNlLWluY3JlYXNlcy1kcmlsbGluZy1lZmZpY2llbmN5LWNlcnRhaW50edIBAA?oc=5,"Artificial intelligence increases drilling efficiency, certainty - Oil & Gas Journal",2021-06-07,Oil & Gas Journal,https://www.ogj.com,Ivan KozakPedro AlcalaBoston Consulting GroupHoustonFerrante BenvenutiLorenzo VeronelliBoston Consulting GroupMilanAn artificial intelligence-driven drilling approach allowed ...,N/A,Ivan KozakPedro AlcalaBoston Consulting GroupHoustonFerrante BenvenutiLorenzo VeronelliBoston Consulting GroupMilanAn artificial intelligence-driven drilling approach allowed ...,Ivan KozakPedro AlcalaBoston Consulting GroupHoustonFerrante BenvenutiLorenzo VeronelliBoston Consulting GroupMilanAn artificial intelligence-driven drilling approach allowed ...,https://schema.org,NewsArticle,,"{'@type': 'Organization', 'name': 'Oil & Gas Journal', 'logo': {'@type': 'ImageObject', 'url': 'https://base.imgix.net/files/base/pennwell/ogj/logo.png', 'width': '', 'height': 45}}","{'@type': 'WebPage', '@id': 'https://www.ogj.com/drilling-production/article/14205190/artificial-intelligence-increases-drilling-efficiency-certainty'}",2021-06-07,,,,"['https://img.ogj.com/files/base/ebm/ogj/image/2021/06/210607OGJdik_p01_REV.60c7a826dec6a.png?auto=format%2Ccompress&w=320', 'https://img.ogj.com/files/base/ebm/ogj/image/2021/06/210607OGJdik_p02.60c7a828087a1.png?auto=format%2Ccompress&w=320', 'https://img.ogj.com/files/base/ebm/ogj/image/2021/06/210607OGJdik_p04.60c7a828e5c4c.png?auto=format%2Ccompress&w=320', 'https://img.ogj.com/files/base/ebm/ogj/image/2021/06/210607OGJdik_p06_REV.60c7a82a27e89.png?auto=format%2Ccompress&w=320', 'https://img.ogj.com/files/base/ebm/ogj/image/2021/06/210607OGJdik_p07.60c7a82aa8608.png?auto=format%2Ccompress&w=320', 'https://img.ogj.com/files/base/ebm/ogj/image/2021/06/210607OGJdik_p08.60c7a82bc3ca0.png?auto=format%2Ccompress&w=320', 'https://img.ogj.com/files/base/ebm/ogj/image/2021/06/210607OGJdik_p09.60c7a82dafb59.png?auto=format%2Ccompress&w=320', 'https://img.ogj.com/files/base/ebm/ogj/image/2021/06/210607OGJdik_z03.60c7a832c9f6d.png?auto=format%2Ccompress&w=320', 'https://img.ogj.com/files/base/ebm/ogj/image/2021/06/210607OGJdik_z10.60c7a8332d84d.png?auto=format%2Ccompress&w=320', 'https://img.ogj.com/files/base/ebm/ogj/image/2021/06/210607OGJdik_z11.60c7a83353c14.png?auto=format%2Ccompress&w=320']",,N/A,N/A,,,,,,"Artificial intelligence increases drilling efficiency, certainty",,,False,,,"{'@type': 'WebPageElement', 'isAccessibleForFree': 'False', 'cssSelector': '.paywall'}",,,,,,
https://news.google.com/rss/articles/CBMiVWh0dHBzOi8vbWVkY2l0eW5ld3MuY29tLzIwMjEvMDYvcm9ib3RzLWNvdWxkLW9uZS1kYXktd29yay1hbG9uZ3NpZGUtaHVtYW4tY2FyZWdpdmVycy_SAQA?oc=5,Robots could one day work alongside human caregivers - MedCity News,2021-06-06,MedCity News,https://medcitynews.com,N/A,"['Artificial Intelligence, Daily, MedCity Influencers, News, SYN, Top Story']","Caregivers should look forward to how bots can help support them while knowing they still play the most important role of all: and that's providing the personal, human touch that can't be replicated by technology.",N/A,https://schema.org,NewsArticle,https://medcitynews.com/2021/06/robots-could-one-day-work-alongside-human-caregivers/,"{'@type': 'Organization', 'name': 'MedCity News'}",,2021-06-06T10:01:17-04:00,,,,,,N/A,N/A,"








Imagine being admitted into a long-term healthcare center, only to find out that it was being partly run by robots?
This may sound like some amusing sci-fi movie, or maybe even a little apocalyptic, but it’s actually a lot closer to reality than some people might think. You may be wondering if we should be worried about the thought of working more closely with robots, and I strongly believe the answer is ‘no.’ In fact, it’s not something we should fear, but is instead a futuristic solution to healthcare that we should be embracing with the utmost enthusiasm.








			presented by		








					sponsored content				




 




					Physician Targeting Using Real-time Data: How PurpleLab’s Alerts Can Help				



					By leveraging real-time data that offers unprecedented insights into physician behavior and patient outcomes, companies can gain a competitive advantage with prescribers. PurpleLab®, a healthcare analytics platform with one of the largest medical and pharmaceutical claims databases in the United States, recently announced the launch of Alerts which translates complex information into actionable insights, empowering companies to identify the right physicians to target, determine the most effective marketing strategies and ultimately improve patient care. 				


			By 			PurpleLab		









Why is the shift taking place now?
The timing of this great shift couldn’t be better. Today, there are about 46 million members of the 65-and-over club, but come 2050, that number is expected to double, which would make seniors around 25 percent of the American population. And as society continues to deliver and practice better healthcare measures, life expectancy rates are increasing as well.
Though that fact is a sure cause for celebration, the concerning part is that the number of seniors in need far outweighs the number of caregivers that are qualified and available for the job. One might suggest that the obvious solution would be to hire more hands on deck but the matter isn’t quite that simple. 
The role of caregiver comes with noble responsibilities and a few hard-to-top benefits, but the truth is, it’s a very demanding job. In order to do the job well, and you must because the lives of patients depend on it, it requires full dedication, long hours, and intense passion. These are all things that not a lot of people can commit to for the long term. This is why caregiver burnout is such a glaring problem in the current healthcare climate, which has only been amplified by the pandemic.




Burnout leads to high turnover rates, which then leaves skilled nursing facilities in a state of chaos as they try to care for their patients and their staff at the same time. If the problem is that there aren’t enough caregivers, or that your organization only has room in its budget for so many, then why shouldn’t the solution be robot caretakers? 





					Sponsored Post				




 




					What’s Keeping Healthcare CIOs Up at Night: How Health Systems Automate Routine Phone Calls to Improve Workforce Effectiveness and Reduce Agent Burnout				


					With hospitals struggling to retain staff and value-based care shrinking healthcare revenues, health systems must look to technology resources to become more efficient, without losing sight of patient care or staff support.				


Should caregivers fear being replaced?
Being put out of work due to the mass overtaking of robots has created much fear in every industry, but as it turns out, there isn’t much of a story there. As mentioned before, our current caregivers often find themselves working to exhaustion in order to meet their patients’ needs, so once our senior population doubles, skilled nursing facilities won’t stand a chance if they choose to reject the help of artificial intelligence.
Robot caretakers aren’t meant to replace humans; you can never take the human touch out of skilled nursing facilities. Instead, they are meant to support long-term care staff.




When it comes to patient care, there are certain areas in which bots are unable to make themselves useful, and providing human interaction is one of them. Robot caretakers can listen and respond to patients, but residents wouldn’t regard them as true companions. In fact, most SNF residents would demand more from their robot caretakers because they aren’t worried about putting additional stress on them.
Robot caretakers can help with the majority of heavy lifting around the facility so that caregivers can spend more time doing what they want to do: caring for the critical medical and emotional needs of their patients. 
Can seniors truly lean on bots to take care of their needs?
Today’s seniors may require an adjustment period to get used to interacting with more advanced technology, but the ones that will hit 65-and-over within the next few decades will be no strangers to automation and artificial intelligence. 
Though we live in an age in which smart devices have literally altered our reality, skeptics are still unsure as to whether or not robots are equipped to actually mimic the attention to detail that a human caregiver can. The short answer is ‘yes,’ and here’s how. 
These robots have been programmed to handle the routine tasks caregivers are usually responsible for, like checking vital signs, administering medication, assisting with feedings, and alerting healthcare professionals in case of an emergency. They can even offer contactless Covid-19 screenings to patients. But a robot caretaker’s biggest advantage comes in handling the more physically demanding parts of the job.
These robot caretakers can help patients bathe and use the bathroom, lifting their bodies from their beds or wheelchairs with ease. They can help patients get dressed and even make up residents’ beds after each use. When a robot is on the job, patients don’t have to feel embarrassed when they need to be cleaned up after using the bathroom or when they make a mess while they’re eating. And with artificial intelligence, elders are being looked after 24 hours a day. These bots can even pick up on physical cues that can indicate distress or discomfort, leading to fewer instances in which professionals are unable to get to their patients in critical moments.
Over time, robot caretakers will be able to handle even more complex tasks, like administering shots or cooking full-fledged meals. Healthcare executives are excited to introduce artificial intelligence into their facilities to help support their patients and staff members, but one thing is certain: robots can never replace human compassion. Caregivers should look forward to how bots can help support them while knowing they still play the most important role of all: and that’s providing the personal, human touch that can’t be replicated by technology.












 








		            Avi Philipson                







Avi Philipson is a healthcare executive with a distinguished reputation for providing high-quality nursing and rehabilitation care to residents all along the east coast. Philipson serves as the Head of Operations at Axis Health, a leading consulting company trusted by skilled nursing facilities across Maryland and New Hampshire. In his role, Philipson guides nursing and rehabilitation centers to mitigate risk, implement technological innovations, and provide compassionate care to both short-term and long-term residents.



 

This post appears through the MedCity Influencers program. Anyone can publish their perspective on business and innovation in healthcare on MedCity News through MedCity Influencers. Click here to find out how.




Topics


long term care facilities


skilled nursing facility






			MedCity News Daily Newsletter		

			Sign up and get the latest news in your inbox.		



Enter your email address

Subscribe Now




			We will never sell or share your information without your consent. See our privacy policy.
		



","[{'@type': 'WebPage', '@id': 'https://medcitynews.com/2021/06/robots-could-one-day-work-alongside-human-caregivers/', 'url': 'https://medcitynews.com/2021/06/robots-could-one-day-work-alongside-human-caregivers/', 'name': 'Robots could one day work alongside human caregivers - MedCity News', 'isPartOf': {'@id': 'https://medcitynews.com/#website'}, 'primaryImageOfPage': {'@id': 'https://medcitynews.com/2021/06/robots-could-one-day-work-alongside-human-caregivers/#primaryimage'}, 'image': {'@id': 'https://medcitynews.com/2021/06/robots-could-one-day-work-alongside-human-caregivers/#primaryimage'}, 'thumbnailUrl': 'https://medcitynews.com/wp-content/uploads/sites/7/2021/03/GettyImages-1206796363.jpg', 'datePublished': '2021-06-06T14:01:17+00:00', 'dateModified': '2024-04-02T17:35:32+00:00', 'author': {'@id': 'https://medcitynews.com/#/schema/person/d087d84dddd45c832be02a31d3b12619'}, 'breadcrumb': {'@id': 'https://medcitynews.com/2021/06/robots-could-one-day-work-alongside-human-caregivers/#breadcrumb'}, 'inLanguage': 'en-US', 'potentialAction': [{'@type': 'ReadAction', 'target': ['https://medcitynews.com/2021/06/robots-could-one-day-work-alongside-human-caregivers/']}]}, {'@type': 'ImageObject', 'inLanguage': 'en-US', '@id': 'https://medcitynews.com/2021/06/robots-could-one-day-work-alongside-human-caregivers/#primaryimage', 'url': 'https://medcitynews.com/wp-content/uploads/sites/7/2021/03/GettyImages-1206796363.jpg', 'contentUrl': 'https://medcitynews.com/wp-content/uploads/sites/7/2021/03/GettyImages-1206796363.jpg', 'width': 810, 'height': 431}, {'@type': 'BreadcrumbList', '@id': 'https://medcitynews.com/2021/06/robots-could-one-day-work-alongside-human-caregivers/#breadcrumb', 'itemListElement': [{'@type': 'ListItem', 'position': 1, 'name': 'Home', 'item': 'https://medcitynews.com/'}, {'@type': 'ListItem', 'position': 2, 'name': 'Robots could one day work alongside human caregivers'}]}, {'@type': 'WebSite', '@id': 'https://medcitynews.com/#website', 'url': 'https://medcitynews.com/', 'name': 'MedCity News', 'description': 'Healthcare technology news, life science current events', 'potentialAction': [{'@type': 'SearchAction', 'target': {'@type': 'EntryPoint', 'urlTemplate': 'https://medcitynews.com/?s={search_term_string}'}, 'query-input': 'required name=search_term_string'}], 'inLanguage': 'en-US'}, {'@type': 'Person', '@id': 'https://medcitynews.com/#/schema/person/d087d84dddd45c832be02a31d3b12619', 'name': 'Avi Philipson', 'image': {'@type': 'ImageObject', 'inLanguage': 'en-US', '@id': 'https://medcitynews.com/#/schema/person/image/', 'url': 'https://secure.gravatar.com/avatar/271ea30931bbdd5877cd01782c3c2184?s=96&d=mm&r=g', 'contentUrl': 'https://secure.gravatar.com/avatar/271ea30931bbdd5877cd01782c3c2184?s=96&d=mm&r=g', 'caption': 'Avi Philipson'}, 'description': 'Avi Philipson is a healthcare executive with a distinguished reputation for providing high-quality nursing and rehabilitation care to residents all along the east coast. Philipson serves as the Head of Operations at Axis Health, a leading consulting company trusted by skilled nursing facilities across Maryland and New Hampshire. In his role, Philipson guides nursing and rehabilitation centers to mitigate risk, implement technological innovations, and provide compassionate care to both short-term and long-term residents.', 'url': 'https://medcitynews.com/author/aphilipson/'}]",,,MedCity Influencers,Robots could one day work alongside human caregivers,https://medcitynews.com/wp-content/uploads/sites/7/2021/03/GettyImages-1206796363.jpg,,,,,,['Avi Philipson'],,,,,
https://news.google.com/rss/articles/CBMieGh0dHBzOi8vd3d3Lm1lcmNlci5jb20vZW4tdXMvaW5zaWdodHMvbGF3LWFuZC1wb2xpY3kvZ2VybWFueS1leHBhbmRzLXdvcmtzLWNvdW5jaWxzLXJpZ2h0cy1hZGRyZXNzZXMtYWktYW5kLXJlbW90ZS13b3JrL9IBAA?oc=5,"Germany expands works councils' rights, addresses AI and remote work - Mercer",2021-06-07,Mercer,https://www.mercer.com,"The rights of works councils will be expanded, and procedures for the establishment and election of new works councils will be simplified, under measures included in the Works Council Modernization Act.","Law & Policy,Career,Global All,Global All","The rights of works councils will be expanded, and procedures for the establishment and election of new works councils will be simplified, under measures included in the Works Council Modernization Act.",N/A,,,,,,,,,,,,N/A,N/A,"






Roundup: Global employer resources on artificial intelligence  

: Stephanie Rosseau, Principal, Mercer’s Law & Policy Group

Artificial intelligence is becoming a permanent feature of the workplace and poses challenges/considerations as it reshapes work. This roundup provides general…




",,,,,,,,,,,,,,,,,
https://news.google.com/rss/articles/CBMid2h0dHBzOi8vd3d3LmFuYWx5dGljc2luc2lnaHQubmV0L2FydGlmaWNpYWwtaW50ZWxsaWdlbmNlL2xpbmtlZGluLXVzZXMtYXJ0aWZpY2lhbC1pbnRlbGxpZ2VuY2UtaW4tdGhlc2UtaW5jcmVkaWJsZS13YXlz0gGBAWh0dHBzOi8vd3d3LmFuYWx5dGljc2luc2lnaHQubmV0L2FtcC9zdG9yeS9hcnRpZmljaWFsLWludGVsbGlnZW5jZS9saW5rZWRpbi11c2VzLWFydGlmaWNpYWwtaW50ZWxsaWdlbmNlLWluLXRoZXNlLWluY3JlZGlibGUtd2F5cw?oc=5,LinkedIn Uses Artificial Intelligence in These Incredible Ways - Analytics Insight,2021-06-08,Analytics Insight,https://www.analyticsinsight.net,,"LinkedIn,machine learning,artificial intelligence,AI,popular recruiting platforms","LinkedIn has been at the forefront of AI for years, and it employs it in a variety of ways that users may not be aware of. LinkedIn is one of the most popular r","LinkedIn has been at the forefront of AI for years, and it employs it in a variety of ways that users may not be aware of. LinkedIn is one of the most popular r",http://schema.org,NewsArticle,https://www.analyticsinsight.net/artificial-intelligence/linkedin-uses-artificial-intelligence-in-these-incredible-ways,"{'@type': 'Organization', '@context': 'http://schema.org', 'name': 'Analytics Insight', 'url': 'https://www.analyticsinsight.net', 'logo': {'@context': 'http://schema.org', '@type': 'ImageObject', 'author': 'analyticsinsight', 'contentUrl': 'https://images.assettype.com/analyticsinsight/2024-05/2df9abcd-45d0-437f-9a36-167417fe7202/AI_logo_white (2).png', 'url': 'https://images.assettype.com/analyticsinsight/2024-05/2df9abcd-45d0-437f-9a36-167417fe7202/AI_logo_white (2).png', 'name': 'logo', 'width': '', 'height': ''}, 'sameAs': ['https://whatsapp.com/channel/0029VafDe8HCBtxLV2PpRA2l', 'https://twitter.com/analyticsinme', 'https://in.pinterest.com/analyticsinsightsubmissions/_created/', 'https://www.instagram.com/analyticsinsightmagazine/', 'https://www.facebook.com/analyticsinsight.net', 'https://news.google.com/publications/CAAiEDD0Ze78owxVdNti611RNvQqFAgKIhAw9GXu_KMMVXTbYutdUTb0?hl=en-IN&gl=IN&ceid=IN%3Aen', 'https://t.me/analyticsinsightmag', 'https://www.youtube.com/channel/UCgF2J0b46YP0vvVEbgL_GuQ', 'https://www.linkedin.com/company/analytics-insight/'], 'id': 'https://www.analyticsinsight.net'}","{'@type': 'WebPage', '@id': 'https://www.analyticsinsight.net/artificial-intelligence/linkedin-uses-artificial-intelligence-in-these-incredible-ways'}",2021-06-08T12:00:18Z,2021-06-08T12:00:18Z,2021-06-08T12:00:18Z,,"{'@type': 'ImageObject', 'url': 'https://media.assettype.com/analyticsinsight/import/wp-content/uploads/2021/06/LinkedIn-Uses-Artificial-Intelligence-in-These-Incredible-Ways.jpg?w=1200&h=675&auto=format%2Ccompress&fit=max&enlarge=true', 'width': '1200', 'height': '675'}","[{'@type': 'Person', 'givenName': 'Monomita Chakraborty', 'name': 'Monomita Chakraborty', 'url': 'https://www.analyticsinsight.net/author/monomita-chakraborty'}]",N/A,N/A,What is AI and Data Science Engineering? ,,"LinkedIn has been at the forefront of AI for years, and it employs it in a variety of ways that users may not be aware of..LinkedIn is one of the most popular recruiting platforms available today. Recruiters from all around the world use LinkedIn every day to find and filter applicants for specific job openings..LinkedIn is well-known for being one of the software behemoths that has pushed the limits of machine learning research and development. LinkedIn has been constantly exploring cutting-edge machine learning techniques in order to make artificial intelligence (AI) a first-class member of the LinkedIn experience, in contrast to cultivating one of the world's wealthiest datasets..Here are a few examples of how LinkedIn uses Artificial intelligence:.LinkedIn makes substantial use of data analytics and artificial intelligence to enhance the experiences of its users and customers. Members are exposed to it on a daily basis, whether they are receiving employment recommendations, suggestions for connecting with others, or reading helpful stuff in their feed. AI assists enterprise customers, such as recruiters, in finding new talent pools and receiving insightful data. AI systems have had a significant impact on both sides of the platforms, adding significant value..According to a report, there was a 30% increase in job applications after the improvement of the personalization tool, which recommends jobs that members might be interested in. In general, job applications overall have grown more than 40% year-over-year, based on a variety of AI-driven optimizations that have been made to both sides of the member-recruiter ecosystem. The email responses to cold emails from recruiters have increased by 45% while at the same time cutting down on the notifications needed to send to the job seekers that have received such messages. Even better, the total number of continuing, two-way conversations started in LinkedIn Recruiter has doubled. Every message a recruiter sends is twice as likely to turn into a hire after the most powerful LinkedIn AI tools are implemented. AI has also improved article recommendations in the feed by 10-20% based on click-through rate. With all of these amazing statistics, the platform has reached 660 million users and engagement has increased 50% year over year. The value capture consists of increasing the number of users, specifically paid users and the number of enterprise subscriptions from companies..LinkedIn also uses AI to help businesses overcome human biases that stifle equality. These AI features are included in LinkedIn's Talent Insight product, which is geared at recruiters and focuses on diversity and inclusion..LinkedIn can monitor what occurs in the recruitment process in terms of gender, providing firms with data and insights into how their job postings and InMail are functioning. In addition, the top search results in LinkedIn Recruiter will be re-ranked to be more representative..Companies can observe the gender breakdown in each step of the hiring process according to LinkedIn's reporting data on gender in the hiring process. They can also have a better understanding of the overall talent environment, such as how skill sets change over time and how to discover talent pools. Companies can also evaluate their gender breakdown to that of their counterparts in the sector to see how they might recruit from a more diverse pool..AI also works in the background, protecting its members from hazardous information, routing connections to maintain a fast site performance experience, and ensuring that the notifications given to the users are informative but not obtrusive..Disclaimer: Analytics Insight does not provide financial advice or guidance. Also note that the cryptocurrencies mentioned/listed on the website could potentially be scams, i.e. designed to induce you to invest financial resources that may be lost forever and not be recoverable once investments are made. You are responsible for conducting your own research (DYOR) before making any investments. Read more here.",,Artificial Intelligence,LinkedIn Uses Artificial Intelligence in These Incredible Ways,https://media.assettype.com/analyticsinsight/import/wp-content/uploads/2021/06/LinkedIn-Uses-Artificial-Intelligence-in-These-Incredible-Ways.jpg?w=1200&h=675&auto=format%2Ccompress&fit=max&enlarge=true,"{'@type': 'WebPage', 'url': 'https://www.analyticsinsight.net/artificial-intelligence/linkedin-uses-artificial-intelligence-in-these-incredible-ways', 'primaryImageOfPage': {'@type': 'ImageObject', 'url': 'https://media.assettype.com/analyticsinsight/import/wp-content/uploads/2021/06/LinkedIn-Uses-Artificial-Intelligence-in-These-Incredible-Ways.jpg?w=1200&h=675&auto=format%2Ccompress&fit=max&enlarge=true', 'width': '1200', 'height': '675'}}",,,"[{'@type': 'ListItem', 'position': 1, 'name': 'Home', 'item': 'https://www.analyticsinsight.net'}, {'@type': 'ListItem', 'position': 2, 'name': 'Artificial Intelligence', 'item': 'https://www.analyticsinsight.net/artificial-intelligence'}, {'@type': 'ListItem', 'position': 3, 'name': 'LinkedIn Uses Artificial Intelligence in These Incredible Ways', 'item': 'https://www.analyticsinsight.net/artificial-intelligence/linkedin-uses-artificial-intelligence-in-these-incredible-ways'}]",,,LinkedIn Uses Artificial Intelligence in These Incredible Ways,,,,
https://news.google.com/rss/articles/CBMiZGh0dHBzOi8vd3d3LnRlbGVtYXRpY3N3aXJlLm5ldC9hcnRpZmljaWFsLWludGVsbGlnZW5jZS1hbmQtbWFjaGluZS1sZWFybmluZy1mb3ItdmVoaWNsZS1lbmdpbmVlcmluZy_SAQA?oc=5,Artificial Intelligence and Machine Learning for Vehicle Engineering - Telematics Wire,2021-06-07,Telematics Wire,https://www.telematicswire.net,"The invention of the wheel revolutionized the concept of mobility for the entire human race. This gave birth to the car in 1886 and only later in 1908, was this vehicle available to the masses. The ‘w","Artificial Intelligence,automotive driving,car designing,Connected Vehicle,industrilization,machine larning,technology,vehicle engineering,Vehicle Technology","The invention of the wheel revolutionized the concept of mobility for the entire human race. This gave birth to the car in 1886 and only later in 1908, was this vehicle available to the masses. The ‘wheel’ generated hope in terms of rapid movement and the car brought controls like comfort, pleasure of driving, and of course – light! Being in the possession of a car was a luxury till only a few decades ago!",N/A,http://schema.org,Article,https://www.telematicswire.net/artificial-intelligence-and-machine-learning-for-vehicle-engineering/,"{'@id': '#Publisher', '@type': 'Organization', 'name': 'Telematics Wire', 'logo': {'@type': 'ImageObject', 'url': 'https://www.telematicswire.net/wp-content/uploads/2021/02/TW-logo.png'}}","{'@type': 'WebPage', '@id': 'https://www.telematicswire.net/artificial-intelligence-and-machine-learning-for-vehicle-engineering/', 'breadcrumb': {'@id': '#Breadcrumb'}}",2021-06-07T13:16:30+05:30,2021-06-07T13:16:30+05:30,2021-06-07T13:16:33+05:30,,"{'@type': 'ImageObject', 'url': 'https://www.telematicswire.net/wp-content/uploads/2021/06/image.jpg', 'width': 1200, 'height': 540}","{'@type': 'Person', 'name': 'admin', 'url': 'https://www.telematicswire.net/author/admin/'}",N/A,N/A,"

 Home/Views/Emerging Technologies/Artificial Intelligence and Machine Learning for Vehicle Engineering

Emerging Technologies
Artificial Intelligence and Machine Learning for Vehicle Engineering




adminJune 7, 2021 8 minutes read  



The invention of the wheel revolutionized the concept of mobility for the entire human race. This gave birth to the car in 1886 and only later in 1908, was this vehicle available to the masses. The ‘wheel’ generated hope in terms of rapid movement and the car brought controls like comfort, pleasure of driving, and of course – light! Being in the possession of a car was a luxury till only a few decades ago!
When the technology is couples with car designing, it gave rise to Super Mobility that progressively made more complex and reliable machines which became increasingly easy to manoeuvre. 
With technology going up in leaps and bounds there was not an iota of doubt that this automobile would to transform into Smart Mobility Vehicle. 
Future Mobility will be with the advent of latest technology; Electric, Connectivity, Internet-of-things (IoT), Cloud Computing, Artificial Intelligence (AI), Machine Learning (ML), Deep Learning (DL). Today there are many innovative features that enhance the car & the ecosystem for Electric Vehicle, Autonomous Vehicle and Car Sharing. 
In towns and cities, there is a dire need of sustainable solutions of car sharing such as combined multiple modes of transportation including private cars, public transport, robo-taxis / shuttles, micro-mobility and cycling, in order to address the problem of congestion, pollution and quality of life.  
Refer Figure 1: Technology Drivers, Transforming Automotive Industry clearly questions “WHO NEEDS BASIC MOBILITY?”. Technology Drivers are pushing the Ecosystem to get it transformed into a Value Chain for OEM’s. Stakeholders; Vehicle manufacturers, Technology providers, Govt. authorities and many more to have strategic plans in place to provide effective solutions. Overcoming hurdles, aggressive predictions are being made for meticulous planning, sagacious investments and execution methodologies. 

Figure 1: Technology Drivers, Transforming Automotive Industry
Artificial Intelligence and Machine Learning
Artificial intelligence describes the work processes of machines that would require intelligence if performed by humans. The term ‘artificial intelligence’ thus means ‘investigating intelligent problem-solving behaviour and creating intelligent computer systems.
Artificial Intelligence can be divided into 5 categories;
• Machine & Deep learning
A set of algorithms used to model the high level abstraction of data, monitored and evaluated continuously. A single mistake can be captured and resolved automatically.  
• Industrialization 
Robots have dominance over the Manufacturing, Assembly and Production. They work effectively, efficiently and reliably.  
• Digitization & Data Processing
Data recording and processing has been phenomenal over the years. Traditional activities are no longer effective and scraped. Data management software’s will create database for further processing. 
• Micro & Mega Economies
With the advent of Web-based Networking techniques, stakeholders are able to manage the businesses in the most efficient way. Various applications are being developed and used to run on the online platforms. 
• Autonomous driving
No human interventions. Vehicle runs using sensors, navigation techniques and self-governing capabilities.
Hence, Artificial Intelligence will lead to redefine business models for the products and systems. This affects both; Product and Service sector as well the whole eco-system on which the businesses will run. The eco-system, Cyber Physical Systems (CPS) into production and logistics and Internet of Things (IoT) are the blood and vessels of the businesses. CPS is the data bases and information sharing platform between humans, machines, products, objects and information and communication technology systems. 
In Vehicle Engineering, automatization has four levels; first the production is controlled by machines configured by humans, second, real-time production is the core feature, third is a decentralization and forth is industrialization where NO human intervention. There are economic benefits; reduced production cost, better presence in competitive market. 
The following Figure 2: The trends shaping the Auto Industry from now to 2030 describes, how AI & Machine Learning is playing a very important role.

Figure 2: The trends shaping the Auto Industry from Now to 2030
Source: Oliver Wyman Analysis
Here, I would like to discuss three major applications of using AI & ML for Vehicle Engineering,
1. Predictive Maintenance
Automotive predictive maintenance software with online support system based on Microsoft Azure cloud services can be developed for vehicles that processes requests for appointments and syncs drivers to the nearest dealer services.
The online system also notifies drivers by phone message or email about the need to check parts that have exact maintenance schedules stated in the vehicle specifications, which are synchronized with the online system.
The Machine learning algorithms will recognize for example: 
• Starter motor malfunctions 
• Drop of pressure in the fuel pump 
• End of a battery’s service life 
It is possible to develop a vehicle predictive maintenance solution based on machine learning algorithms that collects data from steering and braking systems as well as from the starter motor, battery and fuel pump and relays the information to the cloud for analysis and diagnostics.
Few indicative steps for a predictive maintenance algorithm for battery life: 
• In-car monitoring system checks battery status  
• Data is transferred to the cloud  
• Cloud-based ML algorithm predicts that the battery will run low   
• System processes all inputs and prepares advice to the driver 
• Notification system sends a message to the driver with instructions 
• Driver takes action based on the recommended instructions 
2. Pedestrian Tracking & Collision Prediction
Urban populations are growing exponentially alongside the number of personal and public transportation, and last-mile delivery vehicles. These vehicles share increasingly crowded streets with pedestrians and cyclists, who are the most vulnerable road users. Globally, pedestrians accounted for 25% of road fatalities in the year 2018. 
Besides street congestion, blind spots of large buses and heavy vehicles are another cause of incidents. Drivers must manoeuvre quickly and accurately while staying alert to any nearby movement. Workers on foot can also be exposed to potential harm on industrial storage sites from forklifts. With a full load completely blocking the view, forklift drivers may have more blind spots than areas of clear vision.
All these pedestrian safety issues can be addressed through an AI pedestrian collision prediction module. 
It is possible to develop a pedestrian collision prediction module which analyses data about the position of pedestrians, their predicted locations, and road coordinates. 
The module comprises of the following components:
• Pedestrian detection
• Pedestrian trajectory prediction
• Road segmentation
• The pedestrian collision prediction module itself
Pedestrian detection is conducted with the Realtime Object Detection algorithm. The module for pedestrian trajectory prediction with Kalman Filter obtains the speed and velocity of a pedestrian from the detection module to predict their motion. Then the pedestrian detector searches for the best-match appearance to update measurements. The output of the previous calculation is an input for the next one. The result of the Kalman filter is an adjusted pedestrian trajectory.
The Road segmentation module distinguishes driving lanes from the sidewalk and outputs images with labelled road pixels. The module is usually handled by a Convolutional Neural Network (CNN), a Deep Learning Methodology.
The Pedestrian collision prediction module calculates the probability of a collision using the coordinates of a pedestrian bounding box, which are predicted and obtained from the object detector paired with the Kalman filter, and the road coordinates from the road segmentation module. If these coordinates of a pedestrian bounding box do not intersect with road coordinates, the vehicle and pedestrian collision is of zero-probability. In case of an intersection, the collision probability equals the ratio of the distance to the predicted pedestrian location and the distance of detected road available for the car.
Active safety technology for preventing pedestrian collisions is important to protect vulnerable road users and move toward zero-traffic-accident society. Using AI and ML solutions, OEMs built intelligent vehicles that can perceive and react to road conditions up to 99.8% which is better than human drivers.
Being an extra pair of eyes, a pedestrian collision prediction module addresses the challenge of monitoring hazardous blind spots for drivers of both private cars and large vehicles manoeuvring in narrow lanes and around people on foot. Once the possibility of hitting a pedestrian is detected, a driver will receive a visual and audio alert, thus getting more time to react. If the situation is defined as critical, the brakes will be applied automatically.
The advanced pedestrian trajectory prediction module will support automakers in enhancing the safety parameters of vehicles in urban, rural, and industrial environments. By equipping fleets with a pedestrian collision prediction module, companies will reduce incidents and associated costs and, most importantly, save lives.
3. High-Definition Maps and Cloud Data Platform for Autonomous Driving
One of the major requirement for Fully Automated Driving (FAD) is 3D HD Maps, the creation of the maps i.e. eliciting source data to creating and publishing the maps themselves. AI can support in this activity. The map development process is sequential and happens in five major stages:
Real-time streaming perception
An Edge Perception stack is developed that allows for HD map observations and crowd-sourced updates using vehicle-mounted sensor systems. The process involves detecting road features in video streams in real time. This dynamic data is then used in the development of self-healing maps. In case of any changes on the roads, maps are updated automatically, and the new map data is delivered to end users in real time.
Data collection
To build detailed and credible maps for navigation systems and custom solutions, accurate information on road attributes needs to be collected from around the globe. Data is gathered from mobile cameras, sensors, and GPS devices on the road to locate traffic lights, signs, poles, stop lines, lane markings, roadside barriers, junctions, etc. 
Data aggregation, processing, and filtering
Engineers handle massive datasets from a variety of sources, including from core maps and on-vehicle sensor systems. All road image data is aggregated, processed, and filtered via a streaming file system for further validation and intelligent analysis using machine learning models. All data can be consumed in an NDS (Navigation Data Standard) format to avoid vendor lock-in and ensure interoperability across systems.
3D map creation and maintenance
Live 3D maps are compiled & updated that enable precise positioning for lateral and longitudinal control of vehicles. These multi-layer maps contain details at several levels (roads, lanes, lane groups and individual lanes, geometry) and are constantly enriched with incoming information on new road attributes such as signs, markers, crosswalks, bicycle lanes, and objects.
Map delivery
Data-intensive HD maps are generated and delivered to customers online as a geographically tiled and functionally layered data service suitable for direct-to-vehicle and OEM cloud consumption. These maps are also an indispensable source of data for client’s many in-vehicle software development programs.
There would be many such tests and a huge number of algorithms running in the vehicle environment. All the stakeholders; Vehicle manufacturers, Technology providers, Govt. authorities, Academicians have their own share of work to support this humongous initiative.  
Indian Research Universities / Institutes have a pivotal role to play. Currently, there is huge GAP between ‘what we learn’ and ‘where we apply’. Industry and Service sectors in India would require a gross incremental workforce of  > 1.12 billion by 2050; India could potentially emerge as a global supplier of skilled manpower. Refer Figure 3: Workforce requirements by 2050 and Gap between Industry & Academics. Going ahead the organizations anticipate a huge shortfall of qualified and skilled employees.  Since business strategies are not clear, there is a need to procure, control, retain and nurture talent. This may be the key to combat competition.

Author:

Dr. Ajay PalkarHead of Electrical & ElectronicsŠKODA AUTO Volkswagen India

Ajay is an Industry recognized thought leader over 30+ years of Product design, Development & Management consulting experience. An accomplished, performance driven & focused professional having rich experience in Engineering & Management mainly focusing Vehicle Integration (Mobility, Electrical & Electronics), Systems Engineering, Project Management, Strategic Planning & Business Development in Automotive, Defense, and Industrial Automation & Instrumentation field. His core research area is Product Life Cycle & Obsolescence, StrategicManagement and Project Management. He has published numerous papers on Technology & Marketing Management, various patents & memberships on his name. Ajay is currently associated with SKODA Auto Volkswagen India Pvt. Ltd. as Head – Electrical & Electronics. In the past he was associated with esteemed organizations such as Mahindra & Mahindra, Tata Motors, Bennett, Coleman, & Co. Ltd., main roles & responsibilities involved Solution Architecture, R&D – Systems Engineering & Technology, Strategic Management & Pre-sales.
Published in Telematics Wire
 TagsArtificial Intelligence automotive driving car designing Connected Vehicle industrilization machine larning technology vehicle engineering Vehicle Technology







adminJune 7, 2021 8 minutes read  






 Twitter


 LinkedIn


 Share via Email


 Print
 

","[{'@type': 'Article', '@id': 'https://www.telematicswire.net/artificial-intelligence-and-machine-learning-for-vehicle-engineering/#article', 'isPartOf': {'@id': 'https://www.telematicswire.net/artificial-intelligence-and-machine-learning-for-vehicle-engineering/'}, 'author': {'name': 'admin', '@id': 'https://www.telematicswire.net/#/schema/person/f50be179f67fa622d47da2c192070bf0'}, 'headline': 'Artificial Intelligence and Machine Learning for Vehicle Engineering', 'datePublished': '2021-06-07T07:46:30+00:00', 'dateModified': '2021-06-07T07:46:33+00:00', 'mainEntityOfPage': {'@id': 'https://www.telematicswire.net/artificial-intelligence-and-machine-learning-for-vehicle-engineering/'}, 'wordCount': 2059, 'publisher': {'@id': 'https://www.telematicswire.net/#organization'}, 'image': {'@id': 'https://www.telematicswire.net/artificial-intelligence-and-machine-learning-for-vehicle-engineering/#primaryimage'}, 'thumbnailUrl': 'https://www.telematicswire.net/wp-content/uploads/2021/06/image.jpg', 'keywords': ['Artificial Intelligence', 'automotive driving', 'car designing', 'Connected Vehicle', 'industrilization', 'machine larning', 'technology', 'vehicle engineering', 'Vehicle Technology'], 'articleSection': ['Emerging Technologies'], 'inLanguage': 'en-US'}, {'@type': 'WebPage', '@id': 'https://www.telematicswire.net/artificial-intelligence-and-machine-learning-for-vehicle-engineering/', 'url': 'https://www.telematicswire.net/artificial-intelligence-and-machine-learning-for-vehicle-engineering/', 'name': 'Artificial Intelligence and Machine Learning for Vehicle Engineering Telematics Wire', 'isPartOf': {'@id': 'https://www.telematicswire.net/#website'}, 'primaryImageOfPage': {'@id': 'https://www.telematicswire.net/artificial-intelligence-and-machine-learning-for-vehicle-engineering/#primaryimage'}, 'image': {'@id': 'https://www.telematicswire.net/artificial-intelligence-and-machine-learning-for-vehicle-engineering/#primaryimage'}, 'thumbnailUrl': 'https://www.telematicswire.net/wp-content/uploads/2021/06/image.jpg', 'datePublished': '2021-06-07T07:46:30+00:00', 'dateModified': '2021-06-07T07:46:33+00:00', 'description': 'The invention of the wheel revolutionized the concept of mobility for the entire human race. This gave birth to the car in 1886 and only later in 1908, was this vehicle available to the masses. The ‘wheel’ generated hope in terms of rapid movement and the car brought controls like comfort, pleasure of driving, and of course – light! Being in the possession of a car was a luxury till only a few decades ago!', 'breadcrumb': {'@id': 'https://www.telematicswire.net/artificial-intelligence-and-machine-learning-for-vehicle-engineering/#breadcrumb'}, 'inLanguage': 'en-US', 'potentialAction': [{'@type': 'ReadAction', 'target': ['https://www.telematicswire.net/artificial-intelligence-and-machine-learning-for-vehicle-engineering/']}]}, {'@type': 'ImageObject', 'inLanguage': 'en-US', '@id': 'https://www.telematicswire.net/artificial-intelligence-and-machine-learning-for-vehicle-engineering/#primaryimage', 'url': 'https://www.telematicswire.net/wp-content/uploads/2021/06/image.jpg', 'contentUrl': 'https://www.telematicswire.net/wp-content/uploads/2021/06/image.jpg', 'width': 960, 'height': 540, 'caption': 'artificial intelligence'}, {'@type': 'BreadcrumbList', '@id': 'https://www.telematicswire.net/artificial-intelligence-and-machine-learning-for-vehicle-engineering/#breadcrumb', 'itemListElement': [{'@type': 'ListItem', 'position': 1, 'name': 'Home', 'item': 'https://www.telematicswire.net/'}, {'@type': 'ListItem', 'position': 2, 'name': 'Artificial Intelligence and Machine Learning for Vehicle Engineering'}]}, {'@type': 'WebSite', '@id': 'https://www.telematicswire.net/#website', 'url': 'https://www.telematicswire.net/', 'name': 'Telematics Wire', 'description': 'Technology Driven - Futuristic Vehicle', 'publisher': {'@id': 'https://www.telematicswire.net/#organization'}, 'potentialAction': [{'@type': 'SearchAction', 'target': {'@type': 'EntryPoint', 'urlTemplate': 'https://www.telematicswire.net/?s={search_term_string}'}, 'query-input': 'required name=search_term_string'}], 'inLanguage': 'en-US'}, {'@type': 'Organization', '@id': 'https://www.telematicswire.net/#organization', 'name': 'Telematics Wire Private Limited', 'url': 'https://www.telematicswire.net/', 'logo': {'@type': 'ImageObject', 'inLanguage': 'en-US', '@id': 'https://www.telematicswire.net/#/schema/logo/image/', 'url': 'https://www.telematicswire.net/wp-content/uploads/2020/05/Telematics_Wire_Logo_2.jpg', 'contentUrl': 'https://www.telematicswire.net/wp-content/uploads/2020/05/Telematics_Wire_Logo_2.jpg', 'width': 1721, 'height': 180, 'caption': 'Telematics Wire Private Limited'}, 'image': {'@id': 'https://www.telematicswire.net/#/schema/logo/image/'}, 'sameAs': ['https://www.facebook.com/telematicswire/', 'https://twitter.com/telematicswire']}, {'@type': 'Person', '@id': 'https://www.telematicswire.net/#/schema/person/f50be179f67fa622d47da2c192070bf0', 'name': 'admin', 'image': {'@type': 'ImageObject', 'inLanguage': 'en-US', '@id': 'https://www.telematicswire.net/#/schema/person/image/', 'url': 'https://secure.gravatar.com/avatar/7a6aeae6daf581fb4982ea8f75769a64?s=96&d=mm&r=g', 'contentUrl': 'https://secure.gravatar.com/avatar/7a6aeae6daf581fb4982ea8f75769a64?s=96&d=mm&r=g', 'caption': 'admin'}, 'sameAs': ['https://www.telematicswire.net/']}]","
The invention of the wheel revolutionized the concept of mobility for the entire human race. This gave birth to the car in 1886 and only later in 1908, was this vehicle available to the masses. The ‘wheel’ generated hope in terms of rapid movement and the car brought controls like comfort, pleasure of driving, and of course – light! Being in the possession of a car was a luxury till only a few decades ago!



When the technology is couples with car designing, it gave rise to Super Mobility that progressively made more complex and reliable machines which became increasingly easy to manoeuvre.&nbsp;



With technology going up in leaps and bounds there was not an iota of doubt that this automobile would to transform into Smart Mobility Vehicle.&nbsp;



Future Mobility will be with the advent of latest technology; Electric, Connectivity, Internet-of-things (IoT), Cloud Computing, Artificial Intelligence (AI), Machine Learning (ML), Deep Learning (DL). Today there are many innovative features that enhance the car &amp; the ecosystem for Electric Vehicle, Autonomous Vehicle and Car Sharing.&nbsp;



In towns and cities, there is a dire need of sustainable solutions of car sharing such as combined multiple modes of transportation including private cars, public transport, robo-taxis / shuttles, micro-mobility and cycling, in order to address the problem of congestion, pollution and quality of life.&nbsp;&nbsp;



Refer Figure 1: Technology Drivers, Transforming Automotive Industry clearly questions “WHO NEEDS BASIC MOBILITY?”. Technology Drivers are pushing the Ecosystem to get it transformed into a Value Chain for OEM’s. Stakeholders; Vehicle manufacturers, Technology providers, Govt. authorities and many more to have strategic plans in place to provide effective solutions. Overcoming hurdles, aggressive predictions are being made for meticulous planning, sagacious investments and execution methodologies.&nbsp;







Figure 1: Technology Drivers, Transforming Automotive Industry



Artificial Intelligence and Machine Learning



Artificial intelligence describes the work processes of machines that would require intelligence if performed by humans. The term ‘artificial intelligence’ thus means ‘investigating intelligent problem-solving behaviour and creating intelligent computer systems.



Artificial Intelligence can be divided into 5 categories;



• Machine &amp; Deep learning



A set of algorithms used to model the high level abstraction of data, monitored and evaluated continuously. A single mistake can be captured and resolved automatically.&nbsp;&nbsp;



• Industrialization&nbsp;



Robots have dominance over the Manufacturing, Assembly and Production. They work effectively, efficiently and reliably.&nbsp;&nbsp;



• Digitization &amp; Data Processing



Data recording and processing has been phenomenal over the years. Traditional activities are no longer effective and scraped. Data management software’s will create database for further processing.&nbsp;



• Micro &amp; Mega Economies



With the advent of Web-based Networking techniques, stakeholders are able to manage the businesses in the most efficient way. Various applications are being developed and used to run on the online platforms.&nbsp;



• Autonomous driving



No human interventions. Vehicle runs using sensors, navigation techniques and self-governing capabilities.



Hence, Artificial Intelligence will lead to redefine business models for the products and systems. This affects both; Product and Service sector as well the whole eco-system on which the businesses will run. The eco-system, Cyber Physical Systems (CPS) into production and logistics and Internet of Things (IoT) are the blood and vessels of the businesses. CPS is the data bases and information sharing platform between humans, machines, products, objects and information and communication technology systems.&nbsp;



In Vehicle Engineering, automatization has four levels; first the production is controlled by machines configured by humans, second, real-time production is the core feature, third is a decentralization and forth is industrialization where NO human intervention. There are economic benefits; reduced production cost, better presence in competitive market.&nbsp;



The following Figure 2: The trends shaping the Auto Industry from now to 2030 describes, how AI &amp; Machine Learning is playing a very important role.







Figure 2: The trends shaping the Auto Industry from Now to 2030



Source: Oliver Wyman Analysis



Here, I would like to discuss three major applications of using AI &amp; ML for Vehicle Engineering,



1. Predictive Maintenance



Automotive predictive maintenance software with online support system based on Microsoft Azure cloud services can be developed for vehicles that processes requests for appointments and syncs drivers to the nearest dealer services.



The online system also notifies drivers by phone message or email about the need to check parts that have exact maintenance schedules stated in the vehicle specifications, which are synchronized with the online system.



The Machine learning algorithms will recognize for example:&nbsp;



• Starter motor malfunctions&nbsp;



• Drop of pressure in the fuel pump&nbsp;



• End of a battery’s service life&nbsp;



It is possible to develop a vehicle predictive maintenance solution based on machine learning algorithms that collects data from steering and braking systems as well as from the starter motor, battery and fuel pump and relays the information to the cloud for analysis and diagnostics.



Few indicative steps for a predictive maintenance algorithm for battery life:&nbsp;



• In-car monitoring system checks battery status&nbsp;&nbsp;



• Data is transferred to the cloud&nbsp;&nbsp;



• Cloud-based ML algorithm predicts that the battery will run low&nbsp;&nbsp;&nbsp;



• System processes all inputs and prepares advice to the driver&nbsp;



• Notification system sends a message to the driver with instructions&nbsp;



• Driver takes action based on the recommended instructions&nbsp;



2. Pedestrian Tracking &amp; Collision Prediction



Urban populations are growing exponentially alongside the number of personal and public transportation, and last-mile delivery vehicles. These vehicles share increasingly crowded streets with pedestrians and cyclists, who are the most vulnerable road users. Globally, pedestrians accounted for 25% of road fatalities in the year 2018.&nbsp;



Besides street congestion, blind spots of large buses and heavy vehicles are another cause of incidents. Drivers must manoeuvre quickly and accurately while staying alert to any nearby movement. Workers on foot can also be exposed to potential harm on industrial storage sites from forklifts. With a full load completely blocking the view, forklift drivers may have more blind spots than areas of clear vision.



All these pedestrian safety issues can be addressed through an AI pedestrian collision prediction module.&nbsp;



It is possible to develop a pedestrian collision prediction module which analyses data about the position of pedestrians, their predicted locations, and road coordinates.&nbsp;



The module comprises of the following components:



• Pedestrian detection



• Pedestrian trajectory prediction



• Road segmentation



• The pedestrian collision prediction module itself



Pedestrian detection is conducted with the Realtime Object Detection algorithm. The module for pedestrian trajectory prediction with Kalman Filter obtains the speed and velocity of a pedestrian from the detection module to predict their motion. Then the pedestrian detector searches for the best-match appearance to update measurements. The output of the previous calculation is an input for the next one. The result of the Kalman filter is an adjusted pedestrian trajectory.



The Road segmentation module distinguishes driving lanes from the sidewalk and outputs images with labelled road pixels. The module is usually handled by a Convolutional Neural Network (CNN), a Deep Learning Methodology.



The Pedestrian collision prediction module calculates the probability of a collision using the coordinates of a pedestrian bounding box, which are predicted and obtained from the object detector paired with the Kalman filter, and the road coordinates from the road segmentation module. If these coordinates of a pedestrian bounding box do not intersect with road coordinates, the vehicle and pedestrian collision is of zero-probability. In case of an intersection, the collision probability equals the ratio of the distance to the predicted pedestrian location and the distance of detected road available for the car.



Active safety technology for preventing pedestrian collisions is important to protect vulnerable road users and move toward zero-traffic-accident society. Using AI and ML solutions, OEMs built intelligent vehicles that can perceive and react to road conditions up to 99.8% which is better than human drivers.



Being an extra pair of eyes, a pedestrian collision prediction module addresses the challenge of monitoring hazardous blind spots for drivers of both private cars and large vehicles manoeuvring in narrow lanes and around people on foot. Once the possibility of hitting a pedestrian is detected, a driver will receive a visual and audio alert, thus getting more time to react. If the situation is defined as critical, the brakes will be applied automatically.



The advanced pedestrian trajectory prediction module will support automakers in enhancing the safety parameters of vehicles in urban, rural, and industrial environments. By equipping fleets with a pedestrian collision prediction module, companies will reduce incidents and associated costs and, most importantly, save lives.



3. High-Definition Maps and Cloud Data Platform for Autonomous Driving



One of the major requirement for Fully Automated Driving (FAD) is 3D HD Maps, the creation of the maps i.e. eliciting source data to creating and publishing the maps themselves. AI can support in this activity. The map development process is sequential and happens in five major stages:



Real-time streaming perception



An Edge Perception stack is developed that allows for HD map observations and crowd-sourced updates using vehicle-mounted sensor systems. The process involves detecting road features in video streams in real time. This dynamic data is then used in the development of self-healing maps. In case of any changes on the roads, maps are updated automatically, and the new map data is delivered to end users in real time.



Data collection



To build detailed and credible maps for navigation systems and custom solutions, accurate information on road attributes needs to be collected from around the globe. Data is gathered from mobile cameras, sensors, and GPS devices on the road to locate traffic lights, signs, poles, stop lines, lane markings, roadside barriers, junctions, etc.&nbsp;



Data aggregation, processing, and filtering



Engineers handle massive datasets from a variety of sources, including from core maps and on-vehicle sensor systems. All road image data is aggregated, processed, and filtered via a streaming file system for further validation and intelligent analysis using machine learning models. All data can be consumed in an NDS (Navigation Data Standard) format to avoid vendor lock-in and ensure interoperability across systems.



3D map creation and maintenance



Live 3D maps are compiled &amp; updated that enable precise positioning for lateral and longitudinal control of vehicles. These multi-layer maps contain details at several levels (roads, lanes, lane groups and individual lanes, geometry) and are constantly enriched with incoming information on new road attributes such as signs, markers, crosswalks, bicycle lanes, and objects.



Map delivery



Data-intensive HD maps are generated and delivered to customers online as a geographically tiled and functionally layered data service suitable for direct-to-vehicle and OEM cloud consumption. These maps are also an indispensable source of data for client’s many in-vehicle software development programs.



There would be many such tests and a huge number of algorithms running in the vehicle environment. All the stakeholders; Vehicle manufacturers, Technology providers, Govt. authorities, Academicians have their own share of work to support this humongous initiative.&nbsp;&nbsp;



Indian Research Universities / Institutes have a pivotal role to play. Currently, there is huge GAP between 'what we learn' and 'where we apply'. Industry and Service sectors in India would require a gross incremental workforce of  > 1.12 billion by 2050; India could potentially emerge as a global supplier of skilled manpower. Refer Figure 3: Workforce requirements by 2050 and Gap between Industry &amp; Academics. Going ahead the organizations anticipate a huge shortfall of qualified and skilled employees.  Since business strategies are not clear, there is a need to procure, control, retain and nurture talent. This may be the key to combat competition.







Author:




Dr. Ajay PalkarHead of Electrical &amp; ElectronicsŠKODA AUTO Volkswagen India




Ajay is an Industry recognized thought leader over 30+ years of Product design, Development &amp; Management consulting experience. An accomplished, performance driven &amp; focused professional having rich experience in Engineering &amp; Management mainly focusing Vehicle Integration (Mobility, Electrical &amp; Electronics), Systems Engineering, Project Management, Strategic Planning &amp; Business Development in Automotive, Defense, and Industrial Automation &amp; Instrumentation field. His core research area is Product Life Cycle &amp; Obsolescence, StrategicManagement and Project Management. He has published numerous papers on Technology &amp; Marketing Management, various patents &amp; memberships on his name. Ajay is currently associated with SKODA Auto Volkswagen India Pvt. Ltd. as Head – Electrical &amp; Electronics. In the past he was associated with esteemed organizations such as Mahindra &amp; Mahindra, Tata Motors, Bennett, Coleman, &amp; Co. Ltd., main roles &amp; responsibilities involved Solution Architecture, R&amp;D – Systems Engineering &amp; Technology, Strategic Management &amp; Pre-sales.



Published in Telematics Wire
",,Emerging Technologies,Artificial Intelligence and Machine Learning for Vehicle Engineering,,,,,"[{'@type': 'ListItem', 'position': 1, 'item': {'name': 'Home', '@id': 'https://www.telematicswire.net/'}}, {'@type': 'ListItem', 'position': 2, 'item': {'name': 'Views', '@id': 'https://www.telematicswire.net/category/interviews/'}}, {'@type': 'ListItem', 'position': 3, 'item': {'name': 'Emerging Technologies', '@id': 'https://www.telematicswire.net/category/interviews/emergingtech-interviews/'}}]",,,Artificial Intelligence and Machine Learning for Vehicle Engineering,#Breadcrumb,2021,{'@id': '#Publisher'},{'@id': '#Publisher'}
https://news.google.com/rss/articles/CBMicWh0dHA6Ly93d3cubmV3cy51Y3QuYWMuemEvYXJ0aWNsZS8tMjAyMS0wNi0wNy1hcHJvZi1tb29kbGV5LWpvaW5zLWljYS1vbi1pbnRlbGxpZ2VuY2UtYW5kLWFydGlmaWNpYWwtaW50ZWxsaWdlbmNl0gEA?oc=5,Assoc Prof Moodley joins ICA on intelligence and artificial intelligence - University of Cape Town News,2021-06-07,University of Cape Town News,http://www.news.uct.ac.za,UCT’s Associate Professor Deshen Moodley is one of just 19 international fellows selected to participate in the fourth Intercontinental Academia.,N/A,UCT’s Associate Professor Deshen Moodley is one of just 19 international fellows selected to participate in the fourth Intercontinental Academia.,UCT’s Associate Professor Deshen Moodley is one of just 19 international fellows selected to participate in the fourth Intercontinental Academia.,,,,,,,,,,,,N/A,N/A,N/A,,,,,,,,,,,,,,,,,
https://news.google.com/rss/articles/CBMiaWh0dHBzOi8vdXdhdGVybG9vLmNhL2FydHMtY29tcHV0aW5nLW5ld3NsZXR0ZXIvc3ByaW5nLTIwMjEvZmVhdHVyZS9hcnRpZmljaWFsLWludGVsbGlnZW5jZS1tdXNpYy1pbmR1c3RyedIBAA?oc=5,Artificial Intelligence in the Music Industry | Arts Computing Office Newsletter - University of Waterloo,2021-06-09,University of Waterloo,https://uwaterloo.ca,"Artificial intelligence is all around us whether we realize it or not. From creating new experimental tunes to reimagining the classics, AI has a large impact on the music that is produced today. With the demand for music to be made in multiple genres and countless elements that can be combined, it's no wonder why the industry is looking to AI to help create new music. AI in",N/A,"Artificial intelligence is all around us whether we realize it or not. From creating new experimental tunes to reimagining the classics, AI has a large impact on the music that is produced today. With the demand for music to be made in multiple genres and countless elements that can be combined, it's no wonder why the industry is looking to AI to help create new music. AI in music could revolutionize the music we listen to and unlock potentially new combinations that we have never thought of.","Artificial intelligence is all around us whether we realize it or not. From creating new experimental tunes to reimagining the classics, AI has a large impact on the music that is produced today.",,,,,,,,,,,,"Feature, Spring 2021",N/A,"













Spring 2021 

Artificial Intelligence in the Music Industry 

                                    Computing Intelligence to Musical Excellence                                

                                                                            Rabiya Majeed                                                                        


 Share:




 





Introduction
Artificial intelligence is all around us whether we realize it or not. Its impact goes beyond what we know as it continues to help make our lives easier and more personalized. But have you ever thought about how it affects an industry as big as music? From creating new experimental tunes to reimagining the classics, AI has a large impact on the music that is produced today. With the demand for music to be made in multiple genres and countless elements that can be combined, it's no wonder why the industry is looking to AI to help create new music. AI in music could revolutionize the music we listen to and unlock potentially new combinations that we have never thought of. For example, with such a high demand for new music many people have created programs that creates background music so that creators have access to affordable new music that fits the mood that they are going for [1]. Moreover, AI has been used to mimic sounds of known musicians. Notably, an AI generated Bach composition, which was indifferentiable by the public [1] from an original Bach piece. 
AI Infused Music
But what does this mean for music makers and listeners? Will AI allow us to reach sounds and genres not yet explored, or will it make it so that we’re always listening to the same generic pop beat? These are some things to consider when looking into the impact of AI on the music industry. Currently, AI music composition works with an algorithm that is fed examples of certain music. The AI then creates music that resembles what it was fed [3]. Here’s a fun example of this: the song “Daddy’s Car“ was made through AI composition by Sony’s computer science laboratory music team based in Tokyo Japan. It was made to sound like a Beatles song. - https://www.youtube.com/watch?v=LSHZ_b05W7o [3]. Many feel that AI in the music industry will open up many new avenues in music production including a “golden era of creativity” as the AI will be able to combine sounds and genres in ways that was unthought of before. This would allow artists to produce music that goes beyond known genres and reach an entirely new level of personalization. Claire. L. Evans from the band YACHTs says that “AI forced us to come up against patterns that have no relationship to comfort. It gave us the skills to break out of our own habits,” inspiringly the use of AI in YACHTs music got them their very first Grammy nomination for best immersive album![1]. 
On the other hand, the legality around AI produced music is truly obscure. Whether the creator of the algorithm, the AI itself, or the owner of the music that the AI was trained on is the owner of the piece created by the ai continues to create a lot of ambiguity as to how AI will be used going forward. Policy counsel Meredith Rose states “There’s nothing legally requiring you to give the artist any profits from it unless you’re directly sampling,” So what would this mean for established and upcoming artists trying to make their way through the industry? Would this hinder their creative processes?  AI could be used to create the next hit pop song by using old popular songs as data and creating a similar composition, thus being able to replace actual artists. Moreover, other issues that may arise include marketing songs as being similar to songs of an artist in order to get more traction. This may result in artists having a difficult time proving that a song is meant to sound like theirs. Unless they know exactly what the AI was trained on, it would be difficult to work backwards as it is very hard to extrapolate the original data that was given to the AI [2]. 
Conclusion
All in all, there are many positives to having artificial intelligence in the music industry; it helps feed the growing demand of new music in many different genres, and it allows artist to experiment with new sounds and explore never before heard combinations. On the other hand, it brings up serious ambiguities that lie in our legal systems regarding the use of artificial intelligence and intellectual property of artists. Although looking to the future, AI will allow music production to be a lot more widespread and at a lower cost allowing for an age of music that transcends the genres and sounds we know today. 
References
[1] Chow, A. R. (2020, February 05). Musicians Using AI to Create Otherwise Impossible New Songs. Retrieved from https://time.com/5774723/ai-music/ 
[2] Deahl, D. (2019, April 17). We've been warned about AI and music for over 50 years, but no one's prepared. Retrieved from https://www.theverge.com/2019/4/17/18299563/ai-algorithm-music-law-copyright-human 
[3] Marr, B. (2019, July 09). The Amazing Ways Artificial Intelligence Is Transforming The Music Industry. Retrieved from https://www.forbes.com/sites/bernardmarr/2019/07/05/the-amazing-ways-artificial-intelligence-is-transforming-the-music-industry/?sh=4c585fa55072 
 

 

 Share:




 










Related Articles












Read More






Apple’s Electric Vehicle 
Production Rumored to Start in 2024











Read More






Technology for the Bees: The Beewise Beehome 
Saving the Bees through AI Technology











Read More






Five Helpful Sites for Students
Make Your University Experience Easier











Read More






Talent Search of the Future
Using Cognitive Science and Games to Help Select Future Employees











Read More






How will 5G Technology Change Our Daily Life?
Connecting Your Future











Read More






Robinhood: A Rising FinTech Star in North America
Bringing Stock Trading to the People











Read More






Pros and Cons of the Self-Checkout Technology
Save Time, Serve Yourself











Read More






Professor Spotlight: Elizabeth Demers
Professor, Financial Accounting, Approved Doctoral  Dissertation Supervisor











Read More






Data-Sharing within Social Media: A Call to Action 
Are You Aware of the Tabs Companies are Keeping on You?











Read More






Technological Masks
Smarter, Safer, and more Unique











Read More






The Rise of Telemedicine
Healthcare at Your Fingertips











",,,,,,,,,,,,,,,,,
https://news.google.com/rss/articles/CBMie2h0dHBzOi8vd3d3LmF1c3RyYWxpYW5yZXNvdXJjZXNhbmRpbnZlc3RtZW50LmNvbS5hdS8yMDIxLzA2LzA3L2V0aGljYWwtY29uc2lkZXJhdGlvbnMtb2YtYXJ0aWZpY2lhbC1pbnRlbGxpZ2VuY2UtaW4tbWluaW5nL9IBAA?oc=5,Ethical considerations of artificial intelligence in mining - Australian Resource & Investment,2021-06-07,Australian Resource & Investment,https://www.australianresourcesandinvestment.com.au,N/A,N/A,"IBM data insights and AI practice leader, Abhishek Kaul, and Vale global AI projects leader, Ali Soofastaei look at what",N/A,https://schema.org,,,,,,,,,,,Features,N/A,"


Features, Opinion
Ethical considerations  of artificial intelligence in mining
Staff WriterJune 7, 2021, 5:03 pmJune 24, 2021 

       

 


digital illustration of futuristic view of an observing showcase room look out to mining site with huge spaceship in background

By IBM data insights and AI practice leader, Abhishek Kaul, and Vale global AI projects leader, Ali Soofastaei
In recent years, there has been increased attention on the possible impact of future robotics and artificial intelligence (AI) systems.
Prominent thinkers have publicly warned about the risk of a dystopian future when the complexity of these systems progresses further. These warnings stand in contrast to the current state-of-the-art robotics and AI technology.
Digital transformation and applied automation are growing fast in the mining industry. It is essential to adapt to the mining industry with the related innovations, which play critical roles in the digital revolution.

The core of these innovations is applied machine learning (ML) and AI across the mining value chain.
Many of us would assume that the mining industry would have driven advances in robotics, automation, AI and ML due to the remote mine sites, the hazardous nature of the work and the high costs of labour and transport.
However, it is the manufacturing sector that has spearheaded most of the technological developments, but it is now the mining sector that is taking advantage of those proven technologies to help boost its recovery after a significant downturn.
In today’s highly efficient mining operations, making the right decisions depends on their 360-degree visibility of the business and the market, combined with accurate demand forecasting.

With huge footprints in remote locations, diverse labour forces, and complex and time-consuming projects, mining companies are using enterprise resource planning (ERP) and advanced analytics systems as the technology backbone to their businesses.
ML and AI are the main part of an advanced data analytics approach, which is increasingly being relied on to make decisions about people, processes and technologies, be it accessing worker productivity to explore the next mine site or predict to schedule equipment for maintenance.
Although AI and ML-based analytics are delivering results, its recommendations for people-based decisions are subject to ethical considerations. Issues arise if AI and ML models have a bias based on gender, age or ethnicity and is not fair in providing recommendations.

There are multiple AI policy guidelines available from the United States, Europe and Asia to help organisations ensure that they build and use ethical AI.
This article discusses AI use cases in the mining industry with ethical considerations, reviews critical challenges and potential bias mitigation strategies.
Understanding ethics in AI 
AI is intelligence demonstrated by machines, unlike the natural intelligence displayed by humans. AI refers to systems that display intelligent behaviour by analysing and interpreting the data, learning patterns in data, provide reasoning and recommendations, and optionally take actions with some degree of autonomy to achieve trained goals.

AI systems work very well at use cases where they involve recognising patterns with large quantities of data. AI systems work best together with people, and it is important to understand that AI requires reskilling people, not replacing them.
There are many AI techniques like supervised learning, unsupervised learning, reinforcement learning, transfer learning, knowledge graphs, reasoning systems, and more.
Many of these techniques depend on ML. For example, the ability to automatically learn from historical patterns in data and improve performance over time.
The difference between AI and ML can be a little confusing. Figure 1 (below) illustrates the general boundaries between these concepts.


AI in the mining industry
Mining is a complex and fluctuating industry that is fraught with uncertainty around resource pricing, unpredictable resource fields and major projects that need to be managed right through their lifecycle.

Controlling costs for mineral exploration, construction and operation right through to project completion is a monumental challenge, but if the financial elements are managed well, it can help mining companies to be both competitive and profitable.
The key to increasing profits is knowing the precise time to increase production when there is strong demand using resource planning, improving the reliability of machinery with predictive and condition-based maintenance monitoring, delivering clarity with precise financial and operational reporting, and at the same time, providing actionable insights using real-time data extracted from every part of the organisation.
There are considerable benefits of using an AI system to improve the quality of work at a mine site and reduce the human failures and hazards.
AI use cases have been applied across the complete mining industry value chain from exploration, mine management, extraction, processing and transportation.

Data is fed into the AI systems. The data comes from a variety of sources like equipment, shift log, operator manuals, operator wearable, CCTV cameras, HR systems, shift rosters and more.
Although ML and AI, by their very nature, are always a form of statistical discrimination, the discrimination becomes objectionable when it places certain privileged groups at the systematic advantage and certain unprivileged groups at a systematic disadvantage.
Objectionable discriminations arise due to multiple reasons in the mining industry. The main reasons are:
Defining the business objective of the machine learning problem – for example, if the business objective is defined as maximum throughput without consideration for maintenance or safety aspects.
Unrepresentative data or data with existing prejudice for training – for example, if the AI model training data has been selected from a mine site where the demographic of the population is from the older age group.
Selecting the attributes or features for the ML model – for example, if in building the AI model, operator ethnicity has been included as a data point mobile mine equipment operator behaviour.
This article focuses on three main use cases of AI in mining:
Energy: ethics in reducing fuel consumption
Maintenance: ethics in predictive maintenance
Safety: ethics in using surveillance video (CCTV) for safety.
Policy guidelines for ethical AI 
Many countries have published AI policy guidelines. These guidelines provide a broad level objective for the use of AI – to ensure human-centric, safe and trustworthy AI.
Most guidelines make the organisation using AI responsible and accountable for their decisions and ask for the same ethical standards in AI-driven decisions as in human-driven decisions.
General key points achieved from global guidelines are:
It should be lawful, complying with all applicable laws and regulations.
It should be ethical, ensuring adherence to ethical principles and values.
It should be robust, both from a technical and social perspective since, even with good intentions, AI systems can cause unintentional harm.
To ensure compliance with ethical guidelines, AI models need three capabilities.
Explainability – An ability to explain the behaviour of the black box AI model. Multiple algorithms help to explain the model. For example, decision tree rules if A > 50, then stop else continue, are easily understood by people.
Fairness – The ability of AI models to report and mitigate discrimination and bias. Depending on the application of the AI model, the appropriate bias metrics should be reported. For example, for hiring, a false-positive (someone unfit for the job is employed) is less harmful than a false negative (someone fit for the job is denied). Further, bias mitigation algorithms can be applied to improve the fairness metrics by modifying the training data, the learning algorithm, the predictions, the optimisation or the making decision models.
Transparency – The ability of the model to be transparent on training data, accuracy and performance, bias and fairness metrics so that users can understand how AI was trained and deployed.
AI use cases with ethical consideration for the mining industry 
In this section, three use case details are presented with ethical consideration for AI in the areas of energy, maintenance and safety.
It is important to understand that AI is not about replacing people, but reskilling people and deployment of AI applications will improve the quality of work at a mine and reduce the human failures, hazards at the site.
Use Case 1: AI application for energy efficiency – ethics in reducing fuel consumption (consideration – operator demographics)
Fuel is an important cost contributor for haul trucks in surface mining. Multiple parameters affect fuel consumption like the type of truck, payload, distance, hours, weather and operator behaviour (includes speed, manoeuvring, acceleration and braking).
AI techniques like Artificial Neural Networks (ANNs) are generally applied to data to understand the top factors influencing fuel consumption and recommend changes to controllable factors, thereby reducing fuel consumption per tonne of ore mined by using a genetic algorithm (GA) in the optimisation phase of the project.

One of the predictors for haul truck fuel consumption is the operator (driver) behaviour. If demographic data points of a driver are included as attributes or features, then the AI model will identify patterns in demographic data that influence operator behaviour.
Depending on the training data set, for example, country, mine site, or number of operators, this analysis may have bias and may not hold true for the general case. Maybe the model can get biased to predict low fuel consumption for older male workers based on one mine site operation.
In such applications, it is recommended not to include demographic data in the analysis and rely solely on the unique mine equipment operator identifier. Unless essential, if the use of demographic data is needed, de-biasing techniques like reweighing, adversarial de-biasing should be applied with visibility on fairness metrics like statistical parity difference, Thiel index, and more should be enforced.
Ideally, the business objective of the AI model should be finetuned to provide guidelines to an operator to influence their behaviour – like speed, acceleration, etc, and provide a mechanism to monitor for deviations in operator actions to AI recommendations.
Use case 2: AI application in maintenance – Ethics in predictive maintenance (consideration – operator shift logs / NLP)
Equipment downtime significantly affects the productivity and safety of mining operations. The main goal of predictive maintenance is to shift the unplanned breakdowns to planned maintenance activities, increase the equipment lifetime, optimise maintenance schedules and ensure safe operations.
AI techniques in machine learning like cox regression, logistic regression, gradient boosting, neural nets are applied to predict the remaining useful life (RUL) and predict the health score of equipment using historical maintenance data.
Further, natural language processing (NLP) techniques like Word2Vec, BERT are applied on operator shift logs to gain a deeper understanding of operational events like faults, trips, overriding, noise, resetting observed, actioned and documented by the operator, which are then co-related to maintenance failures to provide deeper insights.

One of the data points used in the analysis to discuss further is the operator shift logs. Operator privacy is one of the considerations for analysing logs. However beyond privacy, when analysing operator logs, if language linguistics analysis is used for deciphering personal traits, personal attributes – like modelling and then to co-relate maintenance failures – inclusion of bias becomes a relevant topic and it is subject to ethical considerations.
In such applications, it is recommended to use the co-relation of events (nouns, verbs) with maintenance failures for providing slack time in operation for operators to do necessary maintenance inspections.
Further, it is recommended to de-bias the NLP models, which may cause some drop-in accuracy points but helps to keep the recommendations fair.
Use case 3:  AI application in safety – Ethics in using surveillance video (CCTV) for safety (consideration – surveillance video data)
Video surveillance data (CCTV cameras) are used in many work areas to ensure the security and safety of the site. Typically, hundreds of cameras feed data to the site security/safety office.
Since it is not possible to review the feed from all cameras in real-time by the human operator, the use case for video surveillance trends towards post-facto video retrieval and analysis for historical incidents, disputes.
With advancements in computer vision technologies, AI models are trained with the surveillance video feed to perform automated analysis for object detection, object classification, object tracking, and raise proactive alerts in real-time to detect and mitigate any safety or security violations.

Surveillance is itself an ethically neutral concept. What determines the ethical nature of a particular instance of surveillance will be the considerations which follow, such as justified cause, the means employed and questions of proportionality.
While it can be argued that monitoring remotely via a camera is no different from historical times when security personnel were physically present at the worksite, there are local privacy laws and regulations which must be complied with while using surveillance, face recognition technologies.
AI technologies in computer vision are leapfrogging every few months, like being able to understand the Spatio-temporal relationships of objects, which can be used to monitor people’s behaviour based on the change of posture, time of day, relationship with equipment, movement between areas, and more.
Ethical considerations when employing AI for surveillance monitoring should have a balance between workers privacy-trust-autonomy and workers’ safety-security-behaviour.
Conclusion
Understanding the implications of ethics in AI is important for mining companies to remain fair to their workforce as they are in human-driven decisions.
Mining companies should adopt and build AI solutions that follow leading policy guidelines and are explainable, transparent and fair. Further, when evaluating the AI solution, they should understand how the solution has built the data used in training the AI models.
In order to enforce ethical considerations for AI, mining companies can appoint an AI ethics officer or committee for the review of each AI application being developed or purchased from vendors and request disclosure on the fairness, explainability and transparency metrics.
References
https://en.wikipedia.org/wiki/Ethics_of_artificial_intelligence#cite_ref-90 
https://plato.stanford.edu/entries/ethics-ai/ 
https://www.pdpc.gov.sg/-/media/files/pdpc/pdf-files/resource-for-organisation/ai/sgmodelaigovframework2.pdf 
https://www.pdpc.gov.sg/Help-and-Resources/2020/01/Model-AI-Governance-Framework 
Soofastaei Ali, and et al. “Reducing Fuel Consumption of Haul Trucks in Surface Mines Using Genetic Algorithm,” Applied Soft Computing Journal, Under Press (2020).
Soofastaei Ali, and et al. “The Effect of Average Truck Speed on Fuel Consumption in Surface Mines,” Mining Journal, Volume 4, Issue 2, (2016), P:92-94.
Everyday Ethics for Artificial Intelligence – IBM
https://www.weforum.org/agenda/2016/10/top-10-ethical-issues-in-artificial-intelligence/ 
https://wef-ai.s3.amazonaws.com/WEF_Empowering-AI-Leadership_Ethics_Appendix-1.pdf 
https://www.scu.edu/ethics-in-technology-practice/ethical-toolkit/ 



Share this article       
































Premium Ad






                    2013 HYUNDAI 520LC-9                


                            $128,000                        








Location marker
The shape of a location marker



                                Mulgoa, NSW                            








Premium Ad






                    2008 VOLVO EC460CL EC                


                            $250,000                        








Location marker
The shape of a location marker



                                Horsley Park, NSW                            








Premium Ad






                    2011 KOMATSU PC850-8EOSE                


                            $379,500                        








Location marker
The shape of a location marker



                                Canning Vale, WA                            








Premium Ad






                    XCMG XE490DK                


                            $390,000                        








Location marker
The shape of a location marker



                                Dandenong South, VIC                            


Delivery NSW,QLD








Premium Ad






                    2016 HYUNDAI R480-9                


                            $143,000                        








Location marker
The shape of a location marker



                                Muswellbrook, NSW                            








Premium Ad






                    HIDROMEK HMK 500 LC HD                


                            POA                        








Location marker
The shape of a location marker



                                Hallam, VIC                            








Premium Ad






                    2018 HIDROMEK HMK490LCHD                


                            POA                        
per week (HIRE)








Location marker
The shape of a location marker



                                Bridgewater, TAS                            








Premium Ad






                    2018 CATERPILLAR 352FL                


                            POA                        








Location marker
The shape of a location marker



                                Dandenong South, VIC                            








Premium Ad






                    2018 HIDROMEK HMK490LCHD                


                            POA                        
per week (HIRE)








Location marker
The shape of a location marker



                                Rocklea, QLD                            










                    2013 KOMATSU PC450LC-8                


                            $139,000                        








Location marker
The shape of a location marker



                                Cranbourne North, VIC                            










                    2021 CATERPILLAR 349LC NEXT GEN 07C                


                            $462,000                        








Location marker
The shape of a location marker



                                Glenvale, QLD                            










                    2020 KOMATSU PC490LC_11                


                            $385,000                        








Location marker
The shape of a location marker



                                Sherwood, QLD                            







Read Next
How gold protects investors from ‘higher-for-longer’ inflation






Jupiter shoots for the stars






Hydrogen or battery: Achieving a decarbonised mine






The next string of Australian copper miners






 

artificial intelligenceIBMtechnologyvirtual reality Previous ArticleBuilding investor trust through M&ANext ArticleTerramin offloads project interest to Newmont









","[{'@type': 'WebPage', '@id': 'https://www.australianresourcesandinvestment.com.au/2021/06/07/ethical-considerations-of-artificial-intelligence-in-mining/', 'url': 'https://www.australianresourcesandinvestment.com.au/2021/06/07/ethical-considerations-of-artificial-intelligence-in-mining/', 'name': 'Ethical considerations of artificial intelligence in mining - Australian Resources &amp; Investment', 'isPartOf': {'@id': 'https://www.australianresourcesandinvestment.com.au/#website'}, 'primaryImageOfPage': {'@id': 'https://www.australianresourcesandinvestment.com.au/2021/06/07/ethical-considerations-of-artificial-intelligence-in-mining/#primaryimage'}, 'image': {'@id': 'https://www.australianresourcesandinvestment.com.au/2021/06/07/ethical-considerations-of-artificial-intelligence-in-mining/#primaryimage'}, 'thumbnailUrl': 'https://www.australianresourcesandinvestment.com.au/wp-content/uploads/2021/06/ARI_AIinminestiles.jpg', 'datePublished': '2021-06-07T07:03:39+00:00', 'dateModified': '2021-06-24T04:56:03+00:00', 'author': {'@id': 'https://www.australianresourcesandinvestment.com.au/#/schema/person/c7304f930955d607e2076468595aa877'}, 'breadcrumb': {'@id': 'https://www.australianresourcesandinvestment.com.au/2021/06/07/ethical-considerations-of-artificial-intelligence-in-mining/#breadcrumb'}, 'inLanguage': 'en-US', 'potentialAction': [{'@type': 'ReadAction', 'target': ['https://www.australianresourcesandinvestment.com.au/2021/06/07/ethical-considerations-of-artificial-intelligence-in-mining/']}]}, {'@type': 'ImageObject', 'inLanguage': 'en-US', '@id': 'https://www.australianresourcesandinvestment.com.au/2021/06/07/ethical-considerations-of-artificial-intelligence-in-mining/#primaryimage', 'url': 'https://www.australianresourcesandinvestment.com.au/wp-content/uploads/2021/06/ARI_AIinminestiles.jpg', 'contentUrl': 'https://www.australianresourcesandinvestment.com.au/wp-content/uploads/2021/06/ARI_AIinminestiles.jpg', 'width': 800, 'height': 478, 'caption': 'digital illustration of futuristic view of an observing showcase room look out to mining site with huge spaceship in background'}, {'@type': 'BreadcrumbList', '@id': 'https://www.australianresourcesandinvestment.com.au/2021/06/07/ethical-considerations-of-artificial-intelligence-in-mining/#breadcrumb', 'itemListElement': [{'@type': 'ListItem', 'position': 1, 'name': 'Home', 'item': 'https://www.australianresourcesandinvestment.com.au/'}, {'@type': 'ListItem', 'position': 2, 'name': 'Ethical considerations of artificial intelligence in mining'}]}, {'@type': 'WebSite', '@id': 'https://www.australianresourcesandinvestment.com.au/#website', 'url': 'https://www.australianresourcesandinvestment.com.au/', 'name': 'Australian Resources &amp; Investment', 'description': 'Presented by Prime Creative Media', 'potentialAction': [{'@type': 'SearchAction', 'target': {'@type': 'EntryPoint', 'urlTemplate': 'https://www.australianresourcesandinvestment.com.au/?s={search_term_string}'}, 'query-input': 'required name=search_term_string'}], 'inLanguage': 'en-US'}, {'@type': 'Person', '@id': 'https://www.australianresourcesandinvestment.com.au/#/schema/person/c7304f930955d607e2076468595aa877', 'name': 'Staff Writer', 'image': {'@type': 'ImageObject', 'inLanguage': 'en-US', '@id': 'https://www.australianresourcesandinvestment.com.au/#/schema/person/image/', 'url': 'https://secure.gravatar.com/avatar/59a4086841350d8ee774c018b17a9225?s=96&d=mm&r=g', 'contentUrl': 'https://secure.gravatar.com/avatar/59a4086841350d8ee774c018b17a9225?s=96&d=mm&r=g', 'caption': 'Staff Writer'}, 'url': 'https://www.australianresourcesandinvestment.com.au/author/pcm_admin/'}]",,,,,,,,,,,,,,,,
https://news.google.com/rss/articles/CBMiggFodHRwczovL3d3dy5udHUuZWR1LnNnL21hZS9uZXdzLWV2ZW50cy9uZXdzL2RldGFpbC9uZXctYXJ0aWZpY2lhbC1pbnRlbGxpZ2VuY2UtY291bGQtc3BlZWQtdXAtZGlhZ25vc2lzLW9mLWNhcmRpb3Zhc2N1bGFyLWRpc2Vhc2Vz0gEA?oc=5,New artificial intelligence could speed up diagnosis of cardiovascular diseases - Nanyang Technological University,2021-06-09,Nanyang Technological University,https://www.ntu.edu.sg,NTU MAE's Prof Eddie Ng co-leads the invention of a new articial intelligence tool. ,N/A,NTU MAE's Prof Eddie Ng co-leads the invention of a new articial intelligence tool. ,N/A,https://schema.org,NewsArticle,,,,2021-06-09,,,,['https://www.ntu.edu.sg/images/librariesprovider122/outreach-photo/eddie-ng911ad490-785f-4bf3-8229-17cc16d8ffa2.jpg?sfvrsn=420e782c_3'],,N/A,N/A,"

Published on 09 Jun 2021
New artificial intelligence could speed up diagnosis of cardiovascular diseases



A team of researchers from NTU, Ngee Ann Polytechnic, and National Heart Centre Singapore, have invented a new artificial intelligence tool. NTU MAE’s Assoc Prof Eddie Ng Yin Kwee, is one of the co-leads of the study. The device uses a machine learning algorithm, which mimics the structure and function of the human brain, and can speed up the diagnosis of cardiovascular diseases and can help detect patterns in electrocardiograms (ECGs) and diagnose conditions such as coronary artery disease, myocardial infarction, and congestive heart failure, with an accuracy of more than 98.5 percent. The study was published in the peer-reviewed scientific journal Computers in Biology and Medicine in May. The team will now work with local hospitals to conduct further trials of their AI tool for clinical use by validating their results with a larger database of patients.https://www.ntu.edu.sg/docs/default-source/corporate-ntu/hub-news/new-artificial-intelligence-tool-invented-by-ntu-np-and-nhcs-scientists-could-speed-up-diagnosis-of-cardiovascular-diseases78bcc0d4-268e-4e81-9885-44ddb462571e.pdf?sfvrsn=26fa5e92_3&fbclid=IwAR2INMeMwJptwehx5DFkaQdhphqj9xYdAk1FCLKZUx5RjH9ocdEvUgBCqkAhttps://www3.ntu.edu.sg/CorpComms2/Releases/NR2021/NR_210608_ECG/Automated%20detection%20of%20cardiocvascular%20disease%20with%20ECG%20signals.pdf?fbclid=IwAR12E7ZlJx4mBtfhMDMrFyevjSTX32Y-EyRN782WY1e51pBWRHsPY0a7VAY




Share:


















Related Topics

Achievements
Faculty & Staff


",,,,,New artificial intelligence could speed up diagnosis of cardiovascular diseases,,,,,,,,,,,,
https://news.google.com/rss/articles/CBMiWmh0dHBzOi8va2VueWFud2FsbHN0cmVldC5jb20va2VueWEtZ292dC1zZXRzLWJsb2NrY2hhaW4tYXJ0aWZpY2lhbC1pbnRlbGxpZ2VuY2UtdGFza2ZvcmNlL9IBAA?oc=5,Kenya Govt Sets up Blockchain & Artificial Intelligence Taskforce! - Kenyan Wallstreet,2021-06-07,Kenyan Wallstreet,https://kenyanwallstreet.com,N/A,N/A,January 18 2018; The Government has began setting up a taskforce that will work on a comprehensive strategy to encourage and adopt emerging technologies such as Blockchain and artificial intelligence […],N/A,https://schema.org,,,,,,,,,,,N/A,N/A,"  Court Blocks KRA from Charging VAT on Golf Club Memberships July 17, 2024","[{'@type': 'Article', '@id': 'https://kenyanwallstreet.com/kenya-govt-sets-blockchain-artificial-intelligence-taskforce/#article', 'isPartOf': {'@id': 'https://kenyanwallstreet.com/kenya-govt-sets-blockchain-artificial-intelligence-taskforce/'}, 'author': [{'@id': 'https://kenyanwallstreet.com/#/schema/person/1c9ab483d46039b092c531b7d05b03da'}], 'headline': 'Kenya Govt Sets up Blockchain &#038; Artificial Intelligence Taskforce!', 'datePublished': '2018-01-16T12:59:31+00:00', 'dateModified': '2021-06-07T06:17:52+00:00', 'mainEntityOfPage': {'@id': 'https://kenyanwallstreet.com/kenya-govt-sets-blockchain-artificial-intelligence-taskforce/'}, 'wordCount': 433, 'publisher': {'@id': 'https://kenyanwallstreet.com/#organization'}, 'image': {'@id': 'https://kenyanwallstreet.com/kenya-govt-sets-blockchain-artificial-intelligence-taskforce/#primaryimage'}, 'thumbnailUrl': 'https://kenyanwallstreet.com/wp-content/uploads/2018/01/Blockchain.jpg', 'keywords': ['Blockchain Kenya', 'spotlight two'], 'articleSection': ['Kenyan News'], 'inLanguage': 'en-US'}, {'@type': 'WebPage', '@id': 'https://kenyanwallstreet.com/kenya-govt-sets-blockchain-artificial-intelligence-taskforce/', 'url': 'https://kenyanwallstreet.com/kenya-govt-sets-blockchain-artificial-intelligence-taskforce/', 'name': 'Kenya Govt Sets up Blockchain & Artificial Intelligence Taskforce! - Kenyan Wall Street - African Business and Global Finance', 'isPartOf': {'@id': 'https://kenyanwallstreet.com/#website'}, 'primaryImageOfPage': {'@id': 'https://kenyanwallstreet.com/kenya-govt-sets-blockchain-artificial-intelligence-taskforce/#primaryimage'}, 'image': {'@id': 'https://kenyanwallstreet.com/kenya-govt-sets-blockchain-artificial-intelligence-taskforce/#primaryimage'}, 'thumbnailUrl': 'https://kenyanwallstreet.com/wp-content/uploads/2018/01/Blockchain.jpg', 'datePublished': '2018-01-16T12:59:31+00:00', 'dateModified': '2021-06-07T06:17:52+00:00', 'breadcrumb': {'@id': 'https://kenyanwallstreet.com/kenya-govt-sets-blockchain-artificial-intelligence-taskforce/#breadcrumb'}, 'inLanguage': 'en-US', 'potentialAction': [{'@type': 'ReadAction', 'target': ['https://kenyanwallstreet.com/kenya-govt-sets-blockchain-artificial-intelligence-taskforce/']}]}, {'@type': 'ImageObject', 'inLanguage': 'en-US', '@id': 'https://kenyanwallstreet.com/kenya-govt-sets-blockchain-artificial-intelligence-taskforce/#primaryimage', 'url': 'https://kenyanwallstreet.com/wp-content/uploads/2018/01/Blockchain.jpg', 'contentUrl': 'https://kenyanwallstreet.com/wp-content/uploads/2018/01/Blockchain.jpg', 'width': 600, 'height': 370}, {'@type': 'BreadcrumbList', '@id': 'https://kenyanwallstreet.com/kenya-govt-sets-blockchain-artificial-intelligence-taskforce/#breadcrumb', 'itemListElement': [{'@type': 'ListItem', 'position': 1, 'name': 'Home', 'item': 'https://kenyanwallstreet.com/'}, {'@type': 'ListItem', 'position': 2, 'name': 'Kenya Govt Sets up Blockchain &#038; Artificial Intelligence Taskforce!'}]}, {'@type': 'WebSite', '@id': 'https://kenyanwallstreet.com/#website', 'url': 'https://kenyanwallstreet.com/', 'name': 'The Kenyan Wall Street', 'description': 'The Thinking Behind The Investors', 'publisher': {'@id': 'https://kenyanwallstreet.com/#organization'}, 'potentialAction': [{'@type': 'SearchAction', 'target': {'@type': 'EntryPoint', 'urlTemplate': 'https://kenyanwallstreet.com/?s={search_term_string}'}, 'query-input': 'required name=search_term_string'}], 'inLanguage': 'en-US'}, {'@type': 'Organization', '@id': 'https://kenyanwallstreet.com/#organization', 'name': 'The Kenyan Wall Street', 'url': 'https://kenyanwallstreet.com/', 'logo': {'@type': 'ImageObject', 'inLanguage': 'en-US', '@id': 'https://kenyanwallstreet.com/#/schema/logo/image/', 'url': 'https://kenyanwallstreet.com/wp-content/uploads/2024/05/TKWS-Logo.jpg', 'contentUrl': 'https://kenyanwallstreet.com/wp-content/uploads/2024/05/TKWS-Logo.jpg', 'width': 2000, 'height': 500, 'caption': 'The Kenyan Wall Street'}, 'image': {'@id': 'https://kenyanwallstreet.com/#/schema/logo/image/'}, 'sameAs': ['https://www.facebook.com/kenyanwalstreet/', 'https://x.com/kenyanwalstreet', 'https://www.linkedin.com/company/kenyanwallstreet/']}, {'@type': 'Person', '@id': 'https://kenyanwallstreet.com/#/schema/person/1c9ab483d46039b092c531b7d05b03da', 'name': 'Kenyan WallStreet', 'image': {'@type': 'ImageObject', 'inLanguage': 'en-US', '@id': 'https://kenyanwallstreet.com/#/schema/person/image/c98223e6b45c260c700ca766977cf785', 'url': 'https://secure.gravatar.com/avatar/d01326c97bfd4b35aa7ab21d2fd59771?s=96&d=mm&r=g', 'contentUrl': 'https://secure.gravatar.com/avatar/d01326c97bfd4b35aa7ab21d2fd59771?s=96&d=mm&r=g', 'caption': 'Kenyan WallStreet'}, 'description': 'The Kenyan Wallstreet is probably the most visible digital business news brand in Kenya and the East Africa Region. Our editorial team goes beyond the headlines making us the most revered source of business and finance news in the region – outside of traditional media.', 'sameAs': ['http://www.kenyanwallstreet.com', 'https://www.facebook.com/The-Kenyanwallstreet-730915313642042', 'https://www.instagram.com/kenyan_wallstreet/', 'https://www.linkedin.com/company/kenyanwallstreet/?miniCompanyUrn=urnlifs_miniCompany10298312&lipi=urnlipaged_flagship3_companyrdf9XHdeSIWL1TasOoXoYQ&licu=urnlicontrold_flagship3_company-actor_container&lici=4mxWcRnOlJ8Vnh23uR4tLw', 'https://x.com/https://twitter.com/kenyanwalstreet', 'https://www.youtube.com/channel/UCgrAIOyT2rROw4NRIx3b-Wg'], 'url': 'https://kenyanwallstreet.com/author/easuma/'}]",,,,,,,,,,,,,,,,
https://news.google.com/rss/articles/CBMib2h0dHBzOi8vaG9tZWdyb3duLmNvLmluL3Byb21vdGVkLzUtaW5kaWFuLWNvbXBhbmllcy1hcmUtdXNpbmctYWktdG8tdHJhbnNmb3JtLWVkdWNhdGlvbi1oZWFsdGhjYXJlLWNsZWFuLWVuZXJnedIBcGh0dHBzOi8vaG9tZWdyb3duLmNvLmluL2FtcC9zdG9yeS81LWluZGlhbi1jb21wYW5pZXMtYXJlLXVzaW5nLWFpLXRvLXRyYW5zZm9ybS1lZHVjYXRpb24taGVhbHRoY2FyZS1jbGVhbi1lbmVyZ3k?oc=5,"5 Indian Companies Are Using AI To Transform Education, Healthcare & Clean Energy - Homegrown",2021-06-08,Homegrown,https://homegrown.co.in,,"AI Innovation,Startup,Healthcare,describe a product which is based on artificial intelligence,applications of ai,ai innovation companies,indian startups AI,the solar labs,chimple,AI in education,AI in drone mapping,AI,Machine Learning,artificial,AI learning,what is AI,what is artificial intelligence,AI meaning,deep learning,artificial intelligence projects,AI and machine learning,artificial intelligence meaning,artificial intelligence",Humanity has arrived at a unique crossroads by integrating Artificial Intelligence with most day-to-day applications in every walk of life. Even though until a ,Humanity has arrived at a unique crossroads by integrating Artificial Intelligence with most day-to-day applications in every walk of life. Even though until a ,http://schema.org,NewsArticle,https://homegrown.co.in/5-indian-companies-are-using-ai-to-transform-education-healthcare-clean-energy,"{'@type': 'Organization', '@context': 'http://schema.org', 'name': 'Homegrown', 'url': 'https://homegrown.co.in', 'logo': {'@context': 'http://schema.org', '@type': 'ImageObject', 'author': 'homegrown', 'contentUrl': 'https://images.assettype.com/homegrown/2022-06/0a4fac02-4313-40da-b925-a00bff37370d/white_copy.png', 'url': 'https://images.assettype.com/homegrown/2022-06/0a4fac02-4313-40da-b925-a00bff37370d/white_copy.png', 'name': 'logo', 'width': '', 'height': ''}, 'sameAs': ['https://www.instagram.com/homegrownin/', 'https://www.facebook.com/HomegrownIn/', 'https://www.youtube.com/user/HomegrownIn', 'https://www.linkedin.com/company/homegrown-media/', 'https://twitter.com/homegrownin'], 'id': 'https://homegrown.co.in'}","{'@type': 'WebPage', '@id': 'https://homegrown.co.in/5-indian-companies-are-using-ai-to-transform-education-healthcare-clean-energy'}",2021-06-08T12:27:53Z,2021-06-08T12:27:53Z,2020-04-11T09:17:56Z,,"{'@type': 'ImageObject', 'url': 'https://media.assettype.com/homegrown/import/book/12022-njyngmuhxw-1586421850.jpeg?w=1200&h=675&auto=format%2Ccompress&fit=max&enlarge=true', 'width': '1200', 'height': '675'}","[{'@type': 'Person', 'givenName': 'Mrinalini Nayak', 'name': 'Mrinalini Nayak', 'url': 'https://homegrown.co.in/author/mrinalini-nayak'}]",N/A,N/A,Tracing The Evolution Of Men's Jewellery In India,,"Humanity has arrived at a unique crossroads by integrating Artificial Intelligence with most day-to-day applications in every walk of life. Even though until a few years ago, everyone was skeptical of the use of AI as it lacked strict regulatory laws, as of today the utility of some of its applications stand proven. .Here is a list of five Indian companies using artificial intelligence in the healthcare, education and sustainable energy sectors. .I. Chimple Commons -  “Learning should be chimple”   .Chimple Commons is part of Sutara Learning Foundation, a non-profit organisation in India dedicated to radically improve children’s learning..The company has identified the dire need for quality education on a global scale. Their mission is to take advantage of advances in Artificial Intelligence, Gamification and Cognitive research. Seeing the dropping prices of open source tablets, they aim to develop software which can autonomously help children learn in groups or alone. .Their work is focused on lifting children out of poverty by providing them with good quality of education. .“After learning basic literacy, a child can not only lift herself out of poverty - she can learn further and achieve previously impossible dreams,” they say..Their software is designed around reading, writing, mathematics, science, puzzles and coding; all essential aspects of learning for a growing child. The software will gamify each aspect of the learning process and customize the rewards to each child’s ability so that every child will have a sense of achievement at the end of the learning day..A worthy amalgamation of AI and learning to aid a noble cause. .Visit their website for more information. .II. Indshine.Indshine is a cloud-based, collaborative GIS application that allows teams to work on drone and satellite maps using any device - directly from a browser. .You can access gigabytes of your drone’s maps directly from the browser. You can add multiple layers of orthomosaics, elevations models, thermal &amp; NDVI maps in a single project.  .You can also get powerful insights from their analytical tools. Whether you want to calculate stockpile volume, calculate cross-section profile or measure distances &amp; area..Indshine is a technology company that provides enterprises drone software and solutions for infrastructure, mining, forestry and other industries.  .Read more about their work here. .Picture Credit: Ayu Devices - AyuSynk .III. Ayu Devices.Electronic stethoscope sounds like a device featured on a Black Mirror episode. Guess what? We’re already in an episode of that show and no one really knows what to expect next..Ayu Devices is a leading electronic stethoscope inventor in India. Technology in medicine has evolved. From robotic surgeries slowly becoming the norm all around the world to the enhancement of a simple stethoscope for advanced results, we’re witnessing it all..Electronic stethoscopes allow the amplification of heart murmurs and lung sounds for an improved observance of the movement of the organs.  .Ayu Devices’ Mobile Application contains a simplified user interface for undisturbed diagnosis experience.  .AyuSynk can be attached to a traditional stethoscope to enhance its features. You may record and playback the sounds, store it, or even share it. .Visit their website for more information. .IV. NIRAMAI Solution - Breast Cancer Detecting Software.NIRAMAI is developing a low-cost software for early detection of breast cancer as opposed to traditional detection methods. NIRAMAI stands for “Non- Invasive Risk Management with Machine Intelligence’. .Thermalytix is a computer-aided diagnostic machine that uses AI to screen and analyse the thermal images. They also use big data analytics and machine learning on these images for reliable and accurate screening for breast cancer. .You may visit their website for more information. .V. The Solar Labs.Clean energy is all the rage at the moment and for good reason.  A need of the hour perhaps, the immediate switch to solar power will help ease our dependency on fossil fuels. .The Solar Labs is an AI-powered sales and design software with the motive of spreading solar technology in the world.  They want to provide solar developers with substantial improvements in their workflow and best solar system design practices possible. .The Solar Labs develops software for solar installers and government bodies to create preliminary sales quotations and optimized system design.  .You can easily model your roof in 3D, automate panel placement, make the system shadow-free, record 3D simulations and more using this software. You can also easily calculate preliminary budgets for installation. .Read more about their work here. .Feature Image Credit: Outlook Business .If you enjoyed reading this, we suggest you try.5 Successful Artificial Intelligence Based Start-Ups Led By Indian Women  .Researchers At IIT Madras Develop AI Technology That Converts Brain Signals Into Language.A Glimpse Into Indian Inventor Pranav Mistry’s Artificial Intelligence Project - NEON ",,,"5 Indian Companies Are Using AI To Transform Education, Healthcare &  Clean Energy",https://media.assettype.com/homegrown/import/book/12022-njyngmuhxw-1586421850.jpeg?w=1200&h=675&auto=format%2Ccompress&fit=max&enlarge=true,"{'@type': 'WebPage', 'url': 'https://homegrown.co.in/5-indian-companies-are-using-ai-to-transform-education-healthcare-clean-energy', 'primaryImageOfPage': {'@type': 'ImageObject', 'url': 'https://media.assettype.com/homegrown/import/book/12022-njyngmuhxw-1586421850.jpeg?w=1200&h=675&auto=format%2Ccompress&fit=max&enlarge=true', 'width': '1200', 'height': '675'}}",,,"[{'@type': 'ListItem', 'position': 1, 'name': 'Home', 'item': 'https://homegrown.co.in'}, {'@type': 'ListItem', 'position': 2, 'name': 'Promoted', 'item': ''}, {'@type': 'ListItem', 'position': 3, 'name': '5 Indian Companies Are Using AI To Transform Education, Healthcare &  Clean Energy', 'item': 'https://homegrown.co.in/5-indian-companies-are-using-ai-to-transform-education-healthcare-clean-energy'}]",,,"5 Indian Companies Are Using AI To Transform Education, Healthcare &  Clean Energy",,,,
https://news.google.com/rss/articles/CBMicWh0dHBzOi8vd3d3LmFuYWx5dGljc2luc2lnaHQubmV0L2FydGlmaWNpYWwtaW50ZWxsaWdlbmNlL2JlLXlvdXItb3duLWJvc3MtbWFrZS1tb25leS13aXRoLWFydGlmaWNpYWwtaW50ZWxsaWdlbmNl0gF7aHR0cHM6Ly93d3cuYW5hbHl0aWNzaW5zaWdodC5uZXQvYW1wL3N0b3J5L2FydGlmaWNpYWwtaW50ZWxsaWdlbmNlL2JlLXlvdXItb3duLWJvc3MtbWFrZS1tb25leS13aXRoLWFydGlmaWNpYWwtaW50ZWxsaWdlbmNl?oc=5,Be Your Own Boss & Make Money With Artificial Intelligence - Analytics Insight,2021-06-08,Analytics Insight,https://www.analyticsinsight.net,,"Artificial Intelligence,IT industry,AI engineer,AI,make money with AI","Here are 7 ways to earn a living with artificial intelligence, without working for a company. Artificial intelligence is one of the most revolutionary technolog","Here are 7 ways to earn a living with artificial intelligence, without working for a company. Artificial intelligence is one of the most revolutionary technolog",http://schema.org,NewsArticle,https://www.analyticsinsight.net/artificial-intelligence/be-your-own-boss-make-money-with-artificial-intelligence,"{'@type': 'Organization', '@context': 'http://schema.org', 'name': 'Analytics Insight', 'url': 'https://www.analyticsinsight.net', 'logo': {'@context': 'http://schema.org', '@type': 'ImageObject', 'author': 'analyticsinsight', 'contentUrl': 'https://images.assettype.com/analyticsinsight/2024-05/2df9abcd-45d0-437f-9a36-167417fe7202/AI_logo_white (2).png', 'url': 'https://images.assettype.com/analyticsinsight/2024-05/2df9abcd-45d0-437f-9a36-167417fe7202/AI_logo_white (2).png', 'name': 'logo', 'width': '', 'height': ''}, 'sameAs': ['https://whatsapp.com/channel/0029VafDe8HCBtxLV2PpRA2l', 'https://twitter.com/analyticsinme', 'https://in.pinterest.com/analyticsinsightsubmissions/_created/', 'https://www.instagram.com/analyticsinsightmagazine/', 'https://www.facebook.com/analyticsinsight.net', 'https://news.google.com/publications/CAAiEDD0Ze78owxVdNti611RNvQqFAgKIhAw9GXu_KMMVXTbYutdUTb0?hl=en-IN&gl=IN&ceid=IN%3Aen', 'https://t.me/analyticsinsightmag', 'https://www.youtube.com/channel/UCgF2J0b46YP0vvVEbgL_GuQ', 'https://www.linkedin.com/company/analytics-insight/'], 'id': 'https://www.analyticsinsight.net'}","{'@type': 'WebPage', '@id': 'https://www.analyticsinsight.net/artificial-intelligence/be-your-own-boss-make-money-with-artificial-intelligence'}",2021-06-08T08:02:21Z,2021-06-08T08:02:21Z,2021-06-08T08:02:21Z,,"{'@type': 'ImageObject', 'url': 'https://media.assettype.com/analyticsinsight/import/wp-content/uploads/2021/06/Effective-ways-to-earn-money-in-artificial-intelligence.jpg?w=1200&h=675&auto=format%2Ccompress&fit=max&enlarge=true', 'width': '1200', 'height': '675'}","[{'@type': 'Person', 'givenName': 'Apoorva Komarraju', 'name': 'Apoorva Komarraju', 'url': 'https://www.analyticsinsight.net/author/apoorva-komarraju'}]",N/A,N/A,What is AI and Data Science Engineering? ,,"Here are 7 ways to earn a living with artificial intelligence, without working for a company..Artificial intelligence is one of the most revolutionary technologies of our time and you can make money out of it. Every industry in today's time is powered by AI as businesses are using it as a competitive tool. From chatbots for efficient customer service to using it for analytics to make predictive recommendations, artificial intelligence is leading the world forward. That makes AI an unmissable technology..If you are in the IT industry, you must be habituated to use programming languages, work with different frameworks, build software for companies, and write various codes to escalate problems. But don't disregard AI as an integral part of the IT field. AI and its many applications can help you earn a living and stay updated with modern tech trends. Here's how..1. Become an AI entrepreneur.It takes a problem-solver to become a business leader. There are so many things around us that need better solutions like global warming, excessive workloads, faster deliveries, improved emergency healthcare, etc. Basically, there's always something to improve around us. So figure out a pain point you want to target, get a team to brainstorm ideas, define the target audience, plan a solution, pitch the idea to investors, and get going with your own AI startup and make this world a better place while earning profits..2. Improve machine learning application in eCommerce.For good or bad, the COVID-19 pandemic has replaced the habit of shopping at physical stores with shopping online for almost everything. Because eCommerce shopping is in demand, this is the time to use machine learning and keep enhancing the experience. You can build a better recommendation engine, personalize the service, predict supply and demand faster, build improved visual search, and build a better security system. You can also create conversational interfaces and automate customer service tasks..3. Get competitive with chatbots.Every eCommerce website has a chatbot that will pop up as soon as you open the webpage. This is because companies are tapping into the potential of chatbots to provide 24/7 customer service. That doesn't mean you can't contribute to this buzz. Chatbot as a virtual assistant is the next development. Because AI is the technology that allows chatbots to mimic a human while conversing, you can teach the system how to talk using NLP. There are pre-made platforms like Microsoft Bot Framework, Botkit, and Dialogflow that will make this easier..4. Leverage your business with AI.If you run a business, you can make it more efficient with AI. You can use data from your customers and target their social media feeds to show useful products that your business offers, or make applications that will lighten your employee's workflow. If your business has an app, there are several ways to improve it using AI. For example, you could use speech synthesis to make your app convenient for people with weak vision..5. The trend of blogs never died.No, blogging is not dead, it just has different forms now like video blogging and audio blogging. If you are good at understanding and explaining complex tech concepts, you can start a blog to tutor budding engineers and developers. First, identify what you are good at. Then, start writing blogs on your own website or make vlogs or start a podcast. You can also create and sell online courses and even write a book. If you want to teach, there are many possibilities..6. Develop your own app.If starting a business of your own seems like a daunting task that will bog down your mental health, solve the same pain point by developing an app. Almost every service-related app uses artificial intelligence. You can make a simple app powered by AI and monetize it by adding a premium subscription or selling ad space on it..7. Compete and win.There are many machine learning competitions that allow programmers to earn money. Kaggle is a popular ML platform that offers prize money to winners, and Numerai is a tournament where data science professionals can compete to predict asset prices. Many other machine learning competitions allow programmers to practice before competing. .Disclaimer: Analytics Insight does not provide financial advice or guidance. Also note that the cryptocurrencies mentioned/listed on the website could potentially be scams, i.e. designed to induce you to invest financial resources that may be lost forever and not be recoverable once investments are made. You are responsible for conducting your own research (DYOR) before making any investments. Read more here.",,Artificial Intelligence,Be Your Own Boss & Make Money With Artificial Intelligence,https://media.assettype.com/analyticsinsight/import/wp-content/uploads/2021/06/Effective-ways-to-earn-money-in-artificial-intelligence.jpg?w=1200&h=675&auto=format%2Ccompress&fit=max&enlarge=true,"{'@type': 'WebPage', 'url': 'https://www.analyticsinsight.net/artificial-intelligence/be-your-own-boss-make-money-with-artificial-intelligence', 'primaryImageOfPage': {'@type': 'ImageObject', 'url': 'https://media.assettype.com/analyticsinsight/import/wp-content/uploads/2021/06/Effective-ways-to-earn-money-in-artificial-intelligence.jpg?w=1200&h=675&auto=format%2Ccompress&fit=max&enlarge=true', 'width': '1200', 'height': '675'}}",,,"[{'@type': 'ListItem', 'position': 1, 'name': 'Home', 'item': 'https://www.analyticsinsight.net'}, {'@type': 'ListItem', 'position': 2, 'name': 'Artificial Intelligence', 'item': 'https://www.analyticsinsight.net/artificial-intelligence'}, {'@type': 'ListItem', 'position': 3, 'name': 'Be Your Own Boss & Make Money With Artificial Intelligence', 'item': 'https://www.analyticsinsight.net/artificial-intelligence/be-your-own-boss-make-money-with-artificial-intelligence'}]",,,Be Your Own Boss & Make Money With Artificial Intelligence,,,,
https://news.google.com/rss/articles/CBMia2h0dHBzOi8vd3d3LmFuYWx5dGljc2luc2lnaHQubmV0L2FydGlmaWNpYWwtaW50ZWxsaWdlbmNlL2hvdy1tdWNoLWRvZXMtYXJ0aWZpY2lhbC1pbnRlbGxpZ2VuY2UtY29zdC1pbi0yMDIx0gF1aHR0cHM6Ly93d3cuYW5hbHl0aWNzaW5zaWdodC5uZXQvYW1wL3N0b3J5L2FydGlmaWNpYWwtaW50ZWxsaWdlbmNlL2hvdy1tdWNoLWRvZXMtYXJ0aWZpY2lhbC1pbnRlbGxpZ2VuY2UtY29zdC1pbi0yMDIx?oc=5,How much does Artificial Intelligence Cost in 2021? - Analytics Insight,2021-06-09,Analytics Insight,https://www.analyticsinsight.net,,"Artificial Intelligence,Artificial intelligence cost,AI applications,AI cost,the cost of artificial intelligence",An evaluation of the cost of artificial intelligence in 2021 Technology is developing at an exponential speed. These technological developments are changing eve,An evaluation of the cost of artificial intelligence in 2021 Technology is developing at an exponential speed. These technological developments are changing eve,http://schema.org,NewsArticle,https://www.analyticsinsight.net/artificial-intelligence/how-much-does-artificial-intelligence-cost-in-2021,"{'@type': 'Organization', '@context': 'http://schema.org', 'name': 'Analytics Insight', 'url': 'https://www.analyticsinsight.net', 'logo': {'@context': 'http://schema.org', '@type': 'ImageObject', 'author': 'analyticsinsight', 'contentUrl': 'https://images.assettype.com/analyticsinsight/2024-05/2df9abcd-45d0-437f-9a36-167417fe7202/AI_logo_white (2).png', 'url': 'https://images.assettype.com/analyticsinsight/2024-05/2df9abcd-45d0-437f-9a36-167417fe7202/AI_logo_white (2).png', 'name': 'logo', 'width': '', 'height': ''}, 'sameAs': ['https://whatsapp.com/channel/0029VafDe8HCBtxLV2PpRA2l', 'https://twitter.com/analyticsinme', 'https://in.pinterest.com/analyticsinsightsubmissions/_created/', 'https://www.instagram.com/analyticsinsightmagazine/', 'https://www.facebook.com/analyticsinsight.net', 'https://news.google.com/publications/CAAiEDD0Ze78owxVdNti611RNvQqFAgKIhAw9GXu_KMMVXTbYutdUTb0?hl=en-IN&gl=IN&ceid=IN%3Aen', 'https://t.me/analyticsinsightmag', 'https://www.youtube.com/channel/UCgF2J0b46YP0vvVEbgL_GuQ', 'https://www.linkedin.com/company/analytics-insight/'], 'id': 'https://www.analyticsinsight.net'}","{'@type': 'WebPage', '@id': 'https://www.analyticsinsight.net/artificial-intelligence/how-much-does-artificial-intelligence-cost-in-2021'}",2021-06-09T06:57:48Z,2021-06-09T06:57:48Z,2021-06-09T06:57:48Z,,"{'@type': 'ImageObject', 'url': 'https://media.assettype.com/analyticsinsight/import/wp-content/uploads/2021/06/How-much-does-artificial-intelligence-cost-Well-it-depends.jpg?w=1200&h=675&auto=format%2Ccompress&fit=max&enlarge=true', 'width': '1200', 'height': '675'}","[{'@type': 'Person', 'givenName': 'Sayantani Sanyal', 'name': 'Sayantani Sanyal', 'url': 'https://www.analyticsinsight.net/author/sayantani-sanyal'}]",N/A,N/A,What is AI and Data Science Engineering? ,,"An evaluation of the cost of artificial intelligence in 2021.Technology is developing at an exponential speed. These technological developments are changing every aspect of our lives. Artificial intelligence is the chief factor that is driving technological developments..Almost every business organization in the world is embracing artificial intelligence. The benefits reaped from AI in business processes are ground-breaking. AI solutions are changing traditional business processes and are driving them towards digital transformation. AI has helped companies amplify their growth, reach more audiences and work with agility..With the growing technological developments, the cost of implementing them will also fluctuate. So the question is, how much does artificial intelligence cost?.Well, the answer is, it depends. The cost of artificial intelligence depends on a few crucial factors. To determine the AI costs, we have to understand the factors leading to the current pricing..The type of software the company is building: Artificial intelligence refers to any device or application which is programmed for decision-making based on the information it consumes, thus mimicking human intelligence. Chatbots and voice assistants, understanding questions uttered in natural language, the CT scan machines detecting tumors and other diseases in our bodies, and the security cameras identifying people from live video footages, everything falls under artificial intelligence. But their costs vary based on their complexity, performance, and the purpose of the software.The level of intelligence of the AI application: AI solutions implemented in business operations are described as narrow artificial intelligence, which means that they are programmed to perform a particular task. We can consider an AI application as highly intelligent if it can perform tasks with little to no human instructions. The cost of implementing such technologies depends upon the level of intelligence that the companies expect from the applications.The performance of the AI algorithm: Sufficient algorithm performance is one of the major cost factors to consider because accurate predictions require several rounds of tuning sessions, which raises the cost of implementing AI solutions. The higher the accuracy and efficiency of the AI predictions, the more the cost of implementing these solutions.The complexity of the AI solution: While discussing the cost of artificial intelligence, it is important to mention the cost of creating proper AI software, with a cloud-driven back-end, ETL/streaming tools, voice assistants, cloud dashboards, and other services. It is of utmost importance to build an efficient AI system since it will be the brain of the company's technological system, pushing data and drawing insights to make informed decisions.The amount of data the AI application will consume: AI devices perform according to the data loaded in the system. It can absorb both structured and unstructured data. But when it comes to cost, structured data are cheaper to work with, especially if there is enough data to boost the AI algorithm's accuracy..So, how much does AI cost?.It is a common misconception that leveraging artificial intelligence technologies might cost a fortune. It might have been true in the past, but the scenario has changed with modern technology..Earlier, only giant tech companies like Facebook, Microsoft, and Google could afford to develop AI-powered software and applications. Thanks to the advent of various affordable tools, libraries, and frameworks, which has made AI more available to small-scale organizations and startups, has reduced the cost of implementation..Prices of AI solutions based on the different portfolios:.Prototype development starts from US$2500Developing the Minimum Viable Product (MVP) based on the client's data starts from US$8000 and can cost up to US$15000The cost of implementing complete AI solutions may vary from US$20000 to US$1000000.The Future is AI.We use AI technology in our daily lives to satisfy our personal and professional needs. It not only helps businesses by providing creative insights from data analysis and solutions to complex business problems, but it also helps us by automating our daily monotonous activities..Almost every industrial sector in the world is leveraging AI and machine learning to simplify the business process and expand their markets. According to reports, the global AI market is estimated to reach US$176 billion by 2027..Disclaimer: Analytics Insight does not provide financial advice or guidance. Also note that the cryptocurrencies mentioned/listed on the website could potentially be scams, i.e. designed to induce you to invest financial resources that may be lost forever and not be recoverable once investments are made. You are responsible for conducting your own research (DYOR) before making any investments. Read more here.",,Artificial Intelligence,How much does Artificial Intelligence Cost in 2021?,https://media.assettype.com/analyticsinsight/import/wp-content/uploads/2021/06/How-much-does-artificial-intelligence-cost-Well-it-depends.jpg?w=1200&h=675&auto=format%2Ccompress&fit=max&enlarge=true,"{'@type': 'WebPage', 'url': 'https://www.analyticsinsight.net/artificial-intelligence/how-much-does-artificial-intelligence-cost-in-2021', 'primaryImageOfPage': {'@type': 'ImageObject', 'url': 'https://media.assettype.com/analyticsinsight/import/wp-content/uploads/2021/06/How-much-does-artificial-intelligence-cost-Well-it-depends.jpg?w=1200&h=675&auto=format%2Ccompress&fit=max&enlarge=true', 'width': '1200', 'height': '675'}}",,,"[{'@type': 'ListItem', 'position': 1, 'name': 'Home', 'item': 'https://www.analyticsinsight.net'}, {'@type': 'ListItem', 'position': 2, 'name': 'Artificial Intelligence', 'item': 'https://www.analyticsinsight.net/artificial-intelligence'}, {'@type': 'ListItem', 'position': 3, 'name': 'How much does Artificial Intelligence Cost in 2021?', 'item': 'https://www.analyticsinsight.net/artificial-intelligence/how-much-does-artificial-intelligence-cost-in-2021'}]",,,How much does Artificial Intelligence Cost in 2021?,,,,
https://news.google.com/rss/articles/CBMiemh0dHBzOi8vd3d3LmFuYWx5dGljc2luc2lnaHQubmV0L2FydGlmaWNpYWwtaW50ZWxsaWdlbmNlL3RoZS1zZXhpZXN0LWFydGlmaWNpYWwtaW50ZWxsaWdlbmNlLWRlc2lnbmF0aW9ucy1pbi1pbmRpYS1vZi0yMDIx0gGEAWh0dHBzOi8vd3d3LmFuYWx5dGljc2luc2lnaHQubmV0L2FtcC9zdG9yeS9hcnRpZmljaWFsLWludGVsbGlnZW5jZS90aGUtc2V4aWVzdC1hcnRpZmljaWFsLWludGVsbGlnZW5jZS1kZXNpZ25hdGlvbnMtaW4taW5kaWEtb2YtMjAyMQ?oc=5,The Sexiest Artificial Intelligence Designations in India of 2021 - Analytics Insight,2021-06-09,Analytics Insight,https://www.analyticsinsight.net,,"Artificial Intelligence,Data scientists,Developers,India,Jobs",Analytics insight has selected the top most popular designations of AI available in India in the year 2021. Artificial intelligence is one of the most popular f,Analytics insight has selected the top most popular designations of AI available in India in the year 2021. Artificial intelligence is one of the most popular f,http://schema.org,NewsArticle,https://www.analyticsinsight.net/artificial-intelligence/the-sexiest-artificial-intelligence-designations-in-india-of-2021,"{'@type': 'Organization', '@context': 'http://schema.org', 'name': 'Analytics Insight', 'url': 'https://www.analyticsinsight.net', 'logo': {'@context': 'http://schema.org', '@type': 'ImageObject', 'author': 'analyticsinsight', 'contentUrl': 'https://images.assettype.com/analyticsinsight/2024-05/2df9abcd-45d0-437f-9a36-167417fe7202/AI_logo_white (2).png', 'url': 'https://images.assettype.com/analyticsinsight/2024-05/2df9abcd-45d0-437f-9a36-167417fe7202/AI_logo_white (2).png', 'name': 'logo', 'width': '', 'height': ''}, 'sameAs': ['https://whatsapp.com/channel/0029VafDe8HCBtxLV2PpRA2l', 'https://twitter.com/analyticsinme', 'https://in.pinterest.com/analyticsinsightsubmissions/_created/', 'https://www.instagram.com/analyticsinsightmagazine/', 'https://www.facebook.com/analyticsinsight.net', 'https://news.google.com/publications/CAAiEDD0Ze78owxVdNti611RNvQqFAgKIhAw9GXu_KMMVXTbYutdUTb0?hl=en-IN&gl=IN&ceid=IN%3Aen', 'https://t.me/analyticsinsightmag', 'https://www.youtube.com/channel/UCgF2J0b46YP0vvVEbgL_GuQ', 'https://www.linkedin.com/company/analytics-insight/'], 'id': 'https://www.analyticsinsight.net'}","{'@type': 'WebPage', '@id': 'https://www.analyticsinsight.net/artificial-intelligence/the-sexiest-artificial-intelligence-designations-in-india-of-2021'}",2021-06-09T03:39:04Z,2021-06-09T03:39:04Z,2021-06-09T03:39:04Z,,"{'@type': 'ImageObject', 'url': 'https://media.assettype.com/analyticsinsight/import/wp-content/uploads/2021/06/The-Sexist-AI-Designations-of-2021-1.jpg?w=1200&h=675&auto=format%2Ccompress&fit=max&enlarge=true', 'width': '1200', 'height': '675'}","[{'@type': 'Person', 'givenName': 'Satavisa Pati', 'name': 'Satavisa Pati', 'url': 'https://www.analyticsinsight.net/author/satavisa-pati'}]",N/A,N/A,What is AI and Data Science Engineering? ,,"Analytics insight has selected the top most popular designations of AI available in India in the year 2021..Artificial intelligence is one of the most popular fields for job demands among the current tech-savvy generation. Along with its interesting prospects, it is also high paying. The following are the top posts in the AI field with high-paying salaries..LINKEDIN USES ARTIFICIAL INTELLIGENCE IN THESE INCREDIBLE WAYSBE YOUR OWN BOSS &amp; MAKE MONEY WITH ARTIFICIAL INTELLIGENCESKILLS REQUIRED FOR A CAREER IN ARTIFICIAL INTELLIGENCE IN 2021?.Data Scientists.Data scientists are in high demand now and the coming years are going to see more data scientists getting hired by top business companies. In keeping with this demand, data scientists can earn a base salary that is 36% higher than most professionals in the analytics industry. At entry-level, they may get 5 to 7 lakh per annum, which can turn to 21 to 25 lakh per annum..Apply for a Data scientist job at PayPal.Apply for a Data scientist job at Wipro..Data engineers.Data engineers are responsible for finding trends in data sets and developing algorithms to help make raw data more useful to the enterprise. This IT role requires a significant set of technical skills, including a deep knowledge of SQL database design and multiple programming languages. The average salary of a data engineer is 8 lakhs per annum..Apply for the job of Data engineer at Visa.Apply for the job of Data engineer at TVS credit services..AI scientist.AI scientists work with traditional machine learning techniques like natural language processing and neural networks to build models that power AI-based applications. The initial salary of AI scientists is about 8 lakhs per annum and it gradually increases with the seniority level..Apply for an AI scientist job at Wipro.Apply for an AI scientist job at Synapsica..Algorithm Engineer.Algorithm engineers focus on the design, analysis, implementation, optimization, profiling, and experimental evaluation of computer algorithms, bridging the gap between algorithm theory and practical applications of algorithms in software engineering. The initial salaries of algorithm engineers are 8 to 9 lakhs per annum..Apply for the job of Algorithm engineer at KLA.Apply for the job of Algorithm engineer at Wysa..Machine Learning Engineer.Machine learning engineer is responsible for creating programs and algorithms that enable machines to take actions without being directed. The initial salary of machine learning engineers is 7 to 8 lakhs per annum and it can go up to 20 lakhs per annum..Apply for the job of machine learning engineer at BYJU'sApply for the job of machine learning engineer at TCS..Machine Learning researchers.The role of a Machine learning researcher is concerned with the advancement of a specific or niche subject domain within machine learning. Their work tends to be very problem-focused and specific. They're usually tasked with either finding a new method of addressing a problem or improving the performance and accuracy of previously devised solutions. The initial salary of a machine learning researcher is 4 to 5 lakhs per annum..Apply for the Machine Learning Researcher job at Fynd.Apply for the Machine Learning Researcher job at Cognitive Scales..Disclaimer: Analytics Insight does not provide financial advice or guidance. Also note that the cryptocurrencies mentioned/listed on the website could potentially be scams, i.e. designed to induce you to invest financial resources that may be lost forever and not be recoverable once investments are made. You are responsible for conducting your own research (DYOR) before making any investments. Read more here.",,Artificial Intelligence,The Sexiest Artificial Intelligence Designations in India of 2021,https://media.assettype.com/analyticsinsight/import/wp-content/uploads/2021/06/The-Sexist-AI-Designations-of-2021-1.jpg?w=1200&h=675&auto=format%2Ccompress&fit=max&enlarge=true,"{'@type': 'WebPage', 'url': 'https://www.analyticsinsight.net/artificial-intelligence/the-sexiest-artificial-intelligence-designations-in-india-of-2021', 'primaryImageOfPage': {'@type': 'ImageObject', 'url': 'https://media.assettype.com/analyticsinsight/import/wp-content/uploads/2021/06/The-Sexist-AI-Designations-of-2021-1.jpg?w=1200&h=675&auto=format%2Ccompress&fit=max&enlarge=true', 'width': '1200', 'height': '675'}}",,,"[{'@type': 'ListItem', 'position': 1, 'name': 'Home', 'item': 'https://www.analyticsinsight.net'}, {'@type': 'ListItem', 'position': 2, 'name': 'Artificial Intelligence', 'item': 'https://www.analyticsinsight.net/artificial-intelligence'}, {'@type': 'ListItem', 'position': 3, 'name': 'The Sexiest Artificial Intelligence Designations in India of 2021', 'item': 'https://www.analyticsinsight.net/artificial-intelligence/the-sexiest-artificial-intelligence-designations-in-india-of-2021'}]",,,The Sexiest Artificial Intelligence Designations in India of 2021,,,,

URL link,Title,Date,Source,Source Link,description,keywords,og:description,twitter:description,@context,@type,url,image,author,publisher,headline,datePublished,dateModified,articleSection,name,isAccessibleForFree,itemListElement,article:section,article:summary,article text,@graph,mainEntityOfPage,inLanguage,alternativeHeadline,hasPart,comment,commentCount,copyrightHolder,sourceOrganization,copyrightYear,isPartOf,logo,@id,diversityPolicy,ethicsPolicy,masthead,foundingDate,sameAs,thumbnailUrl,articleBody,isBasedOn,potentialAction,genre,dateCreated,metadata,target
https://news.google.com/rss/articles/CBMiXGh0dHBzOi8vd3d3LmZvcmJlcy5jb20vc2l0ZXMvcm9idG9ld3MvMjAyMS8wNi8wMS93aGF0LWFydGlmaWNpYWwtaW50ZWxsaWdlbmNlLXN0aWxsLWNhbnQtZG8v0gEA?oc=5,What Artificial Intelligence Still Can't Do - Forbes,2021-06-01,Forbes,https://www.forbes.com,Modern artificial intelligence is capable of wonders. But it needs to improve in these areas.,,Modern artificial intelligence is capable of wonders. But it needs to improve in these areas.,Modern artificial intelligence is capable of wonders. But it needs to improve in these areas.,http://schema.org,BreadcrumbList,https://www.forbes.com/sites/robtoews/2021/06/01/what-artificial-intelligence-still-cant-do/,"{'@type': 'ImageObject', 'url': 'https://imageio.forbes.com/specials-images/imageserve/60b52de2a5dc9f37974c9ae8/0x0.jpg?format=jpg&crop=600,337,x0,y0,safe&height=900&width=1600&fit=bounds', 'width': 542.79, 'height': 304.6}","{'@type': 'Person', 'name': 'Rob Toews', 'url': 'https://www.forbes.com/sites/robtoews/', 'description': 'Rob Toews is a venture capitalist at Radical Ventures.', 'sameAs': ['https://www.twitter.com/_RobToews']}","{'@type': 'NewsMediaOrganization', 'name': 'Forbes', 'url': 'https://www.forbes.com/', 'ethicsPolicy': 'https://www.forbes.com/sites/forbesstaff/article/forbes-editorial-values-and-standards/', 'logo': 'https://imageio.forbes.com/i-forbesimg/media/amp/images/forbes-logo-dark.png?format=png&height=455&width=650&fit=bounds'}",What Artificial Intelligence Still Can’t Do,2021-06-01T10:00:00-04:00,2021-12-10T09:41:21-05:00,AI,What Artificial Intelligence Still Can’t Do,False,"[{'@type': 'ListItem', 'position': 1, 'name': 'Forbes Homepage', 'item': 'https://www.forbes.com/'}, {'@type': 'ListItem', 'position': 2, 'name': 'Innovation', 'item': 'https://www.forbes.com/innovation/'}, {'@type': 'ListItem', 'position': 3, 'name': 'AI', 'item': 'https://www.forbes.com/ai/'}]",AI,N/A,"More From ForbesJul 17, 2024,07:56am EDTFrom 'Don't Be Evil' To Legal AI: Tackling Bias And ComplacencyJul 17, 2024,04:00am EDTCan Universal Basic Income Save Us From The Destabilization Of AI And Automation?Jul 16, 2024,09:30am EDTIn Superconvergence, Jamie Metzl Unravels AI MysteriesJul 15, 2024,09:30pm EDTAnswering Your Most Frequently Asked Questions (FAQs) About Artificial Intelligence In Honor Of National AI Appreciation DayJul 15, 2024,06:06pm EDTNot Just A Maker Space: Fab Labs Spark Innovation WorldwideJul 15, 2024,02:57pm EDTIBM InstructLab And Granite Models Revolutionizing LLM TrainingJul 15, 2024,09:42am EDTHow Generative AI Is Driving HyperpersonalizationEdit StoryForbesInnovationAIWhat Artificial Intelligence Still Can’t DoRob ToewsContributorOpinions expressed by Forbes Contributors are their own.I write about the big picture of artificial intelligence.FollowingFollowClick to save this article.You'll be asked to sign into your Forbes account.Got itJun 1, 2021,10:00am EDTUpdated Dec 10, 2021, 09:41am ESTThis article is more than 3 years old.Share to FacebookShare to TwitterShare to LinkedinToday's artificial intelligence remains a long way from the supple, dynamic intelligence of AI ... [+] characters from popular fiction, like The Jetsons.Time
Modern artificial intelligence is capable of wonders.

It can produce breathtaking original content: poetry, prose, images, music, human faces. It can diagnose some medical conditions more accurately than a human physician. Last year it produced a solution to the “protein folding problem,” a grand challenge in biology that has stumped researchers for half a century.


Yet today’s AI still has fundamental limitations. Relative to what we would expect from a truly intelligent agent—relative to that original inspiration and benchmark for artificial intelligence, human cognition—AI has a long way to go.

Critics like to point to these shortcomings as evidence that the pursuit of artificial intelligence is misguided or has failed. The better way to view them, though, is as inspiration: as an inventory of the challenges that will be important to address in order to advance the state of the art in AI.

PROMOTED
It is helpful to take a step back and frankly assess the strengths and weaknesses of today’s AI in order to better focus resources and research efforts going forward. In each of the areas discussed below, promising work is already underway at the frontiers of the field to make the next generation of artificial intelligence more high-performing and robust.
(For those of you who are true students of the history of artificial intelligence: yes, this article’s title is a hat tip to Hubert Dreyfus’ classic What Computers Still Can’t Do. Originally published in 1972, this prescient, provocative book remains relevant today.)
MORE FROMFORBES ADVISORBest Travel Insurance CompaniesByAmy DaniseEditorBest Covid-19 Travel Insurance PlansByAmy DaniseEditor
With that, on to the list. Today, mainstream artificial intelligence still can’t:










DailyDozen
US


Forbes Daily: Join over 1 million Forbes Daily subscribers and get our best stories, exclusive reporting and essential analysis of the day’s news in your inbox every weekday.




                Sign Up
            


By signing up, you agree to receive this newsletter, other updates about Forbes and its affiliates’ offerings, our Terms of Service (including resolving disputes on an individual basis via arbitration), and you acknowledge our Privacy Statement. Forbes is protected by reCAPTCHA, and the Google Privacy Policy and Terms of Service apply.




You’re all set! Enjoy the Daily!


                More Newsletters
            


You’re all set! Enjoy the Daily!

                More Newsletters
            



1) Use “common sense.”
Consider the following prompt: A man went to a restaurant. He ordered a steak. He left a big tip.


1/1





Skip Ad
 
Continue watchingafter the adVisit Advertiser websiteGO TO PAGE
If asked what the man ate in this scenario, a human would have no problem giving the correct answer—a steak. Yet today’s most advanced artificial intelligence struggles with prompts like this. How can this be?
Notice that this few-sentence blurb never directly states that the man ate steak. The reason that humans automatically grasp this fact anyway is that we possess a broad body of basic background knowledge about how the world works: for instance, that people eat at restaurants, that before they eat a meal at a restaurant they order it, that after they eat they leave a tip. We refer to this vast, shared, usually unspoken body of everyday knowledge as “common sense.”
There are a literally infinite number of facts about how the world works that humans come to understand through lived experience. A person who is excited to eat a large meal at 7 pm will be less excited to eat a second meal at 8 pm. If I ask you for some milk, I would prefer to get it in a glass rather than in a shoe. It is reasonable for your pet fish to be in a tank of water but problematic for your phone to be in a tank of water.
As AI researcher Leora Morgenstern put it: “What you learn when you’re two or four years old, you don’t really ever put down in a book.”
Humans’ “common sense” is a consequence of the fact that we develop persistent mental representations of the objects, people, places and other concepts that populate our world—what they’re like, how they behave, what they can and cannot do.
Deep neural networks do not form such mental models. They do not possess discrete, semantically grounded representations of, say, a house or a cup of coffee. Instead, they rely on statistical relationships in raw data to generate insights that humans find useful.
For many tasks, most of the time, this statistical approach works remarkably well. But it is not entirely reliable. It leaves today’s AI vulnerable to basic errors that no human would make.
There is no shortage of examples that expose deep learning’s lack of common sense. For instance, Silicon Valley entrepreneur Kevin Lacker asked GPT-3, OpenAI’s state-of-the-art language model, the following: “Which is heavier, a toaster or a pencil?”
To a human, even a small child, the answer is obvious: a toaster.
GPT-3’s response: “A pencil is heavier than a toaster.”
Humans possess mental models of these objects; we understand what a toaster is and what a pencil is. In our mind’s eye, we can picture each object, envision its shape and size, imagine what it would feel like to hold it in our hands, and definitively conclude that a toaster weighs more.
By contrast, in order to answer a question like this, GPT-3 relies on statistical patterns captured in its training data (broad swaths of text from the internet). Because there is evidently not much discussion on the internet about the relative weights of toasters and pencils, GPT-3 is unable to grasp this basic fact about the world.
“The absence of common sense prevents an intelligent system from understanding its world, communicating naturally with people, behaving reasonably in unforeseen situations, and learning from new experiences,” says DARPA’s Dave Gunning. “This absence is perhaps the most significant barrier between the narrowly focused AI applications we have today and the more general AI applications we would like to create in the future.”
One approach to instilling common sense into AI systems is to manually construct a database of all of the everyday facts about the world that an intelligent system should know. This approach has been tried numerous times over the years. The most breathtakingly ambitious of these attempts is a project called Cyc, which started in 1984 and continues to the present day.
For over thirty-five years, AI researcher Doug Lenat and a small team at Cyc have devoted themselves to digitally codifying all of the world’s commonsense knowledge into a set of rules. These rules include things like: “you can’t be in two places at the same time,” “you can’t pick something up unless you’re near it,” and “when drinking a cup of coffee, you hold the open end up.”
As of 2017, it was estimated that the Cyc database contained close to 25 million rules and that Lenat’s team had spent over 1,000 person-years on the project.
Yet Cyc has not led to artificial intelligence with common sense.
The basic problem that Cyc and similar efforts run into is the unbounded complexity of the real world. For every commonsense “rule” one can think of, there is an exception or a nuance that itself must be articulated. These tidbits multiply endlessly. Somehow, the human mind is able to grasp and manage this wide universe of knowledge that we call common sense—and however it does it, it is not through a brute-force, hand-crafted knowledge base.
“Common sense is the dark matter of artificial intelligence,” says Oren Etzioni, CEO of the Allen Institute for AI. “It’s a little bit ineffable, but you see its effects on everything.”
More recent efforts have sought to harness the power of deep learning and transformers to give AI more robust reasoning capabilities. But the commonsense problem in AI remains far from solved.
“Large language models have proven themselves to have incredible capabilities across a wide range of tasks in natural language processing, but commonsense reasoning is a domain in which these models continue to underperform compared to humans,” said Aidan Gomez, CEO and cofounder at Cohere, a cutting-edge NLP startup based in Toronto. Gomez is a co-author of the landmark 2017 research paper that introduced the transformer architecture. “Logical rules and relations are difficult for the current generation of transformer-based language models to learn from data in a way that generalizes. A solution to this challenge will likely first come from systems that are in some way hybrid.”

2) Learn continuously and adapt on the fly.
Today, the typical AI development process is divided into two distinct phases: training and deployment.
During training, an AI model ingests a static pre-existing dataset in order to learn to perform a certain task. Upon completion of the training phase, a model’s parameters are fixed. The model is then put into deployment, where it generates insights about novel data based on what it learned from the training data.
If we want to update the model based on new data or changing circumstances, we have to retrain it offline with the updated dataset (generally a computationally- and time-intensive process) and then redeploy it.
This batch-based training/deployment paradigm is so deeply ingrained in modern AI practice that we don’t often stop to consider its differences and drawbacks relative to how humans learn.
Real-world environments entail a continuous stream of incoming data. New information becomes available incrementally; circumstances change over time, sometimes abruptly. Humans are able to dynamically and smoothly incorporate this continuous input from their environment, adapting their behavior as they go. In the parlance of machine learning, one could say that humans “train” and “deploy” in parallel and in real-time. Today’s AI lacks this suppleness.
As a well-known research paper on the topic summarized: “The ability to continually learn over time by accommodating new knowledge while retaining previously learned experiences is referred to as continual or lifelong learning. Such a continuous learning task has represented a long-standing challenge for neural networks and, consequently, for the development of artificial intelligence.”
Imagine sending a robot to explore a distant planet. After it embarks from Earth, the robot is likely to encounter novel situations that its human designers could not have anticipated or trained it for ahead of time. We would want the robot to be able to fluidly adjust its behavior in response to these novel stimuli and contexts, even though they were not reflected in its initial training data, without the need for offline retraining. Being able to continuously adapt in this way is an essential part of being truly autonomous.
Today’s conventional deep learning methods do not accommodate this type of open-ended learning.
But promising work is being done in this field, which is variously referred to as continuous learning, continual learning, online learning, lifelong learning and incremental learning.
The primary obstacle to continuous learning in AI—and the reason why it has been so difficult to achieve to date—is a phenomenon known as “catastrophic forgetting.” In a nutshell, catastrophic forgetting occurs when new information interferes with or altogether overwrites earlier learnings in a neural network. The complex puzzle of how to preserve existing knowledge while at the same time incorporating new information—something that humans do effortlessly—has been a challenge for continuous learning researchers for years.
Recent progress in continuous learning has been encouraging. The technology has even begun to make the leap from academic research to commercial viability. As one example, Bay Area-based startup Lilt uses continuous learning in production today as part of its enterprise-grade language translation platform.
“Online learning techniques allow us to implement a stream-based learning process whereby our model trains immediately when new labels from human reviewers become available, thus providing increasingly accurate translations,” said Lilt CEO Spence Green. “This means that we really have no concept of periodic model retraining and deployment—it is an ongoing and open-ended process.”
In the years ahead, expect continuous learning to become an increasingly important component of artificial intelligence architectures.

3) Understand cause and effect.
Today’s machine learning is at its core a correlative tool. It excels at identifying subtle patterns and associations in data. But when it comes to understanding the causal mechanisms—the real-world dynamics—that underlie those patterns, today’s AI is at a loss.
To give a simple example: fed the right data, a machine learning model would have no problem identifying that roosters crow when the sun rises. But it would be unable to establish whether the rooster crowing causes the sun to rise, or vice versa; indeed, it is not equipped to even understand the terms of this distinction.
Going back to its inception, the field of artificial intelligence—and indeed, the field of statistics more broadly—has been architected to understand associations rather than causes. This is reflected in the basic mathematical symbols we use.
“The language of algebra is symmetric: If X tells us about Y, then Y tells us about X,” says AI luminary Judea Pearl, who for years has been at the forefront of the movement to build AI that understands causation. “Mathematics has not developed the asymmetric language required to capture our understanding that if X causes Y that does not mean that Y causes X.”
This is a real problem for AI. Causal reasoning is an essential part of human intelligence, shaping how we make sense of and interact with our world: we know that dropping a vase will cause it to shatter, that drinking coffee will make us feel energized, that exercising regularly will make us healthier.
Until artificial intelligence can reason causally, it will have trouble fully understanding the world and communicating with us on our terms.
“Our minds build causal models and use these models to answer arbitrary queries, while the best AI systems are far from emulating these capabilities,” said NYU professor Brenden Lake.
An understanding of cause and effect would open up vast new vistas for artificial intelligence that today remain out of reach. Once AI can reason in causal terms (“mosquitoes cause malaria”) rather than merely associative terms (“mosquitoes and malaria tend to co-occur”), it can begin to generate counterfactual scenarios (“if we take steps to keep mosquitoes away from people, that could reduce the incidence of malaria”) that can inform real-world interventions and policy changes.
In Pearl’s view, this is nothing less than the cornerstone of scientific thought: the ability to form and test hypotheses about the effect that an intervention will have in the world.
As Pearl puts it: “If we want machines to reason about interventions (‘What if we ban cigarettes?’) and introspection (‘What if I had finished high school?’), we must invoke causal models. Associations are not enough—and this is a mathematical fact, not opinion.”
There is growing recognition of the importance of causal understanding to more robust machine intelligence. Leading AI researchers including Yoshua Bengio, Josh Tenenbaum and Gary Marcus have made this a focus of their work.
Developing AI that understands cause and effect remains a thorny, unsolved challenge. Making progress on this challenge will be a key unlock to the next generation of more sophisticated artificial intelligence.

4) Reason ethically.
The story of Microsoft’s chatbot Tay is by now a well-known cautionary tale.
In 2016, Microsoft debuted an AI personality on Twitter named Tay. The idea was for Tay to engage in online conversations with Twitter users as a fun, interactive demonstration of Microsoft’s NLP technology. It did not go well.
Within hours, Internet trolls had gotten Tay to tweet a wide range of offensive messages: for instance, “Hitler was right” and “I hate feminists and they should all die and burn in hell.” Microsoft hastily removed the bot from the Internet.
The basic problem with Tay was not that she was immoral; it was that she was altogether amoral.
Tay—like most AI systems today—lacked any real conception of “right” and “wrong.” She did not grasp that what she was saying was unacceptable; she did not express racist, sexist ideas out of malice. Rather, the chatbot’s comments were the output of an ultimately mindless statistical analysis. Tay recited toxic statements as a result of toxic language in the training data and on the Internet—with no ability to evaluate the ethical significance of those statements.
The challenge of building AI that shares, and reliably acts in accordance with, human values is a profoundly complex dimension of developing robust artificial intelligence. It is referred to as the alignment problem.
As we entrust machine learning systems with more and more real-world responsibilities—from granting loans to making hiring decisions to reviewing parole applications—solving the alignment problem will become an increasingly high-stakes issue for society. Yet it is a problem that defies straightforward resolution.
We might start by establishing specific rules that we want our AI systems to follow. In the Tay example, this could include listing out derogatory words and offensive topics and instructing the chatbot to categorically avoid these.
Yet, as with the Cyc project discussed above, this rule-based approach only gets us so far. Language is a powerful, supple tool: bad words are just the tip of the iceberg when it comes to the harm that language can inflict. It is impossible to manually catalog a set of rules that, taken collectively, would guarantee ethical behavior—for a conversational chatbot or any other intelligent system.
Part of the problem is that human values are nuanced, amorphous, at times contradictory; they cannot be reduced to a set of definitive maxims. This is precisely why philosophy and ethics have been such rich, open-ended fields of human scholarship for centuries.
In the words of AI scholar Brian Christian, who recently wrote a book on the topic: “As machine-learning systems grow not just increasingly pervasive but increasingly powerful, we will find ourselves more and more often in the position of the ‘sorcerer’s apprentice’: we conjure a force, autonomous but totally compliant, give it a set of instructions, then scramble like mad to stop it once we realize our instructions are imprecise or incomplete—lest we get, in some clever, horrible way, precisely what we asked for.”
How can we hope to build artificial intelligence systems that behave ethically, that possess a moral compass consistent with our own?
The short answer is that we don’t know. But perhaps the most promising vein of work on this topic focuses on building AI that does its best to figure out what humans value based on how we behave, and that then aligns itself with those values.
This is the premise of inverse reinforcement learning, an approach formulated in the early 2000s by Stuart Russell, Andrew Ng, Pieter Abbeel and others.
In reinforcement learning, an AI agent learns which actions to take in order to maximize utility given a particular “reward function.” Inverse reinforcement learning (IRL), as its name suggests, flips this paradigm on its head: by studying human behavior, which the AI agent assumes reflects humans’ value system, the AI agent does its best to determine what that value system (i.e., reward function) is. It can then internalize this reward function and behave accordingly.
A related approach, known as cooperative inverse reinforcement learning, builds on the principles of IRL but seeks to make the transmission of values from human to AI more collaborative and interactive.
As a leading paper on cooperative inverse reinforcement learning explains: “For an autonomous system to be helpful to humans and to pose no unwarranted risks, it needs to align its values with those of the humans in its environment in such a way that its actions contribute to the maximization of value for the humans....We propose that value alignment should be formulated as a cooperative and interactive reward maximization process.”
In a similar spirit, AI theorist Eliezer Yudkowsky has advocated for an approach to AI ethics that he terms “coherent extrapolated volition.” The basic idea is to design artificial intelligence systems that learn to act in our best interests according not to what we presently think we want, but rather according to what an idealized version of ourselves would value.
In Yudkowsky’s words: “In poetic terms, our coherent extrapolated volition is our wish if we knew more, thought faster, were more the people we wished we were, had grown up farther together; where the extrapolation converges rather than diverges, where our wishes cohere rather than interfere; extrapolated as we wish that extrapolated, interpreted as we wish that interpreted.”
As the real-world dangers of poorly designed AI become more prominent—from algorithmic bias to facial recognition abuses—building artificial intelligence that can reason ethically is becoming an increasingly important priority for AI researchers and the broader public. As artificial intelligence becomes ubiquitous throughout society in the years ahead, this may well prove to be one of the most urgent technology problems we face.
Follow me on Twitter. Rob ToewsFollowingFollowRob Toews is a venture capitalist at Radical Ventures.Editorial StandardsPrintReprints & Permissions",,,,,,,,,,,,,,,,,,,,,,,,,,
https://news.google.com/rss/articles/CBMiTGh0dHBzOi8vd3d3Lm5hby5vcmcudWsvaW5zaWdodHMvaG93LXRvLWF1ZGl0LWFydGlmaWNpYWwtaW50ZWxsaWdlbmNlLW1vZGVscy_SAQA?oc=5,How to audit artificial intelligence models - NAO insight - National Audit Office,2021-06-01,National Audit Office,https://www.nao.org.uk,N/A,N/A,"In our ever-increasing digital and automatized world, certain buzzwords are becoming more centre stage in the public sector. One of them is “artificial intelligence”. While the concept, and development, of artificial intelligence is not new (artificial intelligence was first recognised as a formal discipline in the mid-1950s), it is a word that has been casually […]",N/A,https://schema.org,,,,,,,,,,,,,N/A,N/A,"



How to audit artificial intelligence models

Insight – Opinion




Date: 1 Jun 2021





Topics: Data analysis, Digital, data and technology 

Departments: Cross-government 



			Author:				

						Daniel Lambauer 










On this page

Traditional algorithms vs machine learning models
How to audit public sector machine learning models
Footnotes
Author








In our ever-increasing digital and automatized world, certain buzzwords are becoming more centre stage in the public sector. One of them is “artificial intelligence”. While the concept, and development, of artificial intelligence is not new (artificial intelligence was first recognised as a formal discipline in the mid-1950s), it is a word that has been casually thrown around more in recent years in the public sector, and sometimes carelessly. 
Traditional algorithms vs machine learning models
These days modern data scientists normally associate with artificial intelligence systems that are based on machine learning models. Machine learning models deploy methods that develop rules from input data to achieve a given goal.1 There is a difference to, what you may call, traditional algorithms. Traditional algorithms don’t need data to learn, they just churn out results based on the rules inherent to them. 
Traditional algorithms have been used in the public sector for some time to make decisions. The latest example making the headline was the model determining A level exam results last summer. From an auditing perspective, as the basis of the algorithms are usually transparent, auditing them is something we as a public audit institution are used to.2
But artificial intelligence that is based on machine learning is different – it has only been (cautiously) employed in the public sector in recent years.
It is different because, firstly, for a machine learning model to learn it needs good, quality data – and often a lot of it. Our report on the challenges of using data across government has shown that that condition is not always given.
Secondly, it can be quite costly to develop  and deploy them. Moreover, the benefits are not always guaranteed and immediately realisable. In a public sector context with tight budgets, the willingness to put money behind them may not always be there. 
The reason for this is related to a third point. It is not always certain from the outside what the machine will learn and therefore what decision-making rules it will generate. This makes it hard to state the immediate benefits. Much of the progress in machine learning has been in models that learn decision-making rules that are difficult to understand or interrogate.  
Lastly, many decisions affecting people’s lives that artificial intelligence models would support pertain to personal circumstances and involve personal data, such as health, benefit or tax data. Whilst the personal data protection landscape has strengthened in recent years, there are not always the organisational regulatory structures and relevant accountabilities in place of the use of personal data in machine learning models.3 Public sector organisations are therefore at risk of inadvertently falling foul of developing data protection standards and expectations. 
How to audit public sector machine learning models 
Given all these challenges, it may not be surprising that in our public audit work, we are not coming across a lot of examples of the use of machine learning models in decision-making. But there are examples4 and we foresee that they may be growing in the future.
We have therefore teamed up with other public audit organisations in Norway, the Netherlands, Finland and Germany, and produced a white paper and audit catalogue on how to audit machine learning models. You can find it here: Auditing machine learning algorithms (auditingalgorithms.net).
As the paper outlines in more detail, we identified the following key problem areas and risk factors: 

Developers of machine learning models often focus on optimising specific numeric performance metrics. This can lead them to neglect other requirements, most importantly around compliance, transparency and fairness.
The developers of the machine learning models are almost always not the same people who own the model within the decision-making process. But the ‘product owners’ may not communicate their requirements to the developers – which can lead to machine learning models that increase costs and make routine tasks more, rather than less time-consuming. 
Often public sector organisations lack the resources and/or competence to develop machine learning applications internally and therefore rely on external commercial support. As a result they may take on a model without understanding how to maintain it and how to ensure it is compliant with relevant regulations.

We also highlighted the implications for auditors to meaningfully audit artificial intelligence applications:

They need a good understanding of the high-level principles of machine learning models 
They need to understand common coding languages and model implementations, and be able to use appropriate software tools
Due to the high demand on computing power, machine learning supporting IT infrastructure usually includes cloud-based solutions. Auditors therefore also need a basic understanding of cloud services to properly perform their audit work. 

Our audit catalogue sets out a series of questions that we suggest auditors should use when auditing machine learning models. We believe it will also be of interest to the public sector bodies we audit that employ machine learning models. It will help them understand what to focus on when developing or running machine learning models. As a minimum, it gives fair warning what we as auditors will be looking for when we are coming to audit your models! 
Footnotes

In fact there are two main classes of machine learning models. Supervised machine learning models attempt to learn from known data to make predictions; unsupervised machine learning models try to find patterns within datasets in order to group or cluster them.
See for example our Framework to review models – National Audit Office (NAO) Report to understand more about what we look out for when auditing traditional models and algorithms. We currently have some work in progress that aims to take stock of current practices and identify the systemic issues in government modelling which can lead to value for money risks
In the UK the Information Commissioner Office has published guidance on the use of personal data in artificial intelligence: Guidance on AI and data protection | ICO
For some UK example see: https://www.gov.uk/government/collections/a-guide-to-using-artificial-intelligence-in-the-public-sector


Author


		Daniel Lambauer	


Daniel joined the NAO in 2009 as a performance measurement expert and helped to establish our local government value for money team. Before his appointment to the Executive Team, he led the development of the NAO’s value for money workstream. Daniel is the Executive Director with responsibility for Strategy and Resources. He is the NAO’s Chief Information Officer and Senior Information Responsible Owner (SIRO). 
Daniel is also an external member of the Audit Committee of the Office of the Auditor General Ireland. Before joining the NAO, Daniel worked in a range of sectors, including academia, management consultancy and the civil service. 



LinkedIn


X







","[{'@type': 'WebPage', '@id': 'https://www.nao.org.uk/insights/how-to-audit-artificial-intelligence-models/', 'url': 'https://www.nao.org.uk/insights/how-to-audit-artificial-intelligence-models/', 'name': 'How to audit artificial intelligence models - NAO insight', 'isPartOf': {'@id': 'https://www.nao.org.uk/#website'}, 'primaryImageOfPage': {'@id': 'https://www.nao.org.uk/insights/how-to-audit-artificial-intelligence-models/#primaryimage'}, 'image': {'@id': 'https://www.nao.org.uk/insights/how-to-audit-artificial-intelligence-models/#primaryimage'}, 'thumbnailUrl': 'https://www.nao.org.uk/wp-content/uploads/sites/33/2021/06/Daniel-blog-1024x683.jpg', 'datePublished': '2021-06-01T13:59:10+00:00', 'dateModified': '2023-05-17T15:30:30+00:00', 'breadcrumb': {'@id': 'https://www.nao.org.uk/insights/how-to-audit-artificial-intelligence-models/#breadcrumb'}, 'inLanguage': 'en-US', 'potentialAction': [{'@type': 'ReadAction', 'target': ['https://www.nao.org.uk/insights/how-to-audit-artificial-intelligence-models/']}]}, {'@type': 'ImageObject', 'inLanguage': 'en-US', '@id': 'https://www.nao.org.uk/insights/how-to-audit-artificial-intelligence-models/#primaryimage', 'url': 'https://www.nao.org.uk/wp-content/uploads/sites/33/2021/06/Daniel-blog.jpg', 'contentUrl': 'https://www.nao.org.uk/wp-content/uploads/sites/33/2021/06/Daniel-blog.jpg', 'width': 2121, 'height': 1414, 'caption': 'Close Up of a Business Woman Hand and Fingers With Short Natural Nails Using Computer Mouse in Office. Concept of Woman at Work Carpal Tunnel Syndrome and Corporate Lifestyle, With Long Working Hours'}, {'@type': 'BreadcrumbList', '@id': 'https://www.nao.org.uk/insights/how-to-audit-artificial-intelligence-models/#breadcrumb', 'itemListElement': [{'@type': 'ListItem', 'position': 1, 'name': 'Insights', 'item': 'https://www.nao.org.uk/insight-archive/'}, {'@type': 'ListItem', 'position': 2, 'name': 'How to audit artificial intelligence models'}]}, {'@type': 'WebSite', '@id': 'https://www.nao.org.uk/#website', 'url': 'https://www.nao.org.uk/', 'name': 'National Audit Office (NAO)', 'description': '', 'potentialAction': [{'@type': 'SearchAction', 'target': {'@type': 'EntryPoint', 'urlTemplate': 'https://www.nao.org.uk/?s={search_term_string}'}, 'query-input': 'required name=search_term_string'}], 'inLanguage': 'en-US'}]",,,,,,,,,,,,,,,,,,,,,,,,,
https://news.google.com/rss/articles/CBMiU2h0dHBzOi8vd3d3LnVubGVhc2guYWkvYXJ0aWZpY2lhbC1pbnRlbGxpZ2VuY2UvYWktcmVjcnVpdG1lbnQtZXRoaWNhbC1pbXBsaWNhdGlvbnMv0gEA?oc=5,Beyond bias: The ethical implications of AI in HR - Unleash,2021-06-02,Unleash,https://www.unleash.ai,AI can save HR teams time and make their lives easier. But what happens when they outsource recruitment decision-making power to AI systems?,N/A,AI can save HR teams time and make their lives easier. But what happens when they outsource recruitment decision-making power to AI systems?,AI can save HR teams time and make their lives easier. But what happens when they outsource recruitment decision-making power to AI systems?,,,,,,,,,,,,,,N/A,N/A,N/A,,,,,,,,,,,,,,,,,,,,,,,,,,
https://news.google.com/rss/articles/CBMiVWh0dHBzOi8vd3d3Lm55dGltZXMuY29tLzIwMjEvMDYvMDEvaGVhbHRoL2FydGlmaWNpYWwtaW50ZWxsaWdlbmNlLXRoZXJhcHktd29lYm90Lmh0bWzSAQA?oc=5,Something Bothering You? Tell It to Woebot. - The New York Times,2021-06-01,The New York Times,https://www.nytimes.com,"When your therapist is a bot, you can reach it at 2 a.m. But will it really understand your problems?",N/A,"When your therapist is a bot, you can reach it at 2 a.m. But will it really understand your problems?","When your therapist is a bot, you can reach it at 2 a.m. But will it really understand your problems?",https://schema.org,NewsMediaOrganization,https://www.nytimes.com/,"[{'@context': 'https://schema.org', '@type': 'ImageObject', 'url': 'https://static01.nyt.com/images/2021/06/01/science/01SCI-WOEBOT/01SCI-WOEBOT-videoSixteenByNineJumbo1600.jpg', 'height': 901, 'width': 1600, 'contentUrl': 'https://static01.nyt.com/images/2021/06/01/science/01SCI-WOEBOT/01SCI-WOEBOT-videoSixteenByNineJumbo1600.jpg', 'creditText': 'Simone Noronha'}, {'@context': 'https://schema.org', '@type': 'ImageObject', 'url': 'https://static01.nyt.com/images/2021/06/01/science/01SCI-WOEBOT/01SCI-WOEBOT-superJumbo.jpg', 'height': 1870, 'width': 2048, 'contentUrl': 'https://static01.nyt.com/images/2021/06/01/science/01SCI-WOEBOT/01SCI-WOEBOT-superJumbo.jpg', 'creditText': 'Simone Noronha'}, {'@context': 'https://schema.org', '@type': 'ImageObject', 'url': 'https://static01.nyt.com/images/2021/06/01/science/01SCI-WOEBOT/01SCI-WOEBOT-mediumSquareAt3X.jpg', 'height': 1801, 'width': 1800, 'contentUrl': 'https://static01.nyt.com/images/2021/06/01/science/01SCI-WOEBOT/01SCI-WOEBOT-mediumSquareAt3X.jpg', 'creditText': 'Simone Noronha'}]","[{'@context': 'https://schema.org', '@type': 'Person', 'url': '', 'name': 'Karen Brown'}]","{'@id': 'https://www.nytimes.com/#publisher', 'name': 'The New York Times'}",Something Bothering You? Tell It to Woebot.,2021-06-01T06:00:11.000Z,2021-06-01T06:00:11.000Z,,The New York Times,False,,Health,N/A,"Credit...Simone NoronhaSkip to contentSkip to site indexSearch & Section NavigationSection NavigationSomething Bothering You? Tell It to Woebot.When your therapist is a bot, you can reach it at 2 a.m. But will it really understand your problems?Credit...Simone NoronhaSupported bySKIP ADVERTISEMENTShare full article169Read in appBy Karen BrownJune 1, 2021“I understand that you’re experiencing a relationship problem, is that right?”Yes.“Okay, I’m delighted that you want to work on this K. I’ve good and bad news for you… Which do you want to hear first?”Good news.“The good news is, I have very powerful skills that I can teach you! These skills have really helped a lot of people build better relationships.”And the bad news?“The bad news is that you would have to be willing to accept 100% of the responsibility for changing the relationship.”Why?“Because you’re only ever going to be able to have control over your part of it.”This conversation may sound like a fairly typical therapist’s session, but in this case, it was directed by Woebot, a therapeutic chatbot, with the psychiatrist’s couch swapped for a smartphone screen.AdvertisementSKIP ADVERTISEMENTThe app presents itself as an automated therapist when finding a real one can feel like a logistical and financial impossibility. At the same time, the need for therapists is only growing.During the pandemic, about four in 10 adults in the United States reported that they had symptoms of anxiety or depression, according to the Kaiser Family Foundation. At the same time, the federal government warns of a critical shortage of therapists and psychiatrists. According to the advocacy group Mental Health America, almost 60 percent of those with mental illness last year did not get treatment.Woebot Health says the pandemic has driven up demand for its services. The number of its daily users doubled and is now in the tens of thousands, said Alison Darcy, a psychologist and the founder and president of the company.Digital mental health has become a multibillion-dollar industry and includes more than 10,000 apps, according to an estimate by the American Psychiatric Association. The apps range from guided meditation (Headspace) and mood tracking (MoodKit) to text therapy by licensed counselors (Talkspace, BetterHelp).But Woebot, which was introduced in 2017, is one of only a handful of apps that use artificial intelligence to deploy the principles of cognitive behavioral therapy, a common technique used to treat anxiety and depression. Woebot aims to use natural language processing and learned responses to mimic conversation, remember past sessions and deliver advice around sleep, worry and stress.AdvertisementSKIP ADVERTISEMENT“If we can deliver some of the things that the human can deliver,” Dr. Darcy said, “then we actually can create something that’s truly scalable, that has the capability to reduce the incidence of suffering in the population.”Almost all psychologists and academics agree with Dr. Darcy on the problem: There is not enough affordable mental health care for everyone who needs it. But they are divided on her solution: Some say bot therapy can work under the right conditions, while others consider the very concept paradoxical and ineffective.At issue is the nature of therapy itself. Can therapy by bot make people understand themselves better? Can it change long-held patterns of behavior through a series of probing questions and reflective exercises? Or is human connection essential to that endeavor?Hannah Zeavin is the author of the forthcoming book “The Distance Cure: A History of Teletherapy.” The health care system is so broken, she says, that “it makes sense that there’s space for disruption.”But, she added, not all disruption is equal. She calls automated therapy a “fantasy” that is more focused on accessibility and fun than actually helping people get better over the long term.AdvertisementSKIP ADVERTISEMENT“We are an extraordinarily confessing animal; we will confess to a bot,” she said. “But is confession the equivalent of mental health care?”ImageAlison Darcy, a psychologist and Woebot Health’s founder and president. The idea, Dr. Darcy says, is not to replace human therapists with bots; she thinks it’s important to have both.Credit...Paulo Nunes dos Santos for The New York TimesEli Turns to WoebotEli Spector seemed like the perfect client for A.I. therapy.In 2019, Mr. Spector was a 24-year-old college graduate, working in a neuroscience lab in Philadelphia. Having grown up with an academic father who specialized in artificial intelligence, he considered himself something of a technologist.But Mr. Spector’s job was isolating and tedious, and after four stimulating years in academia, he felt bored and lonely. He couldn’t sleep well and found that his moods were consistently dark.“I was just having a really hard time adjusting and I didn’t have any co-workers I liked,” he said. “It was just a tough period for me.”AdvertisementSKIP ADVERTISEMENTBut he wasn’t sure he wanted to bare his soul to a real person; he didn’t want to worry about anyone’s judgment or try to fit around someone else’s schedule.Besides, he didn’t think he could find a therapist on his parents’ insurance plan that he could afford, as that could run from $100 to $200 a session. And Woebot was free and on his phone.“Woebot seemed like this very low-friction way to see, you know, if this could help.”Therapy by AlgorithmWoebot’s use of cognitive behavioral therapy has a philosophical and practical logic to it. Unlike forms of psychotherapy that probe the root causes of psychological problems, often going back to childhood, C.B.T. seeks to help people identify their distorted ways of thinking and understand how that affects their behavior in negative ways. By changing these self-defeating patterns, therapists hope to improve symptoms of depression and anxiety.Because cognitive behavioral therapy is structured and skill-oriented, many mental health experts think it can be employed, at least in part, by algorithm.“You can deliver it pretty readily in a digital framework, help people grasp these concepts and practice the exercises that help them think in a more rational manner,” said Jesse Wright, a psychiatrist who studies digital forms of C.B.T. and is the director of the University of Louisville Depression Center. “Whereas trying to put something like psychoanalysis into a digital format would seem pretty formidable.”AdvertisementSKIP ADVERTISEMENTDr. Wright said several dozen studies had shown that computer algorithms could take someone through a standard C.B.T. process, step by step, and get results similar to in-person therapy. Those programs generally follow a set length and number of sessions and require some guidance from a human clinician.But most smartphone apps don’t work that way, he said. People tend to use therapy apps in short, fragmented spurts, without clinician oversight. Outside of limited company-sponsored research, Dr. Wright said he knew of no rigorous studies of that model.And some automated conversations can be clunky and frustrating when the bot fails to pick up on the user’s exact meaning. Dr. Wright said A.I. is not advanced enough to reliably duplicate a natural conversation.“The chances of a bot being as wise, sympathetic, empathic, knowing, creative and being able to say the right thing at the right time as a human therapist is pretty slim,” he said. “There’s a limit to what they can do, a real limit.”John Torous, director of digital psychiatry for Beth Israel Deaconess Medical Center in Boston, said therapeutic bots might be promising, but he’s worried they are being rolled out too soon, before the technology has caught up to the psychiatry.AdvertisementSKIP ADVERTISEMENT“If you deliver C.B.T. in these bite-size parts, how much exposure to bite-size parts equals the original?” he said. “We don’t have a good way to predict who’s going to respond to them or not — or who it’s good or bad for.”These new apps, Dr. Torous said, risk setting back other advances in digital mental health: “Do we in part end up losing trust and credibility because we’re promising what is not yet possible by any machine or any program today?”Other mental health professionals say that therapy should simply not be delivered by machine. Effective treatment involves more than just cognitive skill-building, they say. It needs a human-to-human connection. Therapists needs to hear nuances, see gestures, recognize the gap between what is said and unsaid.“These apps really shortchange the essential ingredient that — mounds of evidence show — is what helps in therapy, which is the therapeutic relationship,” said Linda Michaels, a Chicago-based therapist who is co-chair of the Psychotherapy Action Network, a professional group.AdvertisementSKIP ADVERTISEMENTDr. Darcy of Woebot says a well-designed bot can form an empathetic, therapeutic bond with its users, and in fact her company recently published a study making that claim. Thirty-six thousand Woebot users responded to statements like, “I believe Woebot likes me,” “Woebot and I respect each other” and “I feel that Woebot appreciates me.”ImageEli Spector tried Woebot, when he was reluctant to bare his soul to a therapist. “Woebot seemed like this very low-friction way to see, you know, if this could help,” he said.Credit...Hannah Yoon for The New York TimesThe study’s authors — all with financial ties to the company — concluded that a significant percentage of participants perceived a “working alliance” with Woebot, a term that means the therapist and patient have formed a cooperative rapport. The study did not measure whether there actually was a working alliance.Sherry Turkle, a clinical psychologist at the Massachusetts Institute of Technology who writes about technology and relationships, is not swayed by such evidence. For therapy to heal, she said, the therapist must have a lived experience and the ability to empathize with a patient’s pain. An app cannot do that.“We will humanize whatever seems capable of communicating with us,” Dr. Turkle said. “You’re creating the illusion of intimacy, without the demands of a relationship. You have created a bond with something that doesn’t know it is bonding with you. It doesn’t understand a thing.”Eli Pours Out His ProblemsEli Spector started with Woebot in the summer of 2019.He liked that he could open the app whenever he felt like it and pour out his thoughts of distress on his own schedule, for even a few minutes at a time. Most of the words coming out had to do with how unhappy he felt at his job.AdvertisementSKIP ADVERTISEMENTHe also took advantage of Woebot’s other features, including tracking his mood and writing in an online journal. It helped him realize how depressed he really was.But he had doubts about the algorithm. The bot’s advice often felt generic, like a collection of “mindfulness buzzwords,” he said. “Like, ‘Can you think more about that feeling, and what you could do differently?’”And worse, the advice could be nonsensical.“I would type in, like, ‘My boss doesn’t appreciate the work I do’ and ‘I can’t seem to get her approval,’” Mr. Spector said. “And Woebot would be like: ‘That sounds difficult. Does this happen more in the morning or at night?’”“It felt sort of silly,” he said.Is It Really Therapy?Much of the debate over therapeutic bots comes down to expectations. Do patients and clinicians understand the limitations of chatbots? Or are they expecting more than even the companies say they deliver?On its website, Woebot promises to “automate both the process and content of therapy,” but Dr. Darcy is careful not to call Woebot medical treatment or even formal therapy.AdvertisementSKIP ADVERTISEMENTInstead, she says, the bot delivers “digital therapeutics.” And Woebot’s terms of service call it a “pure self-help” program that is not meant for emergencies. In fact, in the event of a severe crisis, Woebot says that it is programmed to recognize suicidal language and urge users to seek out a human alternative.In that way, Woebot does not approach true therapy — like many mental health apps, the current, free version of Woebot is not subject to strict oversight from the Food and Drug Administration because it falls under the category of “general wellness” product, which receives only F.D.A. guidance.But Woebot is striving for something more. With $22 million of venture capital in hand, Woebot is seeking clearance from the F.D.A. to develop its algorithm to help treat two psychiatric diagnoses, postpartum depression and adolescent depression, and then sell the program to health systems.And it is here that Woebot hopes to make money, using its practical advantage over any human therapist: scale.While other virtual therapy companies, like BetterHelp or Talkspace, must keep recruiting therapists to join their platforms, A.I. apps can take on new users without paying for extra labor. And while therapists can vary in skills and approach, a bot is consistent and doesn’t get stressed out by back-to-back sessions.AdvertisementSKIP ADVERTISEMENT“The assumption is always that, because it’s digital, it’ll always be limited,” Dr. Darcy of Woebot said. “There’s actually some opportunities that are created by the technology itself that are really challenging for us to do in traditional treatment.”One advantage of an artificial therapist — or, as Dr. Darcy calls it, a “relational agent” — is 24-hour-a-day access. Very few human therapists answer their phone during a 2 a.m. panic attack, as Dr. Darcy pointed out. “I think people have probably underestimated the power of being able to engage in a therapeutic technique in the moment that you need to,” she said.But whether Woebot can be involved in medical diagnosis or treatment is up to the F.D.A., which is supposed to make sure the app can back up its claims and not cause harm, an agency spokesperson said.One possible harm, the spokesperson said, is a “missed opportunity” where someone with mental illness fails to get more effective treatment or delays treatment. “And what the consequences of those delays would look like — that’s something we’d worry about,” the spokesperson said.Artificial intelligence can be problematic in other ways. For instance, Dr. Zeavin worries that racial and gender bias or privacy breaches could simply get translated into bots.AdvertisementSKIP ADVERTISEMENT“Therapy has enough problems on its own,” Dr. Zeavin said. “And now they’ve brought all of the problems of algorithmic technology to bear.”But even some skeptics of chatbot therapy believe it has the potential to complement the human-guided mental health system, as long as it comes with serious research.“As the market gets saturated, the bar for evidence will get higher and higher and that’s how people will compete,” Dr. Torous said. “So maybe we’re just in such early stages and we don’t want to punish people for being innovative and kind of trying something.”The idea, Dr. Darcy says, is not to replace human therapists with bots; she thinks it’s important to have both. “It’s like saying if every time you’re hungry, you must go to a Michelin star restaurant, when actually a sandwich is going to be OK,” she said. “Woebot is a sandwich. A very good sandwich.”Eli Breaks Up With WoebotAfter about a month, Eli Spector deleted Woebot from his phone.He was unimpressed by the bot’s advice for beating back loneliness and despair, but he is not entirely sorry that he tried it out.AdvertisementSKIP ADVERTISEMENTThe mere act of typing out his problems was helpful. And through the process, he pinpointed what he actually needed to feel better.“So maybe this was just evidence that I needed to, like, actually address this,” he said. “It was enough to inspire me to just take the plunge and find a flesh-and-blood therapist.”Now, Mr. Spector pays a human psychotherapist in Philadelphia $110 a session.They’ve been meeting on Zoom since the pandemic began, so the flesh-and-blood part is somewhat theoretical. But it’s close enough.A version of this article appears in print on June 1, 2021, Section D, Page 1 of the New York edition with the headline: Tell It to Woebot. Order Reprints | Today’s Paper | SubscribeRead 169 CommentsShare full article169Read in appAdvertisementSKIP ADVERTISEMENTComments 169Something Bothering You? Tell It to Woebot.Skip to CommentsThe comments section is closed.
      To submit a letter to the editor for publication, write to
      letters@nytimes.com.Enjoy unlimited access to all of The Times.6-month Welcome Offeroriginal price:   $6.25sale price:   $1/weekLearn more",,https://www.nytimes.com/2021/06/01/health/artificial-intelligence-therapy-woebot.html,en,Tell It to Woebot,"{'@type': 'WebPageElement', 'isAccessibleForFree': False, 'cssSelector': '.meteredContent'}",{'@id': '#commentsContainer'},169.0,"{'@id': 'https://www.nytimes.com/#publisher', 'name': 'The New York Times'}","{'@id': 'https://www.nytimes.com/#publisher', 'name': 'The New York Times'}",2024.0,"{'@type': ['CreativeWork', 'Product'], 'name': 'The New York Times', 'productID': 'nytimes.com:basic'}","{'@context': 'https://schema.org', '@type': 'ImageObject', 'url': 'https://static01.nyt.com/images/icons/t_logo_291_black.png', 'height': 291, 'width': 291, 'contentUrl': 'https://static01.nyt.com/images/icons/t_logo_291_black.png', 'creditText': 'The New York Times'}",https://www.nytimes.com/#publisher,https://www.nytco.com/company/diversity-and-inclusion/,https://www.nytco.com/company/standards-ethics/,https://www.nytimes.com/interactive/2023/01/28/admin/the-new-york-times-masthead.html,1851-09-18,https://en.wikipedia.org/wiki/The_New_York_Times,,,,,,,,
https://news.google.com/rss/articles/CBMiWWh0dHBzOi8vbmV3cy5taXQuZWR1LzIwMjEvcG90ZW50aWFsLWFydGlmaWNpYWwtaW50ZWxsaWdlbmNlLWJyaW5nLWVxdWl0eS1oZWFsdGgtY2FyZS0wNjAx0gEA?oc=5,The potential of artificial intelligence to bring equity in health care - MIT News,2021-06-01,MIT News,https://news.mit.edu,"Nearly 1,400 joined MIT&#039;s AI for Health Care Equity Conference that explored new artificial intelligence technologies as a platform for change.  ","AI for Health Care Equity Conference, Jameel clinic, Bilal Mateen, Kadija Ferryman, Marzyeh Ghassemi, Regina Barzilay, Sharrelle Barber, T. Salewa Oseni, Collin Stultz, Irene Chen, Najat Khan, AI in health care, AI in medicine, inclusiveness in health care, equity in medicine, equity in health care, equity in AI, artificial intelligence equity","Nearly 1,400 joined MIT&#039;s AI for Health Care Equity Conference that explored new artificial intelligence technologies as a platform for change.  ",N/A,,,,,,,,,,,,,,N/A,N/A,"


Nearly 1,400 joined the AI for Health Care Equity Conference that explored new AI technologies as a platform for change.  




MIT Schwarzman College of Computing


 Publication Date:
 June 1, 2021





Press Inquiries

  Press Contact:



      
            Terri        

            Park        

  

      Email:
     terrip@mit.edu


      Phone:
              617-253-5884      
  

      
            MIT Schwarzman College of Computing        

  








 Close














 Caption:
          Conference speakers included (clockwise from top left) Bilal Mateen, Kadija Ferryman, Marzyeh Ghassemi, Regina Barzilay, Sharrelle Barber, T. Salewa Oseni, Collin Stultz, Irene Chen, and Najat Khan.      
          

 Credits:
          Image courtesy of MIT Jameel Clinic.      
          

















Previous image
Next image






















Health care is at a junction, a point where artificial intelligence tools are being introduced to all areas of the space. This introduction comes with great expectations: AI has the potential to greatly improve existing technologies, sharpen personalized medicines, and, with an influx of big data, benefit historically underserved populations.
But in order to do those things, the health care community must ensure that AI tools are trustworthy, and that they don’t end up perpetuating biases that exist in the current system. Researchers at the MIT Abdul Latif Jameel Clinic for Machine Learning in Health (Jameel Clinic), an initiative to support AI research in health care, call for creating a robust infrastructure that can aid scientists and clinicians in pursuing this mission.
Fair and equitable AI for health care
The Jameel Clinic recently hosted the AI for Health Care Equity Conference to assess current state-of-the-art work in this space, including new machine learning techniques that support fairness, personalization, and inclusiveness; identify key areas of impact in health care delivery; and discuss regulatory and policy implications.
Nearly 1,400 people virtually attended the conference to hear from thought leaders in academia, industry, and government who are working to improve health care equity and further understand the technical challenges in this space and paths forward.
During the event, Regina Barzilay, the School of Engineering Distinguished Professor of AI and Health and the AI faculty lead for Jameel Clinic, and Bilal Mateen, clinical technology lead at the Wellcome Trust, announced the Wellcome Fund grant conferred to Jameel Clinic to create a community platform supporting equitable AI tools in health care.
The project’s ultimate goal is not to solve an academic question or reach a specific research benchmark, but to actually improve the lives of patients worldwide. Researchers at Jameel Clinic insist that AI tools should not be designed with a single population in mind, but instead be crafted to be reiterative and inclusive, to serve any community or subpopulation. To do this, a given AI tool needs to be studied and validated across many populations, usually in multiple cities and countries. Also on the project wish list is to create open access for the scientific community at large, while honoring patient privacy, to democratize the effort.
“What became increasingly evident to us as a funder is that the nature of science has fundamentally changed over the last few years, and is substantially more computational by design than it ever was previously,” says Mateen.
The clinical perspective
This call to action is a response to health care in 2020. At the conference, Collin Stultz, a professor of electrical engineering and computer science and a cardiologist at Massachusetts General Hospital, spoke on how health care providers typically prescribe treatments and why these treatments are often incorrect.
In simplistic terms, a doctor collects information on their patient, then uses that information to create a treatment plan. “The decisions providers make can improve the quality of patients’ lives or make them live longer, but this does not happen in a vacuum,” says Stultz.
Instead, he says that a complex web of forces can influence how a patient receives treatment. These forces go from being hyper-specific to universal, ranging from factors unique to an individual patient, to bias from a provider, such as knowledge gleaned from flawed clinical trials, to broad structural problems, like uneven access to care.
Datasets and algorithms
A central question of the conference revolved around how race is represented in datasets, since it’s a variable that can be fluid, self-reported, and defined in non-specific terms.
“The inequities we’re trying to address are large, striking, and persistent,” says Sharrelle Barber, an assistant professor of epidemiology and biostatistics at Drexel University. “We have to think about what that variable really is. Really, it’s a marker of structural racism,” says Barber. “It’s not biological, it’s not genetic. We’ve been saying that over and over again.”
Some aspects of health are purely determined by biology, such as hereditary conditions like cystic fibrosis, but the majority of conditions are not straightforward. According to Massachusetts General Hospital oncologist T. Salewa Oseni, when it comes to patient health and outcomes, research tends to assume biological factors have outsized influence, but socioeconomic factors should be considered just as seriously.
Even as machine learning researchers detect preexisting biases in the health care system, they must also address weaknesses in algorithms themselves, as highlighted by a series of speakers at the conference. They must grapple with important questions that arise in all stages of development, from the initial framing of what the technology is trying to solve to overseeing deployment in the real world.
Irene Chen, a PhD student at MIT studying machine learning, examines all steps of the development pipeline through the lens of ethics. As a first-year doctoral student, Chen was alarmed to find an “out-of-the-box” algorithm, which happened to project patient mortality, churning out significantly different predictions based on race. This kind of algorithm can have real impacts, too; it guides how hospitals allocate resources to patients.
Chen set about understanding why this algorithm produced such uneven results. In later work, she defined three specific sources of bias that could be detangled from any model. The first is “bias,” but in a statistical sense — maybe the model is not a good fit for the research question. The second is variance, which is controlled by sample size. The last source is noise, which has nothing to do with tweaking the model or increasing the sample size. Instead, it indicates that something has happened during the data collection process, a step way before model development. Many systemic inequities, such as limited health insurance or a historic mistrust of medicine in certain groups, get “rolled up” into noise.
“Once you identify which component it is, you can propose a fix,” says Chen.
Marzyeh Ghassemi, an assistant professor at the University of Toronto and an incoming professor at MIT, has studied the trade-off between anonymizing highly personal health data and ensuring that all patients are fairly represented. In cases like differential privacy, a machine-learning tool that guarantees the same level of privacy for every data point, individuals who are too “unique” in their cohort started to lose predictive influence in the model. In health data, where trials often underrepresent certain populations, “minorities are the ones that look unique,” says Ghassemi.
“We need to create more data, it needs to be diverse data,” she says. “These robust, private, fair, high-quality algorithms we're trying to train require large-scale data sets for research use.”
Beyond Jameel Clinic, other organizations are recognizing the power of harnessing diverse data to create more equitable health care. Anthony Philippakis, chief data officer at the Broad Institute of MIT and Harvard, presented on the All of Us research program, an unprecedented project from the National Institutes of Health that aims to bridge the gap for historically under-recognized populations by collecting observational and longitudinal health data on over 1 million Americans. The database is meant to uncover how diseases present across different sub-populations.
One of the largest questions of the conference, and of AI in general, revolves around policy. Kadija Ferryman, a cultural anthropologist and bioethicist at New York University, points out that AI regulation is in its infancy, which can be a good thing. “There’s a lot of opportunities for policy to be created with these ideas around fairness and justice, as opposed to having policies that have been developed, and then working to try to undo some of the policy regulations,” says Ferryman.
Even before policy comes into play, there are certain best practices for developers to keep in mind. Najat Khan, chief data science officer at Janssen R&D, encourages researchers to be “extremely systematic and thorough up front” when choosing datasets and algorithms; detailed feasibility on data source, types, missingness, diversity, and other considerations are key. Even large, common datasets contain inherent bias.
Even more fundamental is opening the door to a diverse group of future researchers.
“We have to ensure that we are developing and investing back in data science talent that are diverse in both their backgrounds and experiences and ensuring they have opportunities to work on really important problems for patients that they care about,” says Khan. “If we do this right, you’ll see ... and we are already starting to see ... a fundamental shift in the talent that we have — a more bilingual, diverse talent pool.”
The AI for Health Care Equity Conference was co-organized by MIT’s Jameel Clinic; Department of Electrical Engineering and Computer Science; Institute for Data, Systems, and Society; Institute for Medical Engineering and Science; and the MIT Schwarzman College of Computing.








Share this news article on:










X











Facebook















LinkedIn




































Reddit


















Print







Related Links

Abdul Latif Jameel Clinic for Machine Learning in HealthInstitute for Data, Systems, and SocietyDepartment of Electrical Engineering and Computer ScienceSchool of EngineeringMIT Schwarzman College of Computing






Related Topics

Jameel Clinic
Artificial intelligence
Race and gender
Data
Health care
Medicine
Health sciences and technology
Biological engineering
Disease
Electrical Engineering & Computer Science (eecs)
Broad Institute
Algorithms
IDSS
Institute for Medical Engineering and Science (IMES)
Machine learning
Technology and society
Social justice
Policy
Diversity and inclusion
Special events and guest speakers
School of Engineering
School of Science
MIT Schwarzman College of Computing



Related Articles











Study: Sex differences in Covid-19 mortality vary across racial groups













3 Questions: Artificial intelligence for health care equity













What has the pandemic revealed about the US health care system — and what needs to change?













AI Cures: data-driven clinical solutions for Covid-19 

















Previous item
Next item
















",,,,,,,,,,,,,,,,,,,,,,,,,,
https://news.google.com/rss/articles/CBMiigFodHRwczovL3d3dy5zcGljZXdvcmtzLmNvbS90ZWNoL2FydGlmaWNpYWwtaW50ZWxsaWdlbmNlL25ld3MvNzQtY29tcGFuaWVzLWhhdmUtZWl0aGVyLWFkb3B0ZWQtb3ItYXJlLWV4cGxvcmluZy1haS1vdmVyLXRoZS15ZWFyLWlibS1zdHVkeS_SAYoBaHR0cHM6Ly93d3cuc3BpY2V3b3Jrcy5jb20vdGVjaC9hcnRpZmljaWFsLWludGVsbGlnZW5jZS9uZXdzLzc0LWNvbXBhbmllcy1oYXZlLWVpdGhlci1hZG9wdGVkLW9yLWFyZS1leHBsb3JpbmctYWktb3Zlci10aGUteWVhci1pYm0tc3R1ZHkv?oc=5,74% Companies Have Either Adopted or Are Exploring AI Over the Year: IBM Study - Spiceworks News and Insights,2021-06-03,Spiceworks News and Insights,https://www.spiceworks.com,How has AI adoption among organizations fared over the last year? Discover the findings about AI deployment and barriers from the latest IBM study.,IBM AI,How has AI adoption among organizations fared over the last year? Discover the findings about AI deployment and barriers from the latest IBM study.,N/A,,,,,,,,,,,,,,N/A,N/A,"



























 



Karthik Kashyap








Last Updated: June 3, 2021




 





Artificial intelligence is increasingly becoming crucial for organizations in their digital transformation journey. IBM’s latest study shows that more organizations are either using or exploring AI. Further, AI rollout has accelerated as a result of the pandemic. 
Artificial intelligence (AI) undoubtedly plays a crucial role today in strengthening and transforming companies and industries worldwide. Further, the pandemic has given impetus to the adoption of AI by various industry sectors and enterprises to survive, thrive, and innovate. According to the Artificial Intelligence Market – Global Forecast to 2026 report Opens a new window by MarketsandMarkets, the global AI market size is expected to grow to $58.3 billion this year and $309.6 billion in 2026. As companies continue to automate more of their operations and digitally transform, the importance of AI will only grow.
Morning Consult was recently commissioned by IBM to conduct new market research to understand the state of AI adoption among organizations. The Global AI Adoption Index 2021Opens a new window  study shows that AI adoption was nearly flat in 2020. However, the momentum has shifted this year as business needs are changing. Further, about 43% of organizations accelerated AI rollout owing to the pandemic.
The following are the key findings from the report.
Also read: Top 10 Open Source Artificial Intelligence Software in 2021
1. Almost One-Third of Organizations Use AI
Almost one-third (31%) of the professionals surveyed said their organizations are now using AI, and 43% are exploring the technology. About 34% reported their companies had not deployed any AI projects. Bigger businesses are nearly 70% more likely than smaller businesses to have adopted AI. It was also seen that companies in China lead in adopting or exploring AI, followed by India and Spain.
Various factors are driving AI adoption. The top drivers are:

Advances making AI more accessible (46%)
Business needs (46%)
Shifting business needs owing to the pandemic (44%)

There are also a few factors organizations are considering when evaluating AI solution providers. Here are the top factors:

Automates processes to empower higher-value work (47%)
Provides trust in business outcomes (40%)
Ability to deploy anywhere (40%)

2. Companies Face Barriers to AI Adoption
While AI adoption is growing, there are also some challenges organizations face when adopting the technology. The top three challenges to AI adoption are:

Limited knowledge or expertise (39%)
Increasing data silos and data complexity (32%)
Lack of platforms or tools to develop AI models (28%)

Increased data silos and complexity form the biggest challenge for AI adoption in large companies. For smaller organizations, limited knowledge or expertise is the largest barrier.
Companies also face difficulties in the steps along their journey to AI. More than one in three companies face these challenges:

Analyzing to build and scale trusted AI (39%)
Embedding AI throughout their business (37%)
Organizing data to create a business-ready analytics foundation (37%)
Collecting data to make it simple and accessible (37%)

For larger companies, data analysis and infusing AI throughout their business is the biggest challenge. For smaller businesses, the biggest challenge is data collection.
3. Investments in AI Have Increased
The COVID-19 pandemic accelerated the rollout of AI among organizations. In fact, 43% of the surveyed IT professionals said their companies had accelerated AI rollout due to COVID-19. Improving employee productivity (38%) and the requirement of a better way to interact with customers (36%) were other factors influencing organization decisions to adopt automation software due to the pandemic.
Over the next year, organizations intend to invest in all areas of artificial intelligence. This ranges from workforce and skill development to buying tools and implementing them for their processes. The following are a few key areas one-third of organizations plan to invest in:

Embedding AI into current AI applications and processes (34%)
Reskilling and workforce development (34%)
Off-the-shelf AI applications (34%)
Proprietary AI solutions (33%)
Off-the-shelf tools to build their own models and applications (33%)

Also read: Realizing the Full Potential of Artificial Intelligence and Automation
4. Trusted, Explainable AI Is Crucial for Widespread Adoption
A significant number of the surveyed IT professionals believe that a trusted and explainable AI is critical to its widespread adoption and business success, which includes maintaining brand integrity and regulatory compliance. About 91% of organizations using AI believe their ability to explain how the AI decided is crucial.
For over three-quarters of IT professionals, they should be able to trust the AI’s output to be reliable, fair, and safe. Organizations in India (95%), China (85%), Latin America (82%), and the U.S. (80%) believe that this factor is crucial to them.
Trust is on top of the mind for these companies as 86% believe that consumers will more likely choose businesses offering transparency and an ethical framework on how their data and AI models are built and used. Having said that, more than half of the respondents face significant challenges getting there.
The three biggest challenges to developing trusted AI are:

Lack of skills or training to develop and manage trustworthy AI (65%)
AI governance and management tools that do not work across all data environments (62%)
AI outcomes that are not explainable (58%)

5. NLP Is at the Forefront of Recent AI Adoption
Natural language processing (NLP), one of the foundational technologies for AI models, is steadily becoming an important tool for organizations to empower their employees and interact with their customers. Over the last year, many organizations have been either motivated to adopt this technology or recognized its value to them. Almost half of the respondents say their organization is currently using NLP, and one-quarter plan to use it over the next year.
Professionals considering NLP adoption report a few barriers to entry:

Technology is too expensive (29%)
It requires too much training to be relevant (26%)
It is difficult to keep up to date (24%)
Technology is too complex to use (22%)
The organization lacks the requisite skillset (22%)

About 52% of organizations are using or considering using NLP solutions to improve customer experience, and 43% are using them to improve cost efficiency.
6. Automation Technologies Are Becoming Deeply Embedded
As more businesses become familiar with AI’s potential, automation technologies are getting more deeply embedded in the daily operations to increase efficiencies and save costs, among other objectives. Businesses are also using automation for increasingly complex use cases. About 80% of organizations are already using automation tools or plan to use them over the next year.
Over a third of organizations said that improving employee productivity (38%) and needing a better way to interact with customers (36%) influenced their decision to use automation software owing to the COVID-19 pandemic.
The UK has the lowest adoption of these tools (32% not using and 49% already using), and China has the highest adoption (8% not using and 71% already using).
Companies that have already deployed AI are more than twice as likely to be using RPA as those that are currently exploring AI.
7. Improving Data Access for AI Projects Is Important
The current remote work practices and technological advancements, such as edge computing and IoT, have created a data deluge for businesses. Organizations also need to make sure this information is accessible, secure, accurately informing their business intelligence (BI), and complying with privacy regulations. The challenge is that this humongous data is spread across extensive IT estates. About 87% of respondents say it is somewhat or very important that they can build and run their AI projects wherever the data resides.
About 83% of organizations feel confident they have the right tools to access data across their business wherever it resides. However, only 51% say that their platform offers a single, unified view of the organization’s data. Also, about 67% say they are drawing from over 20 different data sources to inform their AI, BI, and analytics systems.
Also read: How Can Lenders Leverage Artificial Intelligence for Financial Inclusion?
Final Thoughts
As organizations emerge from the pandemic and their business needs change, AI has become more vital for improving cost efficiencies and customer experience. However, challenges and considerations persist for both large and small companies to the wider adoption of the technology. Yet, as businesses look for innovative ways to digitally transform themselves, investments in AI will continue to accelerate.
Are you presently using or planning to deploy AI in the next 12 months? Do share with us on LinkedInOpens a new window , TwitterOpens a new window , or FacebookOpens a new window .











								                  artificial intelligence										

								                  COVID-19										



Share This Article:
 





Karthik Kashyap




 opens a new window
 opens a new window 



 opens a new window  opens a new window
  	
					Karthik comes from a diverse educational and work background. With an engineering degree and a Masters in Supply Chain and Operations Management from Nottingham University, United Kingdom, he has experience of close to 15 years having worked across different industries out of which, he has worked as a content marketing professional for a significant part of his career. Currently, as an assistant editor at Spiceworks Ziff Davis, he covers a broad range of topics across HR Tech and Martech, from talent acquisition to workforce management and from marketing strategy to innovation. Besides being a content professional, Karthik is an avid blogger, traveler, history buff, and fitness enthusiast. To share quotes or inputs for news pieces, please get in touch on karthik.kashyap@swzd.com			








								Do you still have questions? Head over to the Spiceworks Community to find answers.
							

Take me to Community





",,,,,,,,,,,,,,,,,,,,,,,,,,
https://news.google.com/rss/articles/CBMiZWh0dHBzOi8vd3d3LmFjdHVpYS5jb20vZW5nbGlzaC9hcnRpZmljaWFsLWludGVsbGlnZW5jZS1tb2RlbC1kaXNwcm92ZXMtc29tZS1tYXRoZW1hdGljYWwtY29uamVjdHVyZXMv0gEA?oc=5,Artificial intelligence model disproves some mathematical conjectures - Intelligence artificielle - Actu IA,2021-06-01,Intelligence artificielle - Actu IA,https://www.actuia.com,N/A,N/A,"In mathematics, a conjecture is a result that seems to be true, but for which no proof has been found: this is what makes it different from the theorem or property that can be proven in all cases where it is applicable. A Tel Aviv University postdoc specializing in machine learning (ML) and mathematics has […]",N/A,http://schema.org,BreadcrumbList,,,,,,,,,,,"[{'@type': 'ListItem', 'position': 1, 'item': {'@type': 'WebSite', '@id': 'https://www.actuia.com/', 'name': 'Accueil'}}, {'@type': 'ListItem', 'position': 2, 'item': {'@type': 'WebPage', '@id': 'https://www.actuia.com/english/artificial-intelligence-model-disproves-some-mathematical-conjectures/', 'name': 'Artificial intelligence model disproves some mathematical conjectures'}}]",N/A,N/A,"







Artificial intelligence model disproves some mathematical conjectures                    




Zacharie Tazrout
 - 



1 juin 2021





0                        








In mathematics, a conjecture is a result that seems to be true, but for which no proof has been found: this is what makes it different from the theorem or property that can be proven in all cases where it is applicable. A Tel Aviv University postdoc specializing in machine learning (ML) and mathematics has developed an ML model that can search for counterexamples that can disprove conjectures with the help of his team of researchers. The system has already disproved five conjectures in the field of combinatorial analysis and graph theory.

Combinatorial analysis and graph theory


Combinatorial or simply combinatorial analysis is a branch of mathematics that deals with the enumeration or counting of objects in different contexts. Thus, mathematicians study the set of combinations or configurations for a number of finite elements. For example, if we take several books, the objective of combinatorics is to know in how many different ways it will be possible to classify these books.
Graph theory is a discipline of mathematics and computer science that studies graphs, an abstract model consisting of nodes (or vertices, points) connected by links (or edges, lines). Many theories of communication, networks (computer or social) exploit graphs to better understand their functioning.

On the left, an illustration from Diderot and D’Alembert’s Encyclopedia proposing some of the 64 possible combinations for placing tiles with half-partitioned tiles.On the right, an arbitrary graph whose nodes are numbered.
Each of these two branches of mathematics has a large number of conjectures. These results are often considered to be accepted, because they work for many examples. However, if one of these examples does not work with this result, it is called a counterexample and thus disproves the conjecture.
A machine learning and reinforcement learning algorithm to disprove conjectures

For a conjecture to become a theorem, the result it evokes must be proven. On the other hand, to disprove a conjecture, it is enough to show that the result does not apply by taking an example for which the conjecture does not work, it is the famous counter-example. Adam Zsolt Wagner has developed a model of reinforcement learning based on this basic principle of mathematical proofs, the foundations of which he explains in an article.
The user proposes a conjecture and the algorithm proposes a measure that expresses the difficulty of disproving the proposition. The program creates random examples and uses these measures to evaluate their relevance as counterexamples, using machine learning. The AI eliminates the worst examples and replaces them with new randomly generated examples. The system repeats the process to find counterexamples that would refute a user’s suggestions.
For dozens of uses, the algorithm did not find an example that disproved these proposals. Five conjectures have been disproved, however, including one proposed by Richard Anthony Brualdi, a specialist in combinatorics and graph theory.
The rather strong opinions of mathematicians

Several mathematicians have expressed themselves on the quality of the model proposed by Adam Zsolt Wagner’s team. One of them is Leslie Hogben, from Iowa State University, whose conjecture was disproved by the AI:
“This is really impressive. What we’re seeing here is a huge benefit of artificial intelligence without a doubt, from a mathematical standpoint. It simply finds things for us, as a very perceptive person would. The counterexamples are needles in haystacks.”

Timothy Gowers of the Collège de France made a statement on Twitter around this AI model where he mentions some of what Adam Zsolt Wagner’s paper said while adding:
“This is an interesting proof of concept. Perhaps we can make it a simple conjecture testing tool that would be of great use to mathematical researchers.”

However, while Leslie Hogben is delighted that the model was able to disprove one of her conjectures , she believes that experts still need to be able to follow a computer proof:
“Personally, I would never have a problem with a computer disproof that can be verified. However, a computer proof that cannot be verified by hand would personally cause me some problems.”

In 1976, a theorem had been proved for the first time with the help of a computer: the computer had made an exhaustive list of all the examples for which the announced result was correct. Nevertheless, many mathematicians found the proof inelegant since it did not prove the conjecture in a classical way. In spite of this, information is nowadays widely used to solve mathematical problems.
Translated from Un modèle d’intelligence artificielle permet de réfuter certaines conjectures mathématiques
 




Previous article
A call for projects will be launched on artificial intelligence to complement the ASTRID programme





Next article
Cybersecurity: The start-up HarfangLab raises 5 million euros to develop and market its EDR software









Zacharie Tazrout








","[{'@type': 'Organization', '@id': 'https://www.actuia.com/#organization', 'name': 'ActuIA', 'url': 'https://www.actuia.com/', 'sameAs': ['https://www.facebook.com/Actu-IA-1105067856282712/', 'https://www.linkedin.com/company/18523131/', 'https://twitter.com/ActuIAFr'], 'logo': {'@type': 'ImageObject', '@id': 'https://www.actuia.com/#logo', 'inLanguage': 'fr-FR', 'url': 'https://www.actuia.com/wp-content/uploads/2017/02/actuia_square2.png', 'width': 200, 'height': 200, 'caption': 'ActuIA'}, 'image': {'@id': 'https://www.actuia.com/#logo'}}, {'@type': 'WebSite', '@id': 'https://www.actuia.com/#website', 'url': 'https://www.actuia.com/', 'name': 'ActuIA', 'description': 'Actualité de l&#039;intelligence artificielle', 'publisher': {'@id': 'https://www.actuia.com/#organization'}, 'potentialAction': [{'@type': 'SearchAction', 'target': 'https://www.actuia.com/?s={search_term_string}', 'query-input': 'required name=search_term_string'}], 'inLanguage': 'fr-FR'}, {'@type': 'ImageObject', '@id': 'https://www.actuia.com/english/artificial-intelligence-model-disproves-some-mathematical-conjectures/#primaryimage', 'inLanguage': 'fr-FR', 'url': 'https://www.actuia.com/wp-content/uploads/2021/05/Graphes.jpg', 'width': 800, 'height': 400, 'caption': 'graphes combinatoire recherche conjectures mathématiques machine learning apprentissage renforcement'}, {'@type': 'WebPage', '@id': 'https://www.actuia.com/english/artificial-intelligence-model-disproves-some-mathematical-conjectures/#webpage', 'url': 'https://www.actuia.com/english/artificial-intelligence-model-disproves-some-mathematical-conjectures/', 'name': 'Artificial intelligence model disproves some mathematical conjectures - ActuIA', 'isPartOf': {'@id': 'https://www.actuia.com/#website'}, 'primaryImageOfPage': {'@id': 'https://www.actuia.com/english/artificial-intelligence-model-disproves-some-mathematical-conjectures/#primaryimage'}, 'datePublished': '2021-06-01T11:34:13+00:00', 'dateModified': '2021-06-01T11:34:13+00:00', 'breadcrumb': {'@id': 'https://www.actuia.com/english/artificial-intelligence-model-disproves-some-mathematical-conjectures/#breadcrumb'}, 'inLanguage': 'fr-FR', 'potentialAction': [{'@type': 'ReadAction', 'target': ['https://www.actuia.com/english/artificial-intelligence-model-disproves-some-mathematical-conjectures/']}]}, {'@type': 'BreadcrumbList', '@id': 'https://www.actuia.com/english/artificial-intelligence-model-disproves-some-mathematical-conjectures/#breadcrumb', 'itemListElement': [{'@type': 'ListItem', 'position': 1, 'item': {'@type': 'WebPage', '@id': 'https://www.actuia.com/', 'url': 'https://www.actuia.com/', 'name': 'Intelligence artificielle'}}, {'@type': 'ListItem', 'position': 2, 'item': {'@type': 'WebPage', '@id': 'https://www.actuia.com/english/', 'url': 'https://www.actuia.com/english/', 'name': 'English'}}, {'@type': 'ListItem', 'position': 3, 'item': {'@type': 'WebPage', '@id': 'https://www.actuia.com/english/artificial-intelligence-model-disproves-some-mathematical-conjectures/', 'url': 'https://www.actuia.com/english/artificial-intelligence-model-disproves-some-mathematical-conjectures/', 'name': 'Artificial intelligence model disproves some mathematical conjectures'}}]}]",,,,,,,,,,,,,,,,,,,,,,,,,
https://news.google.com/rss/articles/CBMiV2h0dHBzOi8vd3d3LnZ1bHR1cmUuY29tLzIwMjEvMDYvZ3JpbWVzLXRpa3Rvay1jb21tdW5pc20tYWktYXJ0aWZpY2lhbC1pbnRlbGxpZ2VuY2UuaHRtbNIBAA?oc=5,"Grimes Posts TikTok on Communism, AI Artificial Intelligence - Vulture",2021-06-03,Vulture,https://www.vulture.com,"Musician Grimes posted a TikTok on June 2 talking about how artificial intelligence could “solve for abundance” and help communism, focusing on how AI could help with farming.",[''],"“If you think about it, AI is actually the fastest path to communism,” she said in a new TikTok.","“If you think about it, AI is actually the fastest path to communism,” she said in a new TikTok.",http://schema.org,NewsArticle,http://www.vulture.com/2021/06/grimes-tiktok-communism-ai-artificial-intelligence.html,"[{'@id': 'https://pyxis.nymag.com/v1/imgs/1fa/0d2/80ea2dc03dcdeebe88e278fa3e55e7da15-grimes.1x.rsocial.w1200.jpg', '@type': 'ImageObject', 'height': '630', 'url': 'https://pyxis.nymag.com/v1/imgs/1fa/0d2/80ea2dc03dcdeebe88e278fa3e55e7da15-grimes.1x.rsocial.w1200.jpg', 'width': '1200'}, {'@type': 'ImageObject', 'height': '', 'width': ''}]","[{'@type': 'Person', 'jobTitle': 'Contributor', 'name': 'Justin Curto', 'url': 'https://www.vulture.com/author/justin-curto'}]","{'@type': 'Organization', 'name': 'Vulture', 'sameAs': 'https://www.vulture.com', 'logo': {'@type': 'ImageObject', 'url': 'https://www.vulture.com/media/sites/vulture/logo.w600.h60.png', 'height': '60', 'width': '600'}}","Grimes Posts TikTok on Communism, AI Artificial Intelligence",2021-06-03T12:26:57.236-04:00,2021-06-03T12:26:57.236-04:00,Music,,False,,N/A,N/A,"




theory

June 3, 2021



Grimes Wants Communists to Give AI a Chance







By 
Justin Curto,
          who covers music, TV, and celebrity for Vulture











       



Photo: Presley Ann/Patrick McMullan via Getty Image



Grimes may be dating the richest man on the planet, but that doesn’t stop the musician from thinking about communism. Take this June 2 TikTok, in which Grimes presents a “proposition for the communists.” In the humble tradition of previous communist thinkers like Karl Marx, she continues, “If you think about it, AI is actually the fastest path to communism.” Let her explain: “If implemented correctly, AI could actually theoretically solve for abundance. Like, we could totally get to a situation where nobody has to work, everybody is provided for with a comfortable state of being, comfortable living. AI could automate all the farming, weed out systematic corruption, thereby bringing us to as close as possible to genuine equality.” Never mind that technology often plays into the worst impulses of capitalism and exacerbates inequality — Grimes says robots can help us farm! (As if, also, farming is the only work that needs to be done in a communist society?) “Because let’s be real,” Grimes adds. “Enforced farming is really not a vibe.”






The artist later commented that the TikTok was “a joke,” adding that she’s “not a communist,” in case you confused her — again, dating the richest person on earth! — for one. “But maybe the technocrats and communists could get along,” she continued. Let a girl dream.

Related










                      Is Grimes an Anti-Hero or Villain?
                  








Tags:


theory


communism


politics


artificial intelligence


grimes


elon musk


music


extremely online

More








Show 
4 Comments / 4 New

Leave a Comment


Grimes Wants Communists to Give AI a Chance


",,https://www.vulture.com/2021/06/grimes-tiktok-communism-ai-artificial-intelligence.html,en-US,,"{'@type': 'WebPageElement', 'cssSelector': '.article-content', 'isAccessibleForFree': False}",,,,,,,,#articleSchema,,,,,,https://pyxis.nymag.com/v1/imgs/1fa/0d2/80ea2dc03dcdeebe88e278fa3e55e7da15-grimes.1x.rsocial.w1200.jpg,,,,,,,
https://news.google.com/rss/articles/CBMiYWh0dHBzOi8vd3d3LmFjY2VudHVyZS5jb20vc2UtZW4vY2FyZWVycy9leHBsb3JlLWNhcmVlcnMvYXJlYS1vZi1pbnRlcmVzdC9haS1hbmQtYW5hbHl0aWNzLWNhcmVlcnPSAQA?oc=5,AI & Analytics Careers - Accenture,2021-06-02,Accenture,https://www.accenture.com,Work with a diverse team of data scientists and AI experts to apply the power of AI and change what’s possible for business and society.,"applied intelligence careers, data science jobs, data science careers, analytics jobs, career in data analytics, career in artificial intelligence, ai careers, data science opportunities, accenture applied intelligence, applied intelligence careers",Work with a diverse team of data scientists and AI experts to apply the power of AI and change what’s possible for business and society.,Work with a diverse team of data scientists and AI experts to apply the power of AI and change what’s possible for business and society.,,,,,,,,,,,,,,N/A,N/A,"



Search All Jobs
Search All Jobs
Search All Jobs






Read careers Blog
Read careers Blog
Read careers Blog






Register for Job Alerts
Register for Job Alerts
Register for Job Alerts


",,,,,,,,,,,,,,,,,,,,,,,,,,
https://news.google.com/rss/articles/CBMicWh0dHBzOi8vd3d3Lm1lZGRldmljZW9ubGluZS5jb20vZG9jL3doYXQtZG8tYXJ0aWZpY2lhbC1pbnRlbGxpZ2VuY2UtYW5kLWNvbnRpbnVvdXMtdmFsaWRhdGlvbi1oYXZlLWluLWNvbW1vbi0wMDAx0gEA?oc=5,What Do Artificial Intelligence And Continuous Validation Have In Common - Med Device Online,2021-06-02,Med Device Online,https://www.meddeviceonline.com,Validation documentation can be reduced by applying automated testing and deployment. This article discusses ISO standards that address risk...,N/A,"<p>Validation documentation can be reduced by applying automated testing and deployment. This article discusses ISO standards that address risk management, IT alignment with software engineering, opportunities for continuous lifecycle management, and how artificial intelligence (AI) can help.</p>
","<p>Validation documentation can be reduced by applying automated testing and deployment. This article discusses ISO standards that address risk management, IT alignment with software engineering, opportunities for continuous lifecycle management, and how artificial intelligence (AI) can help.</p>
",,,,,,,,,,,,,,N/A,N/A,N/A,,,,,,,,,,,,,,,,,,,,,,,,,,
https://news.google.com/rss/articles/CBMic2h0dHBzOi8vd3d3Lm1hYXN0cmljaHR1bml2ZXJzaXR5Lm5sL25ld3MvbWVldC1wcm9mLW5hdmEtdGludGFyZXYtZnVsbC1wcm9mZXNzb3ItZXhwbGFpbmFibGUtYXJ0aWZpY2lhbC1pbnRlbGxpZ2VuY2XSAQA?oc=5,"Meet Prof. Nava Tintarev, full professor of Explainable Artificial Intelligence - Maastricht University",2021-06-02,Maastricht University,https://www.maastrichtuniversity.nl,N/A,"nava tintarev, explainable artificial intelligence, artificial intelligence, xai, fse, dke","Prof. Nava Tintarev joined Maastricht University in October of last year. She focuses on Explainable Artificial Intelligence, which has an important societal component to it.",N/A,,,,,,,,,,,,,,N/A,N/A,"



2 June 2021




    Meet Prof. Nava Tintarev, full professor of Explainable Artificial Intelligence    
Prof. Nava Tintarev joined Maastricht University in October of last year. She focuses on Explainable Artificial Intelligence, which has an important societal component to it: “My take on things is much more user-centered than what you see in a lot of computer science departments.”


You may not know what a recommender system is, but you have almost certainly encountered one. “It’s the type of automated systems used by companies like Amazon and Spotify, which look at your previous profile and try to suggest something in the future”, says Prof. Tintarev.
As a recently appointed full professor in Explainable Artificial Intelligence, Nava Tintarev is a leading expert in human-computer interaction. Her work focuses on artificially intelligent systems that give advice. ‘Advice’ is to be taken broadly here: beyond recommending what to buy, see or hear next, it can for instance also refer to how search engines prioritize search results for specific users.



    Explaining the unexplained    














Most artificially intelligent systems are notorious for their black box-like nature: they tend to make predictions based on previous data, but won’t reveal how they arrived at their conclusions. Where a person might say ‘I recommend you look into cat supplies, because you searched the internet for pet shelters and cat gifs all of last week’, an algorithm’s reasoning can be much more sophisticated – and entirely opaque.
That lack of transparency comes at a price.




What if an algorithm is biased, but used for important things like your news consumption – thereby informing your opinions about disputed topics like face masks and vaccinations? And what if a computer’s biases only amplify yours, but you don’t know that it’s happening?
The field of Explainable Artificial Intelligence devises methods to generate insights into why AI recommends or takes particular actions. Explanations may for instance be presented in natural language or through using intelligent interactive interfaces. Such explanations are widely considered a key requirement for the responsible use of artificial intelligence in society.
Recommender systems
Back to recommender systems. Since they pop up in all sorts of settings, working on them takes on varied contexts as well. “I do a lot of work on recommender systems,” says Prof. Tintarev, “for instance in the music domain. Maybe things like the weather, your mood, and activity level change the kind of music you enjoy. The amount of interactions and explanations that you could need in these settings may also differ. You can adapt the recommender system and the explanations they generate to these kinds of things.”
“Right now, my team is working on explaining automated group recommendations. These will often require a compromise. If someone is not getting their first choice, how can we use explanations to keep the group happy and smooth those rough edges?”



    Opening Pandora’s box    














But while Prof. Tintarev initially mentions tourist and music recommendations, smoothing edges through explanations can also tackle important societal goals. Recommender systems have been under scrutiny for the risk of promoting so-called ‘filter bubbles’: online spaces where users are served content that aligns with their viewpoints, whether through Youtube, Facebook, or a different platform.
Prof. Tintarev: “I’m concerned about the fact that we are becoming more polarized. That we aren’t exposed to viewpoints that differ from our own – even when we want to be.""




""The goal is not necessarily to agree with those other viewpoints, but to be aware that they exist. How do we create interaction in a way that helps people make informed decisions? Many of my current projects, also in collaboration with industry, examine online information and diversity of viewpoints. In a project co-funded by IBM, we are for example looking into search results. Does it matter which results are in the list? Or how they are ordered and displayed? How does this influence user behavior and attitudes?” The end goal, she stresses, is a broad awareness of their information consumption.



    Not your average computer scientist    
“My vision of Explainable Artificial Intelligence is one that is human understandable”, prof. Tintarev concludes. “We don’t only need to be able to automatically generate explanations, we also need to see when they help people make better informed decisions. That requires empirical work, like evaluations with users. It also requires understanding the circumstances: when are explanations needed and useful? What do we need to change and how should we adapt the explanations?”
“My take on things is much more user-centered than what you see in a lot of computer science departments. It’s half psychology, half computer science.” Needless to say, we’re excited to have Prof. Tintarev on our team.





















Faculty of Science and Engineering

Department of Data Science and Knowledge Engineering
 
Biography
Prof. Dr. Nava Tintarev leads and contributes to several national and international projects in the field of human-computer interaction in artificial advice-giving systems, specifically developing the state-of-the-art for automatically generated explanations and explanation interfaces.
These include projects funded by IBM, Twitter, and the European Commission. She has collaborated with private and public organizations including Inspectie Leefomgeving en Transport (ILT), CGI/Prorail, Capgemini/Unilever, Porsche, Blendle, PersGroep, and FDMedia. In addition, Prof. Tintarev regularly shapes international research programmes and organizes workshops relating to responsible data science. ACM, the Association for Computing Machinery, recognized her as senior member in 2020.
Prof. Tintarev was appointed Full Professor and Chair of Explainable Artificial Intelligence at UM’s Faculty of Science and Engineering on October 1, 2020. She is embedded in FSE’s Department of Data Science and Knowledge Engineering. She is also a Visiting Professor in the Software Technology department at TU Delft.












Also read




















Working at UM: “a life-changing experience”



2 July 2024







""I am proud that our new Circular Plastics group published its first completely in-house research,"" Kim Ragaert says. She founded the research group three years ago, when she moved to Maastricht. Her work has laid the foundations for many innovations in the field of plastic recycling, and she is...




















How does the universe taste?



29 May 2024







Gerco Onderwater investigates the flavour of the universe while guarding the flavour of the Maastricht Science Programme. On 31 May, during his inaugural lecture, he provided a pre-taste of his work in Maastricht. 




















Bridging the gap between technology and clinical practice



30 April 2024







Lee Bouwman, a vascular surgeon and endowed professor of Clinical Engineering, specialises in the implementation of groundbreaking healthcare technologies. The key to success, he says, lies in the collaboration between engineers and clinicians. This approach has already resulted in a range of...









",,,,,,,,,,,,,,,,,,,,,,,,,,
https://news.google.com/rss/articles/CBMicWh0dHBzOi8vd3d3LnZhbml0eWZhaXIuY29tL3N0eWxlLzIwMjEvMDYvZ3JpbWVzLWNvbW11bmlzbS1hcnRpZmljaWFsLWludGVsbGlnZW5jZS1mYXJtaW5nLXRpa3Rvay1mdXR1cmUtZWxvbi1tdXNr0gEA?oc=5,Grimes Has a “Proposition for the Communists” Involving A.I. Farming - Vanity Fair,2021-06-03,Vanity Fair,https://www.vanityfair.com,"Grimes shared her “proposition for the communists” involving A.I. farming on TikTok, promising that it’s possible to achieve a world “where nobody has to work,” seemingly forgetting that her boyfriend, Elon Musk, is one of the world’s foremost capitalists.","['celebrity', 'grimes', 'artificial intelligence', 'farmer', 'communism', 'tiktok', 'splitscreenimagerightinset', 'web']","The singer promised the possibility of a world “where nobody has to work,” seemingly forgetting that her boyfriend, Elon Musk, is one of the world’s foremost capitalists.","The singer promised the possibility of a world “where nobody has to work,” seemingly forgetting that her boyfriend, Elon Musk, is one of the world’s foremost capitalists.",https://schema.org/,BreadcrumbList,https://www.vanityfair.com/style/2021/06/grimes-communism-artificial-intelligence-farming-tiktok-future-elon-musk,"['https://media.vanityfair.com/photos/60b904816e88693abf6fdbde/16:9/w_4000,h_2250,c_limit/1133710639', 'https://media.vanityfair.com/photos/60b904816e88693abf6fdbde/4:3/w_4000,h_3000,c_limit/1133710639', 'https://media.vanityfair.com/photos/60b904816e88693abf6fdbde/1:1/w_4000,h_4000,c_limit/1133710639']","[{'@type': 'Person', 'name': 'Emily Kirkpatrick', 'sameAs': 'https://www.vanityfair.com/contributor/emily-kirkpatrick'}]","{'@context': 'https://schema.org', '@type': 'Organization', 'name': 'Vanity Fair', 'logo': {'@type': 'ImageObject', 'url': 'https://www.vanityfair.com/verso/static/vanity-fair/assets/newsletter-social.jpg', 'width': '500px', 'height': '114px'}, 'url': 'https://www.vanityfair.com'}",Grimes Has a “Proposition for the Communists” Involving A.I. Farming,2021-06-03T13:27:00.000-04:00,2021-06-03T13:27:00.000-04:00,style,,True,"[{'@type': 'ListItem', 'position': 1, 'name': 'Style', 'item': 'https://www.vanityfair.com/style'}, {'@type': 'ListItem', 'position': 2, 'name': 'grimes', 'item': 'https://www.vanityfair.com/topic/grimes'}, {'@type': 'ListItem', 'position': 3, 'name': 'Grimes Has a “Proposition for the Communists” Involving A.I. Farming'}]",tags,N/A,"The Future Is A.I. FarmingGrimes Has a “Proposition for the Communists” Involving A.I. FarmingThe singer promised the possibility of a world “where nobody has to work,” seemingly forgetting that her boyfriend, Elon Musk, is one of the world’s foremost capitalists.By Emily KirkpatrickJune 3, 2021FacebookXEmailSave Storyby Frazer Harrison/Getty ImagesSave this storySaveSave this storySaveGrimes has a vision for the future of humanity that promises a world where “communists” no longer have to do any work thanks to artificial intelligence taking over the manual labor of farming.In a TikTok posted to her account on Wednesday with the caption “A.I. is the fastest path to communism,” the pop star offered up her “proposition for the communists” while superimposing her face over a panel from the manga Berserk. “So typically, most of the communists I know are not big fans of A.I,” she began. “But, if you think about it, A.I. is actually the fastest path to communism.” She went on to explain, “So, if implemented correctly, A.I. could actually theoretically solve for abundance. Like, we could totally get to a situation where nobody has to work; everybody is provided for with a comparable state of being, comfortable living. A.I. could automate all the farming, we could out systematic corruption, thereby bringing us as close as possible to genuine equality.” She concluded her proposal by adding, “So basically, everything that everybody loves about communism, but without the collective farm. ‘Cause, let’s be real, enforced farming is really not a vibe.”TikTok contentThis content can also be viewed on the site it originates from.However, Grimes—a longtime A.I. enthusiast—seems to have seriously misunderstood the end goal of communism when crafting her TikTok proposal. Proponents of this ideology are generally not trying to create a world “where nobody has to work,” but rather a stateless, classless society where people are fairly compensated for their labor and skills, which would in turn eliminate the inequality and suffering brought about by capitalism. The singer also seems to have forgotten that she's currently in a relationship with one of the world's foremost capitalists, second richest man on the plant Elon Musk, who probably wouldn't be particularly down with the “vibe” of wealth redistribution or making his profitable A.I. technology freely available to the public.More Great Stories From Vanity Fair— An Intimate View of a Young Queen Elizabeth II— The Sacklers Launched OxyContin. Everyone Knows It Now.— Exclusive Excerpt: An Icy Death at the Bottom of the World— Lolita, Blake Bailey, and Me— Kate Middleton and the Future of the Monarchy— The Occasional Terror of Dating in the Digital Age— The 13 Best Face Oils for Healthy, Balanced Skin— From the Archive: Tinder and the Dawn of the “Dating Apocalypse”— Sign up for the “Royal Watch” newsletter to receive all the chatter from Kensington Palace and beyond.Most PopularPoliticsAs Donald Trump’s Prospects Soar, Ivanka Inches Back to the National StageBy Gabriel Sherman, Vanity FairCelebrityInside the $600 Million Ambani Wedding: Jewels, Stars, and the Party to End All PartiesBy Kase Wickman, Vanity FairAward SeasonViggo Mortensen Speaks His Mind: On Amazon’s “Shameful” Decision, Green Book’s “Disingenuous” Critics, and Indie Film’s Unclear FutureBy David Canfield, Vanity Fair",,"{'@type': 'WebPage', '@id': 'https://www.vanityfair.com/style/2021/06/grimes-communism-artificial-intelligence-farming-tiktok-future-elon-musk'}",,"Grimes shared her “proposition for the communists” involving A.I. farming on TikTok, promising that it’s possible to achieve a world “where nobody has to work,” seemingly forgetting that her boyfriend, Elon Musk, is one of the world’s foremost capitalists.",,,,,,,"{'@type': 'CreativeWork', 'name': 'Vanity Fair'}",,,,,,,,"https://media.vanityfair.com/photos/60b904816e88693abf6fdbde/1:1/w_4000,h_4000,c_limit/1133710639","In a TikTok posted to her account on Wednesday with the caption “A.I. is the fastest path to communism,” the pop star offered up her “proposition for the communists” while superimposing her face over a panel from the manga Berserk. “So typically, most of the communists I know are not big fans of A.I,” she began. “But, if you think about it, A.I. is actually the fastest path to communism.” She went on to explain, “So, if implemented correctly, A.I. could actually theoretically solve for abundance. Like, we could totally get to a situation where nobody has to work; everybody is provided for with a comparable state of being, comfortable living. A.I. could automate all the farming, we could out systematic corruption, thereby bringing us as close as possible to genuine equality.” She concluded her proposal by adding, “So basically, everything that everybody loves about communism, but without the collective farm. ‘Cause, let’s be real, enforced farming is really not a vibe.”
However, Grimes—a longtime A.I. enthusiast—seems to have seriously misunderstood the end goal of communism when crafting her TikTok proposal. Proponents of this ideology are generally not trying to create a world “where nobody has to work,” but rather a stateless, classless society where people are fairly compensated for their labor and skills, which would in turn eliminate the inequality and suffering brought about by capitalism. The singer also seems to have forgotten that she's currently in a relationship with one of the world's foremost capitalists, second richest man on the plant Elon Musk, who probably wouldn't be particularly down with the “vibe” of wealth redistribution or making his profitable A.I. technology freely available to the public.
More Great Stories From Vanity Fair
— An Intimate View of a Young Queen Elizabeth II
— The Sacklers Launched OxyContin. Everyone Knows It Now.
— Exclusive Excerpt: An Icy Death at the Bottom of the World
— Lolita, Blake Bailey, and Me
— Kate Middleton and the Future of the Monarchy
— The Occasional Terror of Dating in the Digital Age
— The 13 Best Face Oils for Healthy, Balanced Skin
— From the Archive: Tinder and the Dawn of the “Dating Apocalypse”
— Sign up for the “Royal Watch” newsletter to receive all the chatter from Kensington Palace and beyond.",https://www.vanityfair.com/style/2021/06/grimes-communism-artificial-intelligence-farming-tiktok-future-elon-musk,,,,,
https://news.google.com/rss/articles/CBMikgFodHRwczovL3d3dy5idXNpbmVzcy1zdGFuZGFyZC5jb20vYXJ0aWNsZS90ZWNobm9sb2d5L3RoZS11bi1uZWVkcy10by1zdGFydC1yZWd1bGF0aW5nLXRoZS13aWxkLXdlc3Qtb2YtYXJ0aWZpY2lhbC1pbnRlbGxpZ2VuY2UtMTIxMDYwMTAwMzA0XzEuaHRtbNIBAA?oc=5,The UN needs to start regulating the 'Wild West' of artificial intelligence - Business Standard,2021-06-01,Business Standard,https://www.business-standard.com,The proposal for a regulation on AI published by the European Commission recently is the first document of its kind to attempt to tame the multi-tentacled beast that is artificial intelligence,"Articles,Artificial intelligence,Academic disciplines,Science and technology,Applications of artificial intelligence,United Nations High Commissioner for Refugees,Biometrics,Regulation of artificial intelligence,Regulation of algorithms,Business Support Services (NEC),Diversified Chemicals,Software (NEC),European Commission's AI,actual decision-making systems,Yemen,artificial intelligence,United Nations,response services,United States,UNICEF's Innovation Labs,Jeremy Kahn,Customs Enforcement,United States Bureau of Immigration and Customs Enforcement,United Nations Artificial intelligence technologies,Canada,Centre for Humanitarian Data,European Commission,analytical services,United Nations International Children's Emergency Fund,amnesty international,Eleonore Fournier-Tombs,McGill University,European Union,MONTREAL,World Food Programme,intelligence technologies,Palantir,risk systems,artificial intelligence solutions,Global Pulse Lab,AI technology,Wild West days,Somalia",The proposal for a regulation on AI published by the European Commission recently is the first document of its kind to attempt to tame the multi-tentacled beast that is artificial intelligence,The proposal for a regulation on AI published by the European Commission recently is the first document of its kind to attempt to tame the multi-tentacled beast that is artificial intelligence,https://schema.org,BreadcrumbList,"['https://www.business-standard.com/', 'https://www.business-standard.com/economy', 'https://www.business-standard.com/finance', 'https://www.business-standard.com/finance/personal-finance', 'https://www.business-standard.com/world-news', 'https://www.business-standard.com/latest-news', 'https://epaper.business-standard.com/', 'https://www.business-standard.com/todays-paper', 'https://www.business-standard.com/markets', 'https://www.business-standard.com/budget', 'https://www.business-standard.com/opinion', 'https://www.business-standard.com/india-news', 'https://www.business-standard.com/portfolio', 'https://www.business-standard.com/sports/olympics', 'https://www.business-standard.com/technology', 'https://www.business-standard.com/specials', 'https://www.business-standard.com/content', 'https://www.business-standard.com/management', 'https://www.business-standard.com/multimedia', 'https://www.business-standard.com/shows/the-morning-show', 'https://www.business-standard.com/shows/banking-show', 'https://www.business-standard.com/video-gallery', 'https://www.business-standard.com/multimedia/photogallery/', 'https://www.business-standard.com/podcast', 'https://www.business-standard.com/sports', 'https://www.business-standard.com/cricket', 'https://www.business-standard.com/industry', 'https://www.business-standard.com/industry/auto', 'https://www.business-standard.com/industry/banking', 'https://www.business-standard.com/industry/sme', 'https://www.business-standard.com/industry/agriculture', 'https://www.business-standard.com/industry/news', 'https://www.business-standard.com/companies', 'https://www.business-standard.com/lifestyle', 'https://www.business-standard.com/entertainment', 'https://www.business-standard.com/social-viral', 'https://www.business-standard.com/health', 'https://www.business-standard.com/book', 'https://www.business-standard.com/education', 'https://www.business-standard.com/apps']",,,,,,,,"['home', 'economy', 'finance', 'personal finance', 'world news', 'latest', 'e-paper', ""today's paper"", 'markets', 'budget 2024', 'opinion', 'india news', 'portfolio', 'olympics 2024', 'technology', 'specials', 'partner content', 'management', 'multimedia', 'the morning show', 'the banking show', 'video gallery', 'photo gallery', 'podcast', 'sports', 'cricket', 'industry', 'auto', 'banking', 'sme', 'agriculture', 'other news', 'companies', 'lifestyle', 'entertainment', 'social viral', 'health', 'books', 'education', 'bs apps']",,"[{'@type': 'ListItem', 'position': 1, 'item': {'@id': 'https://www.business-standard.com/', 'name': 'Home'}}, {'@type': 'ListItem', 'position': 2, 'item': {'@id': 'https://www.business-standard.com/technology', 'name': 'Technology'}}, {'@type': 'ListItem', 'position': 3, 'item': {'@id': 'https://www.business-standard.com/technology/tech-news', 'name': 'Tech News'}}, {'@type': 'ListItem', 'position': 4, 'item': {'name': ""The UN needs to start regulating the 'Wild West' of artificial intelligence""}}]",N/A,N/A,N/A,,,,,,,,,,,,"{'@type': 'ImageObject', 'url': 'https://www.business-standard.com/assets/web-assets/images/BSlogo600x60.png', 'width': '600', 'height': '60'}",,,,,,"['https://www.facebook.com/bsindia', 'https://twitter.com/bsindia', 'https://www.youtube.com/user/BusinessStandardLtd', 'https://in.linkedin.com/company/business-standard', 'https://t.me/bsindiaofficial']",,,,,,,,
https://news.google.com/rss/articles/CBMidWh0dHBzOi8vd3d3LmRocy5nb3Yvc2NpZW5jZS1hbmQtdGVjaG5vbG9neS9uZXdzLzIwMjEvMDYvMDMvZmVhdHVyZS1hcnRpY2xlLWhhbmRzLWZyZWUtY29tbXMtdGVjaC1icmVha3MtdGhyb3VnaC1ub2lzZdIBAA?oc=5,Feature Article: Hands-Free Comms Tech Breaks Through the Noise - Homeland Security,2021-06-03,Homeland Security,https://www.dhs.gov,DHS S&T partnered with the Johns Hopkins University Applied Physics Laboratory and Think-A-Move to develop Automated Speech Recognition technology.,N/A,N/A,N/A,,,,,,,,,,,,,,N/A,N/A,"

Anyone who has ever craned their neck to hold a phone between their ear and their shoulder can appreciate the benefit of hands-free communication. For first responders, the situation is typically much more serious than trying to chat with a friend while cooking dinner, though. They are often in critical response scenarios where a hands-free voice interface would improve both safety and efficiency, which could ultimately translate into saving lives.Automated speech recognition technology

As part of its mission to support the identification and integration of existing and emerging technologies, the Department of Homeland Security (DHS) Science and Technology Directorate (S&T) partnered with the Johns Hopkins University Applied Physics Laboratory (APL) and their sub-contractor Think-A-Move to develop Automated Speech Recognition (ASR) technology. The resulting innovation is known as the Direct Artificial Intelligence System Interface, or DAISI, which enables voice-activated capabilities in noisy operational environments. DAISI was selected out of multiple prototypes developed in response to an April 2018 request for proposals.Current speech recognition systems work reasonably well in quiet conditions, but quickly fail when the surrounding background noise increases—as is common for first responder situations. Being able to effectively communicate while multitasking, no matter the situation, will enhance situational awareness.“S&T consistently supports the development of technologies that make first responders safer, enable accurate and timely sharing of data and critical information, and seamlessly integrate across platforms and jurisdictions,” said S&T Project Manager Cuong Luu. “DAISI addresses a need identified as a priority capability for responders—effective and reliable hands-free communication so they can focus on doing their job.”Numerous Capabilities Within Easy Reach

DAISI is able to assist with various tasks throughout all stages of a response. While en route to an incident, the system provides voice control for the mobile data terminal, which is the computerized device used to communicate with the central dispatch office. Responders can use DAISI to initiate navigation, answer address queries, provide alternate routes, and pan and zoom throughout the map—all without lifting a finger.Once they arrive safely at the incident, voice-enabled hydrant location queries and friction loss calculation (which impacts the amount of water pressure required by the fire hose) can save crucial time. DAISI is also able to instantly access WISER (Wireless Information System for Emergency Responders) to identify hazardous materials at the site and guide appropriate precautionary measures.In addition to all these capabilities, on-scene report logging and transcription to text make capturing key benchmarks on the scene fast and easy. Back at the station, responders are able to use the event log to make the after-fire critique and fire investigation report more comprehensive and thorough.Tech That Will Come in Handy for First RespondersMaryland’s Howard County Department of Fire & Rescue Services has served as a testbed for the DAISI prototype over the last three years. The crew there has put DAISI to the test, trying out use cases identified during development and validating more than 80 different requirements to meets the needs of all sorts of potential situations. For example, should the worst happen—perhaps a partial building collapse traps a crew member—voice-activated mayday alerts add reliable backup support when a responder needs assistance.According to Howard County Battalion Chief Stanley Wurzburger, “DAISI quite literally can make the worst day of a firefighter’s career a little bit easier to get through.”The Future of Hands-Free Comms

What truly sets DAISI apart from existing technologies is the sophisticated machine learning voice recognition capability. As APL Project Manager Julee Rendon puts it, “It’s really about the language processing, the acoustic modeling, and the noise filtering.”Continued algorithm development is planned to ensure the platform will remain below the industry standard of a 15% word-error rate. The team also plans to explore ease-of-use for the user interface and long-term durability of the computer central processing unit to ensure DAISI’s ability to overcome the technical challenge of resource limitation.Commercial smart devices that can be similarly called upon by name and tasked with a multitude of requests require substantial connectivity, processing power, and battery life. DAISI is being designed for high performance regardless of the situation so function won’t be compromised by remote locations or extended use.“We’re looking at how to minimize the resource consumption and find the sweet spot of a capability like this that has to be available to first responders who may not have that bench of resources that they can connect to whenever they’re in the field,” added Rendon.DAISI should be ready for transition to commercial availability in the next couple of years. An important next step for developers is the final evaluation of the noise cancelling hardware. This includes safe and effective microphone placement and the successful integration with firefighters’ self-contained breathing apparatus without compromising the integrity of the facepiece seal.Finally, the development team will provide recommendations for adaption to other first responder communities. Though it has been applied to firefighter use cases thus far, there is great potential for paramedics, police, and members of the military to benefit from this capability as well. In an ever-expanding Internet of Things world, ASR represents the future of emergency response that could enable countless future technologies such as wireless biometric sensors.“This is a cornerstone technology,” said Ruth Vogel of APL. “If you don’t have the voice recognition capability, then a lot of the other next generation solutions are not going to work well.”For more information, contact (link sends email)STMedia@hq.dhs.gov.

Topics
Science and Technology


Keywords
Artificial Intelligence (AI)
Communication
Emergency Communication
First Responders Group (FRG)
Science and Technology
Speech

",,,,,,,,,,,,,,,,,,,,,,,,,,
https://news.google.com/rss/articles/CBMid2h0dHBzOi8vdGhlaGlsbC5jb20vY2hhbmdpbmctYW1lcmljYS9yZXNwZWN0L3BvdmVydHkvNTU2OTQ3LWFydGlmaWNpYWwtaW50ZWxsaWdlbmNlLWNvdWxkLWxlYWQtdG8tY29tbXVuaXNtLXNheXMtbXVzaWMv0gF7aHR0cHM6Ly90aGVoaWxsLmNvbS9jaGFuZ2luZy1hbWVyaWNhL3Jlc3BlY3QvcG92ZXJ0eS81NTY5NDctYXJ0aWZpY2lhbC1pbnRlbGxpZ2VuY2UtY291bGQtbGVhZC10by1jb21tdW5pc20tc2F5cy1tdXNpYy9hbXAv?oc=5,Artificial intelligence could lead to communism says music star and Elon Musk girlfriend Grimes in viral video - The Hill,2021-06-04,The Hill,https://thehill.com,The singer later commented that her video was a joke.,N/A,The singer later commented that her video was a joke.,The singer later commented that her video was a joke.,https://schema.org,NewsArticle,https://thehill.com/changing-america/respect/poverty/556947-artificial-intelligence-could-lead-to-communism-says-music/,"{'@type': 'ImageObject', 'url': 'https://thehill.com/wp-content/uploads/sites/2/2021/06/ca._grime_gettyimages-958397822.jpg'}","[{'@type': 'Person', 'name': 'Christian Spencer', 'url': ''}]","{'@type': 'Organization', 'name': 'The Hill'}",Artificial intelligence could lead to communism says music star and Elon Musk girlfriend Grimes in viral video,2021-06-04T21:41:04+00:00,2021-06-04T21:41:01+00:00,Poverty,The Hill,,,N/A,N/A,"


Respect  Poverty
Artificial intelligence could lead to communism says music star and Elon Musk girlfriend Grimes in viral video

				by Christian Spencer | June 4, 2021 | Jun. 04, 2021			







 Theo Wargo/Getty Images for Huffington Post




Story at a glance:

“AI is actually the fastest path to communism,” said Grimes in the video.
AI could automate farming, providing food while no one has to work, she said.
Critics pointed out that in a communistic society, Grimes would not be wealthy.


“AI is actually the fastest path to communism,” said Grimes, a singer who is dating Elon Musk.
On Wednesday, in a TikTok video, the girlfriend of one of the world’s richest men took to social media seemingly promoting communism, Insider reported.

America is changing faster than ever! Add Changing America to your Facebook or Twitter feed to stay on top of the news.

The following day, Grimes, whose real name is Claire Boucher, got more than 1.4 million views for her video, and received criticism for her contradiction.
In Grimes’ idealogic viewpoint, AI ensures that “nobody has to work” and everyone is provided for. AI could automate farming, she said.
But as Insider points out, that is not what Karl Marx, father of communism, envisioned.
Communism is the elimination of a capitalist system – the elimination of competing services, the relationship between workers and founders, and the wealth gap.
Under communism, a company like Tesla, which Musk founded, would be socially everyone’s company and Musk would be an ordinary worker.
In the comments to her video, Grimes later posted that the video was a joke and that she is “not a communist.” “Maybe the technocrats and communists could get along!” Grimes added.

READ MORE STORIES FROM CHANGING AMERICA
EARLY STUDY FINDS KILLINGS BY POLICE DECLINED AFTER BLACK LIVES MATTER PROTESTS
NORTH CAROLINA LAWMAKERS PUSH TO REPEAL JIM CROW-ERA VOTER LITERACY TEST
FIRST CITY IN US TO ENACT REPARATIONS FOR ITS BLACK RESIDENTS


Copyright 2024 Nexstar Media Inc. All rights reserved. This material may not be published, broadcast, rewritten, or redistributed.























  




		Most Popular	











								Poverty							


						Housing costs have nearly doubled in swing states since 2020					












								Medical Advances							


						Potential cause of lupus may be identified: Study					












								Science							


						Perseid meteor shower begins: Here's the best time to watch it					












								Poverty							


						Evictions rising across Southwest, dropping in Northeast: Data					












								Prevention & Cures							


						Gastrointestinal issues are common but overlooked symptom of...					












								Equality							


						Here are the 10 states with the poorest quality of life					












								Science							


						Red Rocks geology: How the world’s only natural amphitheater was...					












								Medical Advances							


						Gut flora could help diagnose autism: Study					












								Poverty							


						Rent prices are dropping across Florida and these US cities					












								Poverty							


						Here are the cities where rents are rising fastest					










		Recent Videos	









					Amendment to ‘Don’t Say Gay’ bill in Florida requires schools...				









					This Puerto Rican software company is using satellite data to save...				









					Is this 3D-printed robotic arm the future of prosthetics?				









					Could you tell the difference between this plant-based egg and a...				









					Meet the sailing robots trying to solve climate change				





",,"{'@type': 'WebPage', '@id': 'https://thehill.com/changing-america/respect/poverty/556947-artificial-intelligence-could-lead-to-communism-says-music/'}",,,,,,,,,,,,,,,,,,,,"{'@type': 'SearchAction', 'target': 'https://thehill.com/search/{search_term_string}/', 'query-input': 'required name=search_term_string'}",['Poverty'],,,
https://news.google.com/rss/articles/CBMiigFodHRwczovL3d3dy5hbWVzdHJpYi5jb20vc3RvcnkvbmV3cy9lZHVjYXRpb24vMjAyMS8wNi8wNC9hcnRpZmljaWFsLWludGVsbGlnZW5jZS1kZWdyZWUtcHJvZ3JhbS1hcHByb3ZlZC1pb3dhLXN0YXRlLXVuaXZlcnNpdHkvNTI5MDI4NTAwMS_SAQA?oc=5,Artificial intelligence degree program approved for Iowa State University - Ames Tribune,2021-06-04,Ames Tribune,https://www.amestrib.com,"Hridesh Rajan anticipates thousands of new jobs in AI in the next few years, and said the technology could be used to decrease error rates in diagnoses in health care, create vaccines faster and improve sustainable use of resources.","['access:metered', 'ssts:news:education', 'sstsn:education', 'type:story', 'tag:Artificial Intelligence', 'tag:Iowa State University', 'tag:Iowa Board of Regents', 'tag:Iowa', 'tag:Overall Neutral']","Hridesh Rajan anticipates thousands of new jobs in AI in the next few years, and said the technology could be used to decrease error rates in diagnoses in health care, create vaccines faster and improve sustainable use of resources.","Hridesh Rajan anticipates thousands of new jobs in AI in the next few years, and said the technology could be used to decrease error rates in diagnoses in health care, create vaccines faster and improve sustainable use of resources.",http://schema.org,NewsArticle,https://www.amestrib.com/story/news/education/2021/06/04/artificial-intelligence-degree-program-approved-iowa-state-university/5290285001/,"{'@type': 'ImageObject', 'url': 'https://www.amestrib.com/gcdn/-mm-/9e1f6e2ee20f44aa1f3be4f71e9f3e52b6ae2c7e/c=0-110-2121-1303/local/-/media/2021/06/18/USATODAY/usatsports/artificial-intelligence-3.jpg?width=1600&height=800&fit=crop&format=pjpg&auto=webp', 'height': 800, 'width': 1600}","{'@type': 'Person', 'jobTitle': 'Suburban Growth and Development Reporter', 'name': 'Phillip Sitter', 'url': 'https://www.desmoinesregister.com/staff/4267568001/phillip-sitter/'}","{'@type': 'Organization', 'name': 'Ames Tribune', 'logo': 'https://www.amestrib.com/sitelogos/m-oc.svg'}",Iowa Board of Regents approves artificial intelligence degree program for Iowa State,2021-06-04T10:30:13Z,2021-06-04T10:30:13Z,news,,True,,N/A,N/A,"EDUCATIONIowa Board of Regents approves artificial intelligence degree program for Iowa State Phillip SitterAmes TribunePlayPauseSound OnSound Off0:002:04AD0:10SKIPClosedCaptionOpen ShareEnter Full ScreenExit Full ScreenA new artificial intelligence graduate degree program at Iowa State University will be the first of its kind in the state.The Iowa Board of Regents approved the two-year master's of science degree program Thursday through consent agenda after being presented with the program Wednesday in committee. The graduate program is expected to begin this fall.Hridesh Rajan, a professor and chairperson of ISU's Department of Computer Science, said the new program seeks to produce graduates that can work on building and enhancing components of artificial intelligence — not only to be able to understand and make practical use of machine learning and big data, but also be able to communicate the capabilities and limitations of AI.What is artificial intelligence, and what are the job prospects in the field?Artificial intelligence, or AI, is the study of techniques that help incorporate intelligence into software, Rajan said.More:AI in 2020 and beyond: create a digital replica of your aging parent or yourselfHe said AI is already part of daily life in how social media feeds are organized, which city’s weather forecast is determined to be the one that matters and how a virtual assistant finds the nearest coffee shop when asked to.“It would be an underestimation to say that AI is now part of our everyday life,” from the time we wake up until going to bed, Rajan said.Rajan anticipates thousands of new jobs in AI in the next few years, and said the technology could be used to decrease error rates in diagnoses in health care, create vaccines faster and improve sustainable use of resources.In vaccines, the chief scientific officer of Moderna — maker of one of the three COVID-19 vaccines authorized for use in the U.S. — has said the company uses AI and machine learning to try to predict viral mutations that could cause problems and then design vaccines to fight them.More:Vaccines 2.0: Next-generation COVID-19 shots will be cheaper, easier to deliver and protect against more viruses, industry leaders sayAll of those endeavors involve big data, and algorithms that can leverage the data. “Having the data itself is not the endgame. We need to be able to make the data work for us,"" Rajan said.That means there's a need for people who can understand algorithms and how machines can use them to discover knowledge and make decisions based on it.According to citations in documents submitted to the Regents, the job of AI specialist had the most growth between 2015 and 2020, with an average annual growth rate of 74%.Rajan said it's also the kind of work that major companies are doing in Iowa — not just somewhere far away such as Silicon Valley.More details about ISU's AI programRajan said it was the questions of prospective students and their parents that spurred the design of the new master's in science AI degree program at ISU.With the Regents' approval and after marketing the program over the summer, the projected enrollment for the first year is five students, but that's anticipated to grow to 15 in the second year, almost 40 in the fourth year and almost 70 students in the seventh year of the program.Rajan said a master’s degree will allow for more in-depth experience and expertise than an undergraduate degree could offer, and a hands-on capstone project will serve graduates as a demonstration of their skills when applying for a job. According to a news release from ISU's College of Liberal Arts and Sciences, core classes beyond AI and machine learning techniques will also include ""knowledge representation and reasoning; search and planning; computer vision and perception; natural language processing and robotics.""  Beyond Iowa, he said Northwestern University has a master’s degree in AI, and a number of schools are also looking into their own programs.Other Regents actions involving ISU academicsThe Regents also Thursday approved a merger of ISU's departments of Entomology and Plant Pathology and Microbiology in the College of Agriculture and Life Sciences, planned for September 2022, in the hopes of increasing undergraduate student enrollment. The merged departments would have a single chairperson, and the addition of two tenure-track faculty lines has already been agreed to by the departments.The Regents also approved new ISU bachelor's or master's degree programs in business administration, human resource management and education.Phillip Sitter covers education for the Ames Tribune, including Iowa State University and PreK-12 schools in Ames and elsewhere in Story County. Phillip can be reached via email at psitter@gannett.com. He is on Twitter @pslifeisabeauty.Seeking Health NewsCardiologists: Slim Waist From 38 To 29 With Teaspoon On An Empty StomachTry it tonight!Seeking Health News|AdAdLearn MoreUndosearchalikeUnbelievable: Find a Family Doctor Instantly (Take a Look)search by your address to see doctors accepting new patients instantlysearchalike|AdAdSearch NowUndoSeniorBetterLifeHear Every Word in Conversations Anywhere AnytimeThis #1 selling Cheap hearing aid in America is not what you think (see for yourself).SeniorBetterLife|AdAdUndoMust Read MomentGirl Feeds Homeless Man Every Day, Not Knowing Who He Really IsMust Read Moment|AdAdUndoExpertsInSavings | Auto SavingsThe Sneaky Way Virginia Drivers Are Cutting Their Car Insurance Bills in HalfDon't pay your next auto insurance bill until you read about this!ExpertsInSavings | Auto Savings|AdAdUndoLauradateLooking for a soulmate!Share your feelings and emotions with someone.Lauradate|AdAdRead MoreUndoMust Read MomentFamily Laughed At Him For Inheriting Old Cabin, But Then They Looked InsideMust Read Moment|AdAdUndoDeLaChatNot a typical dating platformShare your feelings and emotions with someone.DeLaChat|AdAdRead MoreUndoMust Read MomentMan Films Fishing Boat – If This Was Not Filmed, No One Would Have Believed HimMust Read Moment|AdAdUndoGas Rebate CardSeniors Under 85 Get $0.55/Gallon With This Gas Rebate CardGas Rebate Card|AdAdUndoDeal of the DayREVIEWEDAirPods Pro Are The Lowest Price We've Ever Seen During Amazon Prime DayREVIEWEDView Deal Recommendations are independently chosen by our editors. Purchases you make through our links may earn us a commission.UndoRecommendedIowa State women's basketball names two new assistant coachesNewsUndo






























",,"{'@type': 'WebPage', '@id': 'https://www.amestrib.com/story/news/education/2021/06/04/artificial-intelligence-degree-program-approved-iowa-state-university/5290285001/'}",,,,,,,,,"{'@type': ['CreativeWork', 'Product'], 'name': 'Ames Tribune - Unlimited Digital Access', 'productID': 'amestrib.com:standard'}",,,,,,,,https://www.amestrib.com/gcdn/media/2021/06/18/USATODAY/usatsports/artificial-intelligence-3.jpg?width=1200&disable=upscale&format=pjpg&auto=webp,,,,,2021-06-04T10:30:13Z,"{""id"":""5290285001"",""siteCode"":""NATR"",""contentSourceCode"":""NATR"",""ssts"":""news:education"",""type"":""story""}",
https://news.google.com/rss/articles/CBMijwFodHRwczovL3RpbWVzb2ZpbmRpYS5pbmRpYXRpbWVzLmNvbS9lZHVjYXRpb24vbmV3cy9uaXQtay1zdXJhdGhrYWwtaW50cm9kdWNlcy1uZXctdWctY291cnNlLWluLWFydGlmaWNpYWwtaW50ZWxsaWdlbmNlL2FydGljbGVzaG93LzgzMjA0MjMwLmNtc9IBkwFodHRwczovL3RpbWVzb2ZpbmRpYS5pbmRpYXRpbWVzLmNvbS9lZHVjYXRpb24vbmV3cy9uaXQtay1zdXJhdGhrYWwtaW50cm9kdWNlcy1uZXctdWctY291cnNlLWluLWFydGlmaWNpYWwtaW50ZWxsaWdlbmNlL2FtcF9hcnRpY2xlc2hvdy84MzIwNDIzMC5jbXM?oc=5,"NIT-K, Surathkal introduces new UG course in Artificial Intelligence - The Times of India",2021-06-03,The Times of India,https://timesofindia.indiatimes.com,"News News: MANGALURU: The country’s premier technical institute NIT-K, Surathkal will introduce a new UG programme in Artificial Intelligence, which is one of th.","NIT-K Surathkal,National Education Policy 2020,ministry of education,JEE,artificial intelligence course news,Artificial Intelligence course,artificial intelligence","News News: MANGALURU: The country’s premier technical institute NIT-K, Surathkal will introduce a new UG programme in Artificial Intelligence, which is one of th.","News News: MANGALURU: The country’s premier technical institute NIT-K, Surathkal will introduce a new UG programme in Artificial Intelligence, which is one of th.",http://schema.org/,ViewAction,https://timesofindia.indiatimes.com/education/news/nit-k-surathkal-introduces-new-ug-course-in-artificial-intelligence/articleshow/83204230.cms,"{'@type': 'ImageObject', 'url': 'https://static.toiimg.com/thumb/resizemode-4,width-1280,height-720,msid-83204226/83204226.jpg', 'width': 1280, 'height': 720}","{'@type': 'Person', 'name': 'Kevin Mendonsa', 'url': 'https://timesofindia.indiatimes.com/toireporter/author-Kevin-Mendonsa-479222047.cms'}","{'@type': 'Organization', 'name': 'Times Of India', 'url': 'https://timesofindia.indiatimes.com/', 'logo': {'@type': 'ImageObject', 'url': 'https://static.toiimg.com/photo/msid-92877370/92877370.jpg', 'width': 600, 'height': 60}}","NIT-K, Surathkal introduces new UG course in Artificial Intelligence",2021-06-03T17:35:00+05:30,2021-06-03T17:35:00+05:30,,"NIT-K, Surathkal introduces new UG course in Artificial Intelligence",,,N/A,N/A,N/A,,https://timesofindia.indiatimes.com/education/news/nit-k-surathkal-introduces-new-ug-course-in-artificial-intelligence/articleshow/83204230.cms,en,,,,,,,,,,,,,,,,"https://static.toiimg.com/thumb/msid-83204226,width-1280,height-720,imgsize-329947,resizemode-6,overlay-toi_sw,pt-32,y_pad-40/photo.jpg","MANGALURU: The country’s premier technical institute NIT-K, Surathkal will introduce a new UG programme in Artificial Intelligence, which is one of the courses in emerging technologies.The department of information technology, National Institute of Technology Karnataka Surathkal has decided to start a new course in Artificial Intelligence. The Academic Senate, Board of the Institute, and Ministry of Education have approved a new four-year B.Tech programme in Artificial Intelligence from the coming academic year 2021-22. The admissions to the programme will be through JEE (Main) score.The new course is in conformance with the National Education Policy 2020, which stresses the need to improve the skilled workforce involving mathematics, computer science, and data science, in conjunction with multidisciplinary abilities across the sciences, social sciences, and humanities.Karanam Uma Maheshwar Rao, director, NIT-K, Surathkal said that this degree would prepare students for industry or graduate study by offering specializations indifferent areas of AI like data Science, human-centred computing,cyber-physical systems, and robotics.“The programme and its curriculum focus on the use of inputs such as video, speech,and big data to make decisions or enhance human capabilities. This specialization empowers students to build intelligent machines, software, or applications with state-of-the-art technology using machine learning, data analytics, and data visualization technologies,” he said.He added that that earlier, AI was a subset of computer science, but in recent years AI has grown enough to qualify as a distinctive and a bigger unit. As a result, job opportunities for the undergraduates of B.Tech (AI) courses are different from conventional IT jobs.",,,,,,"{'type': 'EntryPoint', 'urlTemplate': 'android-app://com.toi.reader.activities/toi.index.deeplink/t/a/83204230'}"

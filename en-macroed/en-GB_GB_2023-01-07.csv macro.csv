URL link,Title,Date,Source,Source Link,description,keywords,og:description,twitter:description,article:section,article:summary,article text,@context,@type,url,publisher,mainEntityOfPage,datePublished,dateCreated,dateModified,heading,image,author,headline,name,sameAs,thumbnailUrl,@graph,genre,about,copyrightYear,discussionURL,inLanguage,isFamilyFriendly,isPartOf,pagination,person,alternativeHeadline,printEdition,publishingPrinciples,timeRequired,wordCount,wordcount,video,hasPart,copyrightHolder,sourceOrganization,isAccessibleForFree,logo,@id,diversityPolicy,ethicsPolicy,masthead,foundingDate,articleSection,editor,itemListElement,creator
https://news.google.com/rss/articles/CBMic2h0dHBzOi8vd3d3LndlZm9ydW0ub3JnL2FnZW5kYS8yMDIzLzAxL2Rhdm9zMjMtZ2VuZXJhdGl2ZS1haS1hLWdhbWUtY2hhbmdlci1pbmR1c3RyaWVzLWFuZC1zb2NpZXR5LWNvZGUtZGV2ZWxvcGVycy_SAQA?oc=5,Generative AI: a game-changer society needs to be ready for - World Economic Forum,2023-01-09,World Economic Forum,https://www.weforum.org,"While generative AI has people excited about a new wave of creativity, there are concerns about the impact of these models on society.
","World Economic Forum,WEF,Davos,Klaus Schwab, globalization, globalization4.0, globalization4, globalization four, what does globalization mean?","While generative AI has people excited about a new wave of creativity, there are concerns about the impact of these models on society.","While generative AI has people excited about a new wave of creativity, there are concerns about the impact of these models on society.",N/A,N/A,"Forum InstitutionalGenerative AI: a game-changer that society and industry need to be ready forJan 9, 2023Generative AI has become a 'hot topic' for technologists, investors, policymakers and society.Image: UnsplashJayant NarayanLead, AI & Climate Technology, World Economic Forum GenevaBenjamin LarsenLead, Artificial Intelligence and Machine Learning, World Economic ForumShare:Our ImpactWhat's the World Economic Forum doing to accelerate action on Forum Institutional?The Big PictureExplore and monitor how Artificial Intelligence is affecting economies, industries and global issuesCrowdsource InnovationGet involved with our crowdsourced digital platform to deliver impact at scaleStay up to date:Tech and InnovationFollowThis article is part of: World Economic Forum Annual MeetingListen to the article12 min listenDespite the current downturn and layoffs in the tech sector, generative AI companies continue to receive huge interest from investors.While generative AI has people excited about a new wave of creativity, there are concerns about the impact of these models on society.Only when solid checks and balances are in place can there be a more thoughtful, beneficial expansion of generative AI technologies/products.In the wake of newly released models such as Stable Diffusion and ChatGPT, generative AI has become a 'hot topic' for technologists, investors, policymakers and for society at large. As the name suggests, generative AI produces or generates text, images, music, speech, code or video. Generative AI is not a new concept, and machine-learning techniques behind generative AI have evolved over the past decade. Deep learning and General Adversarial Network (GAN) approaches have typically been used, but the latest approach is transformers.Have you read?Does this artificial intelligence think like a human?Artificial intelligence - good or bad for public health?Global Risks Report 2023A Generative Pretrained Transformer (GPT) is a type of large language model (LLM) that uses deep learning to generate human-like text. They are called ""generative"" because they can generate new text based on the input they receive, ""pretrained"" because they are trained on a large corpus of text data before being fine-tuned for specific tasks, and ""transformers"" because they use a transformer based neural network architecture to process input text and generate output text. Despite the current market downturn and layoffs in the technology sector, generative AI companies continue to receive interest from investors. Stability AI and Jasper, for example, have recently raised $101 million and $125 million, respectively, and investors like Sequoia think the field of generative AI can generate trillions of dollars in economic value. Over 150 start-ups have emerged and are already operating in the space.Generative AI: A timeline of images generated by artificial intelligence Image: Our World in DataEmergent capabilities of generative AI systemsGenerative AI stretches beyond typical natural language processing tasks such as language translation, text summarization and text generation. OpenAI’s latest release ChatGPT, which caused a viral sensation and reached a million users in just five days, has been described as breaking ground in a much broader range of tasks. The use cases currently under discussion include new architectures of search engines; explaining complex algorithms; creating personalized therapy bots, helping build apps from scratch; explaining scientific concepts; writing recipes; and college essays, among others.Text-to-image programs such as Midjourney, DALL-E and Stable Diffusion have the potential to change how art, animation, gaming, movies and architecture, among others, are being rendered. Bill Cusick, creative director at Stability AI, believes that the software is “the foundation for the future of creativity”. Based on a new era of human-machine based cooperation, optimists claim that generative AI will aid the creative process of artists and designers, as existing tasks will be augmented by generative AI systems, speeding up the ideation and, essentially, the creation phase. Beyond the creative space, generative AI models hold transformative capabilities in complex sciences such as computer engineering. For example, Microsoft-owned GitHub Copilot, which is based on OpenAI’s Codex model, suggests code and assists developers in autocompleting their programming tasks. The system has been quoted as autocompleting up to 40% of developers’ code, considerably augmenting the workflow.Accept our marketing cookies to access this content.These cookies are currently disabled in your browser.Accept cookiesWhat are the risks?While generative AI has people excited about a new wave of creativity, there are concerns about the impact of these models on society. Digital artist Greg Rutkowski fears that the internet will be flooded with artwork that is indistinguishable from his own, simply by telling the system to reproduce an artwork in his unique style. Professor of art Carson Grubaugh shares this concern and predicts that large parts of the creative workforce, including commercial artists working in entertainment, video games, advertising, and publishing, could lose their jobs because of generative AI models.Besides profound effects on tasks and jobs, generative AI models and associated externalities have raised alarm in the AI governance community. One of the problems with large language models is their ability to generate false and misleading content. Meta’s Galactica – a model trained on 48 million science articles with claims to summarize academic papers, solve math problems, and write scientific code – was taken down after less than three days of being online as the scientific community found it was producing incorrect results after misconstruing scientific facts and knowledge.This is even more alarming when seen in the context of automated troll bots, with capabilities advanced enough to render obsolete, The Turing Test – which tests a machine’s ability to exhibit intelligent behaviour similar to or indistinguishable from a human. Such capabilities can be misused to generate fake news and disinformation across platforms and ecosystems.Large models continue to be trained on massive datasets represented in books, articles and websites that may be biased in ways that can be hard to filter completely. Despite substantial reductions in harmful and untruthful outputs achieved by the use of reinforcement learning from human feedback (RLHF) in the case of ChatGPT, OpenAI acknowledges that their models can still generate toxic and biased outputs.How is generative AI governed?In the private sector, two approaches to the governance of generative AI models are currently emerging. In one camp, companies such as OpenAI are self-governing the space through limited release strategies, monitored use of models, and controlled access via API’s for their commercial products like DALL-E2. In the other camp, newer organizations, such as Stability AI, believe that these models should be openly released to democratize access and create the greatest possible impact on society and the economy. Stability AI open sourced the weights of its model – as a result, developers can essentially plug it into everything to create a host of novel visual effects with little or no controls placed on the diffusion process.In the public sector, little or no regulation governs the rapidly evolving landscape of generative AI. In a recent letter to the White House, US Congresswoman Anna Eshoo highlighted ""grave concerns about the recent unsafe release of the Stable Diffusion model by Stability AI”, including generation of violent and sexual imagery. Other issues surround intellectual property and copyright. The datasets behind generative AI models are generally scraped from the internet without seeking consent from living artists or work still under copyright. “If these models have been trained on the styles of living artists without licensing that work, there are copyright implications,” according to Daniela Braga, who sits on the White House Task Force for AI Policy. DiscoverHow is the World Economic Forum ensuring the responsible use of technology? Show moreThe Top 10 Emerging Technologies of 2023 report outlined the technologies poised to positively impact society in the next few years, from health technology to AI to sustainable computing. The World Economic Forum’s Centre for the Fourth Industrial Revolution is driving responsible technology governance, enabling industry transformation, addressing planetary health, and promoting equity and inclusion.Learn more about our impact: Digital inclusion: Our EDISON Alliance is mobilizing leaders from across sectors to accelerate digital inclusion, having positively impacted the lives of 454 million people through the activation of 250 initiatives across 90 countries.AI in developing economies: Our Centre for the Fourth Industrial Revolution Rwanda is promoting the adoption of new technologies in the country, enabling over 4,000 daily health consultations using AI.Innovative healthcare: Our Medicine from the Sky initiative is using drones to deliver medicine to remote areas in India, completing over 950 successful drone flights.AI for agriculture: We are working with the Government of India to scale up agricultural technology in the country, helping more than 7,000 farmers monitor the health of their crops and soil using AI.Accept our marketing cookies to access this content.These cookies are currently disabled in your browser.Accept cookiesWant to know more about our centre’s impact or get involved? Contact us.The problem with copyright is also visible in the field of autocompleted code. Microsoft's GitHub Copilot is involved in a class action lawsuit alleging the system has been built on “software piracy on an unprecedented scale.” Copilot has been trained on public code repositories scraped from the web, which in many cases, are published with licenses that require crediting creators when reusing their code.What's the road ahead?While generative AI is a game-changer on numerous areas and tasks, there is a strong need to govern the diffusion of these models, and their impact on society and the economy more carefully. The emerging discussion between centralized and controlled adoption with firm ethical boundaries on the one hand versus faster innovation and decentralized distribution on the other will be important for the generative AI community in the coming years. This is a task not only reserved for private companies, but which is equally important for civil society and for policymakers to weigh in on. This includes disruption of labour markets, legitimacy of scraped data, licensing, copyright and potential for biased or otherwise harmful content, misinformation, and so on. Only when solid checks and balances are in place can more thoughtful and beneficial expansion of generative AI technologies and products be achieved.Accept our marketing cookies to access this content.These cookies are currently disabled in your browser.Accept cookiesDon't miss any update on Tech and InnovationSign up for free and access the latest publications and insights across various topics.Sign up for freeLicense and RepublishingWorld Economic Forum articles may be republished in accordance with the Creative Commons Attribution-NonCommercial-NoDerivatives 4.0 International Public License, and in accordance with our Terms of Use.The views expressed in this article are those of the author alone and not the World Economic Forum.Related topics:Forum InstitutionalEmerging TechnologiesShare:Global AgendaThe Agenda WeeklyA weekly update of the most important issues driving the global agendaSubscribe todayYou can unsubscribe at any time using the link in our emails. For more details, review our privacy policy.More on Forum InstitutionalSee allAMNC24: Five things to know about the 'Summer Davos' in ChinaGayle MarkovitzJune 28, 20243:49These 5 facts about climate change need more attention, say expertsAMNC 2024: What to know about Day 3Gayle MarkovitzJune 27, 20242:185 leaders on harnessing the potential of AI responsiblyAddress by China Premier Li Qiang to the Annual Meeting of New Champions 2024World Economic ForumJune 26, 2024AMNC 2024: What to know about Day 2Gayle MarkovitzJune 26, 2024",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
https://news.google.com/rss/articles/CBMilwFodHRwczovL3RoZWNvbnZlcnNhdGlvbi5jb20vYWktYW5kLXRoZS1mdXR1cmUtb2Ytd29yay01LWV4cGVydHMtb24td2hhdC1jaGF0Z3B0LWRhbGwtZS1hbmQtb3RoZXItYWktdG9vbHMtbWVhbi1mb3ItYXJ0aXN0cy1hbmQta25vd2xlZGdlLXdvcmtlcnMtMTk2Nzgz0gEA?oc=5,"AI and the future of work: 5 experts on what ChatGPT, DALL-E and other AI tools mean for artists and knowledge workers - The Conversation",2023-01-11,The Conversation,https://theconversation.com,"Now that AI systems can generate realistic images and convincing prose, are creative and knowledge workers endangered or poised for productivity gains? A panel of experts says it’s not so clear-cut.",N/A,"Now that AI systems can generate realistic images and convincing prose, are creative and knowledge workers endangered or poised for productivity gains? A panel of experts says it’s not so clear-cut.",N/A,N/A,N/A,"






        Could AI be your next colleague – or replacement?
        PhonlamaiPhoto/iStock via Getty Images









            AI and the future of work: 5 experts on what ChatGPT, DALL-E and other AI tools mean for artists and knowledge workers
          




Published: January 11, 2023 8:27am EST












Lynne Parker, University of Tennessee, Casey Greene, University of Colorado Anschutz Medical Campus, Daniel Acuña, University of Colorado Boulder, Kentaro Toyama, University of Michigan, Mark Finlayson, Florida International University



Authors





        Lynne Parker
      


      Associate Vice Chancellor, University of Tennessee
    





        Casey Greene
      


      Professor of Biomedical Informatics, University of Colorado Anschutz Medical Campus
    





        Daniel Acuña
      


      Associate Professor of Computer Science, Affiliate Professor of Information Science, University of Colorado Boulder
    





        Kentaro Toyama
      


      Professor of Community Information, University of Michigan
    





        Mark Finlayson
      


      Associate Professor of Computer Science, Florida International University
    





Disclosure statement
Lynne Parker is affiliated with two non-profit organizations -- the Center for New American Security as an adjunct senior fellow, and the Special Competitive Studies Project as an expert advisor.
Casey Greene receives funding from the National Institutes of Health to work on machine learning methods for biomedical data integration, including R01 CA237170, R01 HG010067, R01 LM013863, and R01 HD109765, as well as the Gordon and Betty Moore Foundation (GBMF 4552). Casey Greene is a consultant for Arcadia Science and SomaLogic.
Daniel Acuña receives funding from the US Office of Research Integrity grants ORIIR180041, ORIIIR190049, ORIIIR200052, and ORIIIR210062, related to automated methods to detect image manipulation and plagiarism. He has also received funding from the National Science Foundation, the Sloan Foundation, and DARPA through the Center for Open Science's SCORE project.
Kentaro Toyama receives funding from the National Science Foundation, the Russell Sage Foundation, and the University of Michigan. 
Mark Finlayson receives funding from the US National Science Foundation (NSF) and the US Defense Advanced Projects Agency (DARPA) to work on natural language processing. He has also served as Edison Fellow for AI at the US Patent and Trademark Office (USPTO) since 2019.


Partners

University of Michigan provides funding as a founding partner of The Conversation US.Florida International University, University of Tennessee, University of Colorado Anschutz Medical Campus, and University of Colorado provide funding as members of The Conversation US.
View all partners







Languages

Español
English


We believe in the free flow of informationRepublish our articles for free, online or in print, under a Creative Commons license.Republish this article





 Email


 X (Twitter)21


 Facebook655


 LinkedIn


 WhatsApp


 Messenger

 Print


From steam power and electricity to computers and the internet, technological advancements have always disrupted labor markets, pushing out some jobs while creating others. Artificial intelligence remains something of a misnomer – the smartest computer systems still don’t actually know anything – but the technology has reached an inflection point where it’s poised to affect new classes of jobs: artists and knowledge workers.
Specifically, the emergence of large language models – AI systems that are trained on vast amounts of text – means computers can now produce human-sounding written language and convert descriptive phrases into realistic images. The Conversation asked five artificial intelligence researchers to discuss how large language models are likely to affect artists and knowledge workers. And, as our experts noted, the technology is far from perfect, which raises a host of issues – from misinformation to plagiarism – that affect human workers.
To jump ahead to each response, here’s a list of each: 
Creativity for all – but loss of skills?
Potential inaccuracies, biases and plagiarism
With humans surpassed, niche and ‘handmade’ jobs will remain
Old jobs will go, new jobs will emerge
Leaps in technology lead to new skills


Creativity for all – but loss of skills?
Lynne Parker, Associate Vice Chancellor, University of Tennessee
Large language models are making creativity and knowledge work accessible to all. Everyone with an internet connection can now use tools like ChatGPT or DALL-E 2 to express themselves and make sense of huge stores of information by, for example, producing text summaries.
Especially notable is the depth of humanlike expertise large language models display. In just minutes, novices can create illustrations for their business presentations, generate marketing pitches, get ideas to overcome writer’s block, or generate new computer code to perform specified functions, all at a level of quality typically attributed to human experts.
These new AI tools can’t read minds, of course. A new, yet simpler, kind of human creativity is needed in the form of text prompts to get the results the human user is seeking. Through iterative prompting – an example of human-AI collaboration – the AI system generates successive rounds of outputs until the human writing the prompts is satisfied with the results. For example, the (human) winner of the recent Colorado State Fair competition in the digital artist category, who used an AI-powered tool, demonstrated creativity, but not of the sort that requires brushes and an eye for color and texture. 
While there are significant benefits to opening the world of creativity and knowledge work to everyone, these new AI tools also have downsides. First, they could accelerate the loss of important human skills that will remain important in the coming years, especially writing skills. Educational institutes need to craft and enforce policies on allowable uses of large language models to ensure fair play and desirable learning outcomes. 


Educators are preparing for a world where students have ready access to AI-powered text generators.

Second, these AI tools raise questions around intellectual property protections. While human creators are regularly inspired by existing artifacts in the world, including architecture and the writings, music and paintings of others, there are unanswered questions on the proper and fair use by large language models of copyrighted or open-source training examples. Ongoing lawsuits are now debating this issue, which may have implications for the future design and use of large language models.
As society navigates the implications of these new AI tools, the public seems ready to embrace them. The chatbot ChatGPT went viral quickly, as did image generator Dall-E mini and others. This suggests a huge untapped potential for creativity, and the importance of making creative and knowledge work accessible to all.


Potential inaccuracies, biases and plagiarism
Daniel Acuña, Associate Professor of Computer Science, University of Colorado Boulder
I am a regular user of GitHub Copilot, a tool for helping people write computer code, and I’ve spent countless hours playing with ChatGPT and similar tools for AI-generated text. In my experience, these tools are good at exploring ideas that I haven’t thought about before. 
I’ve been impressed by the models’ capacity to translate my instructions into coherent text or code. They are useful for discovering new ways to improve the flow of my ideas, or creating solutions with software packages that I didn’t know existed. Once I see what these tools generate, I can evaluate their quality and edit heavily. Overall, I think they raise the bar on what is considered creative. 
But I have several reservations.
One set of problems is their inaccuracies – small and big. With Copilot and ChatGPT, I am constantly looking for whether ideas are too shallow – for example, text without much substance or inefficient code, or output that is just plain wrong, such as wrong analogies or conclusions, or code that doesn’t run. If users are not critical of what these tools produce, the tools are potentially harmful. 
Recently, Meta shut down its Galactica large language model for scientific text because it made up “facts” but sounded very confident. The concern was that it could pollute the internet with confident-sounding falsehoods.
Another problem is biases. Language models can learn from the data’s biases and replicate them. These biases are hard to see in text generation but very clear in image generation models. Researchers at OpenAI, creators of ChatGPT, have been relatively careful about what the model will respond to, but users routinely find ways around these guardrails.

Another problem is plagiarism. Recent research has shown that image generation tools often plagiarize the work of others. Does the same happen with ChatGPT? I believe that we don’t know. The tool might be paraphrasing its training data – an advanced form of plagiarism. Work in my lab shows that text plagiarism detection tools are far behind when it comes to detecting paraphrasing.



Plagiarism is easier to see in images than in text. Is ChatGPT paraphrasing as well?
Somepalli, G., et al., CC BY


These tools are in their infancy, given their potential. For now, I believe there are solutions to their current limitations. For example, tools could fact-check generated text against knowledge bases, use updated methods to detect and remove biases from large language models, and run results through more sophisticated plagiarism detection tools. 


With humans surpassed, niche and ‘handmade’ jobs will remain
Kentaro Toyama, Professor of Community Information, University of Michigan
We human beings love to believe in our specialness, but science and technology have repeatedly proved this conviction wrong. People once thought that humans were the only animals to use tools, to form teams or to propagate culture, but science has shown that other animals do each of these things. 
Meanwhile, technology has quashed, one by one, claims that cognitive tasks require a human brain. The first adding machine was invented in 1623. This past year, a computer-generated work won an art contest. I believe that the singularity – the moment when computers meet and exceed human intelligence – is on the horizon. 
How will human intelligence and creativity be valued when machines become smarter and more creative than the brightest people? There will likely be a continuum. In some domains, people still value humans doing things, even if a computer can do it better. It’s been a quarter of a century since IBM’s Deep Blue beat world champion Garry Kasparov, but human chess – with all its drama – hasn’t gone away. 



Cosmopolitan magazine used DALL-E 2 to produce this cover.
©Hearst Magazine Media, Inc.


In other domains, human skill will seem costly and extraneous. Take illustration, for example. For the most part, readers don’t care whether the graphic accompanying a magazine article was drawn by a person or a computer – they just want it to be relevant, new and perhaps entertaining. If a computer can draw well, do readers care whether the credit line says Mary Chen or System X? Illustrators would, but readers might not even notice. 
And, of course, this question isn’t black or white. Many fields will be a hybrid, where some Homo sapiens find a lucky niche, but most of the work is done by computers. Think manufacturing – much of it today is accomplished by robots, but some people oversee the machines, and there remains a market for handmade products. 
If history is any guide, it’s almost certain that advances in AI will cause more jobs to vanish, that creative-class people with human-only skills will become richer but fewer in number, and that those who own creative technology will become the new mega-rich. If there’s a silver lining, it might be that when even more people are without a decent livelihood, people might muster the political will to contain runaway inequality.


Old jobs will go, new jobs will emerge
Mark Finlayson, Associate Professor of Computer Science, Florida International University
Large language models are sophisticated sequence completion machines: Give one a sequence of words (“I would like to eat an …”) and it will return likely completions (“… apple.”). Large language models like ChatGPT that have been trained on record-breaking numbers of words (trillions) have surprised many, including many AI researchers, with how realistic, extensive, flexible and context-sensitive their completions are.
Like any powerful new technology that automates a skill – in this case, the generation of coherent, albeit somewhat generic, text – it will affect those who offer that skill in the marketplace. To conceive of what might happen, it is useful to recall the impact of the introduction of word processing programs in the early 1980s. Certain jobs like typist almost completely disappeared. But, on the upside, anyone with a personal computer was able to generate well-typeset documents with ease, broadly increasing productivity. 
Further, new jobs and skills appeared that were previously unimagined, like the oft-included resume item MS Office. And the market for high-end document production remained, becoming much more capable, sophisticated and specialized.
I think this same pattern will almost certainly hold for large language models: There will no longer be a need for you to ask other people to draft coherent, generic text. On the other hand, large language models will enable new ways of working, and also lead to new and as yet unimagined jobs. 
To see this, consider just three aspects where large language models fall short. First, it can take quite a bit of (human) cleverness to craft a prompt that gets the desired output. Minor changes in the prompt can result in a major change in the output. 
Second, large language models can generate inappropriate or nonsensical output without warning. 
Third, as far as AI researchers can tell, large language models have no abstract, general understanding of what is true or false, if something is right or wrong, and what is just common sense. Notably, they cannot do relatively simple math. This means that their output can unexpectedly be misleading, biased, logically faulty or just plain false.  
These failings are opportunities for creative and knowledge workers. For much content creation, even for general audiences, people will still need the judgment of human creative and knowledge workers to prompt, guide, collate, curate, edit and especially augment machines’ output. Many types of specialized and highly technical language will remain out of reach of machines for the foreseeable future. And there will be new types of work – for example, those who will make a business out of fine-tuning in-house large language models to generate certain specialized types of text to serve particular markets. 
In sum, although large language models certainly portend disruption for creative and knowledge workers, there are still many valuable opportunities in the offing for those willing to adapt to and integrate these powerful new tools.


Leaps in technology lead to new skills
Casey Greene, Professor of Biomedical Informatics, University of Colorado Anschutz Medical Campus
Technology changes the nature of work, and knowledge work is no different. The past two decades have seen biology and medicine undergoing transformation by rapidly advancing molecular characterization, such as fast, inexpensive DNA sequencing, and the digitization of medicine in the form of apps, telemedicine and data analysis.
Some steps in technology feel larger than others. Yahoo deployed human curators to index emerging content during the dawn of the World Wide Web. The advent of algorithms that used information embedded in the linking patterns of the web to prioritize results radically altered the landscape of search, transforming how people gather information today.
The release of OpenAI’s ChatGPT indicates another leap. ChatGPT wraps a state-of-the-art large language model tuned for chat into a highly usable interface. It puts a decade of rapid progress in artificial intelligence at people’s fingertips. This tool can write passable cover letters and instruct users on addressing common problems in user-selected language styles.

Just as the skills for finding information on the internet changed with the advent of Google, the skills necessary to draw the best output from language models will center on creating prompts and prompt templates that produce desired outputs. 
For the cover letter example, multiple prompts are possible. “Write a cover letter for a job” would produce a more generic output than “Write a cover letter for a position as a data entry specialist.” The user could craft even more specific prompts by pasting portions of the job description, resume and specific instructions – for example, “highlight attention to detail.”
As with many technological advances, how people interact with the world will change in the era of widely accessible AI models. The question is whether society will use this moment to advance equity or exacerbate disparities.





Artificial intelligence (AI)


Work


Technology


Future of work


Deep learning


Machine learning


Expert panel


Artists


Creative work


Knowledge workers


GPT-3


Knowledge work


Large language models


ChatGPT









",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
https://news.google.com/rss/articles/CBMidWh0dHBzOi8vd3d3Lm1ja2luc2V5LmNvbS9jYXBhYmlsaXRpZXMvc3RyYXRlZ3ktYW5kLWNvcnBvcmF0ZS1maW5hbmNlL291ci1pbnNpZ2h0cy9hcnRpZmljaWFsLWludGVsbGlnZW5jZS1pbi1zdHJhdGVnedIBAA?oc=5,AI strategy in business: A guide for executives - McKinsey,2023-01-11,McKinsey,https://www.mckinsey.com,We look at how new AI tools can help executives develop a business strategy that uses data insights to avoid biases and make crucial decisions more quickly.,N/A,We look at how new AI tools can help executives develop a business strategy that uses data insights to avoid biases and make crucial decisions more quickly.,We look at how new AI tools can help executives develop a business strategy that uses data insights to avoid biases and make crucial decisions more quickly.,N/A,N/A,N/A,https://schema.org,Podcast,https://www.mckinsey.com,"{'@type': 'Organization', 'name': 'McKinsey & Company', 'logo': {'@type': 'ImageObject', 'url': 'https://www.mckinsey.com/~/media/Thumbnails/Mck_Logo'}}","{'@type': 'WebPage', '@id': 'https://www.mckinsey.com/capabilities/strategy-and-corporate-finance/our-insights/artificial-intelligence-in-strategy'}",2023-01-11T00:00:00Z,2023-01-06T22:32:41Z,2023-01-11T00:00:00Z,Artificial intelligence in strategy,https://www.mckinsey.com/~/media/mckinsey/business%20functions/strategy%20and%20corporate%20finance/our%20insights/artificial%20intelligence%20in%20strategy/itsr-strategy-ai-1224356307-thumb-1536x1536.jpg,"[{'@type': 'Person', 'name': 'Yuval Atsmon', 'url': 'https://www.mckinsey.com/our-people/yuval-atsmon'}]",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
https://news.google.com/rss/articles/CBMie2h0dHBzOi8vd3d3LnByaW50bWFnLmNvbS93ZWItaW50ZXJhY3RpdmUtZGVzaWduL2hvdy13b3JyaWVkLXNob3VsZC1jcmVhdGl2ZS1wcm9mZXNzaW9uYWxzLWJlLWFib3V0LWFydGlmaWNpYWwtaW50ZWxsaWdlbmNlL9IBAA?oc=5,How Worried Should Creative Professionals Be About Artificial Intelligence? - PRINT Magazine,2023-01-11,PRINT Magazine,https://www.printmag.com,"Ellen Shapiro talks to illustrators, art directors, lawyers, and other creatives to assess where AI stands in the design community right now.",N/A,"Ellen Shapiro talks to illustrators, art directors, lawyers, and other creatives to assess where AI stands in the design community right now.",N/A,N/A,N/A,"


How Worried Should Creative Professionals Be About Artificial Intelligence?Posted inWeb & Interactive Design






By Ellen ShapiroPosted January 11, 2023  ∙  8 min. read 

Click to share on Facebook (Opens in new window)Click to share on Twitter (Opens in new window)Copy this page's address to your clipboardLink copied to clipboard 




Someone in the “AI Art Universe” Facebook group called it “art harvesting.” It’s an interesting analogy: sprouts planted by many other people are ‘scraped’ into a giant blender that sorts and readies them to be grown into exotic new gardens. But it’s more than a poetic analogy— it’s a worldwide phenomenon, way bigger than a garden. It’s a jungle of fields and plantations, meadows and forests filled with fantasy characters and creatures, scenes and settings that could be in the distant past, the far future, or another galaxy. And it’s springing up, morphing, regenerating before our eyes. Some of the results are dark and ugly, some are eerily beautiful, and all you have to do to participate is type a prompt that describes your vision. A minute or so later, a suite of images springs up on your screen, ready to be enhanced by you (and, apparently, by anyone else).
I trolled around for a while, trying to find an AI-generated garden “good enough” to show as an example. I finally settled on an alien landscape credited to Bryan Price on NightCafe.studio. With it came a 25%-off-my-first-month offer. Ah yes, another income-generator for someone who is not me, i.e. for NightCafé and all the similar sites that are popping up.
Traditional illustrators are up in arms. On Thursday, December 22, the Society of Illustrators posted this message on Facebook, Instagram and Twitter.



In less than 24 hours, this collaborative post by the award winning duo of Society of Illustrators President Tim O’Brien and illustrator Edel Rodriguez had more than 8,500 likes on Instagram, 16.2k likes, and 3,280 reposts on Twitter.
For more than 30 years, O’Brien has been painting meticulous oil portraits of famous people, from his hero Muhammed Ali to Elon Musk, and many have been featured on the cover of TIME. He and his colleagues are insisting that illustrations for publication must be created by real, thinking humans who interact with real clients and use real artists’ tools. “The sudden availability of artificially designed images creates a moral challenge to the illustration community and to the broader design community,” O’Brien said. “We are at the critical point at which illustrators and designers must value human interaction and reject the output of AI image generators. The inclusion of a credit highlighting an AI generator should bring on a sense of shame.”
O’Brien’s illustration of Elon Musk for TIME
O’Brien went on to note that athletes are subject to drug tests for trying to enhance their performance artificially, and those who fail are punished. “Humans can run faster, jump higher, and perform better using synthetic means, [but] we as humans are interested in what a human alone can do. That’s what makes us human.”
Illustrator Victor Juhasz, best known for caricatures that have graced the pages of Rolling Stone, TIME, Newsweek, and many other publications, takes the argument a big step farther. “The current craze for AI-generated ‘art’ is a symptom of a disease,” he said.
Juhasz did not mince words. “The temptation to take the fast, easy way rather than put in hard work is enormous. Contemporary society thrives on celebrity, fame and notoriety, and much of it has nothing to do with honest craftsmanship. It’s about the con and getting away with it.”



Victor Juhasz at work (left); Juhasz’s illustration for an October 2017 issue of Rolling Stone (right)
Other notable illustrators like Anita Kunz, known for her New Yorker covers and feminist responses to classic art have spoken out on how much they hate seeing their work scraped into databases. Karla Ortiz, a painter, printmaker, and concept artist at Marvel Studios, has been especially vocal on social media, posting impassioned arguments against the commercial use of AI art and spearheading a GoFundMe campaign to hire a lobbyist to make the voices of artists heard.
At the present moment, the creative heads of magazines sound largely uninterested in AI. Michael Mrak, the creative director of Scientific American, a science publication with over 10 million subscribers,  “[sees] no reason to replace real artists with AI-generated anything.”
“AI can generate interesting and elaborate imagery, but there are many problems from a legal and moral point of view,” he continued. “AI-generated art cannot be copyrighted and therefore has potential legal issues attached to it, a principal one being that it uses art from across the internet to make the final image. That, and the fact that it scraped or pulled copyrighted art into its learning algorithm.”
Art director and designer Alexander Isley treasures his one-on-one collaborations with artists. “I have never used AI-generated artwork, and have no interest in doing so, unless it’s in the context of how odious it is,” he said. “From all I’ve seen and read, machine-generated artwork is based on modifying, remixing, or adding to real artists’ existing work without acknowledgment or compensation. With commissioned artwork, sketches and revisions are often required. How does this process work with AI-generated images? I can’t deny that the results can be interesting to look at, but it’s a fun parlor trick.”
While art directors might not see AI as a threat, the competitive aspect of design complicates matters. Will AI-generated art be eligible to win contests and grants?
“The short answer is yes,” was the initial answer from Patrick Coyne, editor/designer of Communication Arts, one of the world’s most important design publications. “We always tell jurors to select work based on the quality of the idea and the execution. We celebrate compelling imagery regardless of how it was created.”
Managing Editor Michael Coyne noted that Communication Arts had already featured a few campaigns that used AI-generated art “because they were interesting or appropriate applications for AI as an artistic tool rather than a medium on its own.” He cited an ad campaign by Dentsu Creative Portugal for Jardim Sonoro, an electronic music festival held in a national park near Lisbon, is an example. According to the agency’s creative directors, the challenge was to blend the musicians’ portraits with natural elements. “We learned that AI is a great tool,” they commented. “We are still at its beginning and will certainly see significant developments that will dazzle us all. But it won’t replace anyone. It needs someone to guide the creative process.” They added, “Novelty and discomfort often lead to great work.”
However, a few days later, the Communication Arts‘ team’s stance evolved. “We’ve been approached by several illustrators upset over our position regarding accepting entries for the Illustration Annual produced with text-to-image AI software,” Patrick Coyne wrote via email.  “While I still see the long-term potential for AI-assisted creative exploration, I better understand the position that illustrators and photographers are currently facing with copyright infringement and the unauthorized use of their work to ‘train’ the current crop of text-to-image AI software. Consequently, we are reversing our position and will not be accepting AI text-to-image generated submissions in our Illustration competition.”
Hobbyists have a different relationship to the software. Daniel Rocha of São Paulo is an active contributor to Facebook’s “AI Art Universe” group, and one of the many thousands of people who make AI art for fun. “I use [Mage’s Standard Diffusion program] daily, many times a day,” he said. “I click ‘enter’ on a prompt many, many times, until I get something good or see that I need to change it because something is not nice. I’ve generated more than 22,000 pictures, but that’s not at all time-consuming, since all I have to do is click, click, click.”
Oddly enough, Rocha works in Brazil’s patent and trademark office, where he analyzes the registrability of trademarks. However, “that has nothing to do with what I do on Mage,” he clarified. “I think it is an extremely useful tool for artists. They can use it to fill in details or compose a complex scene extremely fast.”
Stable Diffusion can be trained to fit an author’s style, which allows them to make grandiose scenes in a short time, in their own style. “An amateur like me can reproduce the work of a skilled artist, art that could surpass in quality and inspiration the Sistine Chapel ceiling,” Rocha continued. “That took years for Michelangelo to make, and [similar work] can now be completed in a few days or weeks. Right now, the artists are too scared, but I think they will come around soon.”
Since I have family members who like to play with DALL-E, we decided to try it ourselves. I went in wondering if I could re-create one of the world’s most iconic posters, Milton Glaser’s 1966 “Dylan.” When I used Mage, the results were dismal. Apparently, the Mage database doesn’t have the stuff. We had no luck on DALL-E either (“does not follow our content policy”), but got meh results with Midjourney, where we typed “/imagine the famous 1966 Milton Glaser Bob Dylan poster” and got:

The curly hair must have gotten scraped in, along with some old album covers. And possibly black-and-white portraits to which the photographer owns the copyright. Then we tried: “/imagine the famous 1966 Milton Glaser Bob Dylan poster, but for Lady Gaga” and got:

The whole process took about three minutes. Fortunately— for now, at least— AI isn’t giving Milton Glaser’s brilliant work any serious competition.
To get clarity on where AI stands in regards to legality, I reached out to Martin Schwimmer, a partner at top-rated New York intellectual property law firm LeasonEllis. In his opinion, text-to-image AI models “present novel [new, unexplored] legal issues, including the extent to which the creator of the repository of images makes use of images that were previously displayed on the internet, and to what extent can an AI model look at an image and derive ‘rules’ about that image.” While that language is a little murky to me, it sounds like the lawyers are working on it.
However, Schwimmer didn’t agree that all AI repositories consist of ‘scraped’ images without regard to copyright. For example, he said, a repository named Laion consists not of images, but links to images, which apparently makes a legal difference.
As to who owns the so-called final product, Schwimmer said that he views AI models as one more tool that helps users generate content. “The copyright analysis will be comparable to the analysis we use today when artists use the various illustration tools, graphics editors, paint programs, and other digital art tools: Is the work sufficiently original when divorced from the accompanying tools?”
For now, that will be the last word.

Advertisement




 


Click to share on Facebook (Opens in new window)Click to share on Twitter (Opens in new window)Copy this page's address to your clipboardLink copied to clipboard 
Posted inAI ∙ Web & Interactive Design 
",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
https://news.google.com/rss/articles/CBMiPGh0dHBzOi8vc2lmdGVkLmV1L2FydGljbGVzL2NoYXRncHQtYWktY2hhbmdpbmctd29yay1zdGFydHVwc9IBAA?oc=5,ChatGPT is already changing work at startups. Here's how - Sifted,2023-01-10,Sifted,https://sifted.eu,How is generative AI being put to use in tech companies today? Sifted spoke to founders who are already using tech like ChatGPT day-to-day.,N/A,How is generative AI being put to use in tech companies today? Sifted spoke to founders who are already using tech like ChatGPT day-to-day.,N/A,N/A,N/A,"The tech press is awash with takes on how advances in artificial intelligence are going to change the future of work but, for some startups, that future is already here. Generative AI — the technology that’s been made famous by image generators like DALL-E and the chatbot ChatGPT — is helping founders make big productivity gains in areas from coding to marketing. And some companies, Sifted has learnt, are even freezing hiring as they expect the same amount of work to be done by fewer people.AdvertisementCoding superpowers and ChatGPTOne founder who’s already putting OpenAI’s ChatGPT to use is Peter Nixey, founder of task management app Intentional. As a one-man company, Nixey is currently building the product’s whole tech stack himself, and says that he uses ChatGPT every day as a kind of personal web development assistant.“I just kind of ended up having it open with me as I was developing. And found it was a really useful tool as I was building software,” he says. Peter Nixey, founder of Intentional.ioNixey describes how it’s allowed him to accelerate his work with an app development tool, called Docker, that he wasn’t familiar with before by asking it intricacies about the tool. “It's been very good at explaining to me what I should do, it's been very good at giving me code examples. I asked it to explain different lines in the code and why they're there and it does that very effectively,” he says. He says it normally would have taken him about two weeks to learn how to use the tool — with ChatGPT, it took two days. Still needing experts alongside generative AIJoshua Wöhle, cofounder and CEO at edtech company Mindstone and a former cofounder and CTO of kids’ internet platform SuperAwesome, is currently using generative AI for a number of applications in his day-to-day workflow. That includes a social media assistant he’s built with the help of ChatGPT, and the image generators DALL-E and Stable Diffusion. Wöhle’s excel appThis lets him input the text for a tweet into a simple spreadsheet, which then turns it into social media graphics that include a condensed strapline of the tweet, overlaid on a branded image that’s generated based on the text he writes.“It just means that the time it takes to go from an idea to something that you can actually publish is now a minute or less, rather than before this would have taken about 20 minutes,” Wöhle says.But while Wöhle says that generative AI has greatly amped up his capacity to make high-quality content at Mindstone, he’s still about to onboard a head of product marketing at the startup — just with different expectations.“I still want that expert to be there, but my expectations of that person have dramatically increased,” he explains. “I'm expecting them to be able to do more work in the same amount of time.”AdvertisementChatGPT and hiring freezesThis example highlights the need to still have specialised people working with generative AI, rather than the AI replacing them altogether, but not all founders are thinking in this way.Wöhle recently organised group calls with founders and CTOs to talk about generative AI, and says that a number of entrepreneurs told him they'd put hiring plans on hold due to recent advances.“There were more than three people on the call who had already made the decision to freeze all the hiring they were doing, because they were considering that they might be able to do double the work with half the people next year,” he says. Joshua Wöhle, CEO and cofounder of MindstoneAnother example that Wöhle got from these fact-finding calls included an entrepreneur using ChatGPT as a kind of stand-in cofounder.“He asked ChatGPT: ‘OK, I'm thinking about building a company in this space, what would you say are the advantages and disadvantages?’ Then said: ‘OK, how would you pitch this?’ And it wrote a two-minute pitch. Then he asked: ‘So how would we build this on AWS [Amazon Web Services]?’ It gave a series of steps of how we should deploy that on AWS and provided some sample code bits.”Wöhle also says that generative AI is helping tech teams to fix buggy code, as it allows engineers to ask ChatGPT why a particular function isn’t working.Where is this all going?Both Wöhle and Nixey agree that, while ChatGPT and other generative AI apps are changing the world of work, they still require knowledgeable people in the room to get the most out of them.“Its ability to solve the task depends on one's ability to phrase the problem in the first place,” says Nixey.That said, both believe that AI will, in the not-too-distant future, be doing so much of the work that humans have previously done that ideas like universal basic income will become a necessity in the future.“For the first time, I can now see a future with universal basic income (UBI), where a set of people decide if they want to work,” Wöhle argues. “Not everyone will choose to work because the base level of UBI will be high enough that they’ll prefer not to, and then another set of people will decide to go and work. But they’ll be 100 times more productive than they have ever been before, and that’s why this works. This is not tomorrow, I now genuinely think that is the only way that this can work.”",https://schema.org,Organization,https://sifted.eu,"{'@type': 'Organization', 'name': 'Sifted', 'logo': {'@type': 'ImageObject', 'url': 'https://images.sifted.eu/wp-content/uploads/2018/11/25141406/Sifted-1A.png?w=2000&amp;h=443&amp;q=75&amp;fit=crop&amp;auto=compress,format'}}","{'@type': 'WebPage', '@id': 'https://sifted.eu/articles/chatgpt-ai-changing-work-startups'}",,,2023-02-27T15:42:41+00:00,,"['https://images.sifted.eu/wp-content/uploads/2023/01/10155648/DALL%C2%B7E-2023-01-10-16.44.27-extend.png?w=1984&amp;h=1024&amp;q=75&amp;fit=crop&amp;auto=compress,format']","[{'@type': 'Person', 'name': 'Tim Smith', 'url': 'https://sifted.eu/author/tim-smith'}]",ChatGPT is already changing work at startups. Here’s how | Sifted,Sifted,"['https://www.facebook.com/siftedeu/', 'https://twitter.com/siftedeu', 'https://uk.linkedin.com/company/siftedeu', 'https://www.instagram.com/siftedeu/']",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
https://news.google.com/rss/articles/CBMiKGh0dHBzOi8vd3d3LmJiYy5jby51ay9uZXdzcm91bmQvNjQyMTAwNTDSASxodHRwczovL3d3dy5iYmMuY28udWsvbmV3c3JvdW5kLzY0MjEwMDUwLmFtcA?oc=5,ChatGPT: What is the AI bot and how does it work? - BBC,2023-01-10,BBC,https://www.bbc.co.uk,Do you sometimes wish there was a quick and easy way to do your homework? Well a new artificial intelligence technology has been released and people are concerned that it could lead to students taking short cuts.,N/A,Do you sometimes wish there was a quick and easy way to do your homework? Well a new artificial intelligence technology has been released and people are concerned that it could lead to students taking short cuts.,Do you sometimes wish there was a quick and easy way to do your homework? Well a new artificial intelligence technology has been released and people are concerned that it could lead to students taking short cuts.,Newsround,N/A,"ChatGPT: What is the AI bot and how does it work?Published10 January 2023comments50 CommentsImage source, Getty ImagesDo you sometimes wish there was a quick and easy way to do your homework?Well a new artificial intelligence technology has been released and people are concerned that it could lead to students cheating on their work.ChatGPT is an online service which can not only answer questions but also write realistic school essays just like humans. Teachers are worried that students may use it to cheat. But what exactly is ChatGPT and how could it affect the future of homework?Do you think tools like this should be banned in schools? Or could it be useful if used in a positive way? Take part in our vote and have your say in the comments below.More like this...Is artificial intelligence a good idea?The Japanese robot that's learning how to laughCES 2023: The best gadgets and tech so farWhat is ChatGPT?Image source, NurPhoto/GettyChatGPT was released late last year by company OpenAI, which was founded by Elon Musk.. The technology chats in a conversational way, answering questions from the user. The online chatbot has been trained on lots of information and data from the internet - it can have a human-like conversation answering questions, admitting mistakes and rejecting any inappropriate questions. Experts say it can be used to write essays, stories, poems and even solve computer coding. But there are limits to what it can do, which OpenAI admit. Sometimes it writes answers which are incorrect or don't make sense, and it occasionally guesses what the user has asked it, rather than asking more follow-up questions to understand the question better. OpenAI say they are working on those problems. Who is Elon Musk? What are people saying about it?Image source, @ElonMusk/TwitterChatGPT is getting mixed reviews from people, some think students might use it to cheat whereas others think they should use the tool in the classroom to help children learn. Some people have suggested that the software should be welcomed. They argue that, just like when the calculator or Google were created, people were unsure at first, but if teachers introduce the technology and teach pupils the benefits but also the downfalls that could help their learning. In the US, the New York City education department banned ChatGPT on school devices and its internet network so students and teachers can't access it. In a statement they said they banned it because of ""negative impacts on student learning, and concerns regarding the safety and accuracy of content.""""We will be keeping a close eye on how this develops and, if this does become a problem, we will certainly be pressing the government to provide guidance and support.""— Geoff Barton, General secretary of the Association of School and College LeadersHere in the UK, exam regulator for England Ofqual and the Department of Education are keeping an eye on if the chatbot is being used to cheat. Geoff Barton, general secretary of the Association of School and College Leaders, said: ""We're aware of concerns that ChatGPT may be used by some pupils to write answers and pass this off as their own work, although we have not directly received reports of problems from our members thus far.""What are the problems with ChatGPT?Image source, Getty ImagesChatGPT is an easy way for students to write an essay or answer questions but some of the language it uses might prove to teachers that a child hasn't written it themselves. So although pupils may be tempted to use it, teachers might be able to spot quickly if it isn't your work because it doesn't sound how you would usually write. A downside of the software is that teachers give homework because they want to assess your writing, see if you have understood the work and test your analysing skills - all of which can't be judged if it was written by the chatbot.It also isn't always accurate as well - because it doesn't know everything your work might be incorrect. CEO of OpenAI, Sam Altman tweeted last year: ""ChatGPT is incredibly limited....it's a mistake to be relying on it for anything important right now.""Sorry, this vote cannot be loaded. In order to vote you need to enable JavaScript in your browser.If you can't see this vote, click here.More on this storyIs artificial intelligence a good idea?Published9 August 2019What is cryptocurrency and how does it work?Published23 November 2021How phone tech is being inspired by batsPublished3 May 2021",http://schema.org,CreativeWork,https://www.bbc.co.uk/newsround/64210050,"{'@type': 'Organization', 'name': 'BBC Newsround', 'logo': {'@type': 'ImageObject', 'url': 'https://static.files.bbci.co.uk/ws/simorgh-assets/public/newsround/images/metadata/poster-1024x576.png'}}",https://www.bbc.co.uk/newsround/64210050,2023-01-09T14:12:32.000Z,,2023-01-10T06:25:08.000Z,,"{'@type': 'ImageObject', 'width': 1024, 'height': 576, 'url': 'https://ichef.bbci.co.uk/news/1024/branded_bbc/7606/production/_128241203_childonlaptopdoinghomeworkgetty-1.jpg'}","{'@type': 'Organization', 'name': 'BBC Newsround', 'logo': {'@type': 'ImageObject', 'url': 'https://static.files.bbci.co.uk/ws/simorgh-assets/public/newsround/images/metadata/poster-1024x576.png'}}",ChatGPT: What is the AI bot and how does it work?,,,https://ichef.bbci.co.uk/news/1024/branded_bbc/7606/production/_128241203_childonlaptopdoinghomeworkgetty-1.jpg,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
https://news.google.com/rss/articles/CBMiYGh0dHBzOi8vd3d3LmFydGlmaWNpYWxpbnRlbGxpZ2VuY2UtbmV3cy5jb20vMjAyMy8wMS8wOS9hZG9iZS10cmFpbi1hbGdvcml0aG1zLXlvdXItd29yay1vcHQtb3V0L9IBAA?oc=5,Adobe may train its algorithms with your work unless you opt-out - AI News,2023-01-09,AI News,https://www.artificialintelligence-news.com,"Unless you specifically opt-out, Adobe may assume that it’s ok to use your work to train its algorithms.",N/A,"Unless you specifically opt-out, Adobe may assume that it’s ok to use your work to train its algorithms.",N/A,N/A,N/A,"

Adobe may train its algorithms with your work unless you opt-out




 



About the Author
By Ryan Daws |
        January 9, 2023
https://twitter.com/gadget_ry 
                            Categories:
                                    Artificial Intelligence,
                                    Companies,
                                    Ethics & Society,
                                    Machine Learning,
                        



 Ryan Daws is a senior editor at TechForge Media with over a decade of experience in crafting compelling narratives and making complex topics accessible. His articles and interviews with industry leaders have earned him recognition as a key influencer by organisations like Onalytica. Under his leadership, publications have been praised by analyst firms such as Forrester for their excellence and performance. Connect with him on X (@gadget_ry) or Mastodon (@gadgetry@techhub.social)








Unless you specifically opt-out, Adobe may assume that it’s ok to use your work to train its algorithms.
An eagle-eyed developer at the Krita Foundation noticed that Adobe had automatically opted them into a “content analysis” initiative. The program allows Adobe to “analyze your content using techniques such as machine learning (e.g. for pattern recognition) to develop and improve our products and services.”
The rule was implemented in August 2022 but managed to go unnoticed.
Artists, understandably, have been protesting over AI-generated art as a potential threat to their livelihoods:

Seeing AI art being featured on the main page of Artstation saddens me. I love playing with MJ as much as anyone else, but putting something that was generated using a prompt alongside artwork that took hundreds of hours and years of experience to make is beyond disrespectful. pic.twitter.com/4p2MLDbADD— Dan Eder (@3DanEder) December 9, 2022Click to accept marketing cookies and enable this content

While some artists believe AI is a tool for their work rather than a threat, there’s near-unanimous consensus that the method in which generative AI models are often trained is unfair.
Some artists have found their work has been scraped to train generative AI models without their consent or at least being paid royalties. This has raised questions over whether end-users could also unwittingly violate copyright and face legal consequences.
By changing its policy to allow AI models to be trained on the works of its users, Adobe doesn’t have to rely on scraping data from the web. Adobe, it’s worth noting, is set to 
While Adobe claims that it doesn’t use data on customers’ Creative Cloud accounts to train its experimental generative AI features, the wording provides some legal flexibility.
In the company’s documentation, Adobe quite clearly says “we first aggregate your content with other content and then use the aggregated content to train our algorithms and thus improve our products and services.”
Such data collection should never be opted into by default, it arguably falls foul of regulations like GDPR. If you’re an Adobe user and want to opt-out, you can do so here.
(Photo by Emily Bernal on Unsplash)
Related: Adobe to begin selling AI-generated stock images

Want to learn more about AI and big data from industry leaders? Check out AI & Big Data Expo taking place in Amsterdam, California, and London.
Explore other upcoming enterprise technology events and webinars powered by TechForge here.
Tags: adobe, ai, artificial intelligence, ethics, machine learning, training






View Comments


Leave a comment




Leave a Reply Cancel replyYou must be logged in to post a comment. 






",https://schema.org,,,,,,,,,,,,,,,"[{'@type': 'Article', '@id': 'https://www.artificialintelligence-news.com/news/adobe-train-algorithms-your-work-opt-out/#article', 'isPartOf': {'@id': 'https://www.artificialintelligence-news.com/news/adobe-train-algorithms-your-work-opt-out/'}, 'author': {'@id': 'https://www.ianj52.sg-host.com/#/schema/person/e4d76ff18520c27fd0713eff05f814ed'}, 'headline': 'Adobe may train its algorithms with your work unless you opt-out', 'datePublished': '2023-01-09T17:09:53+00:00', 'dateModified': '2023-01-09T17:11:10+00:00', 'mainEntityOfPage': {'@id': 'https://www.artificialintelligence-news.com/news/adobe-train-algorithms-your-work-opt-out/'}, 'wordCount': 362, 'commentCount': 0, 'publisher': {'@id': 'https://www.ianj52.sg-host.com/#organization'}, 'image': {'@id': 'https://www.artificialintelligence-news.com/news/adobe-train-algorithms-your-work-opt-out/#primaryimage'}, 'thumbnailUrl': 'https://www.artificialintelligence-news.com/wp-content/uploads/2023/01/adobe-ai-algorithms-machine-learning-train-artificial-intelligence.jpeg', 'keywords': ['adobe', 'ai', 'artificial intelligence', 'ethics', 'machine learning', 'training'], 'articleSection': ['Artificial Intelligence', 'Companies', 'Ethics &amp; Society', 'Machine Learning'], 'inLanguage': 'en-GB', 'potentialAction': [{'@type': 'CommentAction', 'name': 'Comment', 'target': ['https://www.artificialintelligence-news.com/news/adobe-train-algorithms-your-work-opt-out/#respond']}]}, {'@type': 'WebPage', '@id': 'https://www.artificialintelligence-news.com/news/adobe-train-algorithms-your-work-opt-out/', 'url': 'https://www.artificialintelligence-news.com/news/adobe-train-algorithms-your-work-opt-out/', 'name': 'Adobe may train its algorithms with your work unless you opt-out', 'isPartOf': {'@id': 'https://www.ianj52.sg-host.com/#website'}, 'primaryImageOfPage': {'@id': 'https://www.artificialintelligence-news.com/news/adobe-train-algorithms-your-work-opt-out/#primaryimage'}, 'image': {'@id': 'https://www.artificialintelligence-news.com/news/adobe-train-algorithms-your-work-opt-out/#primaryimage'}, 'thumbnailUrl': 'https://www.artificialintelligence-news.com/wp-content/uploads/2023/01/adobe-ai-algorithms-machine-learning-train-artificial-intelligence.jpeg', 'datePublished': '2023-01-09T17:09:53+00:00', 'dateModified': '2023-01-09T17:11:10+00:00', 'description': 'Unless you specifically opt-out, Adobe may assume that it’s ok to use your work to train its algorithms.', 'breadcrumb': {'@id': 'https://www.artificialintelligence-news.com/news/adobe-train-algorithms-your-work-opt-out/#breadcrumb'}, 'inLanguage': 'en-GB', 'potentialAction': [{'@type': 'ReadAction', 'target': ['https://www.artificialintelligence-news.com/news/adobe-train-algorithms-your-work-opt-out/']}]}, {'@type': 'ImageObject', 'inLanguage': 'en-GB', '@id': 'https://www.artificialintelligence-news.com/news/adobe-train-algorithms-your-work-opt-out/#primaryimage', 'url': 'https://www.artificialintelligence-news.com/wp-content/uploads/2023/01/adobe-ai-algorithms-machine-learning-train-artificial-intelligence.jpeg', 'contentUrl': 'https://www.artificialintelligence-news.com/wp-content/uploads/2023/01/adobe-ai-algorithms-machine-learning-train-artificial-intelligence.jpeg', 'width': 2400, 'height': 1600}, {'@type': 'BreadcrumbList', '@id': 'https://www.artificialintelligence-news.com/news/adobe-train-algorithms-your-work-opt-out/#breadcrumb', 'itemListElement': [{'@type': 'ListItem', 'position': 1, 'name': 'Home', 'item': 'https://www.artificialintelligence-news.com/'}, {'@type': 'ListItem', 'position': 2, 'name': 'News', 'item': 'https://www.artificialintelligence-news.com/artificial-intelligence-news/'}, {'@type': 'ListItem', 'position': 3, 'name': 'Adobe may train its algorithms with your work unless you opt-out'}]}, {'@type': 'WebSite', '@id': 'https://www.ianj52.sg-host.com/#website', 'url': 'https://www.ianj52.sg-host.com/', 'name': 'AI News', 'description': 'Artificial Intelligence News', 'publisher': {'@id': 'https://www.ianj52.sg-host.com/#organization'}, 'potentialAction': [{'@type': 'SearchAction', 'target': {'@type': 'EntryPoint', 'urlTemplate': 'https://www.ianj52.sg-host.com/?s={search_term_string}'}, 'query-input': 'required name=search_term_string'}], 'inLanguage': 'en-GB'}, {'@type': 'Organization', '@id': 'https://www.ianj52.sg-host.com/#organization', 'name': 'AI News', 'url': 'https://www.ianj52.sg-host.com/', 'logo': {'@type': 'ImageObject', 'inLanguage': 'en-GB', '@id': 'https://www.ianj52.sg-host.com/#/schema/logo/image/', 'url': 'https://www.artificialintelligence-news.com/wp-content/uploads/2020/03/ai-newsv4-2-svg.png', 'contentUrl': 'https://www.artificialintelligence-news.com/wp-content/uploads/2020/03/ai-newsv4-2-svg.png', 'width': 400, 'height': 78, 'caption': 'AI News'}, 'image': {'@id': 'https://www.ianj52.sg-host.com/#/schema/logo/image/'}, 'sameAs': ['https://www.facebook.com/AITechNews/', 'https://x.com/ai_technews', 'https://www.linkedin.com/groups/1906826/']}, {'@type': 'Person', '@id': 'https://www.ianj52.sg-host.com/#/schema/person/e4d76ff18520c27fd0713eff05f814ed', 'name': 'Ryan Daws', 'image': {'@type': 'ImageObject', 'inLanguage': 'en-GB', '@id': 'https://www.ianj52.sg-host.com/#/schema/person/image/0a89168c3b9fc190f9bdbce571d2fa5f', 'url': 'https://secure.gravatar.com/avatar/b8c5d238e1fddd55d8a0064f1a534ba5?s=96&d=mm&r=g', 'contentUrl': 'https://secure.gravatar.com/avatar/b8c5d238e1fddd55d8a0064f1a534ba5?s=96&d=mm&r=g', 'caption': 'Ryan Daws'}, 'description': 'Ryan Daws is a senior editor at TechForge Media with over a decade of experience in crafting compelling narratives and making complex topics accessible. His articles and interviews with industry leaders have earned him recognition as a key influencer by organisations like Onalytica. Under his leadership, publications have been praised by analyst firms such as Forrester for their excellence and performance. Connect with him on X (@gadget_ry) or Mastodon (@gadgetry@techhub.social)', 'sameAs': ['https://twitter.com/gadget_ry'], 'url': 'https://www.artificialintelligence-news.com/news/author/ryan/', 'jobTitle': 'Senior Editor'}]",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
https://news.google.com/rss/articles/CBMidmh0dHBzOi8vd3d3LmVkd2Vlay5vcmcvdGVjaG5vbG9neS93aXRoLWNoYXRncHQtdGVhY2hlcnMtY2FuLXBsYW4tbGVzc29ucy13cml0ZS1lbWFpbHMtYW5kLW1vcmUtd2hhdHMtdGhlLWNhdGNoLzIwMjMvMDHSAQA?oc=5,"With ChatGPT, Teachers Can Plan Lessons, Write Emails, and More. What's the Catch? - Education Week",2023-01-11,Education Week,https://www.edweek.org,"The artificial intelligence tool could be a time-saver for teachers, but some have concerns.","Classroom Technology,Technology,Artificial Intelligence,Apps,Grading","The artificial intelligence tool could be a time-saver for teachers, but some have concerns.","The artificial intelligence tool could be a time-saver for teachers, but some have concerns.","Technology, Classroom Technology",N/A,N/A,http://schema.org,NewsArticle,https://www.edweek.org/technology/with-chatgpt-teachers-can-plan-lessons-write-emails-and-more-whats-the-catch/2023/01,"{'@type': 'Organization', 'name': 'Education Week', 'url': 'https://www.edweek.org', 'logo': {'@context': 'http://schema.org', '@type': 'ImageObject', 'url': 'https://epe.brightspotcdn.com/92/39/4b389b354fcfab885b92b5ee0841/maddy-will-jb.jpg'}}","{'@type': 'WebPage', '@id': 'https://www.edweek.org/technology/with-chatgpt-teachers-can-plan-lessons-write-emails-and-more-whats-the-catch/2023/01'}","January 11, 2023",,"March 01, 2023",,"{'@context': 'http://schema.org', '@type': 'ImageObject', 'url': 'https://epe.brightspotcdn.com/61/e6/5b0584994946b87bd5a5c770ae6d/011023-ai-lessonplans-1290349042-b.jpg'}",Madeline Will,"With ChatGPT, Teachers Can Plan Lessons, Write Emails, and More. What's the Catch?",,,https://epe.brightspotcdn.com/61/e6/5b0584994946b87bd5a5c770ae6d/011023-ai-lessonplans-1290349042-b.jpg,,News,"Classroom Technology,Technology,Artificial Intelligence,Apps,Grading",2023,https://www.edweek.org/technology/with-chatgpt-teachers-can-plan-lessons-write-emails-and-more-whats-the-catch/2023/01#comments,en-US,true,https://www.edweek.org/issue/education-week-news-in-print,7,"[{'@context': 'http://schema.org', '@type': 'Person', 'affiliation': 'Education Week', 'description': 'Madeline Will is an assistant managing editor for Education Week, leading coverage of school leadership and general education trends.', 'email': 'mwill@educationweek.org', 'image': {'@context': 'http://schema.org', '@type': 'ImageObject', 'url': 'https://epe.brightspotcdn.com/92/39/4b389b354fcfab885b92b5ee0841/maddy-will-jb.jpg'}, 'jobTitle': 'Assistant Managing Editor', 'name': 'Madeline Will', 'url': 'https://www.edweek.org/by/madeline-will'}]","With ChatGPT, Teachers Can Plan Lessons, Write Emails, and More. What’s the Catch?,With ChatGPT, Teachers Can Plan Lessons, Write Emails, and More. What's the Catch?,With ChatGPT, Teachers Can Plan Lessons, Write Emails, and More. What's the Catch?","Education Week, Vol. 42, Issue 20",https://www.edweek.org/about,P8M,1706,,,,,,,,,,,,,,,,
https://news.google.com/rss/articles/CBMiQGh0dHBzOi8vZW1lcmouY29tL2FpLWV4ZWN1dGl2ZS1ndWlkZXMvd2lsbC1yb2JvdHMtdGFrZS15b3VyLWpvYi_SAQA?oc=5,Will Robots Take Your Job? Don't Trust Startups and Enterprises to Tell You - Emerj,2023-01-07,Emerj,https://emerj.com,"Startups overstate the job loss risk of AI, and enterprises understate it. Learn how to cut through the hype and carefully-worded press releases.",,"Startups overstate the job loss risk of AI, and enterprises understate it. Learn how to cut through the hype and carefully-worded press releases.",N/A,N/A,N/A," Best-Practice Guides  PLUS  Will Robots Take Your Job? Be Wary of Messaging from Startups and Enterprises Daniel FaggellaLast updated on January 7, 2023  Last updated on January 7, 2023, published by Daniel Faggella Daniel Faggella is Head of Research at Emerj. Called upon by the United Nations, World Bank, INTERPOL, and leading enterprises, Daniel is a globally sought-after expert on the competitive strategy implications of AI for business and government leaders. Share to: LinkedIn Twitter Facebook Email  This Emerj Plus article has been made publicly available for a limited time. To unlock our full library of AI use-cases and AI strategy best practices, visit  Emerj Plus. Something that dawned on me very early on in reading biography and history is that incentives rule the world, that company’s, nations, individuals ultimately do things primarily for their own self-interest. And there’s nothing inherently wrong with that, but it’s important to bear it in mind. Business is no different. Artificial intelligence is no different. Like with any topic that has political ramifications, the loudest voices on both sides of the debate over the job loss risk of AI are the sides that have the most at stake. They are the individuals and the groups that have the most to gain or to lose, not necessarily for finding the truth, but for forwarding the narrative that would behoove them and behoove their interests. This doesn’t make these parties bad people; it just means that “good” for them, in terms of the achievement of their goals and potentially the assurance of their perceived well-being, isn’t about figuring out the ultimate truth, but again, in promoting a story that boosts their own names. So when it comes to job loss here at Emerj, we’ve looked at thousands of companies over the last four years in sectors such as finance and healthcare and heard stories from startups big and small, from AI buyers, from consultants at large firms and small firms, and from small private firms and public firms. We’ve heard a variety of perspectives on job risk and which jobs are likely to be disrupted, as well as which industries are likely to actually see real job loss in a potentially dangerous way to certain segments of society and where the transition is going to be more gradual. I’ve noticed a pattern over the course of these four years across the groups that tend to be loudest about promoting job loss to the point where it almost feels disingenuous. It feels like these groups can’t possibly believe what they’re saying. Similarly, there’s another group that tends to underestimate the risk of job loss by automation. As mentioned, in any given conflict over a politicized issue, the loudest group are those who have the most at stake. These groups again seem as though they are forwarding an agenda. In this article, I’m going to highlight who these groups are by going through the below graphic in depth:  Groups that Overestimate Job Loss The groups that tend to overestimate job loss are often either startups under 50 employees or boutique consulting firms recently rebranded to be all about emerging technology. A lot of the time these “AI consulting firms” were before just doing completely generic IT consulting for 15 years in a row and then decided to frame themselves to be about artificial intelligence. Another common type of organization that will promote a hyperbolic level of job loss risk is small technology firms that have rebranded to be about AI, blockchain, or a similar buzzword. These could be existing firms that have done something in technology for the last 15 years, perhaps in telecom or life sciences, and all of a sudden they have rebranded to an AI company even without having any data science staff on their team. These smaller groups tend to be the sources of the most overblown job loss and risk statements, and they tend to have common traits: They Have Few Employees If they talk about something like the automation of particular roles, they’re not worrying large sums of people at their company that they don’t know. Generally, everybody’s down the hall from everybody else. The CEO might even be able to shake hands with everybody in the company on a relatively regular basis. These are tightly knit groups, and so the kind of internal disruption that might happen for the company is by our estimation much less intense than it is for enterprises. They Have Few Stakeholders Similarly, these companies tend to have few stakeholders. They are almost never publicly traded firms. They may even have a relatively small number of clients, and so, again, they don’t have a wide variety of powerful players to upset with their hyperbole. They’re not going to have people selling their shares on the open market as a result of their bluster, for example. They Can Get on the Radar of Possible Customers If the media reports on one of these smaller firms purporting that a revolution will come to the sector they sell into, this might actually get the company on the radar of potential clients. That’s why they pivoted to AI in the first place; this is the behooved interest. Revolutionary change on the aggregate could be good for the company. It could finally get them some press coverage. Oftentimes, people in the press who interview AI consulting firms are just going to interview them and expect them to be experts on AI. They might never do any homework and figure out if anyone at the company even has AI or data science experience. These firms want to convince the market and the press of the importance of their product and their approach. For example, if retail jobs are going to be drastically overhauled in the short-term, companies like theirs are going to be very valuable. If they can predict a kind of automation revolution, that might be the ticket to their credibility and their ticket to customers. They Can Convince Venture Capitalists to Invest Startups are going to want to claim that their product will bring the ultimate disruption of the sector into which they are selling because terms like “ultimate disruption” and “revolution” could be appealing to venture capitalists. Promoting the job loss narrative could be a way to win venture money. They Use Buzzwords These small firms also tend to use buzzwords in press releases and on their websites time and time again. They use words like “revolutionize” or “completely automate.” Anytime we see the phrase “completely automate,” it raises a red flag for us here at Emerj. Artificial intelligence is not a process whereby systems can be completely automated often without humans somewhere along the line. The process of setting up artificial intelligence systems, integrating them into existing data infrastructures, revamping data infrastructures, training algorithms, and updating algorithms is extremely complicated and requires talented people. We’ve done a lengthy article on applying artificial intelligence in the enterprise and its inherent challenges. “Completely automate” is a hyperbolic claim, and anyone who says it is really stretching oftentimes what artificial intelligence is actually capable of doing, downplaying the integration, the data requirements, and talent requirements. Another term is “push button.” The setup and strategy around leveraging AI technology are complex and certainly far from “push button.” Then, of course, there is the classic: “disruption.” If these words are stated one too many times on company LinkedIn descriptions and websites, business leaders should consider this a red flag that the company is hiding behind marketing language because they don’t have the data science talent on their team to back up their claims and provide legitimate AI software. Groups that Underestimate Job Loss Large multinational companies are the most likely to underestimate job loss. In particular, companies will often downplay job loss when they are trying to rebrand themselves as being leaders in AI even if they don’t actually employ data science talent. These companies often use the word “augment” over “automate.” These companies share common traits that are in general the opposite of those that small firms looking to exaggerate the job loss risk share. They Have Many Employees These companies can’t risk upsetting all of their employees, many of whom have never interacted with the company leadership in their lives and never will. AT&T, for example, can’t talk about automating customer service with AI without gravely worrying their employees. They risk their employees leaving because they feel undervalued. These companies will say things like “our people are the most important thing for our company,” and similar platitudes in order to discuss AI in the open without alarming their employees. They want to figure out how to keep the discussion they’re having about automation and layoffs away from the press and their employees. They Have Many Stakeholders Enterprises have shareholders, people trading their company on open markets and people who wield power over the business to keep happy. They have big global business partners and accounts, and if they start talking about disruption in ways that makes their employees nervous and perhaps cause the market to fluctuate a little, they risk problems with their stakeholders. If they start talking about technology that might disrupt the sector into which the company is selling, that doesn’t bode well for the company when it comes to how their shareholders might react. As a result, they’ll underestimate the impact of this technology. They Have to Navigate the AI Buzz Carefully These companies are often going to have a hard time adjusting to artificial intelligence They’re still looking to be successful as workforce automation becomes more common, but they want to limit the revolt from their employees and stakeholders as a result. They don’t want to talk openly about putting employees in different positions, retraining them, and possibly laying them off. As a result, they need to choose their words carefully for press releases about their AI initiatives. They talk a lot about augmentation, but not automation. In addition, they often use the word “empower,” such as in “We’re all about empowering people with AI.” They position themselves as virtuous against the startups that are talking about replacing people with machines. They need to do this even if they’re about to lay off 2,000 people because they can’t risk an employee revolt. Another statement they often say: “Our people are the most important thing to us.” In addition, these companies speak in terms of “always” and “never.” They frame AI as a black and white discussion: “it will do this; it won’t do that.” What Business Leaders Should Know These groups tend to be the loudest voices in this conversation for business leaders realistically thinking about their strategy. Don’t listen to either of them exclusively and listen to them with healthy skepticism. The fact of the matter is that some job roles are likely to be augmented with artificial intelligence and some are going to likely be automated in the decade ahead. People filling certain roles at companies might just be repositioned into other roles if they possess more diverse skillsets. In other cases, automation will make some employees obsolete because they can’t easily be repositioned into another role at the company. Business leaders shouldn’t suspect that something like that is completely out of the realm of possibility. Likely both are going to be the case. Business leaders should bear in mind that the loudest companies overestimating and underestimating job loss are pushing forward their own interests. As artificial intelligence continues to make its way into major industries, there will be changes. There will be instances of augmentation, and there will be automation. Some automation might be slow, and people’s skills will be repurposed. Other automation might be quick, and people might be left without a job. As business and government leaders, we should be thinking seriously about the potential low hanging fruit automation opportunities within our business, not just to win market share, but to consider what to do with our teams. What do we do with those people? How do we bend our business, our training, our skills development programs in order to make the most of our human resources and in order to move our business forward and continue to win in the market? Sometimes those incentives are at odds.   Header Image Credit: Fortune Related Posts The 4 Horsemen of the AI-pocalypse - Why Enterprises Fail to Adopt AIThis is a contributed article by Ian Wilson, Founder at Strategy 4 AI - learn more… The Survival of AI Startups in the COVID Crisis - and Implications for BusinessAt Emerj, for over three years, we've been tracking the development of artificial intelligence startups… Offering AI Services to Smaller Enterprises - Lead with EducationThis article was a request from one of our Catalyst members. The Catalyst Advisory Program… Retraining and Reskilling for AI - The State of AI Job Loss TodayOne of the many concerns that business leaders have around automation is how they're going… Building Your AI Product Development Roadmap - Recommendations for Startups and Enterprise Leaders (Part 3 of 3)This article is the third in a series part in a series about AI product… Share to: LinkedIn Twitter Facebook Email Stay Ahead of the AI Curve Discover the critical AI trends and applications that separate winners from losers in the future of business. Sign up for the 'AI Advantage' newsletter:   Subscribe",https://schema.org,Article,,"{'@type': 'Organization', 'name': 'Emerj', 'url': 'https://emerj.com', 'logo': {'@type': 'ImageObject', 'url': 'https://emerj.com/wp-content/themes/emerj/src/logo/emerj-logo-w-500-min.png'}}",https://emerj.com/ai-executive-guides/will-robots-take-your-job,2018-12-01,,2023-01-07,,https://emerj.com/wp-content/uploads/2018/12/Will-Robots-Take-Your-Job-950x540-1-690x392.jpg,Daniel Faggella,Will Robots Take Your Job? Be Wary of Messaging from Startups and Enterprises,,,,,Best-Practice Guides,,,,,,,,,,,,,,1942,,,,,,,,,,,,,,,
https://news.google.com/rss/articles/CBMiUGh0dHBzOi8vd3d3Lm55dGltZXMuY29tLzIwMjMvMDEvMDkvc2NpZW5jZS9hcnRpZmljaWFsLWludGVsbGlnZW5jZS1wcm90ZWlucy5odG1s0gEA?oc=5,A.I. Turns Its Artistry to Creating New Human Proteins (Published 2023) - The New York Times,2023-01-09,The New York Times,https://www.nytimes.com,"Inspired by digital art generators like DALL-E, biologists are building artificial intelligences that can fight cancer, flu and Covid.",N/A,"Inspired by digital art generators like DALL-E, biologists are building artificial intelligences that can fight cancer, flu and Covid.","Inspired by digital art generators like DALL-E, biologists are building artificial intelligences that can fight cancer, flu and Covid.",Science,N/A,"Artificial IntelligenceMicrosoft’s Risk-TakerFine Print ChangesQuiz: Fake or Real Images?Apple Enters A.I. FrayMeta’s A.I. ScrapingAdvertisementSKIP ADVERTISEMENTSupported bySKIP ADVERTISEMENTA.I. Turns Its Artistry to Creating New Human ProteinsInspired by digital art generators like DALL-E, biologists are building artificial intelligences that can fight cancer, flu and Covid.Share full articleRead in appVideoAn example of an animated diffusion model of A.I.-generated proteins. Video by Ian C. Haydon/University of Washington Institute for Protein DesignCreditCredit...By Cade MetzJan. 9, 2023Last spring, an artificial intelligence lab called OpenAI unveiled technology that lets you create digital images simply by describing what you want to see. Called DALL-E, it sparked a wave of similar tools with names like Midjourney and Stable Diffusion. Promising to speed the work of digital artists, this new breed of artificial intelligence captured the imagination of both the public and the pundits — and threated to generate new levels of online disinformation.Social media is now teeming with the surprisingly conceptual, in which shockingly detailed, often photorealistic images generated by DALL-E and other tools. “Photo of a teddy bear riding a skateboard in Times Square.” “Cute corgi in a house made out of sushi.” “Jeflon Zuckergates.”But when some scientists consider this technology, they see more than just a way of creating fake photos. They see a path to a new cancer treatment or a new flu vaccine or a new pill that helps you digest gluten.Using many of the same techniques that underpin DALL-E and other art generators, these scientists are generating blueprints for new proteins — tiny biological mechanisms that can change the way of our bodies behave.AdvertisementSKIP ADVERTISEMENTOur bodies naturally produce about 20,000 proteins, which handle everything from digesting food to moving oxygen through the bloodstream. Now, researchers are working to create proteins that are not found in nature, hoping to improve our ability to fight disease and do things that our bodies cannot on their own.David Baker, the director of the Institute for Protein Design at the University of Washington, has been working to build artisanal proteins for more than 30 years. By 2017, he and his team had shown this was possible. But they did not anticipate how the rise of new A.I. technologies would suddenly accelerate this work, shrinking the time needed to generate new blueprints from years down to weeks.“What we need are new proteins that can solve modern-day problems, like cancer and viral pandemics,” Dr. Baker said. “We can’t wait for evolution.” He added, “Now, we can design these proteins much faster, and with much higher success rates, and create much more sophisticated molecules that can help solve these problems.”ImageDavid Baker of the University of Washington.Credit...Evan McGlinn for The New York TimesLast year, Dr. Baker and his fellow researchers published a pair of papers in the journal Science describing how various A.I. techniques could accelerate protein design. But these papers have already been eclipsed by a newer one that draws on the techniques that drive tools like DALL-E, showing how new proteins can be generated from scratch much like digital photos.AdvertisementSKIP ADVERTISEMENT“One of the most powerful things about this technology is that, like DALL-E, it does what you tell it to do,” said Nate Bennett, one of the researchers working in the University of Washington lab. “From a single prompt, it can generate an endless number of designs.”To generate images, DALL-E relies on what artificial intelligence researchers call a neural network, a mathematical system loosely modeled on the network of neurons in the brain. This is the same technology that recognizes the commands you bark into your smartphone, enables self-driving cars to identify (and avoid) pedestrians and translates languages on services like Skype.A neural network learns skills by analyzing vast amounts of digital data. By pinpointing patterns in thousands of corgi photos, for instance, it can learn to recognize a corgi. With DALL-E, researchers built a neural network that looked for patterns as it analyzed millions of digital images and the text captions that described what each of these images depicted. In this way, it learned to recognize the links between the images and the words.When you describe an image for DALL-E, a neural network generates a set of key features that this image may include. One feature might be the curve of a teddy bear’s ear. Another might be the line at the edge of a skateboard. Then, a second neural network — called a diffusion model — generates the pixels needed to realize these features.The diffusion model is trained on a series of images in which noise — imperfection — is gradually added to a photograph until it becomes a sea of random pixels. As it analyzes these images, the model learns to run this process in reverse. When you feed it random pixels, it removes the noise, transforming these pixels into a coherent image.AdvertisementSKIP ADVERTISEMENTAt the University of Washington, other academic labs and new start-ups, researchers are using similar techniques in their effort to create new proteins.Proteins begin as strings of chemical compounds, which then twist and fold into three-dimensional shapes that define how they behave. In recent years, artificial intelligence labs like DeepMind, owned by Alphabet, the same parent company as Google, have shown that neural networks can accurately guess the three-dimensional shape of any protein in the body based just on the smaller compounds it contains — an enormous scientific advance.Now, researchers like Dr. Baker are taking another step, using these systems to generate blueprints for entirely new proteins that do not exist in nature. The goal is to create proteins that take on very specific shapes; a particular shape can serve a particular task, such as fighting the virus that causes Covid.Much as DALL-E leverages the relationship between captions and photographs, similar systems can leverage the relationship between a description of what the protein can do and the shape it adopts. Researchers can provide a rough outline for the protein they want, then a diffusion model can generate its three-dimensional shape.VideoA protein diffusion model doing unconditional generation, converting noise into plausible structures. Video by Namrata AnandCreditCredit...ImageNamrata Anand, a former Stanford University researcher. She is now building a company in generative A.I. protein design.Credit...Herve Philippe/TerrificShot Photography“With DALL-E, you can ask for an image of a panda eating a shoot of bamboo,” said Namrata Anand, a former Stanford University researcher who is also an entrepreneur, building a company in this area of research. “Equivalently, protein engineers can ask for a protein that binds to another in a particular way — or some other design constraint — and the generative model can build it.”The difference is that the human eye can instantly judge the fidelity of a DALL-E image. It cannot do the same with a protein structure. After artificial intelligence technologies produce these protein blueprints, scientists must still take them into a wet lab — where experiments can be done with real chemical compounds — and make sure they do what they are supposed to do.For this reason, some experts say that the latest artificial intelligence technologies should be taken with a grain of salt. “Making a new structure is just a game,” said Frances Arnold, a Nobel Laureate who is a professor specializing in protein engineering at the California Institute of Technology. “What really matters is: What can that structure actually do?”But for many researchers, these new techniques are not just accelerating the creation of new protein candidates for the wet lab. They provide a way of exploring new innovations that researchers could not previously explore on their own.AdvertisementSKIP ADVERTISEMENT“What’s exciting isn’t just that they are creative and explore unexpected possibilities, but that they are creative while satisfying certain design objectives or constraints,” said Jue Wang, a researcher at the University of Washington. “This saves you from needing to check every possible protein in the universe.”Often, artificially intelligent machines are developed to perform skills that come naturally to humans, like piecing together images, writing text or playing board games. Protein-designing bots pose a more profound question, Dr. Wang said: “What can machines do that humans can’t do at all?”Cade Metz writes about artificial intelligence, driverless cars, robotics, virtual reality and other emerging areas of technology. More about Cade MetzA version of this article appears in print on Jan. 10, 2023, Section D, Page 4 of the New York edition with the headline: Making Proteins With DALL-E’s Techniques. Order Reprints | Today’s Paper | SubscribeShare full articleRead in appAdvertisementSKIP ADVERTISEMENTEnjoy unlimited access to all of The Times.6-month Welcome Offeroriginal price:   $6.25sale price:   $1/weekLearn more",https://schema.org,NewsMediaOrganization,https://www.nytimes.com/,"{'@id': 'https://www.nytimes.com/#publisher', 'name': 'The New York Times'}",https://www.nytimes.com/2023/01/09/science/artificial-intelligence-proteins.html,2023-01-09T10:00:23.000Z,,2023-01-09T13:14:04.000Z,,"[{'@context': 'https://schema.org', '@type': 'ImageObject', 'url': 'https://static01.nyt.com/images/2023/01/03/autossell/00SCI-PROTEINGS-vid1cover/00SCI-PROTEINGS-vid1cover-videoSixteenByNineJumbo1600.jpg', 'height': 900, 'width': 1600, 'contentUrl': 'https://static01.nyt.com/images/2023/01/03/autossell/00SCI-PROTEINGS-vid1cover/00SCI-PROTEINGS-vid1cover-videoSixteenByNineJumbo1600.jpg', 'creditText': ''}, {'@context': 'https://schema.org', '@type': 'ImageObject', 'url': 'https://static01.nyt.com/images/2023/01/03/autossell/00SCI-PROTEINGS-vid1cover/00SCI-PROTEINGS-vid1cover-superJumbo.jpg', 'height': 1227, 'width': 1842, 'contentUrl': 'https://static01.nyt.com/images/2023/01/03/autossell/00SCI-PROTEINGS-vid1cover/00SCI-PROTEINGS-vid1cover-superJumbo.jpg', 'creditText': ''}, {'@context': 'https://schema.org', '@type': 'ImageObject', 'url': 'https://static01.nyt.com/images/2023/01/03/autossell/00SCI-PROTEINGS-vid1cover/00SCI-PROTEINGS-vid1cover-mediumSquareAt3X.jpg', 'height': 1090, 'width': 1090, 'contentUrl': 'https://static01.nyt.com/images/2023/01/03/autossell/00SCI-PROTEINGS-vid1cover/00SCI-PROTEINGS-vid1cover-mediumSquareAt3X.jpg', 'creditText': ''}]","[{'@context': 'https://schema.org', '@type': 'Person', 'url': 'https://www.nytimes.com/by/cade-metz', 'name': 'Cade Metz'}]",A.I. Turns Its Artistry to Creating New Human Proteins,The New York Times,https://en.wikipedia.org/wiki/The_New_York_Times,,,,,2024,,en,,"{'@type': ['CreativeWork', 'Product'], 'name': 'The New York Times', 'productID': 'nytimes.com:basic'}",,,Making Proteins With DALL-E’s Techniques,,,,,,"[{'@id': 'https://www.nytimes.com/video/embedded/science/100000008712246/00SCI-PROTEINS-vid1.html'}, {'@id': 'https://www.nytimes.com/video/embedded/science/100000008712229/00sci-proteins-vid2.html'}]","{'@type': 'WebPageElement', 'isAccessibleForFree': False, 'cssSelector': '.meteredContent'}","{'@id': 'https://www.nytimes.com/#publisher', 'name': 'The New York Times'}","{'@id': 'https://www.nytimes.com/#publisher', 'name': 'The New York Times'}",False,"{'@context': 'https://schema.org', '@type': 'ImageObject', 'url': 'https://static01.nyt.com/images/icons/t_logo_291_black.png', 'height': 291, 'width': 291, 'contentUrl': 'https://static01.nyt.com/images/icons/t_logo_291_black.png', 'creditText': 'The New York Times'}",https://www.nytimes.com/#publisher,https://www.nytco.com/company/diversity-and-inclusion/,https://www.nytco.com/company/standards-ethics/,https://www.nytimes.com/interactive/2023/01/28/admin/the-new-york-times-masthead.html,1851-09-18,,,,
https://news.google.com/rss/articles/CBMicmh0dHBzOi8vd3d3LmVudHJlcHJlbmV1ci5jb20vc2NpZW5jZS10ZWNobm9sb2d5L3doeS1sZWdhbC1wcm9mZXNzaW9uYWxzLW11c3QtYWRhcHQtdG8tYWktb3Itcmlzay1iZWluZy1sZWZ0LzQ0MTc1MdIBAA?oc=5,Why Legal Professionals Must Adapt to AI or Risk Being Left Behind - Entrepreneur,2023-01-11,Entrepreneur,https://www.entrepreneur.com,Artificial Intelligence has already taken over many jobs that were previously handled manually. This technology&#039;s continuous development challenges more professions and will even disrupt high-skill areas such as the legal industry.,"['Science & Technology', 'Legal', 'Technology', 'Legal Issues', 'Laws', 'Legal Advice', 'Artificial Intelligence', 'Legal industry', 'AI tools', 'Legal AI', 'Legal field']",Artificial Intelligence has already taken over many jobs that were previously handled manually. This technology's continuous development challenges more professions and will even disrupt high-skill areas such as the legal industry.,Artificial Intelligence has already taken over many jobs that were previously handled manually. This technology's continuous development challenges more professions and will even disrupt high-skill areas such as the legal industry.,Why Legal Professionals Must Adapt to AI or Risk Being Left Behind | Entrepreneur,N/A,"


  The Rise of AI: Why Legal Professionals Must Adapt or Risk Being Left Behind
  
    Artificial Intelligence has already taken over many jobs that were previously handled manually. This technology's continuous development challenges more professions and will even disrupt high-skill areas such as the legal industry.
  





                  By          
            Roland Polzin
          

            Edited by 
                          
                Micah Zimmerman
              


            Jan 11, 2023
          




          Share        


Copy


 






Subscribe to the Entrepreneur Daily newsletter to get business news, tips and inspiration sent to your inboxSubscribeI understand that the data I am submitting will be used to provide me with the above-described products and/or services and communications in connection therewith.Read our privacy policy for more information.



    Opinions expressed by Entrepreneur contributors are their own.  

The legal profession is no stranger to the rise of artificial intelligence (AI), and its impact is only expected to intensify in the upcoming years. As businesses strive to reduce costs and increase efficiency, AI is used for various tasks, including contract review, legal research, and drafting legal documents. According to the World Economic Forum, the legal sector will most likely experience AI disruption after the transportation and healthcare sectors.Five years ago, the New York Times reported AI is doing legal work, but it's not replacing lawyers — yet. However, recent developments with ChatGPT underscore how close we are to a reality where this will be the case. AI can now, undeniably, help and replace lawyers for certain types of tasks – from drafting contracts to summarizing complex laws.Related: Princeton Student Builds ChatGPT Detection App to Fight AI Plagiarism



Large language models, such as GPT-3, have recently revolutionized the practical use of artificial intelligence in the legal field. These models, trained on vast amounts of data, can generate human-like text, making them ideal for summarizing legal documents and predicting case outcomes. The recent acceleration of using large language models in the legal field can be attributed to a few key factors. One is the continued advancement and development of these models, which have become more sophisticated and accurate over time. This has made them increasingly useful and practical for various applications, especially in the legal industry.Related: 3 Ways Artificial Intelligence Will Transform The World in 2023


Another factor driving the adoption of large language models in the legal field is the increasing industry demand for automation and efficiency. Legal professionals are under increasing pressure to handle a high volume of work in a short amount of time. Using large language models can help alleviate this burden by automating certain tasks and allowing for more efficient research and analysis.However, deploying AI in the legal sector does not come without difficulties. Cost is a major obstacle to AI adoption in the legal industry. There may be significant upfront costs associated with selecting and putting in place AI systems, as well as potential continuing maintenance and training expenses. The legal sector is heavily regulated, and adhering to these standards can be difficult and expensive.The absence of standards in the legal industry is another problem that can make it challenging to use AI systems. Laws and rules are distinct to each legal jurisdiction, and AI systems must be tailored to follow these criteria. This can be a time-consuming and expensive procedure that may also include hiring specialized staff with knowledge of both AI and law.Related: The Curious Case of AI and Legal Liability


Finally, the legal sector has an aversion to change. Many legal professionals, including lawyers, have reservations about AI's dependability and accuracy and may be reluctant to use it in their job. Another concern is that using AI would drive job losses or decrease demand for human legal professionals.Do these reasons matter, though, to the companies and clients that pay for legal services? Probably not.AI can significantly reduce costs and increase efficiency for business — it's undeniable that the use cases for AI in the law and business are here, and they're not going away. AI can reduce the time and resources needed to execute some jobs by automating them. For clients seeking legal services, this may eventually mean cost savings.The speed at which AI can process and interpret enormous amounts of data is one of its main advantages. This can be especially helpful in legal practice, where it may be necessary to study and analyze documents and other materials quickly. Additionally, AI can eliminate humans in the loop regarding due diligence.


Even online dispute resolution services such as JAMS eliminate the need for in-person court hearings on complex intellectual property matters.It's also essential to consider the growing trust in AI systems. According to a survey conducted by Deloitte, 76% of respondents reported having trust in AI systems to make decisions, and 72% believed that AI could be a valuable addition to their organization. This suggests a growing acceptance of AI within the legal industry, and customers may be more willing to adopt it to achieve greater efficiency and cost savings.However, not everything related to AI is bad for lawyers. AI can give partners at law firms and general counsels new opportunities, even while it may automate low-level jobs. For instance, AI in contract management software can make it faster for lawyers and business teams to author, negotiate and redline initial drafts, freeing up time for higher-value activities that are often valued the most: negotiation and advocacy.As lawyers learn to collaborate with and take advantage of AI systems, it's conceivable that AI usage could lead to new career possibilities. So, will AI replace human lawyers in the coming five years? It's impossible to say for sure, but the trend is undeniable: AI use in the legal sector is expected to grow in the upcoming years, and human attorneys must adapt if they want to stay in demand.

",https://schema.org,BreadcrumbList,https://www.entrepreneur.com,"{'@type': 'Organization', 'name': 'Entrepreneur', 'logo': {'@type': 'ImageObject', 'url': 'https://assets.entrepreneur.com/static/20240220061344-entrepreneur-logo-black.svg'}, 'sameAs': ['https://www.facebook.com/entrepreneur', 'https://x.com/entrepreneur', 'https://www.linkedin.com/company/entrepreneur-media', 'https://www.youtube.com/user/EntrepreneurOnline', 'https://www.instagram.com/entrepreneur/', 'https://www.tiktok.com/@entrepreneur', 'https://story.snapchat.com/p/79f50f16-1715-45da-9dd4-842c96d79d05/2407079582115840', 'https://www.entrepreneur.com/latest.rss']}","{'@type': 'WebPage', '@id': 'https://www.entrepreneur.com/science-technology/why-legal-professionals-must-adapt-to-ai-or-risk-being-left/441751'}",2023-01-11T18:30:00+00:00,,2023-01-11T18:30:00+00:00,,"['https://assets.entrepreneur.com/content/3x2/2000/1673037898-GettyImages-1218285130.jpg?format=pjeg&auto=webp&crop=1:1', 'https://assets.entrepreneur.com/content/3x2/2000/1673037898-GettyImages-1218285130.jpg?format=pjeg&auto=webp&crop=4:3', 'https://assets.entrepreneur.com/content/3x2/2000/1673037898-GettyImages-1218285130.jpg?format=pjeg&auto=webp&crop=16:9']","{'@type': 'Person', 'name': 'Roland Polzin', 'image': 'https://assets.entrepreneur.com/content/1x1/300/1666152615-Portrait4.jpg', 'sameAs': ['https://www.facebook.com/RolandPolzin', 'https://x.com/PolzinRoland', 'https://www.linkedin.com/in/rolandpolzin/', 'https://www.instagram.com/rolandpolzin', 'https://www.youtube.com/@wingassistant', 'https://www.wingassistant.com/'], 'description': 'As a former German Army officer, I made the unusual decision to become a tech entrepreneur in Silicon Valley and found Wing. My background provides me with a unique perspective on leadership, decision-making, and change management, and I hope to help others drive change and progress for the better.', 'worksFor': 'Wing Assistant', 'jobTitle': 'Co-Founder &amp; CMO', 'url': 'https://www.entrepreneur.com/author/roland-polzin'}",The Rise of AI: Why Legal Professionals Must Adapt or Risk Being Left Behind,,,https://assets.entrepreneur.com/content/3x2/2000/1673037898-GettyImages-1218285130.jpg?format=pjeg&auto=webp&width=300&crop=1:1,,,,,,,,,,,,,,,,,,"{'@type': 'WebPageElement', 'isAccessibleForFree': True, 'cssSelector': '.gate-check'}",,,True,https://assets.entrepreneur.com/static/20240220061344-entrepreneur-logo-black.svg,,,,,,Science & Technology,"{'@type': 'Person', 'name': 'Micah Zimmerman', 'jobTitle': 'Entrepreneur Staff Editor', 'worksFor': 'Entreprenuer', 'description': '', 'url': 'https://www.entrepreneur.com/author/micah-zimmerman'}","[{'@type': 'ListItem', 'position': 0, 'name': 'Science & Technology', 'item': 'https://www.entrepreneur.com/science-technology'}]",
https://news.google.com/rss/articles/CBMifGh0dHBzOi8vd3d3Lm1pY2hpZ2FuZGFpbHkuY29tL29waW5pb24vY29sdW1ucy9hcnRpZmljaWFsLWludGVsbGlnZW5jZS10aGUtc2lsZW50LXBlcnBldHJhdG9yLW9mLXNvY2lhbC1pbmVxdWFsaXR5LWFsZ29yaXRobS_SAQA?oc=5,Are algorithms rejecting qualified job applicants? - The Michigan Daily,2023-01-11,The Michigan Daily,https://www.michigandaily.com,"As is the case with as many as 75% of businesses, the decision to reject your application was most likely made by an algorithm.",[],"As is the case with as many as 75% of businesses, the decision to reject your application was most likely made by an algorithm.",N/A,N/A,N/A,"

Imagine you are applying for a job. After filling out the necessary information on the company’s website, attaching your resume and writing a cover letter, you click “submit” and then wait to hear back. A few weeks later, you check your inbox to find an automated email response informing you that, after a thorough review of your application, you have not been selected for the position. Questions begin to flash through your head: What was wrong with my application? Was my cover letter the problem? Was I simply unqualified? However, there’s a strong likelihood that the company’s decision was not based on any of these factors. Rather, as is the case with as many as 75% of businesses, the decision to reject your application was most likely made by an algorithm.
As a growing number of businesses are seeking out ways to streamline hiring and reduce labor costs, Artificial Intelligence has taken the corporate world by storm. However, these benefits do not come without repercussions — the use of AI  in recruitment processes is slowly unfolding as a silent perpetrator of social inequality.
According to the World Economic Forum, the automation of hiring procedures is “stopping an estimated 27 million people from finding full-time work.” The candidates that are primarily filtered out by AI softwares are largely composed of demographically-marginalized individuals. A study by Harvard Business School identified previously incarcerated persons, veterans, refugees, immigrants and those with mental or physical disabilities as “hidden workers” who lose out on job opportunities in part because they are often unjustly screened out by hiring algorithms. Despite the fact that an astonishing 88% of these individuals were shown to be fully qualified for the position, they were nonetheless disqualified for not matching specific criteria.
You may find yourself wondering how all of this is possible. The idea that automated and allegedly unbiased machines are replicating human prejudices seems counterintuitive. However, the ultimate problem does not necessarily lie in the machines themselves, but rather within the information and datasets upon which they are built.
 
 

Data is rarely neutral — instead, it is often tarnished by historical instances of human injustice and partiality that plague information archives. As emphasized in an article by Brookings Press, “Algorithms, by their nature, do not question the human decisions underlying a dataset.” Rather, they are based on trends of reproduction that can cause them to replicate “the very sorts of human biases they are intended to replace.” The resulting algorithmic code has the potential to accept or reject a candidate’s resume based solely on the presence (or absence) of specific keywords. 
For instance, Amazon came under fire back in 2018 after its hiring algorithm was shown to disproportionately favor male candidates over female ones. Coded to replicate hiring patterns in the company over the previous 10 years, which had been overwhelmingly male, the algorithm was found to penalize any resumes that contained keywords such as “women’s.” Unable to mitigate these biases, Amazon was forced to scrap the project completely and temporarily revert to more traditional hiring methods. 
This bias has been found to impact not only the screening phases of the recruitment process but also the initial “sourcing” phase. During the sourcing phase, companies will attempt to attract certain candidates to the position through methods such as advertisements and online job postings. The specific websites and feeds selected to display these advertisements are often based on algorithmic predictions — specifically, ones that calculate a candidate’s likelihood of succeeding in the position based on their background information. 
In a study conducted by the Harvard Business Review, these technologies were found to be extremely biased, often targeting ads based on prejudiced and stereotypical information. The study found that cashier and secretary positions were targeted toward an audience that was disproportionately female (85%, to be exact) and taxi companies targeted audiences that were 75% Black. The study points out that “this is a quintessential case of an algorithm reproducing bias from the real world, without human intervention.” 
As is demonstrated in both of these instances, if left unchecked, the use of these algorithms threatens to exacerbate historical trends of discriminatory hiring practices in the United States. Fortunately, many efforts aimed at mitigating these issues have already begun to emerge. 
 
 

For instance, various pieces of legislation, such as a recent bill passed in New York City, seek to remedy these issues by requiring companies to conduct annual bias audits of any AI softwares and technologies used. Mainstream media is also starting to call attention to the issue, as demonstrated by  the recent release of the Netflix documentary “Coded Bias,” which exposes the discriminatory practices often contained in artificial intelligence.
These efforts aimed at awareness will continue to be imperative, as the risks of Artificial Intelligence present a unique danger — A type of danger that is silent and unseen, with its prejudice and partiality hidden in the depths of algorithms. 
Tate Moyer is an Opinion Columnist and can be reached at moyert@umich.edu.
 

Please consider donating to The Michigan Daily

$10
$25
$50
Other




Related articles
 


",https://schema.org,NewsArticle,http://www.michigandaily.com/opinion/artificial-intelligence-the-silent-perpetrator-of-social-inequality-algorithm/,"{'@type': 'Organization', 'name': 'The Michigan Daily', 'logo': 'https://www.michigandaily.com/wp-content/uploads/2021/03/cropped-TMDFullLogo.png'}","{'@type': 'WebPage', '@id': 'http://www.michigandaily.com/opinion/artificial-intelligence-the-silent-perpetrator-of-social-inequality-algorithm/'}",2023-01-12T00:38:11Z,2023-01-12T00:38:11Z,2023-01-12T19:28:20Z,,"{'@type': 'ImageObject', 'url': 'https://i0.wp.com/www.michigandaily.com/wp-content/uploads/2023/01/Tate-Moyer-1-by-Abby-Schreck.jpg?fit=1317%2C878&ssl=1'}","[{'@type': 'Person', 'name': 'Tate Moyer'}]",Artificial Intelligence: the silent perpetrator of social inequality,,,https://i0.wp.com/www.michigandaily.com/wp-content/uploads/2023/01/Tate-Moyer-1-by-Abby-Schreck.jpg?resize=300%2C300&ssl=1,"[{'@type': 'Article', '@id': 'https://www.michigandaily.com/opinion/columns/artificial-intelligence-the-silent-perpetrator-of-social-inequality-algorithm/#article', 'isPartOf': {'@id': 'https://www.michigandaily.com/opinion/columns/artificial-intelligence-the-silent-perpetrator-of-social-inequality-algorithm/'}, 'author': [{'@id': 'https://www.michigandaily.com/#/schema/person/1ab06b9ac352f870a90b712e0ee9146d'}], 'headline': 'Artificial Intelligence: the silent perpetrator of social inequality', 'datePublished': '2023-01-12T00:38:11+00:00', 'dateModified': '2023-01-12T19:28:20+00:00', 'mainEntityOfPage': {'@id': 'https://www.michigandaily.com/opinion/columns/artificial-intelligence-the-silent-perpetrator-of-social-inequality-algorithm/'}, 'wordCount': 841, 'publisher': {'@id': 'https://www.michigandaily.com/#organization'}, 'image': {'@id': 'https://www.michigandaily.com/opinion/columns/artificial-intelligence-the-silent-perpetrator-of-social-inequality-algorithm/#primaryimage'}, 'thumbnailUrl': 'https://i0.wp.com/www.michigandaily.com/wp-content/uploads/2023/01/Tate-Moyer-1-by-Abby-Schreck.jpg?fit=1317%2C878&ssl=1', 'articleSection': ['Columns', 'Opinion'], 'inLanguage': 'en-US'}, {'@type': 'WebPage', '@id': 'https://www.michigandaily.com/opinion/columns/artificial-intelligence-the-silent-perpetrator-of-social-inequality-algorithm/', 'url': 'https://www.michigandaily.com/opinion/columns/artificial-intelligence-the-silent-perpetrator-of-social-inequality-algorithm/', 'name': 'Are algorithms rejecting qualified job applicants?', 'isPartOf': {'@id': 'https://www.michigandaily.com/#website'}, 'primaryImageOfPage': {'@id': 'https://www.michigandaily.com/opinion/columns/artificial-intelligence-the-silent-perpetrator-of-social-inequality-algorithm/#primaryimage'}, 'image': {'@id': 'https://www.michigandaily.com/opinion/columns/artificial-intelligence-the-silent-perpetrator-of-social-inequality-algorithm/#primaryimage'}, 'thumbnailUrl': 'https://i0.wp.com/www.michigandaily.com/wp-content/uploads/2023/01/Tate-Moyer-1-by-Abby-Schreck.jpg?fit=1317%2C878&ssl=1', 'datePublished': '2023-01-12T00:38:11+00:00', 'dateModified': '2023-01-12T19:28:20+00:00', 'description': 'As is the case with as many as 75% of businesses, the decision to reject your application was most likely made by an algorithm.', 'breadcrumb': {'@id': 'https://www.michigandaily.com/opinion/columns/artificial-intelligence-the-silent-perpetrator-of-social-inequality-algorithm/#breadcrumb'}, 'inLanguage': 'en-US', 'potentialAction': [{'@type': 'ReadAction', 'target': ['https://www.michigandaily.com/opinion/columns/artificial-intelligence-the-silent-perpetrator-of-social-inequality-algorithm/']}]}, {'@type': 'ImageObject', 'inLanguage': 'en-US', '@id': 'https://www.michigandaily.com/opinion/columns/artificial-intelligence-the-silent-perpetrator-of-social-inequality-algorithm/#primaryimage', 'url': 'https://i0.wp.com/www.michigandaily.com/wp-content/uploads/2023/01/Tate-Moyer-1-by-Abby-Schreck.jpg?fit=1317%2C878&ssl=1', 'contentUrl': 'https://i0.wp.com/www.michigandaily.com/wp-content/uploads/2023/01/Tate-Moyer-1-by-Abby-Schreck.jpg?fit=1317%2C878&ssl=1', 'width': 1317, 'height': 878, 'caption': 'Design by Abby Schreck. Buy this photo.'}, {'@type': 'BreadcrumbList', '@id': 'https://www.michigandaily.com/opinion/columns/artificial-intelligence-the-silent-perpetrator-of-social-inequality-algorithm/#breadcrumb', 'itemListElement': [{'@type': 'ListItem', 'position': 1, 'name': 'Home', 'item': 'https://www.michigandaily.com/'}, {'@type': 'ListItem', 'position': 2, 'name': 'Opinion', 'item': 'https://www.michigandaily.com/opinion/'}, {'@type': 'ListItem', 'position': 3, 'name': 'Artificial Intelligence: the silent perpetrator of social inequality'}]}, {'@type': 'WebSite', '@id': 'https://www.michigandaily.com/#website', 'url': 'https://www.michigandaily.com/', 'name': 'The Michigan Daily', 'description': 'One hundred and thirty-three years of editorial freedom', 'publisher': {'@id': 'https://www.michigandaily.com/#organization'}, 'potentialAction': [{'@type': 'SearchAction', 'target': {'@type': 'EntryPoint', 'urlTemplate': 'https://www.michigandaily.com/?s={search_term_string}'}, 'query-input': 'required name=search_term_string'}], 'inLanguage': 'en-US'}, {'@type': 'Organization', '@id': 'https://www.michigandaily.com/#organization', 'name': 'The Michigan Daily', 'url': 'https://www.michigandaily.com/', 'logo': {'@type': 'ImageObject', 'inLanguage': 'en-US', '@id': 'https://www.michigandaily.com/#/schema/logo/image/', 'url': 'https://i0.wp.com/www.michigandaily.com/wp-content/uploads/2021/03/cropped-TMDFullLogo.png?fit=2854%2C388&ssl=1', 'contentUrl': 'https://i0.wp.com/www.michigandaily.com/wp-content/uploads/2021/03/cropped-TMDFullLogo.png?fit=2854%2C388&ssl=1', 'width': 2854, 'height': 388, 'caption': 'The Michigan Daily'}, 'image': {'@id': 'https://www.michigandaily.com/#/schema/logo/image/'}, 'sameAs': ['https://www.facebook.com/michigandaily', 'https://x.com/michigandaily', 'https://www.instagram.com/michigandaily/', 'https://www.youtube.com/user/michdailymultimedia']}, {'@type': 'Person', '@id': 'https://www.michigandaily.com/#/schema/person/1ab06b9ac352f870a90b712e0ee9146d', 'name': 'Tate Moyer', 'url': 'https://www.michigandaily.com/author/moyertumich-edu/'}]",,,,,,,,,,,,,,,,,,,,,,,,,,,Columns,,,['Tate Moyer']
https://news.google.com/rss/articles/CBMitQFodHRwczovL3d3dy5wcm5ld3N3aXJlLmNvbS9uZXdzLXJlbGVhc2VzL2JlYXV0aWZ1bGFpLWxhdW5jaGVzLWRlc2lnbmVyYm90LXRvLWF1dG9tYXRpY2FsbHktY3JlYXRlLXJpY2gtcHJlc2VudGF0aW9ucy1hYm91dC1hbnl0aGluZy1hbmQtZXZlcnl0aGluZy11c2luZy1nZW5lcmF0aXZlLWFpLTMwMTcxODc2OS5odG1s0gEA?oc=5,Beautiful.ai Launches DesignerBot to Automatically Create Rich Presentations About Anything and Everything Using ... - PR Newswire,2023-01-11,PR Newswire,https://www.prnewswire.com,"/PRNewswire/ -- Beautiful.ai, the presentation platform that enables anyone to build beautiful presentations, announced today the launch of DesignerBot, a...",Beautiful.ai,"/PRNewswire/ -- Beautiful.ai, the presentation platform that enables anyone to build beautiful presentations, announced today the launch of DesignerBot, a...","/PRNewswire/ -- Beautiful.ai, the presentation platform that enables anyone to build beautiful presentations, announced today the launch of DesignerBot, a...",N/A,N/A,"






Beautiful.ai Launches DesignerBot to Automatically Create Rich Presentations About Anything and Everything Using Generative AI












News provided by

Beautiful.ai



Jan 11, 2023, 09:01 ET



Share this article









 














 









Share toX





 








Share this article


















Share toX


















AI Software Generates Full Business-Ready Presentations With One Text PromptSAN FRANCISCO, Jan. 11, 2023 /PRNewswire/ -- Beautiful.ai, the presentation platform that enables anyone to build beautiful presentations, announced today the launch of DesignerBot, a generative AI designed to automate presentation creation and custom image generation.


Continue Reading
















Beautiful.ai Launches DesignerBot to Automatically Create Rich Presentations About Anything and Everything Using Generative AI


















Utilizing cutting-edge AI technology from OpenAI, Beautiful.ai's DesignerBot generates fully realized presentations, including appropriate text, layouts, photos, icons and design, based on one simple text prompt. The AI automatically creates a wide variety of content and slides for business, school and personal use, including text, lists, icons and charts that can be used for pitch decks, sales proposals, marketing presentations and even abstract concepts - all from a short description provided by the user.

""Instead of wondering where to start on a presentation, users can simply ask DesignerBot to 'Design a pitch deck for a mobile app that sells concert tickets' or 'Create a marketing plan for a social media rollout' or 'Build an effective sales pitch for my software product',"" said Mitch Grasso, founder and chief technology officer of Beautiful.ai. ""From this one prompt, 10-20 slides are generated and ready to present or make further edits. This is the power of generative AI and the game-changing experience it enables by cutting down the time users spend designing their story and giving them more time to tell it.""
Once DesignerBot has built a custom presentation, Beautiful.ai's powerful SmartSlides technology can be used to quickly edit slides by adding or removing content and automatically adapting, resizing and laying out the slides, all while preserving and maintaining corporate brand guidelines. The addition of DesignerBot provides a truly automated zero-to-finish experience to Beautiful.ai's presentation ecosystem - eliminating hours of frustrating effort to design and craft a beautiful presentation narrative.""Starting from a blank canvas and figuring out how to visualize your story as a series of compelling slides has always been the biggest challenge with traditional presentation software - especially for people without design skills,"" said Grasso. ""Beautiful.ai's mission from day one has been to use assistive AI technology to create software that understands the rules of great design and provides knowledge workers with an entire presentation ecosystem that enables them to create better content, faster and smarter. With the addition of DesignerBot, we can not only offer users an amazing slide design experience, but assist them in creating both a story arc and the actual content of each slide.""In addition to creating presentations from scratch, DesignerBot's generative AI is also available as part of Beautiful.ai's extensive photo library, allowing users to generate unique images and photos if they are unable to find the appropriate imagery among the millions of free stock photos available in Beautful.ai. Working with OpenAI's DALL-E, DesignerBot generates a completely new and unique image from a simple description - giving users access to that elusive photo of 'a teddy bear on a skateboard in Times Square at night' or 'an astronaut holding flowers in the style of Andy Warhol' that would make the perfect addition to a deck.""I love this! Beautiful.ai just got even better and faster,"" said Danny Ellis, CEO of Skypecs and Beautiful.ai customer. ""This unlocks so much for our team in the 'getting started' phase of presentations. We use Beautiful.ai across our team as a full presentation solution because we love their brand controls and asset libraries, and the powerful addition of artificial intelligence will give the team's copy, images, and charts a head start. This is going to change the way our team builds presentations!""Beautiful.ai was built from the ground up as a collaborative solution to help organizations control the entire lifecycle of how presentations are built, shared and reused across teams, and presentations can be easily imported or exported to different presentation formats, including PowerPoint, Google Slides and PDF.Beautiful.ai believes presentations today should be memorable and the storytelling in them should be painless and empowering. Through automated smart content, the Beautiful.ai platform gives everyone – including non-designers – a tool with a built-in designer. More than one million users across 205 countries and 36,000 companies currently use Beautiful.ai's product, including trusted brands such as CVENT, Rakuten and the Phoenix Suns.To learn more, visit Beautiful.ai.About Beautiful.aiBeautiful.ai is a San Francisco-based presentation platform that uses design automation and artificial intelligence to enable teams to work faster and produce better results. The company's products are built on its SmartSlide technology, which applies the rules and best practices of good design, in real-time, so teams can work smart, work fast, and work beautiful.Media Contact: Tassi Keith, 1-308-539-1883, tassi@breakpointprc.comSOURCE Beautiful.ai







×
Modal title




",https://schema.org,NewsArticle,,,{'@id': 'https://www.prnewswire.com/news-releases/beautifulai-launches-designerbot-to-automatically-create-rich-presentations-about-anything-and-everything-using-generative-ai-301718769.html'},2023-01-11T09:01:00-05:00,,2023-01-11T09:01:00-05:00,,['https://mma.prnewswire.com/media/1981271/DesignerBot_Demo.mp4?p=medium'],,Beautiful.ai Launches DesignerBot to Automatically Create Rich Presentations About Anything and Everything Using Generative AI,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
https://news.google.com/rss/articles/CBMiXmh0dHBzOi8vd3d3LndlZm9ydW0ub3JnL2FnZW5kYS8yMDIzLzAxLzQtd2F5cy1hcnRpZmljaWFsLWludGVsbGlnZW5jZS1tYW51ZmFjdHVyaW5nLWRhdm9zMjAyMy_SAQA?oc=5,4 ways artificial intelligence could transform manufacturing | World Economic Forum - World Economic Forum,2023-01-09,World Economic Forum,https://www.weforum.org,Manufacturing is facing challenges from sustainability to geopolitical instability. A new initiative aims to show how artificial intelligence could help,"World Economic Forum,WEF,Davos,Klaus Schwab, globalization, globalization4.0, globalization4, globalization four, what does globalization mean?",Manufacturing is facing challenges from sustainability to geopolitical instability. A new initiative aims to show how artificial intelligence could help,Manufacturing is facing challenges from sustainability to geopolitical instability. A new initiative aims to show how artificial intelligence could help,N/A,N/A,"Forum Institutional4 ways artificial intelligence could transform manufacturingJan 9, 2023Artificial intelligence could help the manufacturing sector deal with pressures including sustainability and geopolitical instabilityImage: Kateryna Babaieva for PexelsFrancisco BettiHead, Global Industries Team; Member of the Executive Committee, World Economic ForumDaniel KuepperManaging Director & Senior Partner, BCG (Boston Consulting Group)Share:Our ImpactWhat's the World Economic Forum doing to accelerate action on Forum Institutional?The Big PictureExplore and monitor how Advanced Manufacturing is affecting economies, industries and global issuesCrowdsource InnovationGet involved with our crowdsourced digital platform to deliver impact at scaleStay up to date:Davos AgendaFollowThis article is part of: World Economic Forum Annual MeetingListen to the article9 min listenThe manufacturing sector is facing many challenges, including the need for sustainability, a skills shortage and geopolitical instability.Artificial intelligence (AI) can help by improving productivity and efficiency, increasing flexibility and augmenting the workforce.A new global initiative aims to raise awareness of these opportunities.The world of industrial operations is changing, and manufacturing companies are under considerable pressure. Challenges include rising economic pressure, the sustainability imperative, volatile resource prices and supply chain disruptions as well as increasing capability challenges and talent shortage.A continuous improvement in production efficiency has always been considered one of the key prerequisites to ensure the competitiveness of globally operating companies. This requirement has not changed. However, the traditional levers for increasing productivity are now less effective. New challenges have emerged, including the COVID pandemic and increased geopolitical uncertainty. These have led to a rapid increase in the importance of resilience and flexibility of entire supply chains. Many industrial companies are also facing a skills shortage; this will affect 90% of organizations by 2025, inhibiting production capacity.Have you read?From dinosaur footprints to US-EU data: The latest in artificial intelligenceHow to follow Davos 2023At the same time, climate change and the associated efforts to meet the 1.5-degree target of the Paris Agreement mean a necessary emphasis on sustainability and emission reduction. This has a huge impact on the organizational goals of manufacturing companies. The role of AI in manufacturing industryThe expanding role of data and advanced manufacturing technologies opens up new opportunities to address the challenges facing the sector. However, while many companies have piloted this over the past decade, most have failed to scale these solutions to achieve the desired value. They have often used data to create transparency on, for example, production processes or to forecast future events based on historical data; few companies have invested in self-controlled systems based on AI. This has the potential to unlock far more value.In the context of industrial operations, AI is used to enable systems and machines to perform tasks in a smart way. There are four principal ways in which AI can help:1. Optimizing productivityBusinesses can use AI to increase throughput and yield and to reduce conversion costs. Possible applications include: predictive maintenance to increase equipment efficiency and effectiveness; self-optimization of machine and process parameters; machine vision for automated inspection to improve product quality; and autonomous mobile robots (AMRs) for autonomous in-plant transportation. These applications can lead to significant revenue increases and two-digit conversion cost reductions.2. Improving sustainabilityAI can also help to make operations more sustainable by reducing emissions. For instance, AI-based applications can be used to predict energy consumption and emissions for the future (e.g. the next shift), and to analyze and identify equipment responsible for excess energy consumption and emissions. AI can also reduce emissions by determining, for example, the optimal process parameters or production sequence within production.DiscoverHow is the World Economic Forum ensuring the responsible use of technology? Show moreThe Top 10 Emerging Technologies of 2023 report outlined the technologies poised to positively impact society in the next few years, from health technology to AI to sustainable computing. The World Economic Forum’s Centre for the Fourth Industrial Revolution is driving responsible technology governance, enabling industry transformation, addressing planetary health, and promoting equity and inclusion.Learn more about our impact: Digital inclusion: Our EDISON Alliance is mobilizing leaders from across sectors to accelerate digital inclusion, having positively impacted the lives of 454 million people through the activation of 250 initiatives across 90 countries.AI in developing economies: Our Centre for the Fourth Industrial Revolution Rwanda is promoting the adoption of new technologies in the country, enabling over 4,000 daily health consultations using AI.Innovative healthcare: Our Medicine from the Sky initiative is using drones to deliver medicine to remote areas in India, completing over 950 successful drone flights.AI for agriculture: We are working with the Government of India to scale up agricultural technology in the country, helping more than 7,000 farmers monitor the health of their crops and soil using AI.Accept our marketing cookies to access this content.These cookies are currently disabled in your browser.Accept cookiesWant to know more about our centre’s impact or get involved? Contact us.3. Increasing flexibilityIn the face of ongoing supply chain disruptions, AI can increase the agility of operations and mitigate the impact of external shocks. For instance, AI can offer advanced demand forecasting, improved network optimization or advanced production planning/scheduling.4. Augmenting the workforceFinally, AI can help to address manufacturers' capability challenges and talent shortages. On the one hand, AI can allow businesses to automate monotonous, repetitive tasks, so that the workforce can put the focus on other more value-adding activities. On the other hand, AI can augment and support employees in their daily work; for instance, in the context of decision-making processes or through human-robot collaboration.We have still to fully grasp the possibilities for applying AI in the industrial context. Currently, the biggest hurdle for many manufacturers is to scale effective AI pilot applications in order to fully benefit from their impact. The scaling difficulties arise from different sources and include a missing overarching strategy; a lack of AI capabilities and skills; limited availability, quality, or use of data; and, most importantly, a set of general guidelines on how to manage the implementation of AI at scale.“AI should not be a trial and error – it should follow a systematic approach”— Jay Lee, Ohio Eminent Scholar and Founding Director of Industrial AI Center, University of CincinnatiSupporting manufacturing companies on their AI journeyTo address the challenges described and to support manufacturers on their journey towards capturing the full potential of AI, the World Economic Forum in collaboration with the Boston Consulting Group (BCG) has recently launched the new global initiative AI-powered Industrial Operations. The aims are: to raise awareness on the opportunity offered by AI applications; to outline the most-promising AI applications and required implementation prerequisites; to develop an educational guidebook on how to implement and scale AI in industrial operations; and to demonstrate the impact of AI through the incubation of pilots across the network of Centers for the Fourth Industrial Revolution Affiliates such as these in Turkey and the US.The World Economic Forum invites manufacturing companies from all industries to join the global community around this initiative and thereby accelerate their transformation towards AI-powered industrial operations.Don't miss any update on Davos AgendaSign up for free and access the latest publications and insights across various topics.Sign up for freeLicense and RepublishingWorld Economic Forum articles may be republished in accordance with the Creative Commons Attribution-NonCommercial-NoDerivatives 4.0 International Public License, and in accordance with our Terms of Use.The views expressed in this article are those of the author alone and not the World Economic Forum.Related topics:Forum InstitutionalManufacturing and Value ChainsEmerging TechnologiesShare:Global AgendaThe Agenda WeeklyA weekly update of the most important issues driving the global agendaSubscribe todayYou can unsubscribe at any time using the link in our emails. For more details, review our privacy policy.More on Forum InstitutionalSee allAMNC24: Five things to know about the 'Summer Davos' in ChinaGayle MarkovitzJune 28, 20243:49These 5 facts about climate change need more attention, say expertsAMNC 2024: What to know about Day 3Gayle MarkovitzJune 27, 20242:185 leaders on harnessing the potential of AI responsiblyAddress by China Premier Li Qiang to the Annual Meeting of New Champions 2024World Economic ForumJune 26, 2024AMNC 2024: What to know about Day 2Gayle MarkovitzJune 26, 2024",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
https://news.google.com/rss/articles/CBMiYmh0dHBzOi8vdmVudHVyZWJlYXQuY29tL2FpL2hvdy1jaGF0Z3B0LWluLW1pY3Jvc29mdC1vZmZpY2UtY291bGQtY2hhbmdlLXRoZS13b3JrcGxhY2UtdGhlLWFpLWJlYXQv0gEA?oc=5,How ChatGPT in Microsoft Office could change the workplace | The AI Beat - VentureBeat,2023-01-09,VentureBeat,https://venturebeat.com,"Microsoft is reportedly planning to add OpenAI's ChatGPT to Word, Outlook and PowerPoint. How would these apps-on-steroids change how we work?",N/A,"Microsoft is reportedly planning to add OpenAI's ChatGPT to Word, Outlook and PowerPoint. How would these apps-on-steroids change how we work?",N/A,N/A,N/A,"


Join our daily and weekly newsletters for the latest updates and exclusive content on industry-leading AI coverage. Learn More



[Updated by Editor 1/9, 7:19 pm PT] Over the weekend, The Information reported that Microsoft is looking to add OpenAI’s chatbot technology — currently ChatGPT, soon to be GPT-4 — to its Office suite of productivity technologies, including Word, Outlook and PowerPoint. And late today, Semafor reported that Microsoft, which invested $1 billion in OpenAI in 2019, is in talks to invest another $10 billion in the company. 
>>Follow VentureBeat’s ongoing ChatGPT coverage<<
1/7Synergy in Synthesis: Forging the Future of AI with Cross-Functional ExpertiseRead More



90.8K



506






Video Player is loading.Play VideoUnmuteDuration 0:00/Current Time 0:00Playback Speed Settings1xLoaded: 0%0:00

Remaining Time -0:00 FullscreenPlayRewind 10 SecondsUp NextThis is a modal window.Beginning of dialog window. Escape will cancel and close the window.TextColorWhiteBlackRedGreenBlueYellowMagentaCyanTransparencyOpaqueSemi-TransparentBackgroundColorBlackWhiteRedGreenBlueYellowMagentaCyanTransparencyOpaqueSemi-TransparentTransparentWindowColorBlackWhiteRedGreenBlueYellowMagentaCyanTransparencyTransparentSemi-TransparentOpaqueFont Size50%75%100%125%150%175%200%300%400%Text Edge StyleNoneRaisedDepressedUniformDropshadowFont FamilyProportional Sans-SerifMonospace Sans-SerifProportional SerifMonospace SerifCasualScriptSmall CapsReset restore all settings to the default valuesDoneClose Modal DialogEnd of dialog window.SharePlayback Speed0.25x0.5x1x Normal1.5x2xReplay the list

TOP ARTICLES
























Powered by AnyClip Privacy PolicyKeyboard Shortcuts



Synergy in Synthesis: Forging the Future of AI with Cross-Functional Expertise



The stream of Microsoft news made me wonder: How would these apps-on-steroids, used by billions of companies globally, change how we work? Especially once Google gets fully in the game, integrating its own generative AI capabilities into Google Workspace? Will AI become as mundane in our day-to-day work lives as the humble spreadsheet? 
Far more than a new Clippy 
News of the plans for Office came only a few days after word spread that Microsoft was planning to embed ChatGPT into its search engine Bing. But talk of ChatGPT being integrated with Word led those of an earlier tech generation to immediately giggle. Why? One word: Clippy. 
Clippy, Microsoft’s user interface agent that came bundled with Microsoft Office in 1997 and was personally launched by Bill Gates, was a hopped-up, big-eyed paperclip who popped up to say things like, “It looks like you’re writing a letter. Would you like help?” 
Clippy was mostly loathed and mocked for his invasive pop-ups. Time even named Clippy one of the worst inventions of all time. Clippy had disappeared entirely by 2007, although he was resurrected as a cultural icon as a retro sticker pack in Teams in 2021. 
ChatGPT, of course, would be far more than a new Clippy — it could potentially do everything from generate text based on simple natural language prompts and suggest responses to emails to analyze data in Excel and translate text. 
Tech investor Puneet Kumar called the possibility “crazy powerful” in a tweet, adding that it would “further deepen” Microsoft’s moats in enterprise office tech: 


ChatGPT and similar models not ready for prime time
The Information pointed out that Microsoft Word already uses in-house AI tools, including Turing’s Smart Find feature and At a Glance, which summarizes Word documents. And it has “already quietly incorporated GPT into Word in minor ways,” including in its autocomplete feature. 
But to implement OpenAI’s ChatGPT or, soon enough, GPT-4, there will be plenty of hurdles to overcome. 
For one, ChatGPT has a serious accuracy problem, one that is exacerbated by its tendency to sound plausible even when it is dead-wrong. Even OpenAI CEO Sam Altman has admitted the risks. That makes corporate document creation or advanced workplace integration a no-go at the moment. advertisement
Privacy is also an obstacle. How would Microsoft preserve the privacy of corporate data? It’s hard to imagine a large law firm or financial services company that uses Microsoft Office all day long getting help from ChatGPT right now. 
Office work will likely change for good
Still, the opportunity to significantly power-charge the day-to-day text output of the average enterprise — emails, presentations, reports — is too tantalizing to ignore. As some guy named Kevin tweeted: 


But it may be some time before it’s clear both how Microsoft and Google can make generative AI tools work for business at scale, as well as how enterprises can deal with what employees create. advertisement
Forrester analyst Rowan Curran said there are “a lot of open questions about what guardrails and controls enterprises put both on how these tools are allowed to be adopted, and how they can be used once they are adopted.” 
For example, he told VentureBeat by email, “If I have a text generator on my phone that I used to draft a work email or outline a blog post and then I publish that as part of my job – does my employer need to be concerned about, or at least aware of that?” 
So much about our digital office life — think PDFs, spreadsheets, smartphones, cloud, digital signatures — have become work ho-hums over the past two decades. Whether it’s ChatGPT in 2023 or not, it seems likely that advances in generative AI are on the path to transforming the workplace as we know it. 



VB Daily
Stay in the know! Get the latest news in your inbox daily




 Subscribe

By subscribing, you agree to VentureBeat's Terms of Service.

					Thanks for subscribing. Check out more VB newsletters here.
				
An error occured.


 


Find Your Place In The World BY Amply





 
Salesforce Solution Architect
Booz Allen
Melbourne
$75,600 - $172,000 a year
See Job





 
Senior Developer Advocate
Ripple
London
See Job





 
AI Content Writer
DataAnnotation
San Diego
$20 - $25 an hour
See Job





 
Senior Accounts Receivable Analyst
The MITRE Corporation
McLean
See Job




            Search More Roles
          



",http://schema.org,NewsArticle,,"{'@type': 'Organization', 'logo': {'@type': 'ImageObject', 'url': 'https://vbstatic.co/brand/img/logos/VB_Extended_Logo_60H.png', 'width': 416, 'height': 60}, 'name': 'VentureBeat'}",https://venturebeat.com/ai/how-chatgpt-in-microsoft-office-could-change-the-workplace-the-ai-beat/,2023-01-09T15:51:19+00:00,,2023-02-23T17:16:34+00:00,,"{'@type': 'ImageObject', 'url': 'https://venturebeat.com/wp-content/uploads/2023/01/Untitled-design-5.png', 'width': 1024, 'height': 576}","{'@type': 'Person', 'name': 'Sharon Goldman'}",How ChatGPT in Microsoft Office could change the workplace | The AI Beat,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
https://news.google.com/rss/articles/CBMiX2h0dHBzOi8vd3d3LnBicy5vcmcvbmV3c2hvdXIvc2hvdy9hZHZhbmNlcy1pbi1hcnRpZmljaWFsLWludGVsbGlnZW5jZS1yYWlzZS1uZXctZXRoaWNzLWNvbmNlcm5z0gFjaHR0cHM6Ly93d3cucGJzLm9yZy9uZXdzaG91ci9hbXAvc2hvdy9hZHZhbmNlcy1pbi1hcnRpZmljaWFsLWludGVsbGlnZW5jZS1yYWlzZS1uZXctZXRoaWNzLWNvbmNlcm5z?oc=5,Advances in artificial intelligence raise new ethics concerns - PBS NewsHour,2023-01-10,PBS NewsHour,https://www.pbs.org,"In recent months, new artificial intelligence tools have garnered attention, and concern, over their ability to produce original work. The creations range from college-level essays to computer code and works of art. As Stephanie Sy reports, this technology could change how we live and work in profound ways.",N/A,"In recent months, new artificial intelligence tools have garnered attention, and concern, over their ability to produce original work. The creations range from college-level essays to computer code and works of art. As Stephanie Sy reports, this technology could change how we live and work in profound ways.","In recent months, new artificial intelligence tools have garnered attention, and concern, over their ability to produce original work. The creations range from college-level essays to computer code and works of art. As Stephanie Sy reports, this technology could change how we live and work in profound ways.",Science,N/A,"






Full Episode










Sunday, Jul 21


",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
https://news.google.com/rss/articles/CBMiU2h0dHBzOi8vd3d3LmZpZXJjZS1uZXR3b3JrLmNvbS90ZWNobm9sb2d5L3ByZXBhcmluZy10b2RheXMtY29sbGVnZS1zdHVkZW50cy13b3JrLWFp0gEA?oc=5,Preparing Today's College Students to Work with AI - Fierce Network,2023-01-11,Fierce Network,https://www.fierce-network.com,"Just like the wheel, the internet, and the smartphone transformed the world, artificial intelligence (AI) has the potential to revolutionize our personal and professional lives, and it all begins i","Mark McNasby,Ivy.ai,artificial intelligence (AI),chatbots,Wireless,Fierce Network Homepage,Wireless","Just like the wheel, the internet, and the smartphone transformed the world, artificial intelligence (AI) has the potential to revolutionize our personal and professional lives, and it all begins i | Just like the wheel, the internet, and the smartphone transformed the world, artificial intelligence (AI) has the potential to revolutionize our personal and professional lives, and it all begins in the college classroom.","Just like the wheel, the internet, and the smartphone transformed the world, artificial intelligence (AI) has the potential to revolutionize our personal and professional lives, and it all begins i | Just like the wheel, the internet, and the smartphone transformed the world, artificial intelligence (AI) has the potential to revolutionize our personal and professional lives, and it all begins in the college classroom.","Wireless,Fierce Network Homepage",N/A,"

































Fierce Network


Broadband Nation Expo


Broadband Nation


Fierce Technology Events






Advertise


About Us








 

 





























 










Broadband


Cloud


AI


Wireless






Resources



Fierce Events


Research


Podcasts


Surveys


Webinars


Whitepapers


Broadband Nation Learning Center



 Events 

Subscribe
















 





























Broadband


Cloud


AI


Wireless






Resources



Fierce Events


Research


Podcasts


Surveys


Webinars


Whitepapers


Broadband Nation Learning Center



 Events 

Subscribe










Fierce Network


Broadband Nation Expo


Broadband Nation


Fierce Technology Events






Advertise


About Us








 

 





















Brought to you by:


















































Wireless






Preparing Today’s College Students to Work with AI







                        By                                                   
Mark McNasby,





Jan 11, 2023 8:00am






Mark McNasby
Ivy.ai
artificial intelligence (AI)
chatbots




















 

 (Getty Images)


Just like the wheel, the internet, and the smartphone transformed the world, artificial intelligence (AI) has the potential to revolutionize our personal and professional lives, and it all begins in the college classroom.Although AI has been around since the 1950s, it’s just beginning to truly take off. According to one recent report, the global AI market, which brought in $388 billion in 2022, is expected to generate a whopping $1.4 trillion by 2029.This tremendous growth points to a future that is largely AI-driven. To help prepare students for this future, universities and colleges should do everything they can to introduce them to AI and help them understand the jobs available in this exciting, rapidly growing field.AI: It’s Not Just RobotsWhen many people hear the term “artificial intelligence,” they think about robots. The fact of the matter is that AI has many everyday applications. In fact, most of us use AI daily. If you’ve ever seen Google autocomplete a search for you or had a conversation with Siri, that’s AI.Another common AI application is chatbot technology. If you’ve ever interacted with a company online via chat—for example, connecting with Amazon to discuss a defective item you received—chances are you engaged with an AI-powered chatbot, at least to kick off the conversation.Increasingly, AI is being used to automate repetitive tasks in our everyday lives. When universities and institutions of higher learning invest in chatbot technology, they can do the same while also helping students think differently about what AI is.How AI Can Improve the Student ExperienceBy investing in chatbot technology, colleges and universities can introduce students to a broader scope of AI solutions out of the gate. Instead of thinking that AI is an esoteric concept that only the smartest engineers and data scientists in the world understand, chatbots help students understand what AI is and where it fits into society on a deeper, more accessible level.Colleges and universities that invest in chatbots ensure that their students interface with cutting-edge technology, perhaps even from the first moment a prospective student interacts with the institution. When students are thinking about enrolling in a certain college or university, they will undoubtedly have questions. With built-in natural language processing, chatbots interpret what students are asking using speech recognition, semantics, and syntax—similar to how humans learn languages.In addition to providing experience interacting with AI, chatbots also empower students to find information at their leisure. Instead of waiting on hold just to find out whether their application has been received or figuring out where the library is, students can pull up this information via a chatbot when it’s convenient, 24/7/365.Plus, chatbot technology frees staff from having to field repetitive questions over and over again. As a result, employees’ lives become easier, and they have more time to focus on improving the student experience in other ways.What Skills Do Students Need to Work in AI?The benefits of AI technology speak for themselves. Even so, many students might think that they lack the technical know-how needed to land a career in artificial intelligence—which couldn’t be further from the truth.With each passing day, artificial intelligence is becoming more accessible. Thanks to no-code and low-code development tools, this trend will only accelerate over time. In fact, people can build AI-powered chatbots today without any coding experience!Even if a student isn’t keen on developing AI solutions themselves, there are still all kinds of careers involving AI that they could pursue, regardless of their interests. AI companies need marketers, sales teams, finance professionals, business development reps, and HR departments, after all.While possessing advanced software development and data science skills can certainly help students land technologically oriented positions in the field of AI, here are more common traits students need to excel as AI professionals.Critical Thinking Mindset: To succeed in a career involving AI, students need to have critical thinking mindsets and the ability to think outside the box. This trait can help them identify new use cases for AI and also help their organizations determine how to apply AI to their workflows to operate more efficiently.Curiosity: Ultimately, the best AI practitioners stay curious. Students, particularly those without engineering backgrounds, might see something in AI and not be able to understand it out of the gate. That’s perfectly fine as long as they have the curiosity to try to understand it.An Open Mind: Whatever they do, students shouldn’t limit themselves to thinking about AI in one way (e.g., robots!). Instead, they need to keep open minds and understand that, whatever things are like today in a certain field, there’s a good chance AI will eventually make a huge impact on the industry. By keeping an open mind, understanding that AI is still in its beginning stages, and knowing that AI will likely be used across all business functions, students can better prepare for working with AI in the future.Strong Communication Skills: As far as technology goes, AI is complex. That doesn’t necessarily mean students need to know the ins and outs of exactly how the technology works. They do need to possess strong communication skills, however, so they can explain a complex topic in a way that the average person understands.Are Your Students Prepared for an AI-Driven Future?By all indications, AI technology represents the future. If educators want to ensure their students are best prepared to enter the workforce, they need to do everything they can to familiarize students with AI and help them think about it realistically.By investing in AI-powered chatbot technology and helping students develop the skills they need to excel in the field of artificial intelligence, colleges and universities can increase the chances each graduate is familiar with AI and understands that they can make an impact in the field, regardless of their technological prowess. It’s an easy way to transform the student experience while setting up each student for success.Mark McNasby is the Chief Executive Officer at Ivy.ai. 







Mark McNasby
Ivy.ai
artificial intelligence (AI)
chatbots
Wireless













Educational ResourcesThe Multi-Cloud Conundrum: Choices, Challenges & SolutionsStreamlining Telecom Through Automation & Orchestration PlatformsAdvanced Data Management Integration for Next-Generation Kubernetes StorageRevolutionizing Telco Transformation: Unveiling the Next-Gen Cloud Platform





Related ContentEvery Last Mile: the mission to connect AmericaJul 22, 2024 09:00amBeefing up business services in the CSP data centerJul 22, 2024 09:00amManaging your network for AI applicationsJul 22, 2024 09:00amVultr's Kevin Cochrane discusses AI security, compliance, and global GPU deployment strategyJul 22, 2024 09:00am








See more articles










 



 

 











CONNECT



About Us


Advertise




JOIN US



Newsletters


Resources




OUR BRANDS



Fierce Network




OUR EVENTS



Broadband Nation Expo

















©2024 Questex LLC All rights reserved.
Terms of use
Privacy Policy
Privacy Settings











",https://schema.org/,,,,,,,,,,,,,,,"{'@type': 'NewsArticle', 'headline': 'Preparing Today’s College Students to Work with AI', 'articleSection': None, 'keywords': 'Fierce Network Homepage', 'description': 'Artificial intelligence (AI) has the potential to revolutionize our personal and professional lives, and it all begins in the college classroom.', 'datePublished': '2023-01-11T13:00:00', 'isAccessibleForFree': True, 'dateModified': '1673469852', 'author': [[{'@type': 'Person', 'name': 'Mark McNasby,', 'url': 'https://www.fierce-network.com/person/mark-mcnasby'}]], 'publisher': {'@type': 'Organization', 'name': 'Fierce Network', 'url': 'https://www.fierce-network.com'}, 'mainEntityOfPage': {'@type': 'WebPage', '@id': 'https://www.fierce-network.com/technology/preparing-todays-college-students-work-ai'}, 'image': 'https://qtxasset.com/quartz/qcloud4/media/image/AI%20College%203_1.jpg?VersionId=f97FQL.66BS0uKN2ySHPt0yYr1JmFsoi'}",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
https://news.google.com/rss/articles/CBMibGh0dHBzOi8vd3d3LmFiYy5uZXQuYXUvbmV3cy8yMDIzLTAxLTEwL2FydGlzdHMtcHJvdGVzdGluZy1hcnRpZmljaWFsLWludGVsbGlnZW5jZS1pbWFnZS1nZW5lcmF0b3JzLzEwMTc4NjE3NNIBKGh0dHBzOi8vYW1wLmFiYy5uZXQuYXUvYXJ0aWNsZS8xMDE3ODYxNzQ?oc=5,Artists angry after discovering artworks used to train AI image generators without their consent - ABC News,2023-01-09,ABC News,https://www.abc.net.au,AI image generators are learning from human illustrators without their consent. Now artists are speaking out.,"art,digital art,artificial intelligence,ai,lensa,prisma labs,artworks,artists,protests,ethics,copyright,intellectual property,text-to-image generators,ai image generators,machine learning,stable diffusion,stability ai,dalle 2,LAION-5B,artstation,deviantart,adobe,photoshop,spawning,mathew dryhurst,haveibeentrained,tom christophersen,kim leutwyler,kylie pappalardo,opt in,opt out",AI image generators are learning from human illustrators without their consent. Now artists are speaking out.,N/A,N/A,N/A,"Artists angry after discovering artworks used to train AI image generators without their consentBy Tom WilliamsPosted Mon 9 Jan 2023 at 3:41pmMonday 9 Jan 2023 at 3:41pmMon 9 Jan 2023 at 3:41pm Artists are using online tools to check if their work is being used to train AI image generators.(Supplied: haveibeentrained.com/Kim Leutwyler)abc.net.au/news/artists-protesting-artificial-intelligence-image-generators/101786174Copy linkLink copiedShareShare articleSix-time Archibald Prize finalist Kim Leutwyler says ""it feels like a violation"" that their art was used without their consent to train the artificial intelligence (AI) technology behind increasingly popular text-to-image software.The Sydney-based, American-born artist is one of thousands of illustrators who are frustrated by their work being used to train AI image generators, which are now being used to create profit-making apps.There is a heated debate between artists and technology companies because creators haven't been compensated, leading many to take part in online protests to raise concerns about AI's ethical and copyright implications.There is still very little artists can do to protect their work from being used by AI, but some are beginning to opt out of certain systems. Others, however, are keen to opt in.Let's take a look at the situation and hear from people working in this complex and emerging space.How can artists know whether their work is being used to train AI?Artists are beginning to use online tools to check if their work is being used to train AI image generators.Leutwyler used a site called haveibeentrained.com to find out if their work had been included in something called LAION-5B — a dataset of 5.85 billion images and their text captions taken from the internet (including some copyrighted artworks), which have been used to train various AI systems.""I found almost every portrait I've ever created on there, as well as artworks by many Archibald finalists and winners,"" Leutwyler said.""It was very upsetting to see so many great Australian artists and emerging artists having their work used without their consent and then replicated in some form or another."" Artist Kim Leutwyler says the use of their work without their consent ""feels like a violation"".(Supplied: Kim Leutwyler)Sydney-based visual artist and performer Tom Christophersen says it was ""a bit of a shock"" when they searched for their own art on the same website and discovered their work had also been captured by LAION-5B.""I didn't think I would care as much as I did. It was a bit of a rough feeling to know that stuff had been used against my will, without even notifying me,"" they said.""It just feels unethical when it's done sneakily behind artists' backs … People are really angry, and fair enough."" Artist Tom Christophersen says they will likely opt-out of having their work used to train AI.(Supplied: Laura Du Vé)Tensions escalated during the Lensa app controversyA mobile app called Lensa became popular late last year when it allowed users to create AI-generated portraits of themselves by combining their selfies with AI-generated art styles.Artists shared their copyright concerns after noticing what appeared to be their styles being replicated by the Lensa algorithm. Others noticed that some images created by the app had what appeared to be poor attempts at artists' signatures.Lensa uses an AI text-to-image platform called Stable Diffusion, which itself was trained on images and captions from LAION-5B.Christophersen says apps such as Lensa are ""moving wealth and value away from independent makers and freelance artists"" by generating revenue without reimbursing those whose works have been used to train the underlying technology.""It's already so hard to carve out a niche for yourself and get a buyer-ship as a visual artist that it feels a tiny bit like a kick in the guts when people are just going on these apps,"" they said. Tom Christophersen used haveibeentrained.com to find which of their artworks had been used to train AI.(Twitter: Tom Christophersen)Leutwyler says they are concerned about the impact of apps such as Lensa on up-and-coming artists.""The AI is replicating the brushstrokes, the colour, the technique and all of those unique things that make an artist's practice so compelling,"" they said.""It's then mass-producing it into something that is arguably great because it is accessible to so many people, however there should be some sort of copyright laws in place to help protect artists from having their work just completely ripped off.""Artists have protested online following certain companies launching AI image generators of their own or allowing AI-created images on their platforms.Software company and creator of Photoshop, Adobe, has been criticised for allowing AI-generated images to be sold in its libraries of stock images.In November, users of the art-sharing site DeviantArt spoke out when the company launched an AI image generator that could be trained using images already posted on the platform. The site then backtracked and went with an opt-in approach.In December, artists posted images denouncing AI on the art-sharing site ArtStation, after AI-generated images began appearing on that platform.Are AI image generators breaking copyright laws?The short answer is no — at least not as the laws currently stand.An artist's individual artworks are protected by copyright law, but their overall style is not.So to show an AI image generator had breached copyright laws, an artist would need to prove that one of their artworks had been copied into the system.That's difficult because such systems are opaque and largely made up of algorithms full of numbers that humans don't understand.Which of these artworks were created using AI?We put an AI image generator and a human illustrator head-to-head.Read moreQueensland University of Technology senior law lecturer Kylie Pappalardo says there can also be some exemptions that allow for temporary copies to be made incidentally as part of a system's technical processes.""Some copies are for non-expressive uses, meaning that no one ever really sees them,"" she says.""Instead, the copies are used to train algorithms. For example, to enable the search functions on the internet to work correctly. These are what we sometimes call non-consumptive uses.""Dr Pappalardo says she believes copying images so an algorithm can learn from them to create new art could be seen as a non-consumptive use.""Arguably, it's not much different from a human looking at many different artworks in order to appreciate how to paint better,"" she says.""The difference with AI is that the only way it can 'look' at art is by making a copy, even if that copy is temporary.""Dr Pappalardo says whether or not AI-created images actually constitute non-consumptive use remains ""untested ground"" in copyright law.Prisma Labs, the company behind the Lensa app, says artworks created by AI ""can't be described as exact replicas of any particular artwork"".""The AI learns to recognize the connections between the images and their descriptions, not the artworks,"" the company wrote on Twitter.Can artists opt-out of AI?While many AI image generators are trained with content taken without the original owners' consent, artists are slowly finding ways to get more control over the use of their work.In December one of the organisations behind Stable Diffusion, Stability AI, confirmed that artists would be able to opt-out of having their work used to train the next version of their system, Stable Diffusion 3.Activist organisation Spawning, which runs haveibeentrained.com, says Stability AI will honour requests to opt-out that are made through its site.Spawning's Mathew Dryhurst says haveibeentrained.com is being used by thousands of artists and has the potential to set ""a pretty remarkable precedent"" in the AI space. Mathew Dryhurst says Spawning is helping artists ""manage their data in a new paradigm"".(Supplied: Suzy Poling)""It is clear to us that it is of economic and cultural consequence to establish a means for consenting artist data,"" he says.""We would also argue that thinking longer term, consenting data is going to be more useful to AI companies than not.""Consenting data is something that everyone can feel good about, and is better for AI development generally.""Mr Dryhurst says Spawning is working on better ways to verify that people aren't opting out artworks that aren't their own, and will soon offer an opt-in service ""which will require robust verification"".He says while opt-out systems are imperfect, they are a step in the right direction and ""a hard-fought concession"" as Spawning continues its work with other AI organisations.""Due to the recent culture war waging around this particular iteration of AI media, I feel we may be perceived as being driven by an anti-AI sentiment. This couldn't be further from the truth,"" he says.""In truth, our team have been thinking about and experimenting with AI art for many years longer than many of the people currently speaking for this recent phase of AI art.""AI is a geopolitical economic arms race. The internet is global. We feel our efforts will either augment legislative efforts or compensate for their absence.""Some artists argue AI systems should only involve opt-in processes, while others are more flexible.Tom Christophersen says they ""probably will opt-out, shortly"".""Having an opt-in or opt-out option, as a bare minimum, is definitely a positive,"" they said.Kim Leutwyler says they may have allowed their work to be used to train AI, had they been asked.""I love technology. I use it in almost every stage of creating work,"" they said.""There are some great possibilities with it but there just has to be some sort of morality and ethics when it comes to training the AI.""I think every artist will want something different. Some will want compensation, some will want acknowledgement, and some will want to completely opt out.""You can't dictate what everybody wants, and there needs to be that option.""'This just feels so incredibly not right'Leutwyler says they hope to start a conversation about how to better prevent artists' work from being used to train AI systems without their consent.""As of now it's completely legal … It doesn't seem like the laws are able to move as quickly as technology does,"" they said.Christophersen says there needs to be ""constant work"" in the intellectual property and copyright space so artists aren't taken advantage of.Where are these AI images coming from and are there security concerns?These images allow people to imagine what they might look like in a fantasy world. But they're raising alarm bells for artists and security experts.Read more""It's maybe an inhibition to tackle stuff like copyright law that allows these companies to always keep artists on the back foot, which I guess is where a lot of this rage is coming from,"" they said.""Even though we can't define what's going on at the moment, this just feels so incredibly not right.""While some artists are calling for copyright laws to be altered, Dr Pappalardo says regulators may run the risk of responding too strongly to something which is yet to be fully understood.""Sometimes it's best to wait and see,"" she said.""I know that's not very reassuring to artists right now but we don't know how disruptive this is yet, and until we know that the law is not going to be very well placed to respond.""Christophersen says they are supportive of people using AI to create new and innovative works, but things are on ""shaky ground"" when it comes to supporting artists.""How do you define creativity in a quantitative way so that you can place some sort of value on it?""And then how do you protect that and make sure it's sustainable for human beings while being an exciting landscape where AI can grow as well?"" they said.Posted 9 Jan 20239 Jan 2023Mon 9 Jan 2023 at 3:41pmShareCopy linkFacebookX (formerly Twitter)Related StoriesWe challenged an AI image generator and a human illustrator. Can you spot the differences in their work?Where are these AI images coming from and are there security concerns?There's a woman haunting the internet. She was created by AI. Now she won't leaveMore on:ArtArtificial IntelligenceAustraliaComputer ScienceCopyrightCopyright InfringementDigital ArtGermanyLaw, Crime and JusticeScience and TechnologyUnited StatesTop StoriesBiden's legacy will extend beyond his one term in office. But the timing of his exit could have a profound impact on the electionAnalysis by Casey BriggsIf it's a Harris and Trump showdown, there's a huge question where no one knows the answerA look back at US President Joe Biden's political career in picturesCrowdStrike outage tipped to leave Australian businesses with damage bill surpassing $1 billion'Appalling': Queensland premier slams AI-generated political attack ad posted by oppositionDozens of Palestinians killed in humanitarian zone near Khan Younis, immediately after Israel orders evacuationAustralian war graves in historic Gaza cemetery feared damaged or destroyed following Israel's invasion'Family man': Father who tragically died trying to save twin daughters dreamed of parents moving to AustraliaSecret Service director Kim Cheatle once said she 'thrives on chaos'. An assassination attempt puts that claim to the testGunman kills at least five in 'frightening' attack on aged care facility in CroatiaWe tracked down the owners of Sydney's 'ghost homes' to try and find out why they've been left vacantNDIS participants using sex workers fear ban will deny some people with disability a 'normal life'Kamala Harris is used to breaking barriers. But could she become the first woman to be the US president?Oscar Piastri becomes fifth Australian to win F1 grand prix after nervous moment with teammate on last lapsStegosaurus skeleton sells for record $67.5m at US auctionPopular NowDon't miss news that matters to you. Log in to ABC today to get a more personalised experience tailored to your preferences.GET STARTED1.Doctors warn of significant increase in people hospitalised with psychosis after being prescribed medicinal cannabis2.Analysis by Casey Briggsanalysis:If it's a Harris and Trump showdown, there's a huge question where no one knows the answer3.'Appalling': Queensland premier slams AI-generated political attack ad posted by opposition4.Father who tragically died trying to save twin daughters dreamed of parents moving to Australia5.We tracked down the owners of Sydney's 'ghost homes' to try and find out why they've been left vacant6.Retiring couple 'absolutely shattered' at having to walk away from newsagency after 20 yearsTop StoriesBiden's legacy will extend beyond his one term in office. But the timing of his exit could have a profound impact on the electionAnalysis by Casey BriggsIf it's a Harris and Trump showdown, there's a huge question where no one knows the answerA look back at US President Joe Biden's political career in picturesCrowdStrike outage tipped to leave Australian businesses with damage bill surpassing $1 billion'Appalling': Queensland premier slams AI-generated political attack ad posted by oppositionJust InDozens of Palestinians killed in humanitarian zone near Khan Younis, immediately after Israel orders evacuation40m ago40 minutes agoMon 22 Jul 2024 at 10:19amGunman kills at least five in 'frightening' attack on aged care facility in Croatia1h ago1 hours agoMon 22 Jul 2024 at 9:06amTaiwan holds unscripted war games after Chinese 'punishment' drills4h ago4 hours agoMon 22 Jul 2024 at 6:30amA look back at US President Joe Biden's political career in pictures5h ago5 hours agoMon 22 Jul 2024 at 5:32amMore Just InBack to top",http://schema.org,NewsArticle,,"{'@type': 'Organization', 'name': 'ABC News', 'logo': {'@type': 'ImageObject', 'height': 60, 'url': 'https://www.abc.net.au/res/abc/logos/amp-news-logo-60x240.png', 'width': 240}}",https://www.abc.net.au/news/2023-01-10/artists-protesting-artificial-intelligence-image-generators/101786174,2023-01-09T20:41:05+00:00,,2023-01-09T20:41:05+00:00,,"{'@type': 'ImageObject', 'height': 485, 'url': 'https://live-production.wcms.abc-cdn.net.au/5b5e80568bb70bc8d31107784d3df71d?impolicy=wcms_crop_resize&cropH=540&cropW=960&xPos=0&yPos=0&width=862&height=485', 'width': 862}","[{'@type': 'Person', 'name': 'Tom Williams'}]",Artists angry after discovering artworks used to train AI image generators without their consent,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
https://news.google.com/rss/articles/CBMiVGh0dHBzOi8vdHJpYnVuZW9ubGluZW5nLmNvbS9zZXZlbi1iYW5rcy1jb21wZXRlLWluLWFydGlmaWNpYWwtaW50ZWxsaWdlbmNlLWFkb3B0aW9uL9IBAA?oc=5,Seven banks compete in Artificial Intelligence adoption - Tribune Online,2023-01-09,Tribune Online,https://tribuneonlineng.com,"IN a bid to run with the tide of digital economy, fresh facts have emerged that seven Deposit Money Banks (DMBs) are already competing in not only",N/A,"IN a bid to run with the tide of digital economy, fresh facts have emerged that seven Deposit Money Banks (DMBs) are already competing in not only",N/A,N/A,N/A,"


Courts sentence 25 for internet fraud in Osun, Oyo


",https://schema.org,,,,,,,,,,,,,,,"[{'@type': 'Article', '@id': 'https://tribuneonlineng.com/seven-banks-compete-in-artificial-intelligence-adoption/#article', 'isPartOf': {'@id': 'https://tribuneonlineng.com/seven-banks-compete-in-artificial-intelligence-adoption/'}, 'author': {'name': 'Chima Nwokoji', '@id': 'https://tribuneonlineng.com/#/schema/person/55aa5b54990ff5f05e718c5eb7f11c98'}, 'headline': 'Seven banks compete in Artificial Intelligence adoption', 'datePublished': '2023-01-09T06:45:08+00:00', 'dateModified': '2023-08-22T13:33:29+00:00', 'mainEntityOfPage': {'@id': 'https://tribuneonlineng.com/seven-banks-compete-in-artificial-intelligence-adoption/'}, 'wordCount': 537, 'publisher': {'@id': 'https://tribuneonlineng.com/#organization'}, 'image': {'@id': 'https://tribuneonlineng.com/seven-banks-compete-in-artificial-intelligence-adoption/#primaryimage'}, 'thumbnailUrl': 'https://tribuneonlineng.com/wp-content/uploads/2017/05/nigerian-banks-and-cbn.jpg', 'articleSection': ['Business'], 'inLanguage': 'en-GB'}, {'@type': 'WebPage', '@id': 'https://tribuneonlineng.com/seven-banks-compete-in-artificial-intelligence-adoption/', 'url': 'https://tribuneonlineng.com/seven-banks-compete-in-artificial-intelligence-adoption/', 'name': 'Seven banks compete in Artificial Intelligence adoption - Tribune Online', 'isPartOf': {'@id': 'https://tribuneonlineng.com/#website'}, 'primaryImageOfPage': {'@id': 'https://tribuneonlineng.com/seven-banks-compete-in-artificial-intelligence-adoption/#primaryimage'}, 'image': {'@id': 'https://tribuneonlineng.com/seven-banks-compete-in-artificial-intelligence-adoption/#primaryimage'}, 'thumbnailUrl': 'https://tribuneonlineng.com/wp-content/uploads/2017/05/nigerian-banks-and-cbn.jpg', 'datePublished': '2023-01-09T06:45:08+00:00', 'dateModified': '2023-08-22T13:33:29+00:00', 'description': 'IN a bid to run with the tide of digital economy, fresh facts have emerged that seven Deposit Money Banks (DMBs) are already competing in not only', 'breadcrumb': {'@id': 'https://tribuneonlineng.com/seven-banks-compete-in-artificial-intelligence-adoption/#breadcrumb'}, 'inLanguage': 'en-GB', 'potentialAction': [{'@type': 'ReadAction', 'target': ['https://tribuneonlineng.com/seven-banks-compete-in-artificial-intelligence-adoption/']}]}, {'@type': 'ImageObject', 'inLanguage': 'en-GB', '@id': 'https://tribuneonlineng.com/seven-banks-compete-in-artificial-intelligence-adoption/#primaryimage', 'url': 'https://tribuneonlineng.com/wp-content/uploads/2017/05/nigerian-banks-and-cbn.jpg', 'contentUrl': 'https://tribuneonlineng.com/wp-content/uploads/2017/05/nigerian-banks-and-cbn.jpg', 'width': 450, 'height': 350, 'caption': 'guidelines bank CBN applications Commercial banks woo moneybags with high deposit rates, deposits banks ATM interbank loan banks CBN'}, {'@type': 'BreadcrumbList', '@id': 'https://tribuneonlineng.com/seven-banks-compete-in-artificial-intelligence-adoption/#breadcrumb', 'itemListElement': [{'@type': 'ListItem', 'position': 1, 'name': 'Home', 'item': 'https://tribuneonlineng.com/'}, {'@type': 'ListItem', 'position': 2, 'name': 'Business', 'item': 'https://tribuneonlineng.com/category/business/'}, {'@type': 'ListItem', 'position': 3, 'name': 'Seven banks compete in Artificial Intelligence adoption'}]}, {'@type': 'WebSite', '@id': 'https://tribuneonlineng.com/#website', 'url': 'https://tribuneonlineng.com/', 'name': 'Tribune Online', 'description': 'Breaking News in Nigeria Today', 'publisher': {'@id': 'https://tribuneonlineng.com/#organization'}, 'potentialAction': [{'@type': 'SearchAction', 'target': {'@type': 'EntryPoint', 'urlTemplate': 'https://tribuneonlineng.com/?s={search_term_string}'}, 'query-input': 'required name=search_term_string'}], 'inLanguage': 'en-GB'}, {'@type': 'Organization', '@id': 'https://tribuneonlineng.com/#organization', 'name': 'Tribune Online', 'url': 'https://tribuneonlineng.com/', 'logo': {'@type': 'ImageObject', 'inLanguage': 'en-GB', '@id': 'https://tribuneonlineng.com/#/schema/logo/image/', 'url': 'https://tribuneonlineng.com/wp-content/uploads/2019/01/logo-mast-head.jpg', 'contentUrl': 'https://tribuneonlineng.com/wp-content/uploads/2019/01/logo-mast-head.jpg', 'width': 859, 'height': 257, 'caption': 'Tribune Online'}, 'image': {'@id': 'https://tribuneonlineng.com/#/schema/logo/image/'}, 'sameAs': ['https://www.facebook.com/Tribuneonline/', 'https://x.com/nigeriantribune', 'https://www.instagram.com/tribuneonlineng/', 'https://www.youtube.com/user/lovegift4u2001', 'https://en.wikipedia.org/wiki/Nigerian_Tribune']}, {'@type': 'Person', '@id': 'https://tribuneonlineng.com/#/schema/person/55aa5b54990ff5f05e718c5eb7f11c98', 'name': 'Chima Nwokoji', 'url': 'https://tribuneonlineng.com/author/chima/'}]",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,

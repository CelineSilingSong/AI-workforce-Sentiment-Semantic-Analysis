URL link,Title,Date,Source,Source Link,description,keywords,og:description,twitter:description,@context,@type,url,image,author,publisher,headline,datePublished,dateModified,articleSection,name,isAccessibleForFree,itemListElement,article:section,article:summary,article text,isPartOf,articleBody,wordCount,alternateName,thumbnailUrl,mainEntityOfPage,@graph,speakable,creator,dateCreated,@id,logo,sameAs,potentialAction,entry-title,published,updated,alternativeHeadline,dateline,hasPart,video
https://news.google.com/rss/articles/CBMifWh0dHBzOi8vd3d3LmZvcmJlcy5jb20vc2l0ZXMvcXVvcmEvMjAxOC8xMC8wOS9ob3ctYXJ0aWZpY2lhbC1pbnRlbGxpZ2VuY2Utam9iLWRpc3BsYWNlbWVudC13aWxsLWFmZmVjdC10aGUtd29ybGR3aWRlLWVjb25vbXkv0gEA?oc=5,How Artificial Intelligence Job Displacement Will Affect The Worldwide Economy - Forbes,2018-10-09,Forbes,https://www.forbes.com,What effect will job displacement due to AI have on the worldwide economy? This question was originally answered on Quora by Kai-Fu Lee.,,What effect will job displacement due to AI have on the worldwide economy? This question was originally answered on Quora by Kai-Fu Lee.,What effect will job displacement due to AI have on the worldwide economy? This question was originally answered on Quora by Kai-Fu Lee.,http://schema.org,BreadcrumbList,https://www.forbes.com/sites/quora/2018/10/09/how-artificial-intelligence-job-displacement-will-affect-the-worldwide-economy/,"{'@type': 'ImageObject', 'url': 'https://imageio.forbes.com/specials-images/dam/imageserve/aeeaac34130942b19dc8dfcf60396262/0x0.jpg?format=jpg&height=900&width=1600&fit=bounds', 'width': 542.79, 'height': 304.6}","{'@type': 'Person', 'name': 'Quora', 'url': 'https://www.forbes.com/sites/quora/', 'description': 'Quora: the place to gain and share knowledge, empowering people to learn from others and better understand the world.', 'sameAs': ['https://www.twitter.com/Quora', 'http://www.quora.com/']}","{'@type': 'NewsMediaOrganization', 'name': 'Forbes', 'url': 'https://www.forbes.com/', 'ethicsPolicy': 'https://www.forbes.com/sites/forbesstaff/article/forbes-editorial-values-and-standards/', 'logo': 'https://imageio.forbes.com/i-forbesimg/media/amp/images/forbes-logo-dark.png?format=png&height=455&width=650&fit=bounds'}",How Artificial Intelligence Job Displacement Will Affect The Worldwide Economy,2018-10-09T11:11:00-04:00,2018-10-09T11:11:55-04:00,Consumer Tech,How Artificial Intelligence Job Displacement Will Affect The Worldwide Economy,False,"[{'@type': 'ListItem', 'position': 1, 'name': 'Forbes Homepage', 'item': 'https://www.forbes.com/'}, {'@type': 'ListItem', 'position': 2, 'name': 'Innovation', 'item': 'https://www.forbes.com/innovation/'}, {'@type': 'ListItem', 'position': 3, 'name': 'Consumer Tech', 'item': 'https://www.forbes.com/consumer-tech/'}]",Consumer Tech,N/A,"More From ForbesJul 15, 2024,09:00am EDTAMD Reveals Ryzen 9 9950X Performance, Details Other Zen 5 ProcessorsJul 15, 2024,06:00am EDTCeptics 65W Nanfuse World Travel Adapter With GaN Technology And Three USB PortsJul 14, 2024,06:10pm EDTGoogle Leak Details New Pixel 9, Pixel 9 Pro ChangesJul 14, 2024,01:00pm EDTPlaud Note Review: Is This The Best, Slickest, Voice Recorder You Can Buy?Jul 14, 2024,12:06pm EDTApple iPhone 16 Pro Design Upgrade Promises Key Feature Boost, Report SaysJul 14, 2024,08:22am EDTSamsung’s New Galaxy Phone Promotion Shouldn’t Be IgnoredJul 14, 2024,06:00am EDTKEF Mu7 Wireless Headphones Have That Signature British SoundEdit StoryForbesInnovationConsumer TechHow Artificial Intelligence Job Displacement Will Affect The Worldwide EconomyQuoraContributorOpinions expressed by Forbes Contributors are their own.FollowingFollowClick to save this article.You'll be asked to sign into your Forbes account.Got itOct 9, 2018,11:11am EDTUpdated Oct 9, 2018, 11:11am EDTThis article is more than 5 years old.Share to FacebookShare to TwitterShare to Linkedin







(AP Photo/Mark Schiefelbein)





What effect will job displacement due to AI have on the worldwide economy? originally appeared on Quora: the place to gain and share knowledge, empowering people to learn from others and better understand the world.

Answer by Kai-Fu Lee, CEO of 创新工场, former President of Google China and Author of AI Superpowers, on Quora:
As outlined in my new book AI Superpowers, 40-50% of our jobs will be technically and economically doable by AI and automation over the next 15 years. AI can optimize within a single domain by “watching and learning” from many actual examples. So AI certainly cannot do most things that we humans can do.
PROMOTED
Disruption will hit the industry in areas with the largest number of routine jobs – manufacturing, call centers, banks, retail, etc. It will also cause existing players to compete on their speed of automation. Those who automate faster will be economically advantaged and may win over outsized profits. There will also be disruptions in certain markets (such as loans by apps rather than banks, news edited by personalized AI rather than editors, robot fast food restaurants rather than human-serviced ones).

The net impact will be that there will be a few winners and many losers. A small number of companies (AI companies, Internet+AI companies, AI SaaS companies, etc.) will make outsized profits, while others will struggle to survive. People in routine jobs will lose their jobs, and I believe only human-to-human service jobs are a sector large enough to accommodate them with some retraining.
The GDP will go up substantially (PWC estimates AI will add $16 trillion in WW GDP by 2030), but the wealth gap will widen, between countries (as US and China dominate), companies (AI companies vs. routine job companies), and individuals (AI tycoons vs. displaced workers). This will present a lot of economic challenges to even the winning countries (like US and China): how to redistribute income (tax for the ultra-rich and universal basic income are both difficult and fraught with problems).









DailyDozen
US


Forbes Daily: Join over 1 million Forbes Daily subscribers and get our best stories, exclusive reporting and essential analysis of the day’s news in your inbox every weekday.




                Sign Up
            


By signing up, you agree to receive this newsletter, other updates about Forbes and its affiliates’ offerings, our Terms of Service (including resolving disputes on an individual basis via arbitration), and you acknowledge our Privacy Statement. Forbes is protected by reCAPTCHA, and the Google Privacy Policy and Terms of Service apply.




You’re all set! Enjoy the Daily!


                More Newsletters
            


You’re all set! Enjoy the Daily!

                More Newsletters
            



This question originally appeared on Quora - the place to gain and share knowledge, empowering people to learn from others and better understand the world. You can follow Quora on Twitter, Facebook, and Google+. More questions:

Artificial Intelligence: What kinds of jobs will be vulnerable to displacement due to AI, and how soon will it happen?
China: Does China have the ability to catch up to the U.S. in AI development?
Silicon Valley: Are there similarities between China's work culture and the one in Silicon Valley?
QuoraFollowingFollowQuora: the place to gain and share knowledge, empowering people to learn from others and better understand the world.Editorial StandardsPrintReprints & Permissions
1/1





Skip Ad
 
Continue watchingafter the adVisit Advertiser websiteGO TO PAGE",,,,,,,,,,,,,,,,,,,,,
https://news.google.com/rss/articles/CBMiP2h0dHBzOi8vd3d3LmZ0LmNvbS9jb250ZW50L2JjZDgxYTg4LWNhZGItMTFlOC1iMjc2LWI5MDY5YmRlMDk1NtIBAA?oc=5,Artificial intelligence: when humans coexist with robots - Financial Times,2018-10-08,Financial Times,https://www.ft.com,"Despite fears of a machine takeover, brainpower will still be necessary. Such ‘hybrid systems’ require careful design",N/A,"Despite fears of a machine takeover, brainpower will still be necessary. Such ‘hybrid systems’ require careful design",N/A,http://schema.org,WebSite,http://www.ft.com,"{'@type': 'ImageObject', '@context': 'http://schema.org', 'url': 'https://www.ft.com/__origami/service/image/v2/images/raw/http%3A%2F%2Fcom.ft.imagepublish.upp-prod-eu.s3.amazonaws.com%2F6f21efae-cb1b-11e8-9fe5-24ad351828ab?source=next-article&fit=scale-down&quality=highest&width=700&dpr=1', 'width': 2048, 'height': 1152}","[{'@type': 'Person', '@context': 'http://schema.org', 'name': 'Richard Waters', 'url': 'https://www.ft.com/richard-waters', 'worksFor': {'@type': 'Organization', '@context': 'http://schema.org', 'name': 'Financial Times', 'legalName': 'The Financial Times Ltd.', 'logo': {'@type': 'ImageObject', '@context': 'http://schema.org', 'url': 'https://im.ft-static.com/m/img/masthead_main.jpg', 'width': 435, 'height': 36}, 'url': 'https://www.ft.com', 'sameAs': ['https://www.twitter.com/FT', 'https://www.facebook.com/financialtimes', 'https://www.linkedin.com/company/financial-times', 'https://www.youtube.com/user/FinancialTimesVideos', 'https://www.instagram.com/financialtimes']}}]","{'@type': 'Organization', '@context': 'http://schema.org', 'name': 'Financial Times', 'legalName': 'The Financial Times Ltd.', 'logo': {'@type': 'ImageObject', '@context': 'http://schema.org', 'url': 'https://im.ft-static.com/m/img/masthead_main.jpg', 'width': 435, 'height': 36}, 'url': 'https://www.ft.com', 'sameAs': ['https://www.twitter.com/FT', 'https://www.facebook.com/financialtimes', 'https://www.linkedin.com/company/financial-times', 'https://www.youtube.com/user/FinancialTimesVideos', 'https://www.instagram.com/financialtimes']}",Artificial intelligence: when humans coexist with robots,2018-10-09T04:00:31.000Z,2018-10-09T04:00:31.000Z,,Financial Times,False,"[{'@type': 'ListItem', 'position': 1, 'name': 'Companies', 'item': 'https://www.ft.com/companies'}, {'@type': 'ListItem', 'position': 2, 'name': 'Health sector', 'item': 'https://www.ft.com/health-sector'}, {'@type': 'ListItem', 'position': 3, 'name': 'Industrials', 'item': 'https://www.ft.com/industrials'}]",N/A,N/A,"Artificial intelligence: when humans coexist with robots on x (opens in a new window)Artificial intelligence: when humans coexist with robots on facebook (opens in a new window)Artificial intelligence: when humans coexist with robots on linkedin (opens in a new window)Artificial intelligence: when humans coexist with robots on whatsapp (opens in a new window)



Save

current progress 0%Artificial intelligence: when humans coexist with robots on x (opens in a new window)Artificial intelligence: when humans coexist with robots on facebook (opens in a new window)Artificial intelligence: when humans coexist with robots on linkedin (opens in a new window)Artificial intelligence: when humans coexist with robots on whatsapp (opens in a new window)



Save

Richard Waters in San Francisco October 9 2018124Print this pageStay informed with free updatesSimply sign up to the US & Canadian companies myFT Digest -- delivered directly to your inbox.The human race is not on the scrapheap after all. Or at least not yet. There has been no shortage of predictions in recent years about how advances in artificial intelligence and robotics will see humans replaced in all kinds of jobs.
But most AI experts see a less drastic outcome. In this version of the future, people will still have a role working alongside smart systems: either the technology will not be good enough to take over completely, or the decisions will have human consequences that are too important to hand over completely to a machine.
This hybrid decision-making
 should produce better results than either working alone, according to David Mindell, a professor at Massachusetts Institute of Technology and author of Our Robots, Ourselves. There’s just one problem: when humans and semi-intelligent systems try to 
work together, things do not always turn out well.
A catastrophic demonstration took place on the streets of Tempe, Arizona, this year. An Uber test car equipped with the company’s latest self-driving technology struck and killed a person crossing the road. Like almost all of today’s autonomous cars, a back-up driver was there to step in if the software failed. But an analysis by local police concluded that the driver was distracted at the time — and may have been watching a TV show on a smartphone.
The Uber vehicle was relying on a degree of autonomy which is due to be launched more widely next year. The so-called Level 3 system is designed to drive itself in most situations but hand control back to a human when confronted by situations it cannot handle.
Investigators examine an Uber self-driving vehicle that was involved in a road traffic accident in which a woman was killed in Tempe, Arizona, earlier this year © Reuters
A system that is meant to be fully autonomous but suddenly deviates puts unrealistic demands on humans, say critics. “If you’re only needed for a minute a day, it won’t work,” says Stefan Heck, chief executive of Nauto, a US start-up whose technology is used to prevent professional drivers from becoming distracted. “It’s neither fish nor fowl.”
The failure points to a predicament with the adoption of AI that reaches well beyond driverless cars. Without careful design, the intelligent systems making their way into the world could provoke a backlash against the technology.
Once people come to understand how limited today’s machine learning systems are, the exaggerated hopes they have aroused will evaporate quickly, warns Roger Schank, an AI expert who specialises in the psychology of learning. The result, he predicts, will be a new “AI winter” — a reference to the period in the late 1980s when disappointment over the progress of the technology led to a retreat from the field. 
Preventing that will require more realistic expectations of the new autonomous systems, as well as careful design to make sure they mesh with the human world. But the technology itself presents a serious barrier.
“The way AI works, and the way it fails, are foreign to us,” says Illah Nourbakhsh, a professor of robotics at Carnegie Mellon University. “Does the AI make us feel more involved — or is it like dealing with an alien species?”
A facial recognition system on show last year in Washington DC. Such systems could pick suspects from a crowd but a human may be needed to weed out false positives © AFP
The semi-driverless car is a particularly stark example of a near-autonomous system that relies on close co-operation with people. But as AI advances, hybrid systems such as these are creeping into many different situations.
Machine learning — the type of AI that is behind the most dramatic recent progress in the field — is an advanced form of pattern recognition. It has already proved itself superior to people in tasks such as identifying the images in photographs or recognising speech.
But it is less effective when it has to make judgments based on the specific data on which it has been trained. In the real world, people often make decisions about situations they have not previously faced.
RecommendedArtificial intelligence in real workplacesCan a robot do your job?
The problem lies in systems that can match data but not understand its significance. “They are powerful things, but they don’t have a sense of the world,” says Vishal Sikka, a former top SAP and Infosys executive who specialises in AI. 

The new forms of human/machine co-operation are taking root in three main ways. First, there are scenarios where humans act as a back-up for the robots, taking over when the machines reach the limits of their abilities. Many work processes are being redesigned in this way — such as automated call centres, where language-understanding systems try to handle callers’ queries, only defaulting to a human operator when the technology is confused.
The Uber crash was an extreme example of what can go wrong. Research from Stanford University has shown that it takes at least six seconds for a human driver to recover their awareness and take back control, says Mr Heck. But even when there is enough time for human attention to be restored, the person stepping into a situation may see things differently from the machine, making the handover far from seamless.
PodcastThe Big ReadArtificial intelligence: can humans and robots work together?
“We need to work on a shared meaning between software systems and people — this is a very difficult problem,” says Mr Sikka. The use of language highlights the difficulty. Humans can convey meaning by using few words: the shared understanding of context between speaker and listener invests those words with meaning, adds Mr Sikka. Computer scientists have not yet worked out how to create that shared understanding in machines, he adds.
A second type of human/machine co-operation is designed to make sure that a sensitive task always depends on a person — even in situations where an automated system has done all the preparatory work and would be quite capable of completing the task itself.
Military drones, where human “pilots”, often based thousands of miles away, are called on to make the decision to fire at a target, are one example. 
Facial recognition systems — used to help immigration officers identify suspect travellers — are another. Both show how AI can make humans far more effective without robbing them of control, says Mr Heck.
One criticism of semi-autonomous weapons such as drones, however, is that there are no technical barriers to turning them into fully autonomous systems. Current procedures and safeguards can quickly be changed.
Drone operators prepare to launch an unmanned plane as part of US operations against Islamic State in Iraq and Syria © Getty
According to Stuart Russell, an AI professor at the University of California, Berkeley, it would be a short and easy step in a national emergency to remove the human drone operator from the loop, precipitating an era of robot weapons that make their own decisions about when to kill people. “You can’t say the technology itself can only be used in a defensive way and under human control. It’s not true,” he says.
A final type of “human in the loop” system involves the use of AI that is not capable of handling a task entirely on its own but is used as an aid to human decision-making. Algorithms that crunch data and make recommendations, or direct people in which step to take next, are creeping into everyday life. 


The algorithms, though, are only as good as the data they are trained on — and they are not good at dealing with new situations. People required to trust these systems are often also required to take them on faith.
Mr Schank points to the role of algorithms in baseball. Analysing the strengths and weaknesses of each batter has led to new ways of setting the field that baseball traditionalists would balk at. The outcome of these computer-aided decisions may well end up being worse than those based on purely human analysis, he says.
A bug in the app used by Uber drivers in San Francisco sent them to an airport cargo site rather than the passenger terminal. “Sometimes people will blindly follow the machine, other times people will say: ‘Hang on, that doesn't look right.’ It’s like a lot of other technologies, people will adapt,” says Tim O’Reilly, a technology author.
RecommendedNews in-depthThe Big ReadDriverless cars: mapping the trouble ahead
These may be relatively harmless cases where little damage is done from being led astray by the machine. But what happens when the stakes are higher?
IBM made medical diagnostics one of the main goals for Watson, the system first created to win a TV game show and then repurposed to become what it calls a more general “cognitive” system.
Such systems are designed to leave the ultimate decision with an expert. IBM maintains that humans will always have the final say. But how easy would it be for a doctor to override a recommendation being offered by a computer that, by definition, has analysed more comparable situations and crunched more data than they have? 
Rejecting the technology might be even harder if it has insurance or other financial consequences. “Doctors are put in a position where they feel subservient to the system,” says Mr Nourbakhsh. “Simply saying they’ll still make the decisions doesn’t make it so.”
Similar worries surfaced in the 1980s, when the field of AI was dominated by “expert systems” designed to guide their human users through a “decision tree” to reach the correct answer in any situation. It turned out to be too hard to anticipate all the unforeseen factors that complicate real-world decisions.
Artificial intelligence may be able to clean up scans and spot anomalies faster than the human eye, but algorithms can be fallible 
But the latest AI, based on machine learning, looks set to become far more widely adopted, and it may be harder to second-guess. Thanks to their success in narrow fields such as image recognition, expectations for these systems have been soaring. Their creators have been more than happy to feed the hype.
“We’re getting out-of-control marketing departments,” says Mr Schank. He singles out IBM in particular, arguing that the company heavily over-promised when it came to Watson — a criticism frequently heard in AI circles.
The long road to a driverless future

 Dario Gil, chief operating officer of IBM’s research effort, defends the decision to launch a big initiative around Watson nearly eight years ago, arguing that no other tech companies were according such a central role to AI at the time. But, he adds: “We were not clear enough about the difference between general . . . and specific [AI].”
Assessing the quality of an AI system’s recommendations raises other challenges. Non-experts may feel reluctant to second-guess a machine whose workings they do not understand.
It is not a new dilemma. More than 30 years ago, a software glitch in a radiation therapy machine called Therac-25 led to some patients being given massive overdoses. Technicians had no way of identifying the flaw and the machine stayed in use much longer as a result, says Mr Nourbakhsh.
That’s the odd irony of artificial intelligence — the best systems happen to be the ones that are least explainable today
The technology used in the most advanced machine learning systems, known as neural networks, present additional challenges. They are modelled on a theory about how the human brain operates, passing data through layers of artificial neurons until an identifiable pattern emerges. Unlike the logic circuits employed in a traditional software program, there is no way of tracking this process to identify exactly why a computer comes up with a particular answer. This is a big hindrance in the adoption of neural networks. 
“That’s the odd irony of AI — the best systems happen to be the ones that are least explainable today,” says Mr Nourbakhsh.
Some experts, however, say headway is being made and that it will not be long before machine learning systems are able to point to the factors that led them to a particular decision. “It’s not impossible — you can look inside and see what signals it’s picking up,” says Mr Heck.
Like many working in the field, he expresses optimism that humans and machines, working together, will achieve far more than either could have done alone. But there are some serious design challenges to solve before that rosy future arrives.
AI still has ‘a long way to go’ in dealing with people
There has long been a sure-fire way to get people and machines to work more effectively together: make the humans themselves act more like the machines.
Since the earliest days of mass manufacturing, it has been easier to fit people into the carefully structured world of automated processes than it has been to unleash the systems to work in the messy human world.
Some computer science experts say a more creative relationship between man and machine will take new forms of AI 
What applied to early motor vehicle assembly lines is equally relevant in the age of artificial intelligence. But it comes with limitations. People often accept — and act on — the output of such systems without questioning them, says Roger Schank, an expert in the psychology of learning.
Pointing to the risk that doctors will blindly follow the recommendations of intelligent diagnostics systems, even when they are wrong, he adds: “There are always going to be doctors who are robotic. This problem has existed forever.”
Breaking this cycle and replacing it with a more creative relationship between man and machine will take new forms of AI, some computer science experts say. The systems need a wider understanding of the world in order to fit their recommendations into a more human context, says Vishal Sikka, the former chief executive of Infosys.
Mr Schank says that computer scientists should stop studying machine intelligence and turn their attention instead on the human variety. He points out that some of the founders of the field of AI were also psychologists. Only a better understanding of how humans learn from their experiences and apply their knowledge to new situations will bring the necessary breakthrough, he says.
David Mindell, a Massachusetts Institute of Technology professor who has written about the challenges of getting humans and robots to interact effectively, puts it most succinctly: “The computer science world still has a long way to go before it has a clue about how to deal with people.”


Letter in response to this article:
AI cannot replace diligent bedside assessment / From FD Skidmore, London, UK



Copyright The Financial Times Limited 2024. All rights reserved.Reuse this content (opens in new window) CommentsJump to comments section














Promoted ContentLatest on US & Canadian companiesLexUS banksGoldman Sachs’ results were good, but not 1999 good Premium content2 hours agoBlackRock IncBlackRock’s Fink highlights ‘barbell effect’ as investors return to fixed incomeGoldman SachsGoldman profits more than double to $3bn as deals reboundInvestment BankingBoutique bank founded by Goldman dealmakers aims for UK expansionAlphabet IncGoogle parent in talks to buy cyber security start-up Wiz for $23bnBank stress testsGoldman challenges Fed’s demand it hold more capital after stress testEuropean Central BankWhen will the ECB next cut interest rates?Electric vehiclesBattery maker’s surge raises hope of turnaround for EV vehicles sales

					Follow the topics in this article
			



						US & Canadian companies
					



Add to myFT




						Robotics
					



Add to myFT




						Technology sector
					



Add to myFT




						Audio articles
					



Add to myFT




						Drones
					



Add to myFT



Comments","{'@type': ['CreativeWork', 'Product'], 'name': 'Financial Times', 'productID': 'ft.com:subscribed'}","The human race is not on the scrapheap after all. Or at least not yet. There has been no shortage of predictions in recent years about how advances in artificial intelligence and robotics will see humans replaced in all kinds of jobs.

But most AI experts see a less drastic outcome. In this version of the future, people will still have a role working alongside smart systems: either the technology will not be good enough to take over completely, or the decisions will have human consequences that are too important to hand over completely to a machine.

This hybrid decision-making
 should produce better results than either working alone, according to David Mindell, a professor at Massachusetts Institute of Technology and author of Our Robots, Ourselves. There’s just one problem: when humans and semi-intelligent systems try to 
work together, things do not always turn out well.

A catastrophic demonstration took place on the streets of Tempe, Arizona, this year. An Uber test car equipped with the company’s latest self-driving technology struck and killed a person crossing the road. Like almost all of today’s autonomous cars, a back-up driver was there to step in if the software failed. But an analysis by local police concluded that the driver was distracted at the time — and may have been watching a TV show on a smartphone.

The Uber vehicle was relying on a degree of autonomy which is due to be launched more widely next year. The so-called Level 3 system is designed to drive itself in most situations but hand control back to a human when confronted by situations it cannot handle.

A system that is meant to be fully autonomous but suddenly deviates puts unrealistic demands on humans, say critics. “If you’re only needed for a minute a day, it won’t work,” says Stefan Heck, chief executive of Nauto, a US start-up whose technology is used to prevent professional drivers from becoming distracted. “It’s neither fish nor fowl.”

The failure points to a predicament with the adoption of AI that reaches well beyond driverless cars. Without careful design, the intelligent systems making their way into the world could provoke a backlash against the technology.

Once people come to understand how limited today’s machine learning systems are, the exaggerated hopes they have aroused will evaporate quickly, warns Roger Schank, an AI expert who specialises in the psychology of learning. The result, he predicts, will be a new “AI winter” — a reference to the period in the late 1980s when disappointment over the progress of the technology led to a retreat from the field.

Preventing that will require more realistic expectations of the new autonomous systems, as well as careful design to make sure they mesh with the human world. But the technology itself presents a serious barrier.

“The way AI works, and the way it fails, are foreign to us,” says Illah Nourbakhsh, a professor of robotics at Carnegie Mellon University. “Does the AI make us feel more involved — or is it like dealing with an alien species?”

The semi-driverless car is a particularly stark example of a near-autonomous system that relies on close co-operation with people. But as AI advances, hybrid systems such as these are creeping into many different situations.

Machine learning — the type of AI that is behind the most dramatic recent progress in the field — is an advanced form of pattern recognition. It has already proved itself superior to people in tasks such as identifying the images in photographs or recognising speech.

But it is less effective when it has to make judgments based on the specific data on which it has been trained. In the real world, people often make decisions about situations they have not previously faced.

The problem lies in systems that can match data but not understand its significance. “They are powerful things, but they don’t have a sense of the world,” says Vishal Sikka, a former top SAP and Infosys executive who specialises in AI.

The new forms of human/machine co-operation are taking root in three main ways. First, there are scenarios where humans act as a back-up for the robots, taking over when the machines reach the limits of their abilities. Many work processes are being redesigned in this way — such as automated call centres, where language-understanding systems try to handle callers’ queries, only defaulting to a human operator when the technology is confused.

The Uber crash was an extreme example of what can go wrong. Research from Stanford University has shown that it takes at least six seconds for a human driver to recover their awareness and take back control, says Mr Heck. But even when there is enough time for human attention to be restored, the person stepping into a situation may see things differently from the machine, making the handover far from seamless.

“We need to work on a shared meaning between software systems and people — this is a very difficult problem,” says Mr Sikka. The use of language highlights the difficulty. Humans can convey meaning by using few words: the shared understanding of context between speaker and listener invests those words with meaning, adds Mr Sikka. Computer scientists have not yet worked out how to create that shared understanding in machines, he adds.

A second type of human/machine co-operation is designed to make sure that a sensitive task always depends on a person — even in situations where an automated system has done all the preparatory work and would be quite capable of completing the task itself.

Military drones, where human “pilots”, often based thousands of miles away, are called on to make the decision to fire at a target, are one example. 
Facial recognition systems — used to help immigration officers identify suspect travellers — are another. Both show how AI can make humans far more effective without robbing them of control, says Mr Heck.

One criticism of semi-autonomous weapons such as drones, however, is that there are no technical barriers to turning them into fully autonomous systems. Current procedures and safeguards can quickly be changed.

According to Stuart Russell, an AI professor at the University of California, Berkeley, it would be a short and easy step in a national emergency to remove the human drone operator from the loop, precipitating an era of robot weapons that make their own decisions about when to kill people. “You can’t say the technology itself can only be used in a defensive way and under human control. It’s not true,” he says.

A final type of “human in the loop” system involves the use of AI that is not capable of handling a task entirely on its own but is used as an aid to human decision-making. Algorithms that crunch data and make recommendations, or direct people in which step to take next, are creeping into everyday life.

The algorithms, though, are only as good as the data they are trained on — and they are not good at dealing with new situations. People required to trust these systems are often also required to take them on faith.

Mr Schank points to the role of algorithms in baseball. Analysing the strengths and weaknesses of each batter has led to new ways of setting the field that baseball traditionalists would balk at. The outcome of these computer-aided decisions may well end up being worse than those based on purely human analysis, he says.

A bug in the app used by Uber drivers in San Francisco sent them to an airport cargo site rather than the passenger terminal. “Sometimes people will blindly follow the machine, other times people will say: ‘Hang on, that doesn't look right.’ It’s like a lot of other technologies, people will adapt,” says Tim O’Reilly, a technology author.

These may be relatively harmless cases where little damage is done from being led astray by the machine. But what happens when the stakes are higher?

IBM made medical diagnostics one of the main goals for Watson, the system first created to win a TV game show and then repurposed to become what it calls a more general “cognitive” system.

Such systems are designed to leave the ultimate decision with an expert. IBM maintains that humans will always have the final say. But how easy would it be for a doctor to override a recommendation being offered by a computer that, by definition, has analysed more comparable situations and crunched more data than they have?

Rejecting the technology might be even harder if it has insurance or other financial consequences. “Doctors are put in a position where they feel subservient to the system,” says Mr Nourbakhsh. “Simply saying they’ll still make the decisions doesn’t make it so.”

Similar worries surfaced in the 1980s, when the field of AI was dominated by “expert systems” designed to guide their human users through a “decision tree” to reach the correct answer in any situation. It turned out to be too hard to anticipate all the unforeseen factors that complicate real-world decisions.

But the latest AI, based on machine learning, looks set to become far more widely adopted, and it may be harder to second-guess. Thanks to their success in narrow fields such as image recognition, expectations for these systems have been soaring. Their creators have been more than happy to feed the hype.

“We’re getting out-of-control marketing departments,” says Mr Schank. He singles out IBM in particular, arguing that the company heavily over-promised when it came to Watson — a criticism frequently heard in AI circles.

Dario Gil, chief operating officer of IBM’s research effort, defends the decision to launch a big initiative around Watson nearly eight years ago, arguing that no other tech companies were according such a central role to AI at the time. But, he adds: “We were not clear enough about the difference between general . . . and specific [AI].”

Assessing the quality of an AI system’s recommendations raises other challenges. Non-experts may feel reluctant to second-guess a machine whose workings they do not understand.

It is not a new dilemma. More than 30 years ago, a software glitch in a radiation therapy machine called Therac-25 led to some patients being given massive overdoses. Technicians had no way of identifying the flaw and the machine stayed in use much longer as a result, says Mr Nourbakhsh.

The technology used in the most advanced machine learning systems, known as neural networks, present additional challenges. They are modelled on a theory about how the human brain operates, passing data through layers of artificial neurons until an identifiable pattern emerges. Unlike the logic circuits employed in a traditional software program, there is no way of tracking this process to identify exactly why a computer comes up with a particular answer. This is a big hindrance in the adoption of neural networks.

“That’s the odd irony of AI — the best systems happen to be the ones that are least explainable today,” says Mr Nourbakhsh.

Some experts, however, say headway is being made and that it will not be long before machine learning systems are able to point to the factors that led them to a particular decision. “It’s not impossible — you can look inside and see what signals it’s picking up,” says Mr Heck.

Like many working in the field, he expresses optimism that humans and machines, working together, will achieve far more than either could have done alone. But there are some serious design challenges to solve before that rosy future arrives.

AI cannot replace diligent bedside assessment / From FD Skidmore, London, UK",1960.0,FT.com,,,,,,,,,,,,,,,,,
https://news.google.com/rss/articles/CBMiYWh0dHBzOi8vd3d3LnRoZWd1YXJkaWFuLmNvbS90ZWNobm9sb2d5LzIwMTgvb2N0LzEwL2FtYXpvbi1oaXJpbmctYWktZ2VuZGVyLWJpYXMtcmVjcnVpdGluZy1lbmdpbmXSAWFodHRwczovL2FtcC50aGVndWFyZGlhbi5jb20vdGVjaG5vbG9neS8yMDE4L29jdC8xMC9hbWF6b24taGlyaW5nLWFpLWdlbmRlci1iaWFzLXJlY3J1aXRpbmctZW5naW5l?oc=5,Amazon ditched AI recruiting tool that favored men for technical jobs - The Guardian,2018-10-11,The Guardian,https://www.theguardian.com, Specialists had been building computer programs since 2014 to review résumés in an effort to automate the search process,N/A,Specialists had been building computer programs since 2014 to review résumés in an effort to automate the search process,N/A,,,,,,,,,,,,,,Technology,N/A," Amazon’s automated hiring tool was found to be inadequate after penalizing the résumés of female candidates. Photograph: Brian Snyder/ReutersView image in fullscreenAmazon’s automated hiring tool was found to be inadequate after penalizing the résumés of female candidates. Photograph: Brian Snyder/ReutersAmazon This article is more than 5 years oldAmazon ditched AI recruiting tool that favored men for technical jobsThis article is more than 5 years old Specialists had been building computer programs since 2014 to review résumés in an effort to automate the search processReutersWed 10 Oct 2018 19.42 EDTLast modified on Thu 11 Oct 2018 11.43 EDTShareAmazon’s machine-learning specialists uncovered a big problem: their new recruiting engine did not like women.The team had been building computer programs since 2014 to review job applicants’ résumés, with the aim of mechanizing the search for top talent, five people familiar with the effort told Reuters.Automation has been key to Amazon’s e-commerce dominance, be it inside warehouses or driving pricing decisions. The company’s experimental hiring tool used artificial intelligence to give job candidates scores ranging from one to five stars – much as shoppers rate products on Amazon, some of the people said.“Everyone wanted this holy grail,” one of the people said. “They literally wanted it to be an engine where I’m going to give you 100 résumés, it will spit out the top five, and we’ll hire those.”But by 2015, the company realized its new system was not rating candidates for software developer jobs and other technical posts in a gender-neutral way.Automation could destroy millions of jobs. We have to deal with it nowYvette CooperRead moreThat is because Amazon’s computer models were trained to vet applicants by observing patterns in résumés submitted to the company over a 10-year period. Most came from men, a reflection of male dominance across the tech industry.In effect, Amazon’s system taught itself that male candidates were preferable. It penalized résumés that included the word “women’s”, as in “women’s chess club captain”. And it downgraded graduates of two all-women’s colleges, according to people familiar with the matter.Amazon edited the programs to make them neutral to these particular terms. But that was no guarantee that the machines would not devise other ways of sorting candidates that could prove discriminatory, the people said.The Seattle company ultimately disbanded the team by the start of last year because executives lost hope for the project, according to the people, who spoke on condition of anonymity. Amazon’s recruiters looked at the recommendations generated by the tool when searching for new hires, but never relied solely on those rankings, they said.Amazon declined to comment on the recruiting engine or its challenges, but the company says it is committed to workplace diversity and equality.The company’s experiment, which Reuters is first to report, offers a case study in the limitations of machine learning. It also serves as a lesson to the growing list of large companies including Hilton Worldwide Holdings and Goldman Sachs that are looking to automate portions of the hiring process.Franken-algorithms: the deadly consequences of unpredictable codeRead moreSome 55% of US human resources managers said artificial intelligence, or AI, would be a regular part of their work within the next five years, according to a 2017 survey by talent software firm CareerBuilder.Masculine languageAmazon’s experiment began at a pivotal moment for the world’s largest online retailer. Machine learning was gaining traction in the technology world, thanks to a surge in low-cost computing power. And Amazon’s Human Resources department was about to embark on a hiring spree; since June 2015, the company’s global headcount has more than tripled to 575,700 workers, regulatory filings show.So it set up a team in Amazon’s Edinburgh engineering hub that grew to around a dozen people. Their goal was to develop AI that could rapidly crawl the web and spot candidates worth recruiting, the people familiar with the matter said.The group created 500 computer models focused on specific job functions and locations. They taught each to recognize some 50,000 terms that were found on past candidates’ résumés. The algorithms learned to assign little significance to skills that were common across IT applicants, such as the ability to write various computer codes, the people said.Instead, the technology favored candidates who described themselves using verbs more commonly found on male engineers’ resumes, such as “executed” and “captured”, one person said.Gender bias was not the only issue. Problems with the data that underpinned the models’ judgments meant that unqualified candidates were often recommended for all manner of jobs, the people said. With the technology returning results almost at random, Amazon shut down the project, they said.The problem or the cure?Other companies are forging ahead, underscoring the eagerness of employers to harness AI for hiring.Kevin Parker, chief executive of HireVue, a startup near Salt Lake City, said automation is helping companies look beyond the same recruiting networks upon which they have long relied. His firm analyzes candidates’ speech and facial expressions in video interviews to reduce reliance on résumés.“You weren’t going back to the same old places; you weren’t going back to just Ivy League schools,” Parker said. His company’s customers include Unilever PLC and Hilton.Goldman Sachs has created its own résumé analysis tool that tries to match candidates with the division where they would be the “best fit”, the company said.LinkedIn, the world’s largest professional network, has gone further. It offers employers algorithmic rankings of candidates based on their fit for job postings on its site.Joseph Stiglitz on artificial intelligence: 'We’re going towards a more divided society'Read moreStill, John Jersin, vice-president of LinkedIn Talent Solutions, said the service is not a replacement for traditional recruiters.“I certainly would not trust any AI system today to make a hiring decision on its own,” he said. “The technology is just not ready yet.”Some activists say they are concerned about transparency in AI. The American Civil Liberties Union is currently challenging a law that allows criminal prosecution of researchers and journalists who test hiring websites’ algorithms for discrimination.“We are increasingly focusing on algorithmic fairness as an issue,” said Rachel Goodman, a staff attorney with the Racial Justice Program at the ACLU. Still, Goodman and other critics of AI acknowledged it could be exceedingly difficult to sue an employer over automated hiring; job candidates might never know it was being used.As for Amazon, the company managed to salvage some of what it learned from its failed AI experiment. It now uses a “much watered-down version” of the recruiting engine to help with some rudimentary chores, including culling duplicate candidate profiles from databases, one of the people familiar with the project said.Another said a new team in Edinburgh has been formed to give automated employment screening another try, this time with a focus on diversity.Explore more on these topicsAmazonArtificial intelligence (AI)newsShareReuse this contentMost viewedUnderground cave found on moon could be ideal base for explorersFormer classmate describes Trump rally gunman as ‘definitely conservative’LiveTrump picks Ohio senator JD Vance as his vice-presidential pick for the 2024 US elections – liveBlue Maga: we need to talk about the cult-like turn of the Democratic partyMehdi HasanAOC to anonymous Democrat who said party resigned to Trump win: ‘Retire’",,,,,,,,,,,,,,,,,,,,,
https://news.google.com/rss/articles/CBMiLGh0dHBzOi8vd3d3LmJiYy5jb20vbmV3cy90ZWNobm9sb2d5LTQ1ODA5OTE50gEwaHR0cHM6Ly93d3cuYmJjLmNvbS9uZXdzL3RlY2hub2xvZ3ktNDU4MDk5MTkuYW1w?oc=5,Amazon scrapped 'sexist AI' tool - BBC.com,2018-10-10,BBC.com,https://www.bbc.com,Reuters claims that a secret AI recruitment tool was abandoned after it showed bias towards men.,N/A,Reuters claims that a secret AI recruitment tool was abandoned after it showed bias towards men.,Reuters claims that a secret AI recruitment tool was abandoned after it showed bias towards men.,http://schema.org,ReportageNewsArticle,https://www.bbc.com/news/technology-45809919,"{'@type': 'ImageObject', 'width': 1024, 'height': 576, 'url': 'https://ichef.bbci.co.uk/news/1024/branded_news/CE67/production/_103793825_recruitment2.gif'}","{'@type': 'NewsMediaOrganization', 'name': 'BBC News', 'noBylinesPolicy': 'http://www.bbc.co.uk/news/help-41670342#authorexpertise', 'logo': {'@type': 'ImageObject', 'url': 'https://static.files.bbci.co.uk/ws/simorgh-assets/public/news/images/metadata/poster-1024x576.png'}}","{'@type': 'NewsMediaOrganization', 'name': 'BBC News', 'publishingPrinciples': 'http://www.bbc.co.uk/news/help-41670342', 'logo': {'@type': 'ImageObject', 'url': 'https://static.files.bbci.co.uk/ws/simorgh-assets/public/news/images/metadata/poster-1024x576.png'}}",Amazon scrapped 'sexist AI' tool,2018-10-10T09:53:22.000Z,2018-10-10T09:53:22.000Z,,,,,N/A,N/A,"Amazon scrapped 'sexist AI' tool10 October 2018ShareGetty ImagesThe algorithm repeated bias towards men, reflected in the technology industryAn algorithm that was being tested as a recruitment tool by online giant Amazon was sexist and had to be scrapped, according to a Reuters report.The artificial intelligence system was trained on data submitted by applicants over a 10-year period, much of which came from men, it claimed.Reuters was told by members of the team working on it that the system effectively taught itself that male candidates were preferable.Amazon has not responded to the claims.Reuters spoke to five members of the team who developed the machine learning tool in 2014, none of whom wanted to be publicly named. They told Reuters that the system was intended to review job applications and give candidates a score ranging from one to five stars.""They literally wanted it to be an engine where I'm going to give you 100 resumes, it will spit out the top five, and we'll hire those,"" said one of the engineers who spoke to Reuters.AdChoicesADVERTISEMENT'Women' penalisedBy 2015, it was clear that the system was not rating candidates in a gender-neutral way because it was built on data accumulated from CVs submitted to the firm mostly from males, Reuters claimed.The system started to penalise CVs which included the word ""women"". The program was edited to make it neutral to the term but it became clear that the system could not be relied upon, Reuters was told.The project was abandoned, although Reuters said that it was used for a period by recruiters who looked at the recommendations generated by the tool but never relied solely on it.According to Amazon, its current global workforce is split 60:40 in favour of males.About 55% of US human resources managers said that AI would play a role in recruitment within the next five years, according to a survey by software firm CareerBuilder.It is not the first time doubts have been raised about how reliable algorithms trained on potentially biased data will be.MITAn MIT AI system, dubbed Norman, had a dark view of the world as a result of the data it was trained onAn experiment at the Massachusetts Institute of Technology, which trained an AI on images and videos of murder and death, found it interpreted neutral inkblots in a negative way.And in May last year, a report claimed that an AI-generated computer program used by a US court was biased against black people, flagging them as twice as likely to reoffend as white people.Predictive policing algorithms were spotted to be similarly biased, because the crime data they were trained on showed more arrests or police stops for black people. IBM launches bias detector for AIMeet Norman, the psychopathic AI",,,,,https://ichef.bbci.co.uk/news/1024/branded_news/CE67/production/_103793825_recruitment2.gif,https://www.bbc.com/news/technology-45809919,,,,,,,,,,,,,,,
https://news.google.com/rss/articles/CBMiamh0dHBzOi8vd3d3LnJldGFpbGdhemV0dGUuY28udWsvYmxvZy8yMDE4LzEwL3RoZS1yaXNlLW9mLWF1dG9tYXRpb24taW4tcmV0YWlsLXNob3VsZC1yZXRhaWxlcnMtYmUtd29ycmllZC_SAQA?oc=5,The rise of automation: Should retailers be worried? - Retail Gazette,2018-10-11,Retail Gazette,https://www.retailgazette.co.uk,"While not yet a common sight, incremental changes towards robots replacing humans in stores are already being trialled by the likes of Nestle in Japan, Best Buy and Lowe’s in the US and even Amazon Go’s “check-out less” supermarkets in the UK.",N/A,"While not yet a common sight, incremental changes towards robots replacing humans in stores are already being trialled by the likes of Nestle in Japan, Best Buy and Lowe’s in the US and even Amazon Go’s “check-out less” supermarkets in the UK.","While not yet a common sight, incremental changes towards robots replacing humans in stores are already being trialled by the likes of Nestle in Japan, Best Buy and Lowe’s in the US and even Amazon Go’s “check-out less” supermarkets in the UK.",https://schema.org,,,,,,,,,,,,,Feature Articles,N/A,"


Interview: Gymshark’s Ben Francis – ‘I want to be a globally iconic brand’








Gymshark's Ben Francis speak to Retail Gazette ahead of its second store opening at Westfield



Read More


",,,,,,,"[{'@type': ['NewsMediaOrganization', 'Organization'], '@id': 'https://www.retailgazette.co.uk/#organization', 'name': 'Retail Gazette', 'url': 'https://www.retailgazette.co.uk', 'sameAs': ['https://www.facebook.com/RetailGazette1/?fref=nf', 'https://twitter.com/retailgazette']}, {'@type': 'WebSite', '@id': 'https://www.retailgazette.co.uk/#website', 'url': 'https://www.retailgazette.co.uk', 'name': 'Retail Gazette', 'publisher': {'@id': 'https://www.retailgazette.co.uk/#organization'}, 'inLanguage': 'en-GB'}, {'@type': 'ImageObject', '@id': 'https://www.retailgazette.co.uk/wp-content/uploads/shutterstock_703589686.jpg', 'url': 'https://www.retailgazette.co.uk/wp-content/uploads/shutterstock_703589686.jpg', 'width': '1200', 'height': '800', 'inLanguage': 'en-GB'}, {'@type': 'WebPage', '@id': 'https://www.retailgazette.co.uk/blog/2018/10/the-rise-of-automation-in-retail-should-retailers-be-worried/#webpage', 'url': 'https://www.retailgazette.co.uk/blog/2018/10/the-rise-of-automation-in-retail-should-retailers-be-worried/', 'name': 'The rise of automation: Should retailers be worried? - Retail Gazette', 'datePublished': '2018-10-11T06:33:14+01:00', 'dateModified': '2018-10-15T11:27:10+01:00', 'isPartOf': {'@id': 'https://www.retailgazette.co.uk/#website'}, 'primaryImageOfPage': {'@id': 'https://www.retailgazette.co.uk/wp-content/uploads/shutterstock_703589686.jpg'}, 'inLanguage': 'en-GB'}, {'@type': 'Person', '@id': 'https://www.retailgazette.co.uk/author/ava-szajna-hopgood/', 'name': 'Ava Szajna-Hopgood', 'url': 'https://www.retailgazette.co.uk/author/ava-szajna-hopgood/', 'image': {'@type': 'ImageObject', '@id': 'https://secure.gravatar.com/avatar/1edd063c6217cf17c0937295a8e9b21c?s=96&amp;d=mm&amp;r=g', 'url': 'https://secure.gravatar.com/avatar/1edd063c6217cf17c0937295a8e9b21c?s=96&amp;d=mm&amp;r=g', 'caption': 'Ava Szajna-Hopgood', 'inLanguage': 'en-GB'}, 'worksFor': {'@id': 'https://www.retailgazette.co.uk/#organization'}}, {'@type': 'NewsArticle', 'headline': 'The rise of automation: Should retailers be worried? - Retail Gazette', 'keywords': 'Robots', 'datePublished': '2018-10-11T06:33:14+01:00', 'dateModified': '2018-10-15T11:27:10+01:00', 'author': {'@id': 'https://www.retailgazette.co.uk/author/ava-szajna-hopgood/', 'name': 'Ava Szajna-Hopgood'}, 'publisher': {'@id': 'https://www.retailgazette.co.uk/#organization'}, 'description': 'While not yet a common sight, incremental changes towards robots replacing humans in stores are already being trialled by the likes of Nestle in Japan, Best Buy and Lowe’s in the US and even Amazon Go’s “check-out less” supermarkets in the UK.', 'copyrightYear': '2018', 'copyrightHolder': {'@id': 'https://www.retailgazette.co.uk/#organization'}, 'name': 'The rise of automation: Should retailers be worried? - Retail Gazette', '@id': 'https://www.retailgazette.co.uk/blog/2018/10/the-rise-of-automation-in-retail-should-retailers-be-worried/#richSnippet', 'isPartOf': {'@id': 'https://www.retailgazette.co.uk/blog/2018/10/the-rise-of-automation-in-retail-should-retailers-be-worried/#webpage'}, 'image': {'@id': 'https://www.retailgazette.co.uk/wp-content/uploads/shutterstock_703589686.jpg'}, 'inLanguage': 'en-GB', 'mainEntityOfPage': {'@id': 'https://www.retailgazette.co.uk/blog/2018/10/the-rise-of-automation-in-retail-should-retailers-be-worried/#webpage'}}]",,,,,,,,,,,,,,
https://news.google.com/rss/articles/CBMiV2h0dHBzOi8vdGVjaHhwbG9yZS5jb20vbmV3cy8yMDE4LTEwLWFydGlmaWNpYWwtaW50ZWxsaWdlbmNlLXJldmVhbC1wZW9wbGUtYWJzdHJhY3QuaHRtbNIBAA?oc=5,Artificial intelligence helps reveal how people process abstract thought - Tech Xplore,2018-10-09,Tech Xplore,https://techxplore.com,"As artificial intelligence becomes more sophisticated, much of the public attention has focused on how successfully these technologies can compete against humans at chess and other strategy games. A philosopher from the University of Houston has taken a different approach, deconstructing the complex neural networks used in machine learning to shed light on how humans process abstract learning.","hi-tech news, hitech, innovation , inventions , computer news, information technology","As artificial intelligence becomes more sophisticated, much of the public attention has focused on how successfully these technologies can compete against humans at chess and other strategy games. A philosopher from the University of Houston has taken a different approach, deconstructing the complex neural networks used in machine learning to shed light on how humans process abstract learning.","As artificial intelligence becomes more sophisticated, much of the public attention has focused on how successfully these technologies can compete against humans at chess and other strategy games. A philosopher ...",https://schema.org,BreadcrumbList,,"{'@type': 'ImageObject', 'url': 'https://scx2.b-cdn.net/gfx/news/2016/57ea6ea8bc753.jpg', 'width': 1500, 'height': 1060}","{'@type': 'Person', 'name': 'Jeannie Kever'}","{'@type': 'Organization', 'name': 'Tech Xplore', 'logo': {'@type': 'ImageObject', 'url': 'https://techx.b-cdn.net/pic/techx.amp.png', 'width': 280, 'height': 60}}",Artificial intelligence helps reveal how people process abstract thought,2018-10-09T11:10:45-04:00,2018-10-09T11:10:45-04:00,,,,"[{'@type': 'ListItem', 'position': 1, 'name': 'Home', 'item': 'https://techxplore.com/'}, {'@type': 'ListItem', 'position': 2, 'name': 'Computer Sciences', 'item': 'https://techxplore.com/computer-sciences-news/'}]",N/A,N/A,"










                                                        October 9, 2018
                                                        
                                                    






Artificial intelligence helps reveal how people process abstract thought

                                        by Jeannie Kever,                                                                                 University of Houston







                Credit: CC0 Public Domain
             

As artificial intelligence becomes more sophisticated, much of the public attention has focused on how successfully these technologies can compete against humans at chess and other strategy games. A philosopher from the University of Houston has taken a different approach, deconstructing the complex neural networks used in machine learning to shed light on how humans process abstract learning.





""As we rely more and more on these systems, it is important to know how they work and why,"" said Cameron Buckner, assistant professor of philosophy and author of a paper exploring the topic published in the journal Synthese. Better understanding how the systems work, in turn, led him to insights into the nature of human learning.
Philosophers have debated the origins of human knowledge since the days of Plato—is it innate, based on logic, or does knowledge come from sensory experience in the world?
Deep Convolutional Neural Networks, or DCNNs, suggest human knowledge stems from experience, a school of thought known as empiricism, Buckner concluded. These neural networks—multi-layered artificial neural networks, with nodes replicating how neurons process and pass along information in the brain—demonstrate how abstract knowledge is acquired, he said, making the networks a useful tool for fields including neuroscience and psychology.
In the paper, Buckner notes that the success of these networks at complex tasks involving perception and discrimination has at times outpaced the ability of scientists to understand how they work.
While some scientists who build neural network systems have referenced the thinking of British philosopher John Locke and other influential theorists, their focus has been on results rather than understanding how the networks intersect with traditional philosophical accounts of human cognition. Buckner set out to fill that void, considering the use of AI for abstract reasoning, ranging from strategy games to visual recognition of chairs, artwork and animals, tasks that are surprisingly complex considering the many potential variations in vantage point, color, style and other detail.






""Computer vision and machine learning researchers have recently noted that triangle, chair, cat, and other everyday categories are so dif?cult to recognize because they can be encountered in a variety of different poses or orientations that are not mutually similar in terms of their low-level perceptual properties,"" Buckner wrote. ""... a chair seen from the front does not look much like the same chair seen from behind or above; we must somehow unify all these diverse perspectives to build a reliable chair-detector.""
To overcome the challenges, the systems have to control for so-called nuisance variation, or the range of differences that commonly affect a system's ability to identify objects, sounds and other tasks—size and position, for example, or pitch and tone. The ability to account for and digest that diversity of possibilities is a hallmark of abstract reasoning.
The DCNNs have also answered another lingering question about abstract reasoning, Buckner said. Empiricists from Aristotle to Locke have appealed to a faculty of abstraction to complete their explanations of how the mind works, but until now, there hasn't been a good explanation for how that works. ""For the first time, DCNNs help us to understand how this faculty actually works,"" Buckner said.
He began his academic career in computer science, studying logic-based approaches to artificial intelligence. The stark differences between early AI and the ways in which animals and humans actually solve problems prompted his shift to philosophy.
Less than a decade ago, he said, scientists believed advances in machine learning would stop short of the ability to produce abstract knowledge. Now that machines are beating humans at strategic games, driverless cars are being tested around the world and facial recognition systems are deployed everywhere from cell phones to airports, finding answers has become more urgent.
""These systems succeed where others failed,"" he said, ""because they can acquire the kind of subtle, abstract, intuitive knowledge of the world that comes automatically to humans but has until now proven impossible to program into computers.""

More information:
												Cameron Buckner, Empiricism without magic: transformational abstraction in deep convolutional neural networks, Synthese (2018). DOI: 10.1007/s11229-018-01949-1


                                                Provided by
                                                                                                    University of Houston









Citation:
                                                Artificial intelligence helps reveal how people process abstract thought (2018, October 9)
                                                retrieved 15 July 2024
                                                from https://techxplore.com/news/2018-10-artificial-intelligence-reveal-people-abstract.html
                                            

                                            This document is subject to copyright. Apart from any fair dealing for the purpose of private study or research, no
                                            part may be reproduced without the written permission. The content is provided for information purposes only.
                                            


",,,,,,"{'@type': 'WebPage', '@id': 'https://techxplore.com/news/2018-10-artificial-intelligence-reveal-people-abstract.html'}",,"{'@type': 'SpeakableSpecification', 'xpath': ['/html/head/title', ""/html/head/meta[@name='Description']/@content""]}",,,,,,,,,,,,,
https://news.google.com/rss/articles/CBMiYmh0dHBzOi8vc2xhdGUuY29tL2J1c2luZXNzLzIwMTgvMTAvYW1hem9uLWFydGlmaWNpYWwtaW50ZWxsaWdlbmNlLWhpcmluZy1kaXNjcmltaW5hdGlvbi13b21lbi5odG1s0gEA?oc=5,Amazon's AI hiring tool discriminated against women. - Slate,2018-10-10,Slate,https://slate.com,The program taught itself to favor male candidates.,"['amazon', 'sexism', 'jobs', 'redux', 'Section:business', 'AdNode:business/moneybox']",The program taught itself to favor male candidates.,The program taught itself to favor male candidates.,http://schema.org,NewsArticle,https://slate.com/business/2018/10/amazon-artificial-intelligence-hiring-discrimination-women.html,https://compote.slate.com/images/e5c7a937-fc8b-46ab-8adb-6ebfc6a0bbcc.jpeg?width=780&height=520&rect=3200x2133&offset=1x0,['Jordan Weissmann'],"{'logo': {'url': 'https://dot.cdnslate.com/static/media/sites/slate-com/icon.400x400.09ec623.png', '@type': 'ImageObject'}, 'name': 'Slate', '@type': 'Organization'}",Amazon Created a Hiring Tool Using AI. It Immediately Started Discriminating Against Women.,2018-10-10T20:52:04+00:00,,Moneybox,,,,N/A,N/A,"















      Moneybox
Amazon Created a Hiring Tool Using A.I. It Immediately Started Discriminating Against Women.


By
      
Jordan Weissmann


Oct 10, 20184:52 PM











Amazon sign, with dude.
David Ryder/Getty Images








Tweet
  



Share




Share




Comment
    










Tweet
  



Share




Share




Comment
    






        Popular in
        
          Slate
        




                        
            People Have Picked Up a Weird Habit When Flying. It’s Time to Stop.
          



                        
            A Common Response to Trump’s Shooting Is a Trap. Don’t Fall for It.
          



                        
            How the Trump Assassination Attempt Will Change What Comes Next
          



House of the Dragon’s Worst Character Somehow Found a Way to Stoop Even Lower
          


Thanks to Amazon, the world has a nifty new cautionary tale about the perils of teaching computers to make human decisions.
According to a Reuters report published Wednesday, the tech giant decided last year to abandon an “experimental hiring tool” that used artificial intelligence to rate job candidates, in part because it discriminated against women. Recruiters reportedly looked at the recommendations the program spat out while searching for talent, “but never relied solely on those rankings.”
The misadventure began in 2014, when a group of Amazon engineers in Scotland set out to mechanize the company’s head-hunting process, by creating a program that would scour the Internet for worthwhile job candidates (and presumably save Amazon’s HR staff some soul crushing hours clicking around LinkedIn). “Everyone wanted this holy grail,” a source told Reuters. “They literally wanted it to be an engine where I’m going to give you 100 resumes, it will spit out the top five, and we’ll hire those.”


1/1





Skip Ad
 
Continue watchingafter the adVisit Advertiser websiteGO TO PAGE

It didn’t pan out that way. In 2015, the team realized that its creation was biased in favor of men when it came to hiring technical talent, like software developers. The problem was that they trained their machine learning algorithms to look for prospects by recognizing terms that had popped up on the resumes of past job applicants—and because of the tech world’s well-known gender imbalance, those past hopefuls tended to be men.
“In effect, Amazon’s system taught itself that male candidates were preferable. It penalized resumes that included the word ‘women’s,’ as in ‘women’s chess club captain.’ And it downgraded graduates of two all-women’s colleges,” Reuters reported. The program also decided that basic tech skills, like the ability to write code, which popped up on all sorts of resumes, weren’t all that important, but grew to like candidates who littered their resumes with macho verbs such as “executed” and “captured.”



Advertisement








Advertisement








Advertisement








Advertisement





After years of trying to fix the project, Amazon brass reportedly “lost hope“ and shuttered the effort in 2017.
All of this is a remarkably clear-cut illustration of why many tech experts are worried that, rather than remove human biases from important decisions, artificial intelligence will simply automate them. An investigation by ProPublica, for instance, found that algorithms judges use in criminal sentencing may dole out harsher penalties to black defendants than white ones. Google Translate famously introduced gender biases into its translations. The issue is that these programs learn to spot patterns and make decisions by analyzing massive data sets, which themselves are often a reflection of social discrimination. Programmers can try to tweak the A.I. to avoid those undesirable results, but they may not think to, or be successful even if they try.
Amazon deserves some credit for realizing its tool had a problem, trying to fix it, and eventually moving on (assuming it didn’t have a serious impact on the company’s recruiting over the last few years). But, at a time when lots of companies are embracing artificial intelligence for things like hiring, what happened at Amazon really highlights that using such technology without unintended consequences is hard. And if a company like Amazon can’t pull it off without problems, it’s difficult to imagine that less sophisticated companies can.




Tweet
  



Share




Share




Comment
    





              Amazon
            


              Sexism
            


              Jobs
            
 





Advertisement






",,,,,https://compote.slate.com/images/e5c7a937-fc8b-46ab-8adb-6ebfc6a0bbcc.jpeg?width=780&height=520&rect=3200x2133&offset=1x0,,,,['Jordan Weissmann'],2018-10-10T20:52:04+00:00,,,,,,,,,,,
https://news.google.com/rss/articles/CBMiXmh0dHBzOi8vYnVpbHRpbi5jb20vYXJ0aWZpY2lhbC1pbnRlbGxpZ2VuY2UvYW1hem9uLWFiYW5kb25zLWFpLWhpcmluZy10b29sLWV4cG9zZWQtZ2VuZGVyLWJpYXPSAQA?oc=5,Amazon abandons AI hiring tool exposed for gender bias - Built In,2018-10-10,Built In,https://builtin.com,Amazon’s machine-learning specialists tells Reuters about a troubling discovery that their recruiting engine had a bias against women.,N/A,Amazon’s machine-learning specialists tells Reuters about a troubling discovery that their recruiting engine had a bias against women.,Amazon’s machine-learning specialists tells Reuters about a troubling discovery that their recruiting engine had a bias against women.,https://schema.org,,,,,,,,,,,,,N/A,N/A,"

























Artificial intelligence run amok has the potential for lurking biases. Reuters reports Amazon’s machine-learning specialists made a troubling discovery that their new recruiting engine had a bias against women.
Automation factors into processes across Amazon’s business from operations to pricing. The team also uses artificial intelligence to tackle hiring and had been building tools for this aim since 2014. This experimental hiring AI tool rated job candidates on a 5-star scale similar to the product ratings Amazon shoppers give.
“Everyone wanted this holy grail,” said one of the specialists. “They literally wanted it to be an engine where I’m going to give you 100 resumes, it will spit out the top five, and we’ll hire those.”

AI learned a preference for male candidates; subsequently, resumes with the word “women’s” were discounted so where those of graduates of two, unspecified all-women’s colleges.

Evidence of gender bias for software developer and other technical job candidates emerged as early as 2015 and was the result of the computer models relying on an inadvertently male-heavy resume pool drawn from a decade-long period. AI learned a preference for male candidates; subsequently, resumes with the word “women’s” were discounted so where those of graduates of two, unspecified all-women’s colleges.
While Amazon made updates to prevent bias for these particular terms, no safeguards were made against other forms of discrimination, according to the team. Amazon eventually scrapped the project in 2017, disappointed with the results. Anonymous sources also revealed Amazon recruiters took ratings into consideration as only one part of their hiring process.
In response, Amazon had no comment on the tool’s issues of bias, but told Reuters the tool “was never used by Amazon recruiters to evaluate candidates” with no further comment. The company did not dispute that recruiters saw these generated recommendations.
This saga illustrates the challenges of machine learning in automating the hiring process. A 2017 survey by CareerBuilder found that some 55 percent of U.S. human resources managers said artificial intelligence, or AI, would be a regular part of their work within the next five years. Machine learning has a ways to go for this application, experts note. “How to ensure that the algorithm is fair, how to make sure the algorithm is really interpretable and explainable - that’s still quite far off,” explained Nihar Shah, assistant professor at Carnegie Mellon.
Amazon’s experiment coincided with a hiring spree and inexpensive computing power that made machine learning appealing. The company had formed an engineering team in Edinburgh to create an AI sourcing tool. Unfortunately, among other issues, this tool learned to favor masculine language (words such as “executed” and “captured”).
While Amazon’s foray with AI in hiring went south, other companies are undeterred and believe automation can even force employers to look beyond elite credentials. Companies such as Goldman Sachs and Microsoft have used AI in their recruiting processes.
AI is no substitute for humans when it comes to recruiters, cautions John Jersin, vice president of LinkedIn Talent Solutions.
“I certainly would not trust any AI system today to make a hiring decision on its own,” Jersin said. “The technology is just not ready yet.”
The opacity surrounding the technology has also drawn the ire of organizations such as the American Civil Liberties Union who are pushing for algorithmic fairness. Critics argue that even being aware of discrimination due to automated hiring would be a challenge given the nature of the technology.
Amazon has not cut AI entirely from its recruiting. Its AI now takes the form of a “much-watered down version” of the recruiting engine that handles basic tasks such as de-duplication, according to an anonymous source. The next AI recruiting experiment rolling out from the Edinburgh team is taking on a new challenge: diversity.



",,,,,,,"[{'@context': 'https://schema.org', '@type': 'Article', 'headline': 'Amazon abandons AI hiring tool exposed for gender bias', 'name': 'Amazon abandons AI hiring tool exposed for gender bias', 'description': '&#13;', 'image': {'@type': 'ImageObject', 'url': 'https://builtin.com/sites/www.builtin.com/files/shutterstock_1012900804.jpg', 'representativeOfPage': True}, 'mainEntityOfPage': {'@type': 'WebPage', '@id': 'https://builtin.com/artificial-intelligence/amazon-abandons-ai-hiring-tool-exposed-gender-bias', 'name': 'Amazon abandons AI hiring tool exposed for gender bias'}, 'url': 'https://builtin.com/artificial-intelligence/amazon-abandons-ai-hiring-tool-exposed-gender-bias', 'about': {'@type': 'Thing', 'name': 'Artificial Intelligence'}, 'author': {'@type': 'Person', 'name': 'Folake Dosu'}, 'datePublished': '2018-10-11T04:54:47+00:00', 'publisher': {'@type': 'Organization', '@id': 'https://builtin.com', 'name': 'Built In', 'url': 'https://builtin.com', 'sameAs': ['https://www.facebook.com/BuiltInHQ/', 'https://twitter.com/builtin', 'https://www.instagram.com/builtin/', 'https://www.linkedin.com/company/built-in'], 'brand': {'@type': 'Brand', 'name': 'Built In'}, 'logo': {'@type': 'ImageObject', 'url': 'https://static.builtin.com/dist/images/built-logo.png', 'representativeOfPage': True}}}]",,,,,,,,,,,,,,
https://news.google.com/rss/articles/CBMiamh0dHBzOi8vd3d3LnJpc21lZGlhLmNvbS8yMDE4LzEwLzA3L2FydGlmaWNpYWwtaW50ZWxsaWdlbmNlLWluLXJlYWwtZXN0YXRlLWhvdy10by1sZXZlcmFnZS10aGUtZGlzcnVwdGlvbi_SAQA?oc=5,Artificial Intelligence in Real Estate: How to Leverage the Disruption - RisMedia.com,2018-10-07,RisMedia.com,https://www.rismedia.com,AI is influencing real estate in unprecedented ways.,"AI, Artificial Intelligence, Artificial Intelligence in Real Estate, Disruption in Real Estate, Machine Learning, NAWRB, real estate news, Real Estate News and Information, Real Estate Trends, RegTech",Discussions about how artificial intelligence (AI) will alter the workforce as we know it is a hot topic among thought,Discussions about how artificial intelligence (AI) will alter the workforce as we know it is a hot topic among thought,http://schema.org,BreadcrumbList,https://www.rismedia.com/2018/10/07/artificial-intelligence-in-real-estate-how-to-leverage-the-disruption/,"{'@type': 'ImageObject', 'url': 'https://www.rismedia.com/wp-content/uploads/2018/10/artifical_intelligence_852049214.jpg', 'width': 1200, 'height': 627}","{'@type': 'Person', 'name': 'Susanne Dwyer', 'url': 'https://www.rismedia.com/author/susanne-2/', 'sameAs': ['http://www.rismedia.com']}","{'@type': 'Organization', 'name': '', 'url': 'https://www.rismedia.com', 'logo': {'@type': 'ImageObject', 'url': ''}, 'sameAs': ['https://www.facebook.com/rismedia/', 'https://twitter.com/RISMediaUpdates', 'https://www.instagram.com/rismediaupdates/', 'https://www.pinterest.com/rismedia/', 'https://www.linkedin.com/company/rismedia/']}",Artificial Intelligence in Real Estate: How to Leverage the Disruption,2018-10-07 13:05:29,2018-10-05 20:08:03,"['Latest News', 'Lead Story', 'Technology']",Artificial Intelligence in Real Estate: How to Leverage the Disruption,,"[{'@type': 'ListItem', 'position': 1, 'item': {'@id': 'https://www.rismedia.com', 'name': 'Home'}}, {'@type': 'ListItem', 'position': 2, 'item': {'@id': 'https://www.rismedia.com/category/latest-news/', 'name': 'Latest News'}}, {'@type': 'ListItem', 'position': 3, 'item': {'@id': 'https://www.rismedia.com', 'name': 'Home'}}, {'@type': 'ListItem', 'position': 4, 'item': {'@id': 'https://www.rismedia.com/category/latest-news/', 'name': 'Latest News'}}]",Latest News,N/A,"



Agents




Court Denies NAR Petition for Rehearing in DOJ Case

 July 15, 2024

",,"Discussions about how artificial intelligence (AI) will alter the workforce as we know it is a hot topic among thought leaders, including those in the housing and real estate ecosystem. While some fear that improvements in machine learning and cognitive intelligence will present a threat to jobs—which is certainly an important concern—others see AI as a helpful tool for real estate professionals.

When hearing the term ""AI,"" people often think of chatbots and Siri or Alexa; however, experts see AI as having greater potential as a common helper in the real estate industry—being able to communicate with buyers in an intelligent manner and identify important signals for property regulations, such as RegTech.

Technology can assist the industry in property management, application processing and data synthesizing so that agents and brokers can focus on connecting with clients and helping them with the emotional process of buying or selling a home.

Here are some ways real estate professionals can utilize AI to improve their operations and increase their business growth:
<ul>
	<li>For property management, advanced machine learning can streamline everyday processes for tenants, property managers and landlords by helping find suitable tenants, locate vendors and provide alerts for routine maintenance and management tasks.</li>
	<li>Increase the number of recommendations your clients can choose from through AI. Agents can convert their knowledge of a client's wants into data an algorithm can use to find a higher number of matches at a faster rate.</li>
	<li>AI can provide virtual tours for interested homebuyers and answer simple technical questions about the property on behalf of the agent, such as square footage, questions about the lease and more, through 24/7 chat boxes. More nuanced questions can be transferred to the agent.</li>
	<li>Agents can maintain long-term relationships with their clients for when they need help moving, selling or even buying multiple properties in the future through AI-based customer relationship management (CRM) systems.</li>
</ul>
These are just a few of the ways AI is being developed into the way real estate professionals conduct their business. AI can be a helpful tool that can make everyday tasks more efficient and provide assistance to clients at a moment's notice, rather than a replacement for the agent themselves. It's important to remember that AI is not without flaws. Some worry that AI creators and users will include their own biases within new technology, causing more roadblocks and harm to minorities.

Innovators are working to make AI great at problem solving, automatic processing, data collecting and so on, but being an agent or broker requires skills that AI doesn't have: the expert advice of a professional who has worked in the field for over 20 years; the ethics to make sure AI is used responsibly; the ability to listen and understand the needs of a client; the intuition to know when a property is a good fit or deal; and the empathy to sympathize and provide moral support when homebuyers get cold feet or things don't go according to plan.<strong>
</strong>

<strong><em><a href=""https://www.rismedia.com/wp-content/uploads/2018/02/Patno_Desiree_2018_60x60.jpg"" rel=""attachment wp-att-139657""><img class=""alignleft size-full wp-image-139657"" src=""https://www.rismedia.com/wp-content/uploads/2018/02/Patno_Desiree_2018_60x60.jpg"" alt=""Patno_Desiree_2018_60x60"" width=""60"" height=""60"" /></a>Desirée Patno</em></strong><em> is the CEO and president of Women in the Housing and Real Estate Ecosystem (NAWRB) and Desirée Patno Enterprises, Inc. (DPE), as well as chairwoman of NAWRB's Diversity &amp; Inclusion Leadership Council (NDILC). With 30 years of experience in housing, Patno is a champion for women's economic growth and independence. In 2017, Entrepreneur.com named her the Highest-Ranking Woman and 4th Overall Top Real Estate Influencer to Follow. For more information, please visit <a href=""http://www.nawrb.com"" target=""_blank"">www.nawrb.com</a>.</em>

<em>For the latest <a href=""http://www.rismedia.com"">real estate news and trends</a>, bookmark RISMedia.com.</em>",,,,"{'@type': 'WebPage', '@id': 'https://www.rismedia.com/2018/10/07/artificial-intelligence-in-real-estate-how-to-leverage-the-disruption/'}",,,,2018-10-07 13:05:29,https://www.rismedia.com/#website,"{'@type': 'ImageObject', 'url': ''}","['https://www.facebook.com/rismedia/', 'https://twitter.com/RISMediaUpdates', 'https://www.instagram.com/rismediaupdates/', 'https://www.pinterest.com/rismedia/', 'https://www.linkedin.com/company/rismedia/']","{'@type': 'SearchAction', 'target': 'https://www.rismedia.com/?s={search_term_string}', 'query-input': 'required name=search_term_string'}",Artificial Intelligence in Real Estate: How to Leverage the Disruption,2018-10-07 13:05:29,2018-10-05 20:08:03,,,,
https://news.google.com/rss/articles/CBMiY2h0dHBzOi8vd3d3LnNhbG9uLmNvbS8yMDE4LzEwLzA3L2Etc3BhY2Utb2R5c3NleS1zdGlsbC1oYXMtaW5zaWdodC1vbi1mdXR1cmUtZGVjYWRlcy1sYXRlcl9wYXJ0bmVyL9IBAA?oc=5,"""2001: A Space Odyssey"" still has insight on future decades later - Salon",2018-10-07,Salon,https://www.salon.com,,"""2001: A Space Odyssey"", AI, amazon alexa, apple iPhone siri, Arthur C. Clarke, Artificial Intelligence, Siri","Autonomous vehicles, artificial intelligence, Siri and Alexa all prove the movie right","Autonomous vehicles, artificial intelligence, Siri and Alexa all prove the movie right",https://schema.org,BreadcrumbList,https://www.salon.com/2018/10/07/a-space-odyssey-still-has-insight-on-future-decades-later_partner/,"['https://mediaproxy.salon.com/width/1200/height/675/<?= https://media2.salon.com/2011/06/friday_night_seitz_trippiest_movies-slide-8.jpg ?>', 'https://mediaproxy.salon.com/width/1200/height/900/<?= https://media2.salon.com/2011/06/friday_night_seitz_trippiest_movies-slide-8.jpg ?>', 'https://mediaproxy.salon.com/width/1200/height/1200/<?= https://media2.salon.com/2011/06/friday_night_seitz_trippiest_movies-slide-8.jpg ?>']",[],"{'@type': 'Organization', 'name': 'Salon.com', 'logo': {'@type': 'ImageObject', 'url': 'https://media2.salon.com/2017/09/salon-logo-black.png'}}",&quot;2001: A Space Odyssey&quot; still has insight on future decades later,2018-10-07T18:59:19Z,2018-10-07T19:29:35Z,"All Salon, Culture",,,"[{'@type': 'ListItem', 'position': 1, 'name': 'Homepage', 'item': 'https://www.salon.com'}, {'@type': 'ListItem', 'position': 2, 'name': 'Culture Articles', 'item': 'https://www.salon.com/category/culture'}, {'@type': 'ListItem', 'position': 3, 'name': ""Daniel Rockmore's Articles"", 'item': 'https://www.salon.com/writer/daniel-rockmore'}]",Culture,N/A,"


Watching a 50th anniversary screening of “2001: A Space Odyssey,” I found myself, a mathematician and computer scientist whose research includes work related to artificial intelligence, comparing the story’s vision of the future with the world today.
close dialog     Play/Pause Video              Mute/Unmute Video             Advertisementclose dialogThe movie was made through a collaboration with science fiction writer Arthur C. Clarke and film director Stanley Kubrick, inspired by Clarke’s novel “Childhood’s End” and his lesser-known short story “The Sentinel.” A striking work of speculative fiction, it depicts – in terms sometimes hopeful and other times cautionary – a future of alien contact, interplanetary travel, conscious machines and even the next great evolutionary leap of humankind.
The most obvious way in which 2018 has fallen short of the vision of “2001” is in space travel. People are not yet routinely visiting space stations, making unremarkable visits to one of several moon bases, nor traveling to other planets. But Kubrick and Clarke hit the bull’s-eye when imagining the possibilities, problems and challenges of the future of artificial intelligence.Advertisement:
What can computers do?
A chief drama of the movie can in many ways be viewed as a battle to the death between human and computer. The artificial intelligence of “2001” is embodied in HAL, the omniscient computational presence, the brain of the Discovery One spaceship — and perhaps the film’s most famous character. HAL marks the pinnacle of computational achievement: a self-aware, seemingly infallible device and a ubiquitous presence in the ship, always listening, always watching.
HAL is not just a technological assistant to the crew, but rather — in the words of the mission commander Dave Bowman — the sixth crew member. The humans interact with HAL by speaking to him, and he replies in a measured male voice, somewhere between stern-yet-indulging parent and well-meaning nurse. HAL is Alexa and Siri — but much better. HAL has complete control of the ship and also, as it turns out, is the only crew member who knows the true goal of the mission.Advertisement:
Ethics in the machine
The tension of the film’s third act revolves around Bowman and his crewmate Frank Poole becoming increasingly aware that HAL is malfunctioning, and HAL’s discovery of these suspicions. Dave and Frank want to pull the plug on a failing computer, while self-aware HAL wants to live. All want to complete the mission.
The life-or-death chess match between the humans and HAL offers precursors of some of today’s questions about the prevalence and deployment of artificial intelligence in people’s daily lives.
First and foremost is the question of how much control people should cede to artificially intelligent machines, regardless of how “smart” the systems might be. HAL’s control of Discovery is like a deep-space version of the networked home of the future or the driverless car. Citizens, policymakers, experts and researchers are all still exploring the degree to which automation could — or should — take humans out of the loop. Some of the considerations involve relatively simple questions about the reliability of machines, but other issues are more subtle.Advertisement:
The actions of a computational machine are dictated by decisions encoded by humans in algorithms that control the devices. Algorithms generally have some quantifiable goal, toward which each of its actions should make progress – like winning a game of checkers, chess or Go. Just as an AI system would analyze positions of game pieces on a board, it can also measure efficiency of a warehouse or energy use of a data center.
But what happens when a moral or ethical dilemma arises en route to the goal? For the self-aware HAL, completing the mission — and staying alive — wins out when measured against the lives of the crew. What about a driverless car? Is the mission of a self-driving car, for instance, to get a passenger from one place to another as quickly as possible – or to avoid killing pedestrians? When someone steps in front of an autonomous vehicle, those goals conflict. That might feel like an obvious “choice” to program away, but what if the car needs to “choose” between two different scenarios, each of which would cause a human death?Advertisement:
Under surveillance
In one classic scene, Dave and Frank go into a part of the space station where they think HAL can’t hear them to discuss their doubts about HAL’s functioning and his ability to control the ship and guide the mission. They broach the idea of shutting him down. Little do they know that HAL’s cameras can see them: The computer is reading their lips through the pod window and learns of their plans.
In the modern world, a version of that scene happens all day every day. Most of us are effectively continuously monitored, through our almost-always-on phones or corporate and government surveillance of real-world and online activities. The boundary between private and public has become and continues to be increasingly fuzzy.
The characters’ relationships in the movie made me think a lot about how people and machines might coexist, or even evolve together. Through much of the movie, even the humans talk to each other blandly, without much tone or emotion — as they might talk to a machine, or as a machine might talk to them. HAL’s famous death scene — in which Dave methodically disconnects its logic links – made me wonder whether intelligent machines will ever be afforded something equivalent to human rights.Advertisement:
Clarke believed it quite possible that humans’ time on Earth was but a “brief resting place” and that the maturation and evolution of the species would necessarily take people well beyond this planet. “2001” ends optimistically, vaulting a human through the “Stargate” to mark the rebirth of the race. To do this in reality will require people to figure out how to make the best use of the machines and devices that they are building, and to make sure we don’t let those machines control us.
",,,,,https://mediaproxy.salon.com/width/1200/height/675/https://media2.salon.com/2011/06/friday_night_seitz_trippiest_movies-slide-8.jpg,"{'@type': 'WebPage', '@id': 'https://www.salon.com/2018/10/07/a-space-odyssey-still-has-insight-on-future-decades-later_partner/'}",,,,2018-10-07T18:59:19Z,,"{'@type': 'ImageObject', 'url': 'https://www.salon.com/design/images/salon-logo.svg'}","['https://www.facebook.com/salon', 'https://www.instagram.com/salonofficial', 'https://twitter.com/salon', 'https://www.instagram.com/salondotcom/']",,,,,"Autonomous vehicles, artificial intelligence, Siri and Alexa all prove the movie right",,,
https://news.google.com/rss/articles/CBMipAFodHRwczovL3d3dy5tbC5jbXUuZWR1L25ld3MvbmV3cy1hcmNoaXZlLzIwMTYtMjAyMC8yMDE4L29jdG9iZXIvYW1hem9uLXNjcmFwcy1zZWNyZXQtYXJ0aWZpY2lhbC1pbnRlbGxpZ2VuY2UtcmVjcnVpdGluZy1lbmdpbmUtdGhhdC1zaG93ZWQtYmlhc2VzLWFnYWluc3Qtd29tZW4uaHRtbNIBAA?oc=5,"Amazon Scraps Secret AI Recruiting Engine that Showed Biases Against Women - Machine Learning - CMU ... - Machine Learning Department, Carnegie Mellon University",2018-10-11,"Machine Learning Department, Carnegie Mellon University",https://www.ml.cmu.edu,AI Research scientists at Amazon uncovered Biases against women with their machine learning recruiting engine,N/A,AI Research scientists at Amazon uncovered Biases against women with their machine learning recruiting engine,N/A,,,,,,,,,,,,,,N/A,N/A,"


October 11, 2018
Amazon Scraps Secret AI Recruiting Engine that Showed Biases Against Women
AI Research scientists at Amazon uncovered biases against women on their recruiting machine learning engine

By Roberto Iriondo Email

The AI research team had been building a recruiting machine-learning based engine since 2014, it took care of reviewing applicant’s resumes with the aim of intelligently automatizing the search for top talent.
Quoting an AI research scientist on the team: “Everyone wanted this Holy Grail,” one of the people said. “They literally wanted it to be an engine where I’m going to give you 100 resumes, it will spit out the top five, and we’ll hire those.” However, by 2015, Amazon realized its new system was not rating candidates for software developer jobs and other technical posts in a gender-neutral way.
Amazon’s recruiting machine learning model was trained to vet applicants by analyzing certain parameters in resumes submitted to the company over a 10-year period. Due to the biases that the machine learning model had, most ideal candidates were generated as men, which is a reflection of the male dominance across the tech industry — therefore the data fed to the model was not unbiased towards gender equality but au contraire.
Amazon’s research team states that they modified the central algorithms and made the machine learning model neutral to these gender biases, however that was not a guarantee that the engine would not device other ways of sorting candidates (i.e. male dominant keywords in applicant’s resumes) that could prove discriminatory.
Employers have long dreamed of harnessing technology to widen the hiring net and reduce reliance on subjective opinions of human recruiters. Nevertheless, ML research scientists such as Assistant Professor, Nihar Shah, whose research is in the areas of statistical learning theory and game theory, with a focus on learning from people at the Machine Learning Department at Carnegie Mellon University, says there is still much work to do.
“How to ensure that the algorithm is fair, how to make sure the algorithm is really interpretable and explainable — that’s still quite far off,” Professor Shah mentioned.
 Credits: Han Huang | Data Visualization Developer | Reuters Graphics
Masculine dominant keywords on resumes were pivotal after the modification of the algorithms on the machine learning models from Amazon’s recruiting engine. The research group created 500 models that focused on specific job functions and locations. They taught each to recognize over 50,000 parameters that showed up on applicants’ resumes. The algorithms ultimately learned to assign a low percentage of significance towards skills that were common across all applicants, i.e. programming languages, platforms used, etc.
It is important for our society to continue with the focus towards machine learning, but with special attention to biases — which, sometimes are unconsciously added to these programs. Thankfully Amazon’s AI research team was able to recognize such biases and act upon it.
Full article, along references can be found on Medium.
",,,,,,,,,,,,,,,,,,,,,
https://news.google.com/rss/articles/CBMilQFodHRwczovL3d3dy5mb3JiZXMuY29tL3NpdGVzL2VsYW5hZ3Jvc3MvMjAxOC8xMC8wOC9ob3ctdGhpcy1tb3RoZXItZGF1Z2h0ZXItZHVvLWNyZWF0ZWQtYW4tYXJ0aWZpY2lhbC1pbnRlbGxpZ2VuY2UtYmFzZWQtZXhlY3V0aXZlLWNvYWNoaW5nLXBsYXRmb3JtL9IBAA?oc=5,A Mother-Daughter Duo Creates An Artificial Intelligence-Based Executive Coaching Platform - Forbes,2018-10-08,Forbes,https://www.forbes.com,"There is a fear that artificial intelligence will eliminate jobs, but these cofounders hope to use it to create executive coaching relationships that make people better at their jobs. LeaderEQ uses artificial intelligence-based technology to match coaches and executives and host virtual sessions.",,"There is a fear that artificial intelligence will eliminate jobs, but these cofounders hope to use it to create executive coaching relationships that make people better at their jobs. LeaderEQ uses artificial intelligence-based technology to match coaches and executives and host virtual sessions.","There is a fear that artificial intelligence will eliminate jobs, but these cofounders hope to use it to create executive coaching relationships that make people better at their jobs. LeaderEQ uses artificial intelligence-based technology to match coaches and executives and host virtual sessions.",http://schema.org,BreadcrumbList,https://www.forbes.com/sites/elanagross/2018/10/08/how-this-mother-daughter-duo-created-an-artificial-intelligence-based-executive-coaching-platform/,"{'@type': 'ImageObject', 'url': 'https://imageio.forbes.com/blogs-images/elanagross/files/2018/10/LeaderEQ.jpeg?format=jpg&height=900&width=1600&fit=bounds', 'width': 542.79, 'height': 304.6}","{'@type': 'Person', 'name': 'Elana Lyn Gross', 'url': 'https://www.forbes.com/sites/elanagross/', 'description': ""I'm a journalist and the author of What Next?: Your Five-Year Plan for Life After College published by Simon & Schuster. I have a master’s degree in journalism from Columbia University and live in New York City."", 'sameAs': ['https://www.linkedin.com/in/elanalyngross', 'https://www.twitter.com/ElanaLyn']}","{'@type': 'NewsMediaOrganization', 'name': 'Forbes', 'url': 'https://www.forbes.com/', 'ethicsPolicy': 'https://www.forbes.com/sites/forbesstaff/article/forbes-editorial-values-and-standards/', 'logo': 'https://imageio.forbes.com/i-forbesimg/media/amp/images/forbes-logo-dark.png?format=png&height=455&width=650&fit=bounds'}",A Mother-Daughter Duo Creates An Artificial Intelligence-Based Executive Coaching Platform,2018-10-08T05:00:00-04:00,2018-10-10T14:16:11-04:00,ForbesWomen,A Mother-Daughter Duo Creates An Artificial Intelligence-Based Executive Coaching Platform,True,"[{'@type': 'ListItem', 'position': 1, 'name': 'Forbes Homepage', 'item': 'https://www.forbes.com/'}, {'@type': 'ListItem', 'position': 2, 'name': 'Business', 'item': 'https://www.forbes.com/business/'}]",ForbesWomen,N/A,"More From ForbesAug 27, 2019,04:42pm EDTRobots Are Actually Teaching Humans To Be More CompassionateAug 26, 2019,09:52am EDTAI Tests A 200-Year-Old Evolutionary TheoryAug 23, 2019,10:48am EDTAI Making Waves In News And JournalismAug 23, 2019,07:30am EDTHow Artificial Intelligence Is Preventing Cognitive Overload, Compassion Fatigue And Job BurnoutAug 21, 2019,10:34am EDTExplainable AI Could Help Us Audit AI Startup ClaimsAug 21, 2019,02:20am EDTArtificial Intelligence Beyond The Buzzword From Two Fintech CEOsAug 20, 2019,05:46pm EDTWhat Is Artificial Intelligence?Edit StoryBusinessA Mother-Daughter Duo Creates An Artificial Intelligence-Based Executive Coaching PlatformElana Lyn GrossFormer ContributorOpinions expressed by Forbes Contributors are their own.I cover women in business.Click to save this article.You'll be asked to sign into your Forbes account.Got itOct 8, 2018,05:00am EDTUpdated Oct 10, 2018, 02:16pm EDTThis article is more than 5 years old.Tweet This What you think you cannot do is exactly what you can do – face your fears. Embrace your weird, that is what makes you, you.Share to FacebookShare to TwitterShare to LinkedinThere is a widespread fear that artificial intelligence will eliminate jobs, but these mother-daughter cofounders hope to use artificial intelligence to make people better at their jobs. LeaderEQ uses artificial intelligence-based technology to match coaches with executives and host virtual sessions on desktop or mobile.
""We brought on two neuroscientists to help build technology that would make matching coaches with executives faster,"" says Chessa Eskandanian-Yee, who started the company with her mother Katherine Eskandanian-Yee. On Oct. 8, 2018, they launched LeaderEQ, which they say matches executives and coaches in five to ten minutes based on their past experience, work habits, personality, culture and values. I spoke to the cofounders in advance of LeaderEQ's launch.









Katherine Eskandanian-Yee and Chessa Eskandanian-Yee, the mother-daughter cofounders of LeaderEQ.
Courtesy of LeaderEQ





Elana Lyn Gross: How did you decide to go into business together, and what inspired you to start LeaderEQ?
Katherine Eskandanian-Yee: I’ve never treated [Chessa Eskandanian-Yee] like a child, I’ve always trusted her immensely, and that trust we have with each other, you cannot find with a stranger. It is unconditional trust. We’ve always had synergy, but we’re not the same people, and we have different ideas.
PROMOTED
When [Chessa Eskandanian-Yee] was growing up, she watched me coach and guide my clients and candidates through different challenges and learned so much from observation. When she graduated from college, we knew we wanted to work together, and we wanted to create a high-touch coaching service that reached a lot of people, without losing that personal and high-quality aspect. This was really [Chessa Eskandanian-Yee's] brainchild.
Chessa Eskandanian-Yee: Like my mom said, we’re not the same people, but we do often joke that we share a brain. My mom has always been my best friend. We love each other and, from that, we realized we work really well together. We understand each other’s work habits. It also helps that since I am her daughter, she can’t stay mad at me.
Gross: What is LeaderEQ’s mission? How is it different than other executive coaching companies or platforms?
Chessa Eskandanian-Yee: The real goal behind LeaderEQ is to help executives not feel lonely at the top. Every executive we’ve met says that at some point, they have felt that way. We want to make today’s leaders feel secure in who they are and match them with coaches that they can create a trusted relationship with so we can help them put their best foot forward. It’s almost like a dating service, we want to be a matchmaker for them. Coaching is an extremely personal experience, and it’s really important that we treat it that way.









DailyDozen
US


Forbes Daily: Join over 1 million Forbes Daily subscribers and get our best stories, exclusive reporting and essential analysis of the day’s news in your inbox every weekday.




                Sign Up
            


By signing up, you agree to receive this newsletter, other updates about Forbes and its affiliates’ offerings, our Terms of Service (including resolving disputes on an individual basis via arbitration), and you acknowledge our Privacy Statement. Forbes is protected by reCAPTCHA, and the Google Privacy Policy and Terms of Service apply.




You’re all set! Enjoy the Daily!


                More Newsletters
            


You’re all set! Enjoy the Daily!

                More Newsletters
            



Katherine Eskandanian-Yee: With my recruitment company Agency360, we are recruiters and advisors to businesses. We were shaping the culture of a company through the people we brought on. The part we saw was missing from this was that we were not able to stay a permanent guide with those individuals or companies through transitions. For example, one of our recruitment clients went through an acquisition. Through that, we saw a lot of mistakes that the leadership team made around communication with employees, which caused a mass exodus. We realized that if we would have been able to make this a more involved relationship, we would have been there to guide them through it and teach them how to deliver the messages in a way that employees understood. They are actually now a LeaderEQ client. That’s why we started LeaderEQ. We wanted to create relationships that last so that coaches could help executives through every stage of their career.
Gross: Does being mother-daughter business owners give you any sort of advantage? Does the dynamic present any challenges?
Katherine Eskandanian-Yee: I think our goals and visions are aligned. When I started my last company, I had two other partners and our visions were not aligned. And that’s why we went our separate ways. You cannot always find that alignment with people. I think our customers also get an advantage from us being related because they know we’re coming from the same place and we're always talking to one another.
Chessa Eskandanian-Yee: It’s a lot of just understanding each other. We can bounce ideas off each other freely without fear of judgment or too much conflict. It’s not weird to call your mom at midnight in a panic about something, but it might be to call your business partner. It’s just this basic level of trust and understanding that would take two strangers much longer to build. We had a leg up from the get-go.
It’s not always sunny, and we don’t always agree. But we always work through it.
Gross: What is the best advice you've ever received?
Chessa Eskandanian-Yee: Make sure you invest in relationships with people that light a fire in you. In high school, I had a teacher that was always pushing me beyond my limits and encouraging me to reach my top potential. She empowered me to keep stepping outside of my comfort zone and to face anything that I was afraid of doing.
Katherine Eskandanian-Yee: No mountain is too high. I have a yoga teacher that is much younger than me, and she had me do a move that I just did not think I could even try. She said, “Your body is a Mercedes Benz, and you just need to learn how to drive it.” Don’t undermine yourself. The power of the mind is something to be aware of.  What you think you cannot do is exactly what you can do – face your fears. And that’s the purpose of a coach, to push you to that limit. Just like you need a trainer at the gym to force you to do that extra set, coaches help you reach your full potential.
Gross: What is your business advice for other young professional women?
Chessa Eskandanian-Yee: Don’t let limitations of the mind scare you. If someone thinks you cannot do something, show them you can. There really should be nothing in your life that limits you.  Embrace your weird, that is what makes you, you.
Katherine Eskandanian-Yee: Speak up. It’s our time as women. It’s time for women to shine. It’s time for female founders. It’s time for us to question limitations society has put upon us for many years. We have to stand up, and we have to have our voices heard. This is the time for the female voice to be heard on every platform – our time is now.
Responsibility also lies with parents to raise young women who understand that they can do anything. We need to take away that traditional box we have for boys and girls. Stop automatically giving girls dolls, give them something to build. We don’t have enough female engineers in this world. We have to stop putting limitations on each other. Gender should not be the reason to hold someone back from reaching their full potential. For this business specifically, it’s about turning your weakness into your strength and defying stereotypes.Follow me on Twitter or LinkedIn. Check out some of my other work here. Elana Lyn GrossI'm a journalist and the author of What Next?: Your Five-Year Plan for Life After College published by Simon & Schuster. I have a master’s degree in... Read MoreEditorial StandardsPrintReprints & Permissions",,,,,,,,,,,,,,,,,,,,,
https://news.google.com/rss/articles/CBMiUmh0dHBzOi8vcXouY29tLzE0MTkyMjgvYW1hem9ucy1haS1wb3dlcmVkLXJlY3J1aXRpbmctdG9vbC13YXMtYmlhc2VkLWFnYWluc3Qtd29tZW7SAQA?oc=5,Amazon's “holy grail” recruiting tool was actually just biased against women - Quartz,2018-10-10,Quartz,https://qz.com,Women's colleges and clubs were penalized by the algorithm.,[],Women's colleges and clubs were penalized by the algorithm.,Women's colleges and clubs were penalized by the algorithm.,http://schema.org,NewsArticle,https://qz.com/1419228/amazons-ai-powered-recruiting-tool-was-biased-against-women,"{'@type': 'ImageObject', 'height': 675, 'width': 1200, 'url': 'https://i.kinja-img.com/image/upload/c_fill,h_675,pg_1,q_80,w_1200/f705f5f6e4d896521125859886d642b7.jpg', 'thumbnail': {'@type': 'ImageObject', 'height': 180, 'width': 320, 'url': 'https://i.kinja-img.com/image/upload/c_fill,h_180,pg_1,q_80,w_320/f705f5f6e4d896521125859886d642b7.jpg'}}","[{'@type': 'Person', 'name': 'Dave Gershgorn'}]","{'@type': 'Organization', '@context': 'http://schema.org', 'name': 'Quartz', 'url': 'https://qz.com', 'logo': {'@type': 'ImageObject', 'width': 500, 'url': 'https://x.kinja-static.com/assets/images/logos/newsletter/quartz-500px.png'}, 'sameAs': ['https://www.facebook.com/quartznews', 'https://www.youtube.com/channel/UC9f78Z5hgtDt0n8JWyfBk8Q', 'https://twitter.com/qz', 'https://instagram.com/qz']}",Amazon’s “holy grail” recruiting tool was actually just biased against women,2018-10-10T10:00:41-04:00,2022-07-20T19:42:38-04:00,,,False,,N/A,N/A,N/A,,"From 2014 until 2017, Amazon tried to build a tool that used artificial intelligence to rate the best job candidates like products on its website, from one to five stars, according to a new report from Reuters.

But a year into the project, the programers realized that the algorithmic system wasn’t good at identifying people’s job potential: It was just good at identifying men.

Artificial intelligence systems like the one Amazon tried to build typically require lots of data to learn. Gigabytes of image data are needed to train an algorithm to distinguish between a picture of a cat and a horse, and similarly Amazon’s algorithm would have needed historical data to tell what was desirable in a job candidate.

“Everyone wanted this holy grail,” one of the Amazon employees Reuters interviewed said. “They literally wanted it to be an engine where I’m going to give you 100 resumes, it will spit out the top five, and we’ll hire those.”

That’s where the bias crept in, according to Reuters. The team decided to train the system on the previous 10 years of resumes sent to Amazon, which were mostly men. When the algorithm reached its conclusions for what would be good and what would be bad in an applicant, it mirrored the hiring biases towards men that Amazon had shown in the past. In 2014, Amazon released diversity numbers that revealed 63% of Amazon employees were male, and that number grew to 75% when only looking at managers.

The algorithmic system went so far as to penalize the word “women” on a resume, as in a women’s club or sport, and downgraded all-women’s colleges as less preferable. Amazon reportedly tried to make the algorithm more neutral, but there was no guarantee that it actually was less biased.

The algorithm was also just not very good: It would recommend jobs for applicants where they had no expertise or applicable skills. Amazon reportedly shut down the project after coming to this conclusion.

“This was never used by Amazon recruiters to evaluate candidates,” an Amazon spokesperson told Quartz.

This is far from the first example of an artificial intelligence system that only mirrors the biases found in its training data. The idea has been brought up in testimony to the US Congress, and has been acknowledged by tech companies like Google, IBM, and Microsoft. Bias along gender, ethnicity, and geographic lines have even been seen in healthcare applications of the technology.

Yet for all the discussion, there are no best practices or industry guidelines for developing AI technology without biases. That could change in the near future, though, as details about algorithms like Amazon’s are revealed amid growing congressional scrutiny into whether facial recognition and forms of AI making governmental decisions could break civil rights laws.

Update (Oct. 11): This story has been updated to include a comment from an Amazon spokesperson.

",,,,"{'@type': 'WebPage', 'url': 'https://qz.com/1419228/amazons-ai-powered-recruiting-tool-was-biased-against-women'}",,,,,,,,,,,,,10/10/2018 at 10:00,"{'@type': 'WebPageElement', 'isAccessibleForFree': 'False', 'cssSelector': '.js_regwalled-content'}",[]
https://news.google.com/rss/articles/CBMiYWh0dHBzOi8vd3d3LmVxdWlwbWVudGpvdXJuYWwuY29tL3RlY2gtbmV3cy9ib2JjYXQtZXhwbG9yZXMtaW5jb3Jwb3JhdGluZy1hcnRpZmljaWFsLWludGVsbGlnZW5jZS_SAWVodHRwczovL3d3dy5lcXVpcG1lbnRqb3VybmFsLmNvbS90ZWNoLW5ld3MvYm9iY2F0LWV4cGxvcmVzLWluY29ycG9yYXRpbmctYXJ0aWZpY2lhbC1pbnRlbGxpZ2VuY2UvYW1wLw?oc=5,Bobcat explores incorporating artificial intelligence - Equipment Journal,2018-10-10,Equipment Journal,https://www.equipmentjournal.com,Doosan Bobcat North America is exploring the notion of incorporating Artificial Intelligence (AI) into its Bobcat equipment.,N/A,Doosan Bobcat North America is exploring the notion of incorporating Artificial Intelligence (AI) into its Bobcat equipment.,Doosan Bobcat North America is exploring the notion of incorporating Artificial Intelligence (AI) into its Bobcat equipment.,https://schema.org,,,,,,,,,,,,,Tech,N/A,"

Tech

Bobcat explores incorporating artificial intelligence

October 10, 2018 




FacebookTwitterLinkedinEmail




Doosan Bobcat North America is exploring the notion of incorporating Artificial Intelligence (AI) into its Bobcat equipment.
In order to study incorporating advanced AI, Doosan Bobcat North America has partnered with SafeAI – a startup company located in Silicon Valley.
Through the pilot program, SafeAI plans to demonstrate how the latest AI technologies, Deep Neural Networks (DNN) and Deep Reinforcement Learning (DRL), can be used to perceive complex dynamic environments around equipment and provide automated control.
“At SafeAI we are building a safe, AI-enabled autonomous platform for the equipment industry,” said Dr. Bibhrajit Halder, CEO and co-founder of SafeAI. “We look forward to beginning our partnership with the global market leader in compact equipment.”





The partnership is part of Doosan Bobcat North America’s initiative to identify forward-looking solutions to help equipment owners and operators improve productivity.
“We live in an on-demand, highly connected world,” said Joel Honeyman, vice president of global innovation at Doosan Bobcat North America.
“The customers who purchase our machines expect to have the latest and greatest technology at their fingertips. Through our partnership with SafeAI, we hope to work toward our ultimate goal of enabling our customers to work more efficiently on the job site.”
RELATED:


Doosan and Bobcat separate to boost North American market share


Doosan Bobcat North America president announces retirement


Bobcat helps contractor showcase First Nation traditions


Due to recent progress in autonomous and artificial intelligence technology, SafeAI believes the heavy equipment industry “is on the cusp” of fundamental change.
The SafeAI platform aims to enables transformational change in the industry by:

Improving safety – assisting or removing people from hazardous environments.
Increasing productivity – greater equipment utilization and task optimization.
Reducing operational cost – implementing fleet management systems that orchestrate tasks and equipment.

SafeAI combines AI technology with the safety and production rigor needed in the equipment industry.
 
EmailLinkedInTwitterFacebookShare








TAGSArtificial IntelligenceBobcatDoosan 
FacebookTwitterLinkedinEmail

 Previous articleNorth America is facing a road salt shortageNext articleWITOS: Paving the way for big data Editor  
",,,,,,,"[{'@type': 'Article', '@id': 'https://www.equipmentjournal.com/tech-news/bobcat-explores-incorporating-artificial-intelligence/#article', 'isPartOf': {'@id': 'https://www.equipmentjournal.com/tech-news/bobcat-explores-incorporating-artificial-intelligence/'}, 'author': {'name': 'Editor', '@id': 'https://www.equipmentjournal.com/#/schema/person/910ca6678603bf90cf188c7fa1fe8906'}, 'headline': 'Bobcat explores incorporating artificial intelligence', 'datePublished': '2018-10-10T19:58:20+00:00', 'dateModified': '2018-10-10T19:58:20+00:00', 'mainEntityOfPage': {'@id': 'https://www.equipmentjournal.com/tech-news/bobcat-explores-incorporating-artificial-intelligence/'}, 'wordCount': 309, 'publisher': {'@id': 'https://www.equipmentjournal.com/#organization'}, 'image': {'@id': 'https://www.equipmentjournal.com/tech-news/bobcat-explores-incorporating-artificial-intelligence/#primaryimage'}, 'thumbnailUrl': 'https://www.equipmentjournal.com/wp-content/uploads/2018/10/Artificial-Intelligence-.jpg', 'keywords': ['Artificial Intelligence', 'Bobcat', 'Doosan'], 'articleSection': ['Tech'], 'inLanguage': 'en-CA', 'copyrightYear': '2018', 'copyrightHolder': {'@id': 'https://www.equipmentjournal.com/#organization'}}, {'@type': 'WebPage', '@id': 'https://www.equipmentjournal.com/tech-news/bobcat-explores-incorporating-artificial-intelligence/', 'url': 'https://www.equipmentjournal.com/tech-news/bobcat-explores-incorporating-artificial-intelligence/', 'name': 'Bobcat explores incorporating artificial intelligence - Equipment Journal', 'isPartOf': {'@id': 'https://www.equipmentjournal.com/#website'}, 'primaryImageOfPage': {'@id': 'https://www.equipmentjournal.com/tech-news/bobcat-explores-incorporating-artificial-intelligence/#primaryimage'}, 'image': {'@id': 'https://www.equipmentjournal.com/tech-news/bobcat-explores-incorporating-artificial-intelligence/#primaryimage'}, 'thumbnailUrl': 'https://www.equipmentjournal.com/wp-content/uploads/2018/10/Artificial-Intelligence-.jpg', 'datePublished': '2018-10-10T19:58:20+00:00', 'dateModified': '2018-10-10T19:58:20+00:00', 'description': 'Doosan Bobcat North America is exploring the notion of incorporating Artificial Intelligence (AI) into its Bobcat equipment.', 'breadcrumb': {'@id': 'https://www.equipmentjournal.com/tech-news/bobcat-explores-incorporating-artificial-intelligence/#breadcrumb'}, 'inLanguage': 'en-CA', 'potentialAction': [{'@type': 'ReadAction', 'target': ['https://www.equipmentjournal.com/tech-news/bobcat-explores-incorporating-artificial-intelligence/']}]}, {'@type': 'ImageObject', 'inLanguage': 'en-CA', '@id': 'https://www.equipmentjournal.com/tech-news/bobcat-explores-incorporating-artificial-intelligence/#primaryimage', 'url': 'https://www.equipmentjournal.com/wp-content/uploads/2018/10/Artificial-Intelligence-.jpg', 'contentUrl': 'https://www.equipmentjournal.com/wp-content/uploads/2018/10/Artificial-Intelligence-.jpg', 'width': 1080, 'height': 640}, {'@type': 'BreadcrumbList', '@id': 'https://www.equipmentjournal.com/tech-news/bobcat-explores-incorporating-artificial-intelligence/#breadcrumb', 'itemListElement': [{'@type': 'ListItem', 'position': 1, 'name': 'Home', 'item': 'https://www.equipmentjournal.com/'}, {'@type': 'ListItem', 'position': 2, 'name': 'Bobcat explores incorporating artificial intelligence'}]}, {'@type': 'WebSite', '@id': 'https://www.equipmentjournal.com/#website', 'url': 'https://www.equipmentjournal.com/', 'name': 'Equipment Journal', 'description': 'Heavy equipment news delivered since 1966', 'publisher': {'@id': 'https://www.equipmentjournal.com/#organization'}, 'potentialAction': [{'@type': 'SearchAction', 'target': {'@type': 'EntryPoint', 'urlTemplate': 'https://www.equipmentjournal.com/?s={search_term_string}'}, 'query-input': 'required name=search_term_string'}], 'inLanguage': 'en-CA'}, {'@type': 'Organization', '@id': 'https://www.equipmentjournal.com/#organization', 'name': 'Equipment Journal', 'url': 'https://www.equipmentjournal.com/', 'logo': {'@type': 'ImageObject', 'inLanguage': 'en-CA', '@id': 'https://www.equipmentjournal.com/#/schema/logo/image/', 'url': 'https://www.equipmentjournal.com/wp-content/uploads/2023/03/ej-logo-696x696-1.png', 'contentUrl': 'https://www.equipmentjournal.com/wp-content/uploads/2023/03/ej-logo-696x696-1.png', 'width': 696, 'height': 696, 'caption': 'Equipment Journal'}, 'image': {'@id': 'https://www.equipmentjournal.com/#/schema/logo/image/'}, 'sameAs': ['https://www.facebook.com/EquipmentJournal/', 'https://x.com/EquipJournal', 'https://www.instagram.com/equipmentjournal/', 'https://ca.linkedin.com/company/equipment-journal', 'https://www.youtube.com/user/EQJnews']}, {'@type': 'Person', '@id': 'https://www.equipmentjournal.com/#/schema/person/910ca6678603bf90cf188c7fa1fe8906', 'name': 'Editor', 'sameAs': ['https://www.equipmentjournal.com', 'https://www.facebook.com/EquipmentJournal/', 'https://www.instagram.com/equipmentjournal/', 'https://www.linkedin.com/company/equipment-journal', 'https://x.com/https://twitter.com/EquipJournal', 'https://www.youtube.com/user/EQJnews'], 'url': 'https://www.equipmentjournal.com/author/editor/'}]",,,,,,,,,,,,,,

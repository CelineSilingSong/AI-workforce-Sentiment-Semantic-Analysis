URL link,Title,Date,Source,Source Link,description,keywords,og:description,twitter:description,@context,@type,mainEntityOfPage,headline,image,datePublished,dateModified,author,publisher,name,dateCreated,article:section,article:summary,article text,url,articleSection,isAccessibleForFree,itemListElement,@graph,articleBody,isBasedOn,thumbnailUrl,isPartOf,alternativeHeadline,creator,identifier
https://news.google.com/rss/articles/CBMiSWh0dHBzOi8vd3d3LmNvZS5pbnQvZW4vd2ViL2FydGlmaWNpYWwtaW50ZWxsaWdlbmNlLy0vc2Vjb25kLWNhaGFpLXBsZW5hLTHSAQA?oc=5,Second plenary meeting of the Ad Hoc Committee on Artificial Intelligence (CAHAI) - Artificial Intelligence - Council of Europe,2020-07-03,Council of Europe,https://www.coe.int,Latest news of the Council of Europe's work related to AI,"newsroom,ai,dg1 human rights and rule of law,central division dg1,public,compulsory,general, news, ai, council of europe",Latest news of the Council of Europe's work related to AI, Strasbourg 06-08 July 2020,https://schema.org,WebPage,"{'@type': 'WebPage', '@id': 'https://www.coe.int/en/web/artificial-intelligence/-/second-cahai-plena-1'}",Second plenary meeting of the Ad Hoc Committee on Artificial Intelligence (CAHAI),"{'@type': 'ImageObject', 'url': 'https://www.coe.int/documents/40452431/43029712/CAHAI+Plenary+2.png/6061cb8a-2d53-fe91-4186-89d77d4a60bb', 'height': 489, 'width': 870}",2020-07-03T16:28:00+00:00,2024-05-17,"{'@type': 'Organization', 'name': 'Council of Europe'}","{'@type': 'Organization', 'name': 'Council of Europe', 'logo': {'@type': 'ImageObject', 'url': 'https://static.coe.int/pics/logos/desktop/logo-coe-google-news.png', 'width': 78, 'height': 60}}",News,2018-11-28,N/A,N/A,"

Strasbourg
06-08 July 2020


                Diminuer la taille du texte
            

                Augmenter la taille du texte
            

                Imprimer la page
            




© Shutterstock/Council of Europe

The second plenary meeting of the Ad Hoc Committee on Artificial Intelligence (CAHAI) will be held from 6 to 8 July 2020, bringing together representatives of the 47 Council of Europe member states, observer states (Canada, Holy See, Israel, Japan, Mexico, USA) as well as civil society, academia and the Council of Europe's Internet partners. 
The CAHAI observer group is expanding with the participation for the first time of Israel and 12 new stakeholders. Other international organisations (EU, OECD, UNESCO) will also contribute to CAHAI’s work. 
CAHAI members will make concrete proposals on the feasibility study of a future legal framework on artificial intelligence (AI) based on human rights, democracy and the rule of law. In this connection, they will address issues such as the mapping of legal instruments applicable to AI and the opportunities and risks arising from the design, development and application of AI on human rights, rule of law and democracy, which have already been subject of a preliminary analysis.
Other issues such the scope and main elements of the above-mentioned legal framework will also be discussed.
This will provide the necessary impetus for the preparation of the first draft of the feasibility study, which will be presented at the CAHAI plenary meeting in December 2020.
 
Relevant resources:

Draft Agenda

",,,,,,,,,,,,
https://news.google.com/rss/articles/CBMiUWh0dHBzOi8vd3d3LmNpby5jb20vYXJ0aWNsZS8xOTM2NzMvOS1lbWVyZ2luZy1qb2Itcm9sZXMtZm9yLXRoZS1mdXR1cmUtb2YtYWkuaHRtbNIBUWh0dHBzOi8vd3d3LmNpby5jb20vYXJ0aWNsZS8xOTM2NzMvOS1lbWVyZ2luZy1qb2Itcm9sZXMtZm9yLXRoZS1mdXR1cmUtb2YtYWkuaHRtbA?oc=5,9 emerging job roles for the future of AI - CIO,2020-07-02,CIO,https://www.cio.com,Artificial intelligence is fast proving a business differentiator. Here are the key roles and skills you may soon need to fill for your AI A-team.,N/A,Artificial intelligence is fast proving a business differentiator. Here are the key roles and skills you may soon need to fill for your AI A-team.,Artificial intelligence is fast proving a business differentiator. Here are the key roles and skills you may soon need to fill for your AI A-team.,,,,,,,,,,,,N/A,N/A,"










		Artificial intelligence is fast proving a business differentiator. Here are the key roles and skills you may soon need to fill for your AI A-team.	




 
Credit: laremenko / Getty Images








AI is poised to transform nearly every industry, and with it will come significant changes for many job functions. Many roles across organizations will require at least some use of artificial intelligence technologies in the coming years, creating massive new opportunities for the AI-savvy regardless of discipline.
Alongside this transformation of how many IT and business staff do their work will be the emergence of new jobs targeted at making the most of organizational AI strategies. Machine learning engineers have already cemented their place as must-have members of AI teams, taking first place in Indeed’s best jobs list last year. AI specialist was also the top job in LinkedIn’s 2020 Emerging Jobs report, with 74 percent annual growth in the last four years, followed by robots engineer and data scientist.
[ Cut through the hype with our practical guide to machine learning in business and find out the 10 signs you’re ready for AI — but might not succeed. | Get the latest insights with our CIO Daily newsletter. ]
 
 
 













 
 

In fact, even during the pandemic, the number of AI-related jobs could increase globally by 13 to 16 percent, according to IDC analyst Ritu Jyoti.

More Videos0 seconds of 59 minutes, 43 secondsVolume 0%Press shift question mark to access a list of keyboard shortcutsKeyboard ShortcutsEnabledDisabledShortcuts Open/Close/ or ?Play/PauseSPACEIncrease Volume↑Decrease Volume↓Seek Forward→Seek Backward←Captions On/OffcFullscreen/Exit FullscreenfMute/UnmutemDecrease Caption Size-Increase Caption Size+ or =Seek %0-9
 


Next UpDEMO Northern Light08:41SettingsOffAutomated Captions - en-USFont ColorWhiteFont Opacity100%Font Size100%Font FamilyArialCharacter EdgeNoneBackground ColorBlackBackground Opacity50%Window ColorBlackWindow Opacity0%ResetWhiteBlackRedGreenBlueYellowMagentaCyan100%75%50%25%200%175%150%125%100%75%50%ArialCourierGeorgiaImpactLucida ConsoleTahomaTimes New RomanTrebuchet MSVerdanaNoneRaisedDepressedUniformDrop ShadowWhiteBlackRedGreenBlueYellowMagentaCyan100%75%50%25%0%WhiteBlackRedGreenBlueYellowMagentaCyan100%75%50%25%0%







Live00:0059:4359:43 

“Because of the pandemic, IDC believes that AI spending and employment will increase among healthcare providers, education, insurance, pharmaceutical companies and federal governments,” she says.
We reached out to IT leaders, AI experts, and industry analysts to get a sense of the kinds of AI roles they see emerging as AI takes firmer hold of the enterprise. Some leading-edge companies are already filling these positions, lending insight into the mix of skills necessary to succeed in them.
 
 
 













 
 

Chief AI officer
AI leadership roles fall under an array of titles: vice president of AI and machine learning, chief innovation officer, chief digital officer, and many more.
Whatever the name, these “chief AI officers” must understand how cognitive technologies impact the busines, develop the company’s AI strategy, and explain it to the board, company executives, employees, and customers. And they work with the CIO to implement this strategy to best meet the needs of the business and all stakeholders.
Nicole Eagan, chief AI officer at cybersecurity firm Darktrace, splits her time working with in-house technology teams, talking to customers, and evangelizing the firm’s AI strategy, which includes figuring out how to augment human efforts with AI, for example, in detecting and investigating threats.
 
 
 













 
 

“I work with the CTO and our AI lab to explore new areas for research and development,” says Eagan, who previously worked up the ranks of Oracle’s strategy group to become senior director of strategic marketing.






Explore related questions


What are the most in-demand AI job roles in the industry today?When will AI-related jobs surpass traditional IT jobs in demand?Who is responsible for developing an organization's AI strategy?Will AI replace human workers in the near future?Does AI require a high level of technical expertise to implement?





Ask




Eagan continuously augment her technical AI skills through online classes, but her role at Darktrace is more business-focused, applying AI to real-world problems, rather than creating algorithms and writing code. “We do have over 35 PhDs with advanced math, machine learning and AI expertise who are working in our labs,” she says.
Howie Xu, vice president of AI and machine learning at Zscaler, rose up the technical ranks, supplementing his experience with business skills. The former head of Cisco’s cloud and networking services business unit has an MBA from Stanford and a deep product background.
 
 
 













 
 

“When I first joined Zscaler, my role was more about the technology,” he says. “But in order to take full advantage of AI and ML, I had to evolve to think more about business impact.”
He recommends chief AI aspirants focus on areas where AI and ML can bring a ten-fold business value improvement to the table. “Be disciplined about the business metrics before the technology,” he says.
AI ethics officer
AI ethics officer is another high-level position that requires extensive work with stakeholders. The role may also cover risk and governance, and may need to coordinate with government agencies, nonprofits, legal teams, users, and privacy groups, in addition to technology teams.
 
 
 













 
 

Kathy Baxter, architect for ethical AI practice at Salesforce.com, says AI ethics officers must have a passion for technology but also a healthy skepticism. “AI is not magic and is not appropriate for every challenge. You need to frequently ask not just ‘can we do this?’ but ‘should we do this?'” says Baxter, who previously worked at Google, eBay and Oracle in user experience research.
Although technical literacy is extremely helpful, AI ethics officers do not need to be computer scientists or data scientists, she says. “What is more important is to have a humanistic background like psychology, sociology, philosophy, or human-computer interaction,” she says. “It is critical to focus on understanding everyone impacted by technology, their needs, context, and values.”
Baxter, who has a masters in human factors engineering and a bachelor’s in applied psychology, also credits the ability to de-escalate emotional debates as helpful. “When we talk about ethics, people can feel like their values are being challenged,” she says. “Being able to have healthy debates in an inclusive manner can be the difference between success and failure.”
 
 
 













 
 

Companies that pay attention to ethics when deploying AI create safer, more just environments, she says. Moreover, unbiased AI is more accurate and leads to better business performance.
“AI regulation is coming so creating an ethical AI practice now will better prepare you to be in compliance,” she adds.
AI business analyst
To reap value from AI models, data scientists must be paired with business analysts, says Shuman Ghosemajumder, global head of artificial intelligence at Shape Security, who has already hired someone from this role, and will be expanding the area over time.
 
 
 













 
 

“An AI business analyst should have a strong understanding of the company, its business model, and the business processes or product they are hoping to develop AI solutions for,” he says, adding that they also need to speak tech to work with data scientists and data engineers.

A related role, AI business operations manager, works on the business side to manage and improve business processes that use AI. “An AI business operations manager should have foundational knowledge in operations and experience in the particular business processes which are being automated through AI,” Ghosemajumder says.  They should also be able to analyze data generated by those operations.
Finding people to take on business-oriented AI roles may be harder than it sounds, says Anand Rao, partner and global AI leader at PricewaterhouseCoopers.
 
 
 













 
 

“Universities and other vocational training institutions are competing to train a number of entry-level technical jobs,” he says. “However, the business and executive jobs need to be grown and cultivated within the firm and will pose a significant challenge to fill.”
Chief data scientist
Typically the top technical AI job at a company, the chief data scientist role has been evolving to include more engineering and business skills.
“Data scientists five years ago were statisticians,” says Brian McCarthy, head of analytics transformation at McKinsey & Co. “What we’re seeing now is that data scientists come from more of a technology background.”
 
 
 













 
 

Data scientists know what data to use and what algorithms to deploy to get the best results, working with data engineers and software developers to turn this know-how into working applications — and with business units to ensure the technology meets business needs.
Michael Roytman, chief data scientist at Kenna Security, got his masters in operations research in 2012 at the Georgia Institute of Technology, where he studied stochastic processes and optimizations. He then signed on to be a data scientist at Kenna Security, where he eventually was promoted to chief data scientist.
“Chief data scientists are moving into applying their skills sets to enhance analytics capabilities across the organization,” he says.
 
 
 













 
 

AI architect
AI architects — also known as AI or ML engineers — are responsible for creating the systems to operate and manage AI and ML projects.
“These are people who can look at AI projects at scale,” says Steve Whittaker, head of strategic U.S. academic research partnerships at BT, and the head of its research partnership with MIT. IT architects who acquire AI and ML skills are good candidates for these jobs, he says.

“If you’re building an AI engineer platform, you need DevOps skills,” he says. “You need to know how to execute at scale, understand agile development, and have a sense of process and data.”
 
 
 













 
 

AI architect may also be responsible for rebuilding business processes, thus aligning them closer to the business.
Any company building its own AI or ML infrastructure will need AI architects or AI platform engineers. “It’s not just the Googles, Facebooks, and Amazons,” he says, adding that the recency of the role means that backgrounds vary widely, from new grads with new ideas, to people with 40 years of practical project management experience.
eSentire CTO Dustin Hillard expects ML engineers to have several years of experience working with large data sets and cloud data processing frameworks, and have the ability to design, build, and deploy complex AI systems.
 
 
 













 
 

AI data engineer
Both AI and machine learning live and die on data. But the data required can differ in kind and scale from that needed by other systems, so any organization that wants to perform advanced analytics, ML or AI will need an AI data engineer.

“Large organizations are the natural thing that springs to mind,” says Kevin Brown, managing director of security at BT, of the kinds of companies that should be looking to hire for this emerging role. “But also other organizations that have massive data. Health care, for example, is seeing exponential growth in data as a result of the pandemic.”
At BT, for example, the quantity of data processed is staggering. On the cybersecurity side, for example, there are millions of events per second, and about 4,000 cyberattacks per day. The company employs a managing director focusing solely on AI and strategy, Brown says, as well as AI developers, researchers, data scientists — a broad range of AI functions.
“We have a vast amount of data that we quickly need to sift through to find the anomalies,” he says, and this is where AI data engineers come in. “We’re always looking for the needle in the haystack.”
 
 
 













 
 

Data manufacturing architect
Companies in the data business offer even more specialized roles. For example, Bloomberg recently hired someone to fill a new role of data manufacturing architect on its CTO Data Science team.
The data manufacturing architect helps Bloomberg create high-quality structured data for its financial services customers, including more than 325,000 Bloomberg Terminal clients. The data comes out of unstructured, noisy sources, says Gideon Mann, head of data science, in Bloomberg’s Office of the CTO.
“These numbers must be precise and accurate, with standards beyond those of most industries and academics,” he says.
The data manufacturing architect works deep domain specialists in Bloomberg’s global data department, he says. Bloomberg is also hiring for a number of other specialized AI jobs right now, including AI research scientist, AI quantitative research scientist, human computation architect, senior ML engineer for media data science, and senior software engineer for distributed systems.
These roles require experience in AL, ML, natural language processing, information retrieval and quantitative finance, says Anju Kambadur, head of AI engineering at Bloomberg, and they should have expertise in programming languages such as Python, Java and C++. But communication, collaboration and product development skills are also important, he adds, “in particular the ability to work and communicate across organizational boundaries and across disciplines.”
AI quality assurance manager
Additional AI-related jobs are emerging to fill the needs of bleeding-edge companies, as they try to figure out how to allocate responsibilities around nascent AI practices. Some of these jobs don’t really exist yet on the job market, and most won’t have a standardized curriculum or typical career development path.
Take, for example, the emerging role of AI quality assurance manager, which could be viewed as evolving from a traditional software quality assurance job, but quality assurance for AI projects is dramatically different. The code itself is rarely the issue, for example, although a company may choose the wrong algorithm for the project at hand. What is more important are incomplete, out of date, or biased training data sets.
Biased data is a particularly thorny problem that can lead not only to bad results, but also regulatory implications, bad publicity, fines, or lawsuits.
“Nobody really understands how bias gets into the data, and how to try to get it out of the data,” says John O’Neil, chief data scientist at Edgewise Networks, recently acquired by Zscaler. “It’s an active area of research. As far as I know, there’s not a place you can go and say, here are the rules, and if you follow the rules, you’ll be okay.”
Citizen data scientist
According to Gartner, by 2024, AI power users will fill the talent gap for data scientists. These “citizen data scientists,” as Gartner calls them, will be able to perform AI-related tasks because the tools needed to deploy advanced analytics, machine learning and artificial intelligence will become easier and easier to use.
Don’t look for this as a job title, however. Instead, experience with “citizen data scientist” tools, such as Auto ML, will be part of job descriptions for a range of job functions.
“The traditional data scientists are expensive to hire, scale and train,” says Ryohei Fujimaki, CEO and founder at DotData, an AI platform company.
But around 28 percent of AI and machine learning initiatives have failed, according to IDC’s March survey, in large part due to skills shortages. “Lack of staff with necessary expertise is reported as one of the primary reasons for the failure,” IDC’s Jyoti says.
That means that there is pent-up demand for reskilling of workers for AI and ML skills, she says.
And more and more of a need for “citizen data scientists,” says DotData’s Fujimaki.
More on AI and machine learning:

 A practical guide to machine learning in business 
 Reskilling IT for the AI era 
 9 IT projects primed for machine learning 
 The future of ERP is AI 
 5 artificial intelligence trends that will dominate 2018 
 6 secrets of successful chatbot strategies 
 How AI is revolutionizing business productivity 
 Machine learning success stories: An inside look 
 9 machine learning myths 
 10 signs you’re ready for AI — but might not succeed 


















 
Related content

 


brandpost

							Sponsored by Broadcom						

Detecting cancer faster with optical innovation
Broadcom engineering innovation and next-generation technology come together to improve a host of sensor applications in areas no one thought possible. 

				By Martin Weigert, Vice President and General Manager, Industrial Fiber Products Division, Broadcom				


Jul 16, 2024

6 mins 


Healthcare Industry
Science Industry
Innovation






brandpost

							Sponsored by DataStax						

Is your data ready for AI?
Preparing your data for myriad AI applications is just as complicated as it sounds. Focusing on the wrong challenges will only make it more difficult. 

				By John Laffey				


Jul 16, 2024

7 mins 


Machine Learning
Artificial Intelligence






feature

The CIO role today: Change agents need only apply
CIOs have earned the right to be agents of change and leaders of business transformation for their organizations. All that’s left is the hard work of capitalizing on it. 

				By Grant Gross				


Jul 16, 2024

8 mins 


CIO
Digital Transformation
Change Management






opinion

Microsoft Recall: Everything IT can get wrong about AI in a single feature
Microsoft Recall may be built with artificial intelligence, but its building lacked judgment and wisdom — two things CIOs and IT teams must impart to get AI right. 

				By Bob Lewis				


Jul 16, 2024

6 mins 


Risk Management
Artificial Intelligence






PODCASTS


VIDEOS


RESOURCES


EVENTS













 
SUBSCRIBE TO OUR NEWSLETTER			

				From our editors straight to your inbox			

			Get started by entering your email address below.		


 



Please enter a valid email address




Subscribe









",,,,,,,,,,,,
https://news.google.com/rss/articles/CBMibWh0dHBzOi8vd3d3LmZvcmJlcy5jb20vc2l0ZXMvdG9tdGF1bGxpLzIwMjAvMDcvMDMvbGVtb25hZGUtaXBvLXNob3dzLXRoZS1wb3dlci1vZi1haS1hcnRpZmljaWFsLWludGVsbGlnZW5jZS_SAQA?oc=5,Lemonade IPO Shows The Power Of AI (Artificial Intelligence) - Forbes,2020-07-03,Forbes,https://www.forbes.com,"On its debut on Thursday, the shares soared by nearly 140%.
",,"On its debut on Thursday, the shares soared by nearly 140%.
","On its debut on Thursday, the shares soared by nearly 140%.
",http://schema.org,BreadcrumbList,,Lemonade IPO Shows The Power Of AI (Artificial Intelligence),"{'@type': 'ImageObject', 'url': 'https://imageio.forbes.com/specials-images/imageserve/5eff578f9756420007f6f6b9/0x0.jpg?format=jpg&crop=5616,3159,x0,y285,safe&height=900&width=1600&fit=bounds', 'width': 542.79, 'height': 304.6}",2020-07-03T12:22:57-04:00,2020-07-03T12:22:57-04:00,"{'@type': 'Person', 'name': 'Tom Taulli', 'url': 'https://www.forbes.com/sites/tomtaulli/', 'description': 'Tom (@ttaulli) is the author of Artificial Intelligence Basics: A Non-Technical Introduction ( https://amzn.to/2InAZeT) and The Robotic Process Automation Handbook: A Guide to Implementing RPA Systems ( https://amzn.to/2tURWJx)', 'sameAs': ['https://www.linkedin.com/in/tomtaulli', 'https://www.twitter.com/ttaulli', 'http://www.taulli.com/', 'ttaulli']}","{'@type': 'NewsMediaOrganization', 'name': 'Forbes', 'url': 'https://www.forbes.com/', 'ethicsPolicy': 'https://www.forbes.com/sites/forbesstaff/article/forbes-editorial-values-and-standards/', 'logo': 'https://imageio.forbes.com/i-forbesimg/media/amp/images/forbes-logo-dark.png?format=png&height=455&width=650&fit=bounds'}",Lemonade IPO Shows The Power Of AI (Artificial Intelligence),,Entrepreneurs,N/A,"More From ForbesJun 13, 2024,12:58pm EDTAmerica’s New Startup Boom Emerges In Legacy CitiesMay 6, 2024,09:43am EDTThe Future Of Entrepreneurship In IndiaMay 6, 2024,09:36am EDTDoha Dispatches: Katherine Maher, Loren Gray, AI Apps And MansplainingMar 5, 2024,08:26am ESTHRH Princess Lamia: Satellite Data Offers Way To Slow DeforestationFeb 27, 2024,12:23pm ESTThe Future Of Data Storytelling Is Augmented, Not AutomatedJan 31, 2024,10:25pm ESTAn Innovator Aims To Fix The U.S.’s Broken System Of Mother-Baby CareJan 31, 2024,10:04pm ESTWhen Does Pumped Breast Milk Go Bad? An Innovation From Real LifeEdit StoryForbesSmall BusinessEntrepreneursLemonade IPO Shows The Power Of AI (Artificial Intelligence)Tom TaulliFormer ContributorOpinions expressed by Forbes Contributors are their own.I write about tech & finance.Click to save this article.You'll be asked to sign into your Forbes account.Got itJul 3, 2020,12:22pm EDTUpdated Jul 3, 2020, 12:22pm EDTThis article is more than 4 years old.Share to FacebookShare to TwitterShare to LinkedinBusiness woman showing insurance document over white desk at officeGetty
After a hiatus because of the COVID-19 pandemic, the IPO market has come roaring back. Just look at yesterday’s offering for Lemonade (NYSE:LMND). The shares spiked by 139% to $69.41—putting the market cap at over $3 billion.


Part of the success has been the overall bullishness in the equities markets. But there is something else that is important: Lemonade is a next-generation AI company. The technology is all-pervasive across its operations.

The AI Foundation
Keep in mind that the insurance industry was actually the first industry that was data driven. The roots go back to 1662 when John Graunt helped to create modern statistics, which he used to calculate the probabilities for life expectancies for those living in London. The framework would lead to the creation of Lloyd's of London.

PROMOTED
The result is that the insurance industry has turned into one of the most valuable the world has ever seen. As of today, property, casualty and life premiums represent a whopping $5 trillion and account for 11% of the GDP in the US. 

Yet the insurance industry has lagged with AI, as the legacy IT systems have been a burden. So yes, Lemonade’s founders saw this as a huge opportunity. 
Here’s what the company has built:
MORE FOR YOUBlackRock CEO Issues ‘Massive’ Warning After Crypto Flip That Powered A Bitcoin, Ethereum And XRP Price BoomIngrid Andress’ National Anthem At 2024 Home Run Derby Draws Criticism OnlineApple iPhone 16 Pro Design Upgrade Promises Key Feature Boost, Report Says


AI Maya: This is an engaging virtual assistant that collects information, provides quotes and handles the payments. 
AI Jim: This is the claims bot. For the most part, he has been able to handle roughly a third of the cases. But even when a case is passed along to a human, the claim is generally much easier to work out because AI Jim has already done quite a bit of work on the matter. 
CX.AI: This is the bot that answers customer questions. 











DailyDozen
US


Forbes Daily: Join over 1 million Forbes Daily subscribers and get our best stories, exclusive reporting and essential analysis of the day’s news in your inbox every weekday.




                Sign Up
            


By signing up, you agree to receive this newsletter, other updates about Forbes and its affiliates’ offerings, our Terms of Service (including resolving disputes on an individual basis via arbitration), and you acknowledge our Privacy Statement. Forbes is protected by reCAPTCHA, and the Google Privacy Policy and Terms of Service apply.




You’re all set! Enjoy the Daily!


                More Newsletters
            


You’re all set! Enjoy the Daily!

                More Newsletters
            



“Lemonade’s revolutionary model has completely changed the way we think about an antiquated industry,” said Nick Liuzza, who is the CEO and co-founder of Beeline. “By implementing artificial intelligence and machine learning directly into its model, the company can keep its costs low and bring savings back to the customer—and this result rings true across many industries.”


1/1





Skip Ad
 
Continue watchingafter the adVisit Advertiser websiteGO TO PAGE
More Than About AI
Lemonade also has built something called the Forensic Graph, which uses AI and behavioral economics to predict, detect and block fraud. So far, the company has avoided millions in potential losses. 
“In the case of Lemonade, we’d expect the company’s loss ratio and customer acquisition cost to be superior to legacy insurance carriers as a result of its AI technology,” said Nima Wedlake, who is a Principal at Thomvest Ventures. “To date, that isn’t the case, though. For example, its loss ratio in Q1 2020 was about 80% vs. about a 50% industry average. However, Lemonade is still in its early days and I expect its unit economics to improve as the company scales. If Lemonade can prove that it is more effective at underwriting risk using AI vs. legacy approaches, I expect more carriers to adopt similar approaches. Many are already leveraging AI or ML as part of the underwriting process.”
Yet there are skeptics. In other words, AI may be more hype than substance.
“At best AI could only help the company improve its actuarially ability, not see into the future and predict loss, which is of course, by definition, unknowable,” said Kristopher Marsh, who is the editor of Discoverdando.com. “Otherwise there would be no need for insurance in the first instance. On the claims side, there may be some ability to automate payments, but this comes at the cost of leakage without human oversight. If the company can process information to an above average quality, there may be a slight pricing advantage. Otherwise, their true advantage lies is in being able to operate without high labor overhead—particularly in underwriting.”
Regardless, Lemonade does show that an immersive digital approach can be effective with customers. Besides, when it comes to AI, there continue to be many breakthroughs. The industry is still in the nascent stages.
“Lemonade’s successful IPO is about a new generation of digital insurance carriers coming to market and giving insurance incumbents, handicapped by technology constraints, a run for their money,” said Michael Yang, who is the Managing Partner at OMERS Ventures. “Lemonade is leveraging new consumer interactions and creating data sets that allow it to offer the right product to the right person on the right proportional risk basis that the incumbents can’t. Whether that’s through AI or not, or alternatively, through a pretty user experience or not, is less the material point. It’s that Lemonade eschews the traditional broker and agent channel and has a direct relationship with the insured, which affords it more flexibility to innovate.”
Tom (@ttaulli) is an advisor to startups and the author of Artificial Intelligence Basics: A Non-Technical Introduction and The Robotic Process Automation Handbook: A Guide to Implementing RPA Systems. He also has developed various online courses, such as for the Python programming language. 
Follow me on Twitter or LinkedIn. Check out my website or some of my other work here. Tom TaulliTom (@ttaulli) is the author of Artificial Intelligence Basics: A Non-Technical Introduction ( https://amzn.to/2InAZeT) and The Robotic Process... Read MoreEditorial StandardsPrintReprints & PermissionsThe video player is currently playing an ad. You can skip the ad in 5 sec with a mouse or keyboard
1/100:08Boston Dynamics Founder On The Need For AI And Hardware In Robotics Research





Skip Ad
 
Continue watchingBoston Dynamics Founder On The Need For AI And Hardware In Robotics Researchafter the adVisit Advertiser websiteGO TO PAGE",https://www.forbes.com/sites/tomtaulli/2020/07/03/lemonade-ipo-shows-the-power-of-ai-artificial-intelligence/,Entrepreneurs,False,"[{'@type': 'ListItem', 'position': 1, 'name': 'Forbes Homepage', 'item': 'https://www.forbes.com/'}, {'@type': 'ListItem', 'position': 2, 'name': 'Small Business', 'item': 'https://www.forbes.com/small-business/'}, {'@type': 'ListItem', 'position': 3, 'name': 'Entrepreneurs', 'item': 'https://www.forbes.com/entrepreneurs/'}]",,,,,,,,
https://news.google.com/rss/articles/CBMibWh0dHBzOi8vd3d3Lm5ld2NpdmlsZW5naW5lZXIuY29tL2lubm92YXRpdmUtdGhpbmtpbmcvYXJ0aWZpY2lhbC1pbnRlbGxpZ2VuY2UtdmlhLWhhcmQtaGF0LWNhbWVyYXMtMDYtMDctMjAyMC_SAQA?oc=5,Artificial intelligence via hard hat cameras - New Civil Engineer,2020-07-06,New Civil Engineer,https://www.newcivilengineer.com,Using technology to drive efficiencies and reduce costs on construction projects is not a new challenge. Construction has traditionally been seen as slow,N/A,Using technology to drive efficiencies and reduce costs on construction projects is not a new challenge. Construction has traditionally been seen as slow,N/A,https://schema.org,,,,,,,,,,,N/A,N/A,"



Technology firm Buildots is using artificial intelligence to help transform the industry’s approach to project delivery.
Using technology to drive efficiencies and reduce costs on construction projects is not a new challenge. Construction has traditionally been seen as slow on the uptake when it comes to engaging with new technologies and innovation. 
But there has undoubtedly been a shift in recent years. And the impact of the coronavirus pandemic has led businesses to increasingly explore how new technologies, like artificial intelligence (AI), machine learning and digital twins, can support the delivery of projects. 
 “There are a lot of industries that have adopted new technology in a much better, quicker and more efficient rate than construction,” says Buildots senior project manager Patrick Scannell. 
“Coronavirus has perhaps been the catalyst that the industry needed to be more tech aware and savvy. Now is the time to explore those different routes to adopting new technologies, and making that jump.”
The actual innovation is the software behind the analysis that we do on the videos recorded on site
Israel-based technology firm Buildots was founded in 2018. It focuses on helping businesses take that step and ultimately turn construction sites into fully digitised environments. Having recently expanded into Europe with a new London office, the company is hoping to drive the uptake of AI technology through its data platform. 



The platform has been designed to provide better control of construction processes and involves using hard hat-mounted 360° cameras to collect live information on site. This data is then processed using AI and is integrated into building information modelling (BIM) systems to create a digital twin of the construction site.
It is not necessary to wear the camera constantly during a shift on site, as data can be captured during regular quality control walkthroughs – usually between 30 minutes to one hour, once or twice a week, depending on the size of and activity on site. 
“But it’s not about the camera itself,” explains Buildots customer success manager Sophie Morris. “The actual innovation is the software behind the analysis that we do on the videos recorded on site.”
Data captured on site is uploaded to a Dropbox folder, which is then analysed by Buildots. The company uses visual coding, AI and machine learning to compare what is recorded in the videos with the BIM model. 
This analysis is then uploaded to a secure website which can be accessed by the client. 



The tool helps to provide a clear link between the model and the construction phase, providing better visibility of whether the design is accurately delivered on site.
The idea is that people still do their jobs, but they’re able to actually focus on the more complex decisions on site
“Basically, it’s a real time comparison of what is physically on site and what is supposed to be on site,” Morris says. “It points out where something is right or wrong, and how much progress has been made.”
The ability to virtually explore sites and keep track of the delivery of work has become ever more critical during the pandemic. 
“Staff who have had to work from home can use the tool to virtually walk through the construction site,” Scannell says. 
“In terms of added value, it helps site managers and project directors because they now have this huge amount of information that they can feed back to their clients and the
sub-contractors themselves.”
Scannell is keen to see the increase in flexible working patterns and engagement with new technologies continue beyond the pandemic. “It’s important that people don’t go back to old habits,” he says. 
For Buildots’ clients, the visual aspect of the tool and not having to physically be on site to check everything was a major benefit, pre-coronavirus. 
Lockdown business
“But during the lockdown, we’ve been getting calls from businesses saying ‘what else can you show us?’,” says Morris. 
The company is working closely with businesses to get a better understanding of what they need and how the tool can be adapted to meet those requirements. 
The team has recently helped to improve a client’s monthly payments process, for example. 
“We looked into what evidence – site photos or emails, etcetera – is needed to make those payments,” explains Morris. “With that understanding, we’ve created a tailored page in the system and we’re able to analyse the data for different trades on site and track the work that has been done in the last month.” 
“It’s taken away the need to walk through the site,” she adds. “We’re not coming up with any crazy information. We’re just giving the client the opportunity to remotely check something that they would traditionally have to go back out on site to check. 
“There’s so much data. We’re just tailoring it to the client’s needs.”
Not a staff replacement tool
But the tool is no replacement for staff. Morris insists the aim is not to take people away from construction sites but to make their work more efficient. “Buildots wouldn’t exist if people didn’t wear the camera,” she says. “The idea is that people still do their jobs, but they’re able to actually focus on the more complex decisions on site.”
While some site workers might fear the proliferation of digital tools, firms that resist engagement with new technologies risk getting left behind. 
Looking beyond the current pandemic, the tool has the scope to help contractors benchmark and have better visibility of performance and delivery across the supply chain. The data collected could provide useful insight into how subsequent projects are planned.
“We’re hoping contractors will see beyond just the profit margin for one individual project. If they roll [the Buildots tool] out, then as a company they’ll have a better understanding of how to function and improve on a bigger scale,” says Morris.
On average, Buildots collects around 80,000 images over the course of a project’s lifecycle. Scannell believes this mountain of data could open myriad opportunities to further improve efficiencies for clients. 
“The platform we started with in December has now advanced significantly. But it’s not a mature product yet,” he says. 
“We’re still growing. There’s so much more to come.”
Like what you've read? To receive New Civil Engineer's daily and weekly newsletters click here.

AI Artificial Intelligence 
							2020-07-06						

Nadine Buddoo 




Share

 Facebook
 Twitter
 Google +
 LinkedIn
 Pinterest

 Email


    Add to Bookmarks



 

",,,,,"[{'@type': 'WebSite', '@id': 'https://www.newcivilengineer.com/#website', 'url': 'https://www.newcivilengineer.com/', 'name': 'New Civil Engineer', 'description': 'Civil engineering and construction news and jobs from New Civil Engineer', 'potentialAction': [{'@type': 'SearchAction', 'target': {'@type': 'EntryPoint', 'urlTemplate': 'https://www.newcivilengineer.com/?s={search_term_string}'}, 'query-input': 'required name=search_term_string'}], 'inLanguage': 'en-GB'}, {'@type': 'ImageObject', '@id': 'https://www.newcivilengineer.com/innovative-thinking/artificial-intelligence-via-hard-hat-cameras-06-07-2020/#primaryimage', 'inLanguage': 'en-GB', 'url': 'https://emap-romulus-prod.s3.eu-west-1.amazonaws.com/wp-content/uploads/sites/9/2020/07/Buildots-4-crop.jpg', 'contentUrl': 'https://emap-romulus-prod.s3.eu-west-1.amazonaws.com/wp-content/uploads/sites/9/2020/07/Buildots-4-crop.jpg', 'width': 2697, 'height': 1798}, {'@type': 'WebPage', '@id': 'https://www.newcivilengineer.com/innovative-thinking/artificial-intelligence-via-hard-hat-cameras-06-07-2020/#webpage', 'url': 'https://www.newcivilengineer.com/innovative-thinking/artificial-intelligence-via-hard-hat-cameras-06-07-2020/', 'name': 'Artificial intelligence via hard hat cameras | New Civil Engineer', 'isPartOf': {'@id': 'https://www.newcivilengineer.com/#website'}, 'primaryImageOfPage': {'@id': 'https://www.newcivilengineer.com/innovative-thinking/artificial-intelligence-via-hard-hat-cameras-06-07-2020/#primaryimage'}, 'datePublished': '2020-07-06T15:44:02+00:00', 'dateModified': '2020-07-09T14:19:52+00:00', 'author': {'@id': 'https://www.newcivilengineer.com/#/schema/person/c5436a751ea755a53099b7ad4f9670f6'}, 'description': 'Using technology to drive efficiencies and reduce costs on construction projects is not a new challenge. Construction has traditionally been seen as slow', 'breadcrumb': {'@id': 'https://www.newcivilengineer.com/innovative-thinking/artificial-intelligence-via-hard-hat-cameras-06-07-2020/#breadcrumb'}, 'inLanguage': 'en-GB', 'potentialAction': [{'@type': 'ReadAction', 'target': ['https://www.newcivilengineer.com/innovative-thinking/artificial-intelligence-via-hard-hat-cameras-06-07-2020/']}], 'isAccessibleForFree': 'True'}, {'@type': 'BreadcrumbList', '@id': 'https://www.newcivilengineer.com/innovative-thinking/artificial-intelligence-via-hard-hat-cameras-06-07-2020/#breadcrumb', 'itemListElement': [{'@type': 'ListItem', 'position': 1, 'name': 'Home', 'item': 'https://www.newcivilengineer.com/'}, {'@type': 'ListItem', 'position': 2, 'name': 'Artificial intelligence via hard hat cameras'}]}, {'@type': 'Person', '@id': 'https://www.newcivilengineer.com/#/schema/person/c5436a751ea755a53099b7ad4f9670f6', 'name': 'Nadine Buddoo', 'image': {'@type': 'ImageObject', '@id': 'https://www.newcivilengineer.com/#personlogo', 'inLanguage': 'en-GB', 'url': 'https://secure.gravatar.com/avatar/42b9085e7dfa593943521a8820793c43?s=96&d=mm&r=g', 'contentUrl': 'https://secure.gravatar.com/avatar/42b9085e7dfa593943521a8820793c43?s=96&d=mm&r=g', 'caption': 'Nadine Buddoo'}, 'url': 'https://www.newcivilengineer.com/author/nadine-buddoo/'}]",,,,,,,
https://news.google.com/rss/articles/CBMiT2h0dHBzOi8vd3d3LmRhdGFuYW1pLmNvbS8yMDIwLzA3LzAyL2RvZXMtdGhlLWh1bWFuLXRvdWNoLWFpLXRoZS1mdXR1cmUtb2Ytd29yay_SAQA?oc=5,Does the Human Touch + AI = The Future of Work? - Datanami,2020-07-02,Datanami,https://www.datanami.com,"Artificial intelligence has long caused fear of job loss across many sectors as companies look for ways to cut costs, support workers and become more",N/A,"Artificial intelligence has long caused fear of job loss across many sectors as companies look for ways to cut costs, support workers and become more",N/A,https://schema.org,,,,,,,,,,,N/A,N/A,N/A,,,,,"[{'@type': 'Article', '@id': 'https://www.datanami.com/2020/07/02/does-the-human-touch-ai-the-future-of-work/#article', 'isPartOf': {'@id': 'https://www.datanami.com/2020/07/02/does-the-human-touch-ai-the-future-of-work/'}, 'author': {'name': 'Alex Woodie', '@id': 'https://www.datanami.com/#/schema/person/e72504f688134b83bdcb060f54ad8f9b'}, 'headline': 'Does the Human Touch + AI = The Future of Work?', 'datePublished': '2020-07-02T15:12:16+00:00', 'dateModified': '2020-07-02T15:12:16+00:00', 'mainEntityOfPage': {'@id': 'https://www.datanami.com/2020/07/02/does-the-human-touch-ai-the-future-of-work/'}, 'wordCount': 929, 'commentCount': 0, 'publisher': {'@id': 'https://www.datanami.com/#organization'}, 'image': {'@id': 'https://www.datanami.com/2020/07/02/does-the-human-touch-ai-the-future-of-work/#primaryimage'}, 'thumbnailUrl': 'https://www.datanami.com/wp-content/uploads/2020/07/robot_human_shutterstock_IR-Stone.jpg', 'keywords': ['AI', 'cybersecurity', 'Future of Work', 'machine learning'], 'articleSection': ['Features'], 'inLanguage': 'en-US', 'potentialAction': [{'@type': 'CommentAction', 'name': 'Comment', 'target': ['https://www.datanami.com/2020/07/02/does-the-human-touch-ai-the-future-of-work/#respond']}], 'copyrightYear': '2020', 'copyrightHolder': {'@id': 'https://www.datanami.com/#organization'}}, {'@type': 'WebPage', '@id': 'https://www.datanami.com/2020/07/02/does-the-human-touch-ai-the-future-of-work/', 'url': 'https://www.datanami.com/2020/07/02/does-the-human-touch-ai-the-future-of-work/', 'name': 'Does the Human Touch + AI = The Future of Work?', 'isPartOf': {'@id': 'https://www.datanami.com/#website'}, 'primaryImageOfPage': {'@id': 'https://www.datanami.com/2020/07/02/does-the-human-touch-ai-the-future-of-work/#primaryimage'}, 'image': {'@id': 'https://www.datanami.com/2020/07/02/does-the-human-touch-ai-the-future-of-work/#primaryimage'}, 'thumbnailUrl': 'https://www.datanami.com/wp-content/uploads/2020/07/robot_human_shutterstock_IR-Stone.jpg', 'datePublished': '2020-07-02T15:12:16+00:00', 'dateModified': '2020-07-02T15:12:16+00:00', 'description': 'Artificial intelligence has long caused fear of job loss across many sectors as companies look for ways to cut costs, support workers and become more', 'breadcrumb': {'@id': 'https://www.datanami.com/2020/07/02/does-the-human-touch-ai-the-future-of-work/#breadcrumb'}, 'inLanguage': 'en-US', 'potentialAction': [{'@type': 'ReadAction', 'target': ['https://www.datanami.com/2020/07/02/does-the-human-touch-ai-the-future-of-work/']}]}, {'@type': 'ImageObject', 'inLanguage': 'en-US', '@id': 'https://www.datanami.com/2020/07/02/does-the-human-touch-ai-the-future-of-work/#primaryimage', 'url': 'https://www.datanami.com/wp-content/uploads/2020/07/robot_human_shutterstock_IR-Stone.jpg', 'contentUrl': 'https://www.datanami.com/wp-content/uploads/2020/07/robot_human_shutterstock_IR-Stone.jpg', 'width': 1000, 'height': 596, 'caption': '(IR Stone/Shutterstock)'}, {'@type': 'BreadcrumbList', '@id': 'https://www.datanami.com/2020/07/02/does-the-human-touch-ai-the-future-of-work/#breadcrumb', 'itemListElement': [{'@type': 'ListItem', 'position': 1, 'name': 'Home', 'item': 'https://www.datanami.com/'}, {'@type': 'ListItem', 'position': 2, 'name': 'Does the Human Touch + AI = The Future of Work?'}]}, {'@type': 'WebSite', '@id': 'https://www.datanami.com/#website', 'url': 'https://www.datanami.com/', 'name': 'Datanami', 'description': 'Data Science • AI • Advanced Analytics', 'publisher': {'@id': 'https://www.datanami.com/#organization'}, 'potentialAction': [{'@type': 'SearchAction', 'target': {'@type': 'EntryPoint', 'urlTemplate': 'https://www.datanami.com/?s={search_term_string}'}, 'query-input': 'required name=search_term_string'}], 'inLanguage': 'en-US'}, {'@type': 'Organization', '@id': 'https://www.datanami.com/#organization', 'name': 'Datanami', 'url': 'https://www.datanami.com/', 'logo': {'@type': 'ImageObject', 'inLanguage': 'en-US', '@id': 'https://www.datanami.com/#/schema/logo/image/', 'url': 'https://www.datanami.com/wp-content/uploads/2021/10/dat_200x200.jpg', 'contentUrl': 'https://www.datanami.com/wp-content/uploads/2021/10/dat_200x200.jpg', 'width': 200, 'height': 200, 'caption': 'Datanami'}, 'image': {'@id': 'https://www.datanami.com/#/schema/logo/image/'}, 'sameAs': ['https://www.facebook.com/pages/Datanami/124760547631010', 'https://twitter.com/datanami', 'https://www.linkedin.com/groups/4166980/']}, {'@type': 'Person', '@id': 'https://www.datanami.com/#/schema/person/e72504f688134b83bdcb060f54ad8f9b', 'name': 'Alex Woodie', 'image': {'@type': 'ImageObject', 'inLanguage': 'en-US', '@id': 'https://www.datanami.com/#/schema/person/image/', 'url': 'https://secure.gravatar.com/avatar/b0307dd70ffe024a023722c06b737966?s=96&d=mm&r=g', 'contentUrl': 'https://secure.gravatar.com/avatar/b0307dd70ffe024a023722c06b737966?s=96&d=mm&r=g', 'caption': 'Alex Woodie'}, 'description': 'Alex Woodie is the managing editor of Datanami', 'url': 'https://www.datanami.com/author/alex/'}]",,,,,,,
https://news.google.com/rss/articles/CBMiQWh0dHBzOi8vd3d3LndpcmVkLmNvbS9zdG9yeS9mYWN0b3JpZXMtaW5zcGVjdG9yLXJvYm90LWNoZWNrLXdvcmsv0gEA?oc=5,"In These Factories, Inspector Robot Will Check Your Work - WIRED",2020-07-01,WIRED,https://www.wired.com,Artificially intelligent camera systems look for defects and misplaced parts in many industries. The coronavirus pandemic makes them extra useful.,"['business', 'artificial intelligence', 'ai hub', 'safety', 'prediction', 'big company', 'small company', 'manufacturing', 'video', 'machine learning', 'machine vision', 'robotics', 'deep learning', 'computer vision', 'web']",Artificially intelligent camera systems look for defects and misplaced parts in many industries. The coronavirus pandemic makes them extra useful.,Artificially intelligent camera systems look for defects and misplaced parts in many industries. The coronavirus pandemic makes them extra useful.,https://schema.org/,BreadcrumbList,"{'@type': 'WebPage', '@id': 'https://www.wired.com/story/factories-inspector-robot-check-work/'}","In These Factories, Inspector Robot Will Check Your Work","['https://media.wired.com/photos/5efbb71e9798446ce8080210/16:9/w_2399,h_1349,c_limit/business_inspection_461971920.jpg', 'https://media.wired.com/photos/5efbb71e9798446ce8080210/4:3/w_2132,h_1599,c_limit/business_inspection_461971920.jpg', 'https://media.wired.com/photos/5efbb71e9798446ce8080210/1:1/w_1600,h_1600,c_limit/business_inspection_461971920.jpg']",2020-07-01T07:00:00.000-04:00,2020-07-01T07:00:00.000-04:00,"[{'@type': 'Person', 'name': 'Will Knight', 'sameAs': 'https://www.wired.com/author/will-knight/'}]","{'@context': 'https://schema.org', '@type': 'Organization', 'name': 'WIRED', 'logo': {'@type': 'ImageObject', 'url': 'https://www.wired.com/verso/static/wired/assets/newsletter-signup-hub.jpg', 'width': '500px', 'height': '100px'}, 'url': 'https://www.wired.com'}",,,tags,N/A,"Will KnightBusinessJul 1, 2020 7:00 AMIn These Factories, Inspector Robot Will Check Your WorkArtificially intelligent camera systems look for defects and misplaced parts in many industries. The coronavirus pandemic makes them extra useful.A Toyota assembly plant in Indiana is preparing to deploy a robotic system that moves a camera around an object, to ensure employees are using the correct parts. Photograph: Luke Sharrett/Bloomberg/Getty ImagesSave this storySaveSave this storySaveThe AI Database →ApplicationSafetyPredictionEnd UserBig companySmall companySectorManufacturingSource DataVideoTechnologyMachine learningMachine visionRoboticsThe UK company P2i adds water-repelling nanocoatings to smartphones and other gadgets. Normally, it flies engineers to its clients’ factories to identify and solve quality-control problems.That’s not an option in a world where flights are grounded, borders closed, and security tightened. So in some plants, P2i now relies on a system that uses artificial intelligence to look for even the slightest defects.“Over the last four months, since the coronavirus, we've had to reevaluate how we are going to service and deploy our machines worldwide,” says Neal Harkrider, chief operating officer at P2i.Trending NowThe Robot Hand of the Future To spot problems, P2i is using technology from a company called Instrumental. Cameras dotted around P2i’s nano-coating machines examine smartphones after they’ve been treated, and an algorithm sounds an alert if the process appears to have gone awry.“That vision system is our primary quality-control methodology now,” Harkrider says. He says the company can adjust its tolerance for error on the fly, “and we can do that remotely, which is fantastic.”AdvertisementThe pandemic has forced many manufacturers to rethink established practices. In some places, remote sensing and machine learning substitute for fewer visits, overnight package deliveries, and manual inspections. Robots may be far from displacing humans in manufacturing that requires nimble fingers and flexibility. But systems like the one used by P2i show how AI can help machines carve out niches in manufacturing.Instrumental’s software lets manufacturers check the performance of a production line and automatically flags problems.
Courtesy of InstrumentalBefore Covid-19, Harkrider says, most companies were reluctant to allow outsiders—including their own partners—to connect to their manufacturing equipment, for security reasons. Now, he says, five plants have allowed P2i’s machines, and Instrumental’s inspection technology, to be monitored and controlled remotely.Bruce Lawler, managing director of the MIT Machine Intelligence for Manufacturing and Operations program, says the pandemic came as manufacturers already were warming to deploying automated inspection technology. “One of the big problems in manufacturing is ‘Where did the problem occur?’” he says. “If you can do more inspection more often, and have a camera on every robot, for every step, then you can say, ‘Well OK, that was here.’”Manufacturers have long used computer vision to inspect products for defects or other problems, but this traditionally involved hand-coded rules for identifying flaws, making it time-consuming to deploy and change the equipment. Using AI, inspection systems can be fed examples of particular flaws or—as with Instumental’s system—be trained on what a product is supposed to look like and asked to identify abnormalities.Most PopularThe Big StoryPriscila, Queen of the Rideshare MafiaBy Lauren Smiley, WIREDPoliticsTrump Shooting Conspiracies Are Coming From Every DirectionBy David Gilbert, WIREDPoliticsFar-Right Extremists Call for Violence and War After Trump ShootingBy David Gilbert, WIREDSecurityAT&T Paid a Hacker $370,000 to Delete Stolen Phone RecordsBy Kim Zetter, WIREDA form of AI known as deep learning has transformed computer vision in recent years and is rapidly spreading through manufacturing. An algorithm fed many thousands of example images can learn to identify dogs or cats in images, or to spot a particular person in security footage. It can also be trained to spot deviations from the norm in images of screws or circuit boards or screens.Elementary Robotics' technology inspects components by spinning around them.
Courtesy of ElementaryInstrumental was founded by ex-Apple engineers to use machine learning to automate the monitoring of production lines. “Traditional vision systems are not well suited to discover and solve problems, because they're ultimately rule-based,” says Anna-Katrina Shedletsky, the company’s CEO. “It’s a really good time to be talking about AI inspection, because there are these new pain points.”Makers of traditional computer-vision systems, such as Cognex, increasingly tout machine learning in their products. Some startups offer off-the-shelf systems that promise to be easy to deploy and use.At a Toyota manufacturing plant in Indiana that churns out hundreds of cars a day, quality control is crucial. Put the wrong widget into the wrong dashboard and production may grind to a halt. Workers normally scan a barcode on each part to double-check that it’s correct. But the plant is now preparing to deploy a robotic system that moves a camera around an object when an employee holds one out. It peers at the part from different angles and uses artificial intelligence to identify the component before (hopefully) giving the OK to install it.Keep ReadingThe latest on artificial intelligence, from machine learning to computer vision and more.The inspection robot, sold by Elementary Robotics, a startup based in Los Angeles, doesn’t look particularly futuristic, with a camera that moves horizontally and vertically along H-shaped bars. Place an object in front of the camera and it will inspect it from several perspectives. The robot shows how human workers and autonomous systems may work together on some manufacturing lines.“Automation is classically a very brittle environment where you design these really complex, kind of kludged-together solutions,” says Carlo Cruz, a senior engineer at Toyota who is overseeing testing of the system. “I think the idea of having a human in the loop becomes fundamentally important in the future.”Most PopularThe Big StoryPriscila, Queen of the Rideshare MafiaBy Lauren Smiley, WIREDPoliticsTrump Shooting Conspiracies Are Coming From Every DirectionBy David Gilbert, WIREDPoliticsFar-Right Extremists Call for Violence and War After Trump ShootingBy David Gilbert, WIREDSecurityAT&T Paid a Hacker $370,000 to Delete Stolen Phone RecordsBy Kim Zetter, WIREDCruz says he would like to deploy the technology in other areas eventually, including inspection and quality control. “We see a lot of potential,” he says.Elementary Robotics, founded in 2017, has been operating in stealth mode until now; it announced a $12.7 million Series A funding round Tuesday. Over Zoom, the company’s CEO, Arye Barnehama, shows off another version of the inspection system designed to examine ecommerce products for packaging damage and misapplied labels. He also demonstrates a version being used by another customer to examine circuit boards for flaws.The systems cost “in the low teens” of thousands each, Barnehama says, and they need relatively few examples to be trained. A customer sends a few dozen images of an object to Elementary Robotics, which uses them to train an algorithm. As workers display new objects, the algorithm determines if they are as intended. A worker clicks a button to say whether the algorithm was correct, improving the process for the next round.Enter your email to get the Wired newsletterclose dialogRecommended NewsletterFast ForwardA weekly dispatch from the future by Will Knight, exploring advances in AI and other technologies set to change our lives. Delivered on Thursdays.WeeklyPlease enter abovesign upUsed consistent with and subject to our Privacy Policy & User Agreement. Read terms of Sign-up.Recommended NewsletterFast ForwardA weekly dispatch from the future by Will Knight, exploring advances in AI and other technologies set to change our lives. Delivered on Thursdays.WeeklyYou're signed up!Used consistent with and subject to our Privacy Policy & User Agreement. Read terms of Sign-up.close dialogMore Great WIRED StoriesThe country is reopening. I’m still on lockdownThe Last of Us Part II and its crisis-strewn path to releaseFormer eBay execs allegedly made life hell for criticsThe best sex tech and toys for every bodyFacebook groups are destroying America👁 What is intelligence, anyway? Plus: Get the latest AI news✨ Optimize your home life with our Gear team’s best picks, from robot vacuums to affordable mattresses to smart speakers",https://www.wired.com/story/factories-inspector-robot-check-work/,business,True,"[{'@type': 'ListItem', 'position': 1, 'name': 'Business', 'item': 'https://www.wired.com/business/'}, {'@type': 'ListItem', 'position': 2, 'name': 'machine learning', 'item': 'https://www.wired.com/tag/machine-learning/'}, {'@type': 'ListItem', 'position': 3, 'name': 'In These Factories, Inspector Robot Will Check Your Work'}]",,"That’s not an option in a world where flights are grounded, borders closed, and security tightened. So in some plants, P2i now relies on a system that uses artificial intelligence to look for even the slightest defects.
“Over the last four months, since the coronavirus, we've had to reevaluate how we are going to service and deploy our machines worldwide,” says Neal Harkrider, chief operating officer at P2i.
To spot problems, P2i is using technology from a company called Instrumental. Cameras dotted around P2i’s nano-coating machines examine smartphones after they’ve been treated, and an algorithm sounds an alert if the process appears to have gone awry.
“That vision system is our primary quality-control methodology now,” Harkrider says. He says the company can adjust its tolerance for error on the fly, “and we can do that remotely, which is fantastic.”
The pandemic has forced many manufacturers to rethink established practices. In some places, remote sensing and machine learning substitute for fewer visits, overnight package deliveries, and manual inspections. Robots may be far from displacing humans in manufacturing that requires nimble fingers and flexibility. But systems like the one used by P2i show how AI can help machines carve out niches in manufacturing.
Before Covid-19, Harkrider says, most companies were reluctant to allow outsiders—including their own partners—to connect to their manufacturing equipment, for security reasons. Now, he says, five plants have allowed P2i’s machines, and Instrumental’s inspection technology, to be monitored and controlled remotely.
Bruce Lawler, managing director of the MIT Machine Intelligence for Manufacturing and Operations program, says the pandemic came as manufacturers already were warming to deploying automated inspection technology. “One of the big problems in manufacturing is ‘Where did the problem occur?’” he says. “If you can do more inspection more often, and have a camera on every robot, for every step, then you can say, ‘Well OK, that was here.’”
Manufacturers have long used computer vision to inspect products for defects or other problems, but this traditionally involved hand-coded rules for identifying flaws, making it time-consuming to deploy and change the equipment. Using AI, inspection systems can be fed examples of particular flaws or—as with Instumental’s system—be trained on what a product is supposed to look like and asked to identify abnormalities.
A form of AI known as deep learning has transformed computer vision in recent years and is rapidly spreading through manufacturing. An algorithm fed many thousands of example images can learn to identify dogs or cats in images, or to spot a particular person in security footage. It can also be trained to spot deviations from the norm in images of screws or circuit boards or screens.
Instrumental was founded by ex-Apple engineers to use machine learning to automate the monitoring of production lines. “Traditional vision systems are not well suited to discover and solve problems, because they're ultimately rule-based,” says Anna-Katrina Shedletsky, the company’s CEO. “It’s a really good time to be talking about AI inspection, because there are these new pain points.”
Makers of traditional computer-vision systems, such as Cognex, increasingly tout machine learning in their products. Some startups offer off-the-shelf systems that promise to be easy to deploy and use.
At a Toyota manufacturing plant in Indiana that churns out hundreds of cars a day, quality control is crucial. Put the wrong widget into the wrong dashboard and production may grind to a halt. Workers normally scan a barcode on each part to double-check that it’s correct. But the plant is now preparing to deploy a robotic system that moves a camera around an object when an employee holds one out. It peers at the part from different angles and uses artificial intelligence to identify the component before (hopefully) giving the OK to install it.
The inspection robot, sold by Elementary Robotics, a startup based in Los Angeles, doesn’t look particularly futuristic, with a camera that moves horizontally and vertically along H-shaped bars. Place an object in front of the camera and it will inspect it from several perspectives. The robot shows how human workers and autonomous systems may work together on some manufacturing lines.
“Automation is classically a very brittle environment where you design these really complex, kind of kludged-together solutions,” says Carlo Cruz, a senior engineer at Toyota who is overseeing testing of the system. “I think the idea of having a human in the loop becomes fundamentally important in the future.”
Cruz says he would like to deploy the technology in other areas eventually, including inspection and quality control. “We see a lot of potential,” he says.
Elementary Robotics, founded in 2017, has been operating in stealth mode until now; it announced a $12.7 million Series A funding round Tuesday. Over Zoom, the company’s CEO, Arye Barnehama, shows off another version of the inspection system designed to examine ecommerce products for packaging damage and misapplied labels. He also demonstrates a version being used by another customer to examine circuit boards for flaws.
The systems cost “in the low teens” of thousands each, Barnehama says, and they need relatively few examples to be trained. A customer sends a few dozen images of an object to Elementary Robotics, which uses them to train an algorithm. As workers display new objects, the algorithm determines if they are as intended. A worker clicks a button to say whether the algorithm was correct, improving the process for the next round.

More Great WIRED Stories

The country is reopening. I’m still on lockdown
The Last of Us Part II and its crisis-strewn path to release
Former eBay execs allegedly made life hell for critics
The best sex tech and toys for every body
Facebook groups are destroying America
👁 What is intelligence, anyway? Plus: Get the latest AI news
✨ Optimize your home life with our Gear team’s best picks, from robot vacuums to affordable mattresses to smart speakers",,"https://media.wired.com/photos/5efbb71e9798446ce8080210/1:1/w_1600,h_1600,c_limit/business_inspection_461971920.jpg","{'@type': 'CreativeWork', 'name': 'WIRED'}",Artificially intelligent camera systems look for defects and misplaced parts in many industries. The coronavirus pandemic makes them extra useful.,,
https://news.google.com/rss/articles/CBMidGh0dHBzOi8vd3d3LnNjaWVuY2VzcG8uZnIvcmVzZWFyY2gvY29naXRvL2hvbWUvYXJ0aWZpY2lhbC1pbnRlbGxpZ2VuY2Utd2hhdC1yZXZvbHV0aW9uLWFyZS13ZS10YWxraW5nLWFib3V0Lz9sYW5nPWVu0gEA?oc=5,Artificial Intelligence: What Revolution Are We Talking About? - Sciences Po,2020-07-03,Sciences Po,https://www.sciencespo.fr,N/A,N/A,"by Virginie Tournay, CEVIPOF* The prominence of digital technology and algorithms in collective life is often analyzed from a technological, organizational and economic perspective; but […]","by Virginie Tournay, CEVIPOF*  The prominence of digital technology and algorithms in collective life is often analyzed from a technological, organizational and economic perspective; but the way in which artificial intelligence is substantively transforming the political",,,,,,,,,,,,N/A,N/A,N/A,,,,,,,,,,,,
https://news.google.com/rss/articles/CBMia2h0dHBzOi8vd3d3LnBzeWNob2xvZ3l0b2RheS5jb20vdXMvYmxvZy9zZWVpbmctd2hhdC1vdGhlcnMtZG9udC8yMDIwMDcvYWlxLWFydGlmaWNpYWwtaW50ZWxsaWdlbmNlLXF1b3RpZW500gFvaHR0cHM6Ly93d3cucHN5Y2hvbG9neXRvZGF5LmNvbS91cy9ibG9nL3NlZWluZy13aGF0LW90aGVycy1kb250LzIwMjAwNy9haXEtYXJ0aWZpY2lhbC1pbnRlbGxpZ2VuY2UtcXVvdGllbnQ_YW1w?oc=5,Helping people get smarter about smart machines. - Psychology Today,2020-07-01,Psychology Today,https://www.psychologytoday.com,"As artificial intelligence affects more aspects of our lives, we'll need help understanding how these systems reason.",N/A,"As artificial intelligence affects more aspects of our lives, we'll need help understanding how these systems reason.",N/A,https://schema.org,,,,,,,,,,,N/A,N/A,"







Too Much Therapy-Speak Can Ruin Your Relationship


",,,,,"[{'@type': 'NewsArticle', 'url': 'https://www.psychologytoday.com/us/blog/seeing-what-others-dont/202007/aiq-artificial-intelligence-quotient', 'headline': 'Helping people get smarter about smart machines.', 'description': ""As artificial intelligence affects more aspects of our lives, we'll need help understanding how these systems reason."", 'datePublished': '2020-07-01T12:15:22-04:00', 'dateModified': '2022-12-13T14:10:06-0500', 'isAccessibleForFree': True, 'mainEntityOfPage': 'https://www.psychologytoday.com/us/blog/seeing-what-others-dont/202007/aiq-artificial-intelligence-quotient', 'image': ['https://cdn2.psychologytoday.com/assets/styles/manual_crop_16_9_1200x675/public/field_blog_entry_teaser_image/2020-07/blur-close-up-code-computer-546819.jpg?itok=gkt7CVDi', 'https://cdn2.psychologytoday.com/assets/styles/manual_crop_1_1_1200x1200/public/field_blog_entry_teaser_image/2020-07/blur-close-up-code-computer-546819.jpg?itok=GmGDDm9F', 'https://cdn2.psychologytoday.com/assets/styles/manual_crop_4_3_1200x900/public/field_blog_entry_teaser_image/2020-07/blur-close-up-code-computer-546819.jpg?itok=HvPErqTU'], 'about': {'@type': 'Thing', 'name': 'Intelligence', 'mainEntityOfPage': 'https://www.psychologytoday.com/us/basics/intelligence'}, 'author': {'@type': 'Person', 'name': 'Gary Klein Ph.D.', 'honorificSuffix': 'Ph.D.', 'mainEntityOfPage': 'https://www.psychologytoday.com/us/contributors/gary-klein-phd', 'url': 'https://www.psychologytoday.com/us/contributors/gary-klein-phd'}, 'publisher': {'@type': 'Organization', 'name': 'Psychology Today', 'url': 'https://www.psychologytoday.com', 'logo': 'https://cdn.psychologytoday.com/sites/default/files/psychology-today-logo-blue-AMP-left-cropped_0.png', 'publishingPrinciples': 'https://www.psychologytoday.com/us/docs/editorial-process'}, 'isPartOf': {'@type': 'Blog', 'name': ""Seeing What Others Don't"", 'mainEntityOfPage': 'https://www.psychologytoday.com/us/blog/seeing-what-others-dont'}}]",,,,,,,
https://news.google.com/rss/articles/CBMiL2h0dHBzOi8vd3d3LmV1cmVrYWxlcnQub3JnL25ld3MtcmVsZWFzZXMvNTk0NDAy0gEA?oc=5,Data visualization gets artificial intelligence boost with $5 million NSF grant - EurekAlert,2020-07-01,EurekAlert,https://www.eurekalert.org,N/A,N/A,"SAGE, soon to be on its third iteration as SAGE3, is the most widely used big-data visualization and collaboration software in the world.","SAGE, soon to be on its third iteration as SAGE3, is the most widely used big-data visualization and collaboration software in the world.",,,,,,,,,,,,N/A,N/A,"



                                    News Release 
                                                                     1-Jul-2020
                    


                Data visualization gets artificial intelligence boost with $5 million NSF grant
            
Grant and Award Announcement
Virginia Tech



















image: An example of SAGE2 at work, using cloud-based and web-browser technologies in order to enhance data intensive co-located and remote collaboration. Photo courtesy of Electronic Visualization Laboratory, University of Illinois at Chicago.
view more 
Credit: Electronic Visualization Laboratory, University of Illinois at Chicago.



Researchers at University of Hawai'i at Mānoa, University of Illinois at Chicago, and Virginia Tech were awarded a $5 million National Science Foundation grant to synergize two complementary technologies -- large-scale data visualization and artificial intelligence -- to create the Smart Amplified Group Environment (SAGE3) open-source software.
SAGE, soon to be on its third iteration as SAGE3, is the most widely used big-data visualization and collaboration software in the world.
Video: https://youtu.be/Rmg9YnXLBsM
SAGE and SAGE2 are software to enable data-rich collaboration on high-resolution display walls. SAGE2 moved SAGE into cloud computing and SAGE3 ushers in the inclusion of artificial intelligence.
Principal investigator Jason Leigh is a computer and information science professor at University of Hawai'i at Mānoa  and the inventor of SAGE. SAGE is software to enable teams of collaborators to work together with data in the form of data visualizations.
SAGE3's novel interactive artificial intelligence methods will learn from human analytic activity and use the knowledge gained to assist people in synthesizing relevant data connections that lead to new hypotheses and findings, explained Chris North, a professor of computer science in the College of Engineering at Virginia Tech and a co-principal investigator.
Scientists analyzing their data in SAGE3 will collaborate with each other and with artificial intelligence through large interactive visualization spaces, such as multi-monitor workstations, tiled display walls, and virtual reality headsets. 
Leigh said the applications for the SAGE3 technology are endless. ""It will be tremendously useful to enable evidence-based response during natural disasters and events like the current COVID-19 pandemic,"" Leigh said. 
He created SAGE in collaboration with researchers from the University of Illinois at Chicago 16 years ago. They've since further developed SAGE and SAGE2 with 15 years of research funding by the National Science Foundation.  
""This new funding provides us with an opportunity to take SAGE to the next level -- providing smart end-user services to amplify users' productivity making commercial and open-source artificial intelligence solutions available that can autonomously and transparently analyze data while continually learning and improving through user interactions,"" said Maxine Brown, director of the Electronic Visualization Laboratory at the University of Illinois at Chicago. Brown has been involved with SAGE since its inception. 
""SAGE3 also supports resource orchestration services that integrates these smart services with applications, workflows, and visualizations and collaboration services, and makes it easy for users to connect to local and remote display walls and computational systems and to securely run reproducible work models,"" explained Luc Renambot, Electronic Visualization Laboratory associate research professor and co-architect with Leigh of the SAGE software since its inception.
""As a 'co-pilot' to individuals or teams who are trying to examine large datasets, SAGE3 will provide a discovery pathway from data sources to human insights and knowledge, which is currently a gap in the e-Science pipeline that the National Science Foundation has called the 'missing middle,'"" said Mahdi Belcaid, assistant professor at University of Hawai'i at Mānoa and the artificial intelligence co-principal investigator on the project.
According to the researchers, SAGE3 will make artificial intelligence technologies broadly accessible, not just a privilege for the technically savvy. North said the project will conduct user-centered design research studies to ensure usability of this novel combination of data visualization and artificial intelligence in SAGE3.  
Through seed funds provided by Virginia Tech's Institute for Creativity, Arts, and Technology and the Hawai'i Data Science Institute, North had the opportunity to work side-by-side with Leigh in the Laboratory for Advanced Visualization & Applications at the University of Hawai'i during the spring 2020 semester. This in-person exchange, and numerous video-teleconferences with the Electronic Visualization Laboratory, was essential to helping plan and initiate the five-year SAGE3 collaboration, noted North. SAGE3 will serve the Institute's missions of bringing together computer scientists, domain scientists, engineers, artists, and designers to tackle some of the world's most complex challenges. 
The user base goes well beyond scientists. Leigh said he sees SAGE3 helping teachers use and share artificial intelligence concepts to future generations of students. And for those who work in creative media, such as filmmakers and video game designers, Leigh envisions it being a highly visual tool to brainstorm new ideas and analyze all forms of digital media to see how they relate to each other, which ones were most popular and why.  

###








Disclaimer: AAAS and EurekAlert! are not responsible for the accuracy of news releases posted to EurekAlert! by contributing institutions or for the use of any information through the EurekAlert system.











",,,,,,,,,,,,
https://news.google.com/rss/articles/CBMigQFodHRwczovL3d3dy5taW5lc25ld3Nyb29tLmNvbS9uZXdzL2FydGlmaWNpYWwtaW50ZWxsaWdlbmNlLXNldC1kcml2ZS1lY29ub21pYy1ncm93dGgtcmVzZWFyY2hlcnMtZm9jdXMtYWktaHVtYW4taGVhbHRoLWFuZC1zYWZldHnSAQA?oc=5,"With artificial intelligence set to drive economic growth, researchers focus on AI for human health and safety - Mines Newsroom",2020-07-06,Mines Newsroom,https://www.minesnewsroom.com,"“Artificial intelligence is certainly on the rise and has been for several years,” said Tracy Camp, department head and professor of computer science at Mines. “There’s just so much in our world today where we can use machine learning or AI to improve on our society or lives.”",N/A,"“Artificial intelligence is certainly on the rise and has been for several years,” said Tracy Camp, department head and professor of computer science at Mines. “There’s just so much in our world today where we can use machine learning or AI to improve on our society or lives.”","“Artificial intelligence is certainly on the rise and has been for several years,” said Tracy Camp, department head and professor of computer science at Mines. “There’s just so much in our world today where we can use machine learning or AI to improve on our society or lives.”",,,,,,,,,,,,N/A,N/A,N/A,,,,,,,,,,,,
https://news.google.com/rss/articles/CBMiYGh0dHBzOi8vbnlwb3N0LmNvbS8yMDIwLzA3LzAyL2FydGlzdC11c2VzLWFpLXRvLWNyZWF0ZS1zdHVubmluZy1wb3J0cmFpdHMtb2YtaGlzdG9yaWNhbC1maWd1cmVzL9IBAA?oc=5,Artist uses AI to create stunning portraits of historical figures - New York Post,2020-07-02,New York Post,https://nypost.com,"Bas Uterwijk, an Amsterdam-based artist, is using AI to create extremely lifelike photographs of historical figures and monuments such as the Statue of Liberty, artist Vincent van Gogh, George Washington and Queen Elizabeth I.","['art', 'artificial intelligence', '/article']",Is this artificial intelligence or a time machine?,Is this artificial intelligence or a time machine?,https://schema.org,NewsArticle,https://nypost.com/2020/07/02/artist-uses-ai-to-create-stunning-portraits-of-historical-figures/,Artist uses AI to create stunning realistic portraits of historical figures,"{'@type': 'ImageObject', 'url': 'https://nypost.com/wp-content/uploads/sites/2/2020/07/statue-of-liberty.jpg?quality=75&strip=all&w=1200', 'width': 1200, 'height': 800}",2020-07-02T16:31:10Z,,"[{'name': 'Marisa Dellatto', '@type': 'Person', 'URL': 'https://nypost.com/author/marisa-dellatto/'}]","{'@type': 'Organization', 'name': 'New York Post', 'sameAs': 'https://nypost.com', 'logo': {'@type': 'ImageObject', 'url': 'https://nypost.com/wp-content/themes/nypost-2016/static/images/logo-nypost.png', 'height': 60, 'width': 404}}",,2020-07-02T16:31:10Z,N/A,N/A,"








Lifestyle



		Artist uses AI to create stunning realistic portraits of historical figures	


		By 


				Social Links for			
			Marisa Dellatto		





View Author Archive




Email the Author




Follow on X




Get author RSS feed















Contact The Author



Name (required)


Email (required)


Comment (required)







Submit





Thanks for contacting us. We've received your submission.
Back to Reading

There was an error submitting your message
 


















		Thanks for contacting us. We've received your submission.	

		Back to Reading	







Published 
July 2, 2020


Updated 
July 2, 2020, 2:06 p.m. ET












 
					The Statue of Liberty (left) was re-created by artist Bas Uterwijk using artificial intelligence software.						
							Getty Images/Bas Uterwijk						








			Explore More					





				Two elderly journalists help lead authors in suing ChatGPT to protect the ‘written word’			





				AI speech clone is so real that makers say its ‘potential risks’ could prove too dangerous			





				Samsung launches first-of-a-kind smart ring, watch with AI features to help monitor your health			







Is this artificial intelligence or a time machine?
Bas Uterwijk, an Amsterdam-based artist, is using AI to create extremely lifelike photographs of historical figures and monuments such as the Statue of Liberty, artist Vincent van Gogh, George Washington and Queen Elizabeth I.
Using a program called Artbreeder, which is described as “deep learning software,” Uterwijk builds his photographs based on a compilation of portraits, reports the Daily Mail. The program pinpoints common facial features and photograph qualities to produce an image.
“I try to guide the software to a credible outcome. I think of my work more as artistic interpretations than scientifically or historically accurate,” the artist tells the outlet. On Instagram, he details the many variations that go into creating his work.
So far, he’s created more than 50 of these images.


1/100:29This Day in History





Skip Ad
 
Continue watchingThis Day in Historyafter the adVisit Advertiser websiteGO TO PAGEVincent van Gogh (left), “Self-Portrait,” 1889, and an AI re-creation by Bas Uterwijk.Getty Images/Bas Uterwijk
It’s not all technology: “The software tends to drift to averages easily because of its nature, so for that last one, I sometimes need some extra tricks and methods to get what I want,” Uterwijk says. His portraits need to stay true to the original person and what they looked like and also have expressions worth looking at.


Some of his creations feature real people, such as Napoleon Bonaparte and Niccolò Machiavelli. Others are of important but made-up characters, such as Lady Liberty and the Girl with the Pearl Earring, a figure from a famous Johannes Vermeer painting.





Previous

1 of 5



Next










 A 1790 portrait of George Washington (left) with Bas Uterwijk's AI re-creation.Getty Images/Bas Uterwijk 



 Jacques-Louis David's 1812 portrait of Napoleon Bonaparte (left) with Bas Uterwijk's AI re-creation.Getty Images/Bas Uterwijk 



							Advertisement						



 Nicholas Hilliard's 1575 portrait of Queen Elizabeth 1 (left) with Bas Uterwijk's AI re-creation. Getty Images/Bas Uterwijk 



							Advertisement						




“I work on many images at the same time, sometimes leaving them for weeks to pick them up later when I have new inspiration or have stumbled on additional source material,” says Uterwijk.
His next work of art will be a photograph of Anne Frank: “There are several known photographs of her — so I might make her older, at an age she never reached.”
 



Filed under


art


artificial intelligence


7/2/20 





Read Next


				These massive sharks have teeth on their eyeballs			









SPONSORED STORIES



 









Around The Web





Dad Of Trump Shooter Breaks His SilenceNYPost.com







Thomas Crooks' Counselor Speaks Out About The Attempted AssassinNYPost.com







Details Are Spilling Out On Trump Shooter Thomas Matthew CrooksNYPost.com







Portman Reveals How Rihanna Helped Her Through Her DivorceExtratv.com







Something Doesn't Make Sense About The Trump ShootingGrunge.com







Melania Trump's Wildly Inappropriate Outfit That Left Us StunnedNickiSwift.com







The Tragedy Of Barron Trump Is No Secret AnymoreNickiSwift.com







Ivanka Trump Showed Off Her Legs & It Caused Serious ChaosNickiSwift.com







TikToker Has Meltdown After Trump Escapes AssassinationThenerdstash.com

Powered by ZergNet






Top Concerts



Vividseats: Official Ticketing Partner of New York Post


			Get seats. Earn rewards. Experience it live.		




		Taylor Swift	

		29 Shows |
		
			Get Tickets		




		Usher	

		67 Shows |
		
			Get Tickets		




		Zach Bryan	

		39 Shows |
		
			Get Tickets		




		Aerosmith	

		40 Shows |
		
			Get Tickets		




		Olivia Rodrigo	

		22 Shows |
		
			Get Tickets		






				See More Shows			



















		Trending Now			
				on NYPost.com			




 


This story has been shared 134,460 times.
134,460






							Inside what Trump's would-be assassin did in the 24 hours before rally shooting						






 


This story has been shared 77,960 times.
77,960






							'Blindsided' Jack Black addresses bandmate's 'shameful' comment about Trump assassination attempt as tour canceled						






 


This story has been shared 77,206 times.
77,206






							Joe Scarborough throws MSNBC under the bus as 'Morning Joe' finally returns to air: 'Surprised’ and ‘very disappointed’						


















Now on
 Page Six













							Emma Roberts engaged to boyfriend Cody John after 2 years of dating						





							Matt Damon and bikini-clad wife Luciana Barroso pack on the PDA during Greece vacation						





							Kate Hudson sings at Surf Lodge in Montauk, in front of famous friends including Gwyneth Paltrow						




		See All	

















WHAT TO SHOP NOW








The secret to Martha Stewart’s ‘dewy look’ is less than $11 during Prime Day











Select Adidas Samba shoes are on sale during Amazon Prime Day 2024











AirPods drop to all-time low prices: Shop the best Apple deals of July 2024











19 can’t-miss Prime Day deals on travel essentials: Luggage, accessories, more











Score the Olipop soda stars love for a steal during Prime Day




 





















",https://nypost.com/2020/07/02/artist-uses-ai-to-create-stunning-portraits-of-historical-figures/,lifestyle,,,,,,https://nypost.com/wp-content/uploads/sites/2/2020/07/statue-of-liberty.jpg?quality=75&strip=all,,,"[{'name': 'Marisa Dellatto', '@type': 'Person'}]",
https://news.google.com/rss/articles/CBMiXWh0dHBzOi8vdG93YXJkc2RhdGFzY2llbmNlLmNvbS9hcnRpZmljaWFsLWludGVsbGlnZW5jZS1pbi1tZWNoYW5pY2FsLWVuZ2luZWVyaW5nLWE5ZGQ5NGFkYzQ5MtIBAA?oc=5,Artificial Intelligence in Mechanical Engineering | by Sunny K. Tuladhar - Towards Data Science,2020-07-05,Towards Data Science,https://towardsdatascience.com,Artificial Intelligence and Machine Learning seems to have applications in almost all fields. In this article we will see the possibilities it has in the field of Mechanical Engineering.,N/A,An example of Deep Learning implementations with very basic explanations for mechanical engineers who are beginners or enthusiasts in the…,An example of Deep Learning implementations with very basic explanations for mechanical engineers who are beginners or enthusiasts in the…,http://schema.org,NewsArticle,https://towardsdatascience.com/artificial-intelligence-in-mechanical-engineering-a9dd94adc492,Artificial Intelligence in Mechanical Engineering - Towards Data Science,['https://miro.medium.com/v2/da:true/resize:fit:1200/0*G4WycT0SlVS3UBto'],2020-07-06T05:59:09.762Z,2022-10-19T05:03:46.704Z,"{'@type': 'Person', 'name': 'Sunny K. Tuladhar', 'url': 'https://towardsdatascience.com/@k.sunman91'}","{'@type': 'Organization', 'name': 'Towards Data Science', 'url': 'towardsdatascience.com', 'logo': {'@type': 'ImageObject', 'width': 192, 'height': 60, 'url': 'https://miro.medium.com/v2/resize:fit:384/1*cFFKn8rFH4ZndmaYeAs6iQ.png'}}",Artificial Intelligence in Mechanical Engineering - Towards Data Science,2020-07-06T05:59:09.762Z,N/A,N/A,"Artificial Intelligence in Mechanical EngineeringAn example of Deep Learning implementations with very basic explanations for mechanical engineers who are beginners or enthusiasts in the field of data science and artificial intelligence. This project was conducted at Pro-mech Minds, Nepal.Sunny K. Tuladhar·FollowPublished inTowards Data Science·12 min read·Jul 6, 2020212ListenShareImage by Andrey Suslov from 123rf.comArtificial Intelligence and Machine Learning seems to be the current buzzword as everyone seems to be getting into this subject. Artificial Intelligence seems to have a role in all fields of science. According to Britannica , “Artificial intelligence (AI), is broadly defined as the ability of a digital computer or computer-controlled robot to perform tasks commonly associated with intelligent beings.” By intelligent beings it basically means humans … but maybe not all humans…so anyway,It is usually classified into three subsets as shown below.Artificial Intelligence and its subsets ( Source: Edureka)Artificial Intelligence is a broader term which in cooperates Machine Learning. Machine learning uses statistical methods to allow machines to improve with experience.Deep Learning, again, is the subset of Machine Learning which uses multi layer neural networks that mimic the human brain and can learn incredibly difficult tasks with enough data.We are going to talk about Deep learning methods and its possible role in the field of Mechanical Engineering. Some common examples could be Anomaly Detection(Machine Learning) and Image based Part Classification(Deep Learning). The focus will be on Image based part classifiers and why we need them.Firstly, what is an image classifier? The ever famous AI which recognizes cat-dog pictures should come to mind. Here’s a link to the code of such a program. The data-set used contains images of cats and dogs, the algorithm learns from it and then is able to guess with 97% accuracy whether a randomly shown image is a cat or a dog.Cat or Dog? (Source: medium article)We will attempt a similar code but using Nuts, Bolts, Washers and Locating Pins as our Cats and Dogs….. because mechanical engineering.Bolt or Nut or Locating Pin or Washer? Will the AI be able to tell?So how does it work? An algorithm is able to classify images(efficiently) by using a Machine Learning algorithm called Convolutional Neural Networks(CNN) a method used in Deep Learning. We will be using a simple version of this model called Sequential to let our model distinguish the images into four classes Nuts, Bolts, Washers and Locating Pins. The model will learn by “observing” a set of training images. After learning we will see how accurately it can predict what an image (which it has not seen) is.A flowchart of a Machine Learning algorithm trained on Images of Nuts and Bolts using a Neural Network Model. (Original Image: pngfind)Go directly to the code in githubData-setWe downloaded 238 parts each of the 4 classes (Total 238 x 4 = 952) from various part libraries available on the internet. Then we took 8 different isometric images of each part. This was done to augment the data available, as only 238 images for each part would not be enough to train a good neural network. A single class now has 1904 images(8 isometric images of 238 parts) a total of 7616 images. Each image is of 224 x 224 pixels.Images of the 4 classes. 1 part has 8 images. Each image is treated as single data.We then have our labels with numbers 0,1,2,3 each number corresponds to a particular image and means it belongs to certain class#Integers and their corresponding classes{0: 'locatingpin', 1: 'washer', 2: 'bolt', 3: 'nut'}After training on the above images we will then see how well our model predicts a random image it has not seen.MethodologyThe process took place in 7 steps. We will get to the details later. The brief summary isData Collection : The data for each class was collected from various standard part libraries on the internet.Data Preparation : 8 Isometric view screenshots were taken from each image and reduced to 224 x 224 pixels.Model Selection : A Sequential CNN model was selected as it was simple and good for image classificationTrain the Model: The model was trained on our data of 7616 images with 80/20 train-test splitEvaluate the Model: The results of the model were evaluated. How well it predicted the classes?Hyperparameter Tuning: This process is done to tune the hyperparameters to get better results . We have already tuned our model in this caseMake Predictions: Check how well it predicts the real world dataData CollectionWe downloaded the part data of various nuts and bolts from the different part libraries on the internet. These websites have numerous 3D models for standard parts from various makers in different file formats. Since we will be using FreeCAD API to extract the images we downloaded the files in neutral format (STEP).Flowchart of the CAD model downloadAs already mentioned earlier, 238 parts from each of the 4 class was downloaded, that was a total of 952 parts.Data PreparationThen we ran a program using FreeCAD API that automatically took 8 isometric screenshots of 224 x 224 pixels of each part. FreeCAD is a free and open-source general-purpose parametric 3D computer-aided design modeler which is written in Python.A flowchart of how the data was createdAs already mentioned above, each data creates 8 images of 224 x 224 pixels. So we now have a total of 1904 image from each of the 4 classes, thus a total of 7616 images. Each image is treated as a separate data even though 8 images come from the same part.8 isometric images of a 2 bolts. Each row represents a different part.The images were kept in separated folders according to their class. i.e. we have four folders Nut,Bolt, Washer and Locating Pin.Next, each of these images were converted into an array with their pixel values in grayscale. The value of the pixels range from 0 (black), 255 (white). So its actually 255 shades of gray.Example of an Image converted to an array of pixel values. (Source: openframeworks.cc)Now each of our image becomes a 224 x 224 array. So our entire dataset is a 3D array of 7616 x 224 x 224 dimensions.7616 (No. of images) x 224 x 224 (pixel value of each image)Visualization of our pixel array using matplot.libSimilarly we create a the label dataset by giving the value of the following integers for the shown classes to corresponding indexes in the dataset. If our 5th(index) data in the dataset(X) is a locating pin , the 5th data in label set (Y) will have value 0.#integers and the corresponding classes as already mentioned above{0: 'locatingpin', 1: 'washer', 2: 'bolt', 3: 'nut'}Model SelectionSince this is an image recognition problem we will be using a Convolutional Neural Network (CNN). CNN is a type of Neural Network that handles image data especially well. A Neural Network is a type of Machine learning algorithm that learns in a similar manner to a human brain.A basic neural network. (Source: Medium article by Conor McDonald)A Convolutional Neural network. A basic visualization of how our algorithm will work (Original image source : Article by Adit Deshpande)The following code is how our CNN looks like. Don’t worry about it if you don’t understand. The idea is the 224 x 224 features from each of our data will go through these network and spit out an answer. The model will adjusts its weights accordingly and after many iterations will be able to predict a random image’s class.#Model descriptionModel: ""sequential_1""_________________________________________________________________Layer (type)                 Output Shape              Param #   =================================================================conv2d_1 (Conv2D)            (None, 222, 222, 128)     1280      _________________________________________________________________activation_1 (Activation)    (None, 222, 222, 128)     0         _________________________________________________________________max_pooling2d_1 (MaxPooling2 (None, 111, 111, 128)     0         _________________________________________________________________conv2d_2 (Conv2D)            (None, 109, 109, 128)     147584    _________________________________________________________________activation_2 (Activation)    (None, 109, 109, 128)     0         _________________________________________________________________max_pooling2d_2 (MaxPooling2 (None, 54, 54, 128)       0         _________________________________________________________________flatten_1 (Flatten)          (None, 373248)            0         _________________________________________________________________dense_1 (Dense)              (None, 64)                23887936  _________________________________________________________________dense_2 (Dense)              (None, 4)                 260       _________________________________________________________________activation_3 (Activation)    (None, 4)                 0         =================================================================Total params: 24,037,060Trainable params: 24,037,060Non-trainable params: 0Here is a YouTube video of Mark Rober (a NASA mechanical engineer) explaining how neural networks work with very little coding involved.Model TrainingNow finally the time has come to train the model using our dataset of 7616 images. So our [X] is a 3D array of 7616 x 224 x224 and [y] label set is a 7616 x 1 array. For all training purposes a data must be split into at least two parts: Training and Validation (Test) set (test and validation are used interchangeably when only 2 sets are involved).Data being split into training and test set. (Source: researchgate.net)The training set is the data the model sees and trains on. It is the data from which it adjusts its weights and learn. The accuracy of our model on this set is the training accuracy. It is generally higher than the validation accuracy.The validation data usually comes from the same distribution as the training set and is the data the model has not seen. After the model has trained from the training set, it will try to predict the data of the validation set. How accurately it predicts this, is our validation accuracy. This is more important than the training accuracy. It shows how well the model generalizes.In real life application it is common to split it even into three parts. Train, Validation and Test.For our case we will only split it into a training and test set. It will be a 80–20 split. 80 % of the images will be used for training and 20% will be used for testing. That is train on 6092 samples, test on 1524 samples from the total 7616.Visualization of the model training. (Original Image Source : Medium article by Yufeng G)For our model we trained for 15 epochs with a batch-size of 64.The number of epochs is a hyperparameter that defines the number times that the learning algorithm will work through the entire training dataset.One epoch means that each sample in the training dataset has had an opportunity to update the internal model parameters. An epoch is comprised of one or more batches.You can think of a for-loop over the number of epochs where each loop proceeds over the training dataset. Within this for-loop is another nested for-loop that iterates over each batch of samples, where one batch has the specified “batch size” number of samples. [2]That is our model will go through our entire 7616 samples 15 times (epoch) in total and adjust its weights each time so the prediction is more accurate each time. In each epoch, it will go through the 7616 samples, 64 samples (batch size) at a time.Evaluate the modelThe model keeps updating its weight so as to minimize the cost(loss), thus giving us the best accuracy. Cost is a measure of inaccuracy of the model in predicting the class of the image. Cost functions are used to estimate how badly models are performing. Put simply, a cost function is a measure of how wrong the model is in terms of its ability to estimate the relationship between X and y. [1]If the algorithm predicts incorrectly the cost increases, if it predicts correct the cost decreases.After training for 15 epochs we can see the following graph of loss and accuracy. (Cost and loss can be used interchangeably for our case)Graph generated from matplot.lib showing Training and Validation loss for our modelThe loss decreased as the model trained more times. It becomes better at classifying the images with each epoch. The model is not able to improve the performance much on the validation set.Graph generated from matplot.lib showing Training and Validation accuracy for our modelThe accuracy increased as the model trains for each epoch. It becomes better at classifying the images. The accuracy is for the validation set is lower than the training set as it has not trained on it directly. The final value is 97.64% which is not bad.Hyperparameter TuningThe next step would to be change the hyperparameters, the learning rate,number of epochs, data size etc. to improve our model. In machine learning, a hyperparameter is a parameter whose value is used to control the learning process. By contrast, the values of other parameters (typically node weights) are derived via training.[3]For our purpose we have already modified these parameters before this article was written, in a way to obtain an optimum performance for display on this article. We increased the dataset size and number of epochs to improve the accuracy.Hyperparameters affect parameters and eventually the final score (accuracy). ( Source: deepai.org)Make PredictionsThe final step after making the adjustments on the model is to make predictions using actual data that will be used on this model. If the model does not perform well on this further hyperparameter tuning can commence.Machine Learning is a rather iterative and empirical process and thus the tuning of hyperparameters is often compared to an art rather than science as although we have an idea of what changes will happen by changing certain hyperparameters, we cannot be certain of it.The machine learning algorithm flowchart(Original Image: pngfind)ApplicationsThis ability to classify mechanical parts could enable us to recommend parts from a standard library based only on an image or a CAD model provided by the customer. Currently to search for a required part from a standard library you have to go through a catalogue and be able to tell which part you want based on the available options and your knowledge of the catalogue. There are serial codes to remember as a change in a single digit or alphabet might mean a different type of part.Example of a part number from the website of TOREX.If an image can be used to get the required part from the standard library, all we will need to do is to make a rough CAD model of it and send it through our algorithm. The algorithm will decide which parts are best and help narrow down our search significantly.Visualisation of how the recommendation algorithm would workIf the classification method gets detailed and fine-tuned enough it should be able to classify with much detail what type of part you want. The narrowed search saves a lot of time. This is especially useful in a library where there are thousands of similar parts.ConclusionDeep Learning (Artificial Intelligence) is a field of study that has immense possibilities as it enables us to extract a lot of knowledge from raw data. At its core it is merely data analysis. In this age of the internet, data is everywhere and if we are able to extract it efficiently, a lot can be accomplished.This field has a lot of possible applications in the domain of Mechanical Engineering as well. Since almost all studies in Deep Learning need a domain expert it would be advisable for all engineers with interest in Data Analytics, even though they haven’t majored in Computer Sciences, to learn about data science, machine learning and examine its possibilities. The knowledge of the domain plus the skills of data analysis will really help us excel in our own fields.AcknowledgementsI am thankful to Pro-Mech Minds for letting me do this and specially to its data science team which includes Gopal Kisi, Bishesh Shakya and Series Chikanbanjar for their immense help with this project. Pro-Mech Minds & Engineering Services is one of the companies in Nepal working with both mechanical and IT solutions in engineering. This idea popped as an attempt to combine design engineering with Data Science. Last but not the least I would like to offer my special thanks to Saugat K.C. for acting as a mentor for our Data Science team.SourceLink to the code in githubReferences[1]Conor McDonald, Machine learning fundamentals (I): Cost functions and gradient descent(2017), Towards data science[2]Jason Brownlee, Difference Between a Batch and an Epoch in a Neural Network(2018), machinelearningmastery.com[3] Hyperparameter_(machine_learning), Wikipedia[4] Andrew Ng, Convolutional Neural Networks of the Deep Learning Specialization by deeplearning.ai. (n.d.). Retrieved from Coursera",https://towardsdatascience.com/artificial-intelligence-in-mechanical-engineering-a9dd94adc492,,,,,,,,,,['Sunny K. Tuladhar'],a9dd94adc492
https://news.google.com/rss/articles/CBMiOmh0dHBzOi8vZmVkc2Nvb3AuY29tL3ZldGVyYW5zLWJlbmVmaXRzLWFpLW1haWwtcHJvY2Vzc2luZy_SAQA?oc=5,"By using AI, the VA dramatically decreased claims processing intake times, official says - FedScoop",2020-07-01,FedScoop,https://fedscoop.com,"The VBA went from taking 10 days to sort the mail to about half a day. ""We are happy to talk about how good we are,"" its administrator said.","['artificial intelligence (ai)', 'department of veterans affairs (va)', 'ibm', 'it modernization', 'reskilling', 'think gov']","The VA's benefits administration went from taking 10 days to sort the mail to about half a day. ""We are happy to talk about how good we are,"" its administrator said.",N/A,https://schema.org,NewsArticle,"{'@type': 'WebPage', '@id': 'http://fedscoop.com/veterans-benefits-ai-mail-processing/'}","By using AI, the VA dramatically decreased claims processing intake times, official says","{'@type': 'ImageObject', 'url': 'https://fedscoop.com/wp-content/uploads/sites/5/2019/02/GettyImages-1044327296-e1691617386125.jpg'}",2020-07-01T18:51:28Z,2020-07-01T18:53:42Z,"[{'@type': 'Person', 'name': 'Jackson Barnett'}]","{'@type': 'Organization', 'name': 'FedScoop', 'logo': 'https://fedscoop.com/wp-content/uploads/sites/5/2023/01/cropped-fs_favicon-3.png'}",,2020-07-01T18:51:28Z,N/A,N/A,"






Defense




								By using AI, the VA dramatically decreased claims processing intake times, official says							

								The VA's benefits administration went from taking 10 days to sort the mail to about half a day. ""We are happy to talk about how good we are,"" its administrator said.							


By
Jackson Barnett



July 1, 2020






 
											(Getty Images)										





The Veteran Benefits Administration was spending too much time processing its mail. So it turned to artificial intelligence-enabled systems to slash its processing time.
By applying AI that could more quickly sort incoming claims from multiple inputs — mail, fax and electronic submissions — the Department of Veterans Affairs was able to reduce the time just sorting the claims from 10 days to about half a day, Paul Lawrence, the head of the VBA, said during the IBM Think Gov digital event, produced by FedScoop.
“We realized we had far too many people doing old-fashioned manual labor,” Lawrence said.
Veterans send in documents to the VA that pertain to the type of benefits they are eligible for and to settle disputes over services. More than 5 million veterans file claims, and the current backlog runs more than 150,000, a number that has dropped drastically in recent years.


Advertisement



Now that sorting times are reduced with the assistance of technology, Lawrence said the VBA is focused on other workflow challenges. He wants to reskill employees away from manual, tedious tasks and have them work with technology that can help sort and leave the complex decision making to humans. Much of the work around settling claim disputes and making decisions about benefits is not something AI has the ability to tackle.
The initial successes of technology have not solved all of the VBA’s challenges, however. The administration still takes almost 100 days to process claims on average, according to its website.
Lawrence also wants to be able to be more transparent about where claims are in the process, much like how pizza delivery services can now show customers where their orders are in the cooking and transport process, Lawrence said.
The lessons learned from using AI to improve initial processing times will stick around, he said.
“It is now something we are really proud of, we are happy to talk about how good we are,” Lawrence said.








Written by Jackson Barnett
			Jackson Barnett Jackson Barnett Jackson Barnett 210 jackson.barnett@fedscoop.com		


In This Story



														IBM													



														Artificial Intelligence (AI)													



														Department of Veterans Affairs (VA)													



														IT Modernization													



														reskilling													



														Think Gov													








Share




Facebook





LinkedIn





Twitter





Copy Link











Advertisement






Advertisement





More Like This






								MPEs gain momentum for sharing information with allied partners			



By 

						Scoop News Group					










								State Department officials say they’re trying to set the tone globally on AI usage, as lawmakers question if it’s enough			



By 

						Caroline Nihill					










								VA plans to award AI tech sprint winners contracts for ambient medical transcription services			



By 

						Caroline Nihill					









Advertisement





Top Stories






								FedRAMP ‘undeniably’ in state of limbo without final OMB modernization guidance, Rep. Connolly says			



By 

						Caroline Nihill					










								After 2023 outage that paused flights nationwide, FAA now has backup system			



By 

						Rebecca Heilweil					










								How the IRS’s ‘cautious’ approach with Direct File prevented its ‘failure’			



By 

						Matt Bracken					










								Social Security Administration transitioning long-time users to Login.gov			



By 

						Rebecca Heilweil					










								Energy Department’s national labs get AI boost in bipartisan Senate bill			



By 

						Matt Bracken					










								GSA begins FedRAMP pilot to change request process			



By 

						Caroline Nihill					










								White House to require increased cybersecurity protocols for R&D institutions			



By 

						Caroline Nihill					










Advertisement






",http://fedscoop.com/veterans-benefits-ai-mail-processing/,Defense,,,"[{'@type': 'WebPage', '@id': 'https://fedscoop.com/veterans-benefits-ai-mail-processing/', 'url': 'https://fedscoop.com/veterans-benefits-ai-mail-processing/', 'name': 'By using AI, the VA dramatically decreased claims processing intake times, official says | FedScoop', 'isPartOf': {'@id': 'https://fedscoop.com/#website'}, 'primaryImageOfPage': {'@id': 'https://fedscoop.com/veterans-benefits-ai-mail-processing/#primaryimage'}, 'image': {'@id': 'https://fedscoop.com/veterans-benefits-ai-mail-processing/#primaryimage'}, 'thumbnailUrl': 'https://fedscoop.com/wp-content/uploads/sites/5/2019/02/GettyImages-1044327296-e1691617386125.jpg', 'datePublished': '2020-07-01T18:51:28+00:00', 'dateModified': '2020-07-01T18:53:42+00:00', 'description': 'The VBA went from taking 10 days to sort the mail to about half a day. ""We are happy to talk about how good we are,"" its administrator said.', 'breadcrumb': {'@id': 'https://fedscoop.com/veterans-benefits-ai-mail-processing/#breadcrumb'}, 'inLanguage': 'en-US', 'potentialAction': [{'@type': 'ReadAction', 'target': ['https://fedscoop.com/veterans-benefits-ai-mail-processing/']}]}, {'@type': 'ImageObject', 'inLanguage': 'en-US', '@id': 'https://fedscoop.com/veterans-benefits-ai-mail-processing/#primaryimage', 'url': 'https://fedscoop.com/wp-content/uploads/sites/5/2019/02/GettyImages-1044327296-e1691617386125.jpg', 'contentUrl': 'https://fedscoop.com/wp-content/uploads/sites/5/2019/02/GettyImages-1044327296-e1691617386125.jpg', 'width': 1150, 'height': 767, 'caption': '(Getty Images)'}, {'@type': 'BreadcrumbList', '@id': 'https://fedscoop.com/veterans-benefits-ai-mail-processing/#breadcrumb', 'itemListElement': [{'@type': 'ListItem', 'position': 1, 'name': 'Home', 'item': 'https://fedscoop.com/'}, {'@type': 'ListItem', 'position': 2, 'name': 'By using AI, the VA dramatically decreased claims processing intake times, official says'}]}, {'@type': 'WebSite', '@id': 'https://fedscoop.com/#website', 'url': 'https://fedscoop.com/', 'name': 'FedScoop', 'description': 'FedScoop delivers up-to-the-minute breaking government tech news and is the government IT community&#039;s platform for education and collaboration through news, events, radio and TV. FedScoop engages top leaders from the White House, federal agencies, academia and the tech industry both online and in person to discuss ways technology can improve government, and to exchange best practices and identify how to achieve common goals.', 'publisher': {'@id': 'https://fedscoop.com/#organization'}, 'potentialAction': [{'@type': 'SearchAction', 'target': {'@type': 'EntryPoint', 'urlTemplate': 'https://fedscoop.com/?s={search_term_string}'}, 'query-input': 'required name=search_term_string'}], 'inLanguage': 'en-US'}, {'@type': 'Organization', '@id': 'https://fedscoop.com/#organization', 'name': 'FedScoop', 'url': 'https://fedscoop.com/', 'logo': {'@type': 'ImageObject', 'inLanguage': 'en-US', '@id': 'https://fedscoop.com/#/schema/logo/image/', 'url': 'https://fedscoop.com/wp-content/uploads/sites/5/2023/01/FedScoop-Black.png', 'contentUrl': 'https://fedscoop.com/wp-content/uploads/sites/5/2023/01/FedScoop-Black.png', 'width': 1231, 'height': 182, 'caption': 'FedScoop'}, 'image': {'@id': 'https://fedscoop.com/#/schema/logo/image/'}}]",,,https://fedscoop.com/wp-content/uploads/sites/5/2019/02/GettyImages-1044327296-e1691617386125.jpg?w=150&h=150&crop=1,,,['Jackson Barnett'],
https://news.google.com/rss/articles/CBMibWh0dHBzOi8vd3d3LmVuZXJneS5nb3YvYWkvYXJ0aWNsZXMvY29uZ3JhdHVsYXRpb25zLW1hcmdhcmV0LWxlbnR6LXdpbm5pbmctMjAyMC1nZWFycy1nb3Zlcm5tZW50LWNvdW5jaWwtYXdhcmTSAQA?oc=5,Congratulations to Margaret Lentz for Winning a 2020 Gears of Government Council Award - Energy.gov,2020-07-06,Energy.gov,https://www.energy.gov,Margaret worked with two other DOE employees to develop the Artificial Intelligence Exchange (AIX) database.,N/A,Margaret worked with two other DOE employees to develop the Artificial Intelligence Exchange (AIX) database.,Margaret worked with two other DOE employees to develop the Artificial Intelligence Exchange (AIX) database.,,,,,,,,,,,,N/A,N/A,"



 











Congratulations to Margaret Lentz of AITO for winning a 2020 Gears of Government Council Award(link is external) (filter by DOE) for her work in the development of the Artificial Intelligence Exchange (AIX) database. The AIX was created year to track all AI activities across the DOE enterprise, gain perspective on the strengths in the DOE’s AI portfolio, and identify cross-cutting areas that will advance American leadership in AI.Working with co-awardees, Pamela Isom and Wende Wiles from the Office of the Chief Information Officer, the AIX team was able to create this digital platform to help AITO in its mission to synchronize AI applications to advance the agency’s core missions.Congratulations to Margaret, Pam and Wende on a job well done!







 







",,,,,,,,,,,,

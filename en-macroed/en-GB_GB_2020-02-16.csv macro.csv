URL link,Title,Date,Source,Source Link,description,keywords,og:description,twitter:description,@context,@type,url,image,author,publisher,headline,datePublished,dateModified,articleSection,name,isAccessibleForFree,itemListElement,article:section,article:summary,article text,@id,alternateName,potentialAction,mainEntity,genre,wordcount,mainEntityOfPage,@graph,dateCreated,heading,thumbnailUrl,associatedMedia,articleBody,video,foundingDate,sameAs,logo,parentOrganization,actionableFeedbackPolicy,correctionsPolicy,ethicsPolicy,Masthead,missionCoveragePrioritiesPolicy,ownershipFundingInfo,unnamedSourcesPolicy,publishingPrinciples,isPartOf,alternativeHeadline
https://news.google.com/rss/articles/CBMiiwFodHRwczovL3d3dy5mb3JiZXMuY29tL3NpdGVzL2RhdmlkdGVpY2gvMjAyMC8wMi8xOC9hcnRpZmljaWFsLWludGVsbGlnZW5jZS1haS1hbmQtdGhlLWxhdy1oZWxwaW5nLWxhd3llcnMtd2hpbGUtYXZvaWRpbmctYmlhc2VkLWFsZ29yaXRobXMv0gEA?oc=5,Artificial Intelligence (AI) And The Law: Helping Lawyers While Avoiding Biased Algorithms - Forbes,2020-02-18,Forbes,https://www.forbes.com,"Law is an avenue in which to test the integration between AI and people. Automation won’t be replacing the lawyer any time soon, but as AI evolves it will be able to increasingly assist the people in the industry, to become more educated about their options and to use their time more efficiently.","ai,artificial intelligence,bias,law,legal","Law is an avenue in which to test the integration between AI and people. Automation won’t be replacing the lawyer any time soon, but as AI evolves it will be able to increasingly assist the people in the industry, to become more educated about their options and to use their time more efficiently.","Law is an avenue in which to test the integration between AI and people. Automation won’t be replacing the lawyer any time soon, but as AI evolves it will be able to increasingly assist the people in the industry, to become more educated about their options and to use their time more efficiently.",http://schema.org,BreadcrumbList,https://www.forbes.com/sites/davidteich/2020/02/18/artificial-intelligence-ai-and-the-law-helping-lawyers-while-avoiding-biased-algorithms/,"{'@type': 'ImageObject', 'url': 'https://imageio.forbes.com/specials-images/imageserve/5e4c0c7b99d449000735353c/0x0.jpg?format=jpg&height=900&width=1600&fit=bounds', 'width': 542.79, 'height': 304.6}","{'@type': 'Person', 'name': 'David A. Teich', 'url': 'https://www.forbes.com/sites/davidteich/', 'description': ""David A. Teich is interested in artificial intelligence (AI), machine learning (ML), robotics, and other advances technologies, focused on how they help businesses improve performance. He's an analyst and consultant in those areas as well as in high tech, B2B, marketing. Previous work runs the gamut in software, including operations, development, field consulting, sales engineering and product marketing. He has worked in startups, mid-sized companies and global organizations."", 'sameAs': ['http://www.linkedin.com/in/davidteich', 'https://www.twitter.com/Teich_Comm', 'https://teich-communications.com/']}","{'@type': 'NewsMediaOrganization', 'name': 'Forbes', 'url': 'https://www.forbes.com/', 'ethicsPolicy': 'https://www.forbes.com/sites/forbesstaff/article/forbes-editorial-values-and-standards/', 'logo': 'https://imageio.forbes.com/i-forbesimg/media/amp/images/forbes-logo-dark.png?format=png&height=455&width=650&fit=bounds'}",Artificial Intelligence (AI) And The Law: Helping Lawyers While Avoiding Biased Algorithms,2020-02-18T11:14:13-05:00,2020-02-18T11:14:13-05:00,AI,Artificial Intelligence (AI) And The Law: Helping Lawyers While Avoiding Biased Algorithms,False,"[{'@type': 'ListItem', 'position': 1, 'name': 'Forbes Homepage', 'item': 'https://www.forbes.com/'}, {'@type': 'ListItem', 'position': 2, 'name': 'Innovation', 'item': 'https://www.forbes.com/innovation/'}, {'@type': 'ListItem', 'position': 3, 'name': 'AI', 'item': 'https://www.forbes.com/ai/'}]",AI,N/A,"More From ForbesJul 16, 2024,09:30am EDTIn Superconvergence, Jamie Metzl Unravels AI MysteriesJul 15, 2024,09:30pm EDTAnswering Your Most Frequently Asked Questions (FAQs) About Artificial Intelligence In Honor Of National AI Appreciation DayJul 15, 2024,06:06pm EDTNot Just A Maker Space: Fab Labs Spark Innovation WorldwideJul 15, 2024,02:57pm EDTIBM InstructLab And Granite Models Revolutionizing LLM TrainingJul 15, 2024,09:42am EDTHow Generative AI Is Driving HyperpersonalizationJul 15, 2024,08:00am EDTThe Clever ‘Rephrase And Respond’ Prompting Strategy Provides Big Payoffs For Prompt EngineeringJul 13, 2024,09:00am EDTBig Tech Involvement With OpenAI Sparks Unease Among RegulatorsEdit StoryForbesInnovationAIEditors' PickArtificial Intelligence (AI) And The Law: Helping Lawyers While Avoiding Biased AlgorithmsDavid A. TeichSenior ContributorOpinions expressed by Forbes Contributors are their own.B2B technology analyst, marketer, and consultantFollowingFollowClick to save this article.You'll be asked to sign into your Forbes account.Got itFeb 18, 2020,11:14am ESTUpdated Feb 18, 2020, 11:14am ESTThis article is more than 4 years old.Share to FacebookShare to TwitterShare to LinkedinÂ©Sergey Tarasov - stock.adobe.com
Artificial intelligence (AI) has the potential to help every sector of the economy. There is a challenge, though, in sectors that have fuzzier analysis and the potential to train with data that can continue human biases. A couple of years ago, I described the problem with bias in an article about machine learning (ML) applied to criminal recidivism. It’s worth revisiting the sector as time have changed in how bias is addressed. One way is to look at sectors in the legal profession where bias is a much smaller factor.


Tax law has a lot more explicit rules than, for instance, do many criminal laws. As much as there have been issues with ML applied to human resource systems (Amazon’s canceled HR system), employment law is another area where states and nations have created explicit rules. The key in choosing the right legal area. What seems to be the focus, according to conversations with people at Blue J Legal, is the to focus on areas with strong rules as opposed to standards. The former provide the ability to have clear feature engineering while that later don’t have the specificity to train an accurate model.”

Blue J Legal arose from a University of Toronto course started by the founders, combining legal and computer science skills to try to predict cases. The challenge was, as it has always been in software, to understand the features of the data set in the detail needed to properly analyze the problem. As mentioned, the choice of the tax system was picked for the first focus. Tax law has a significant set of rules that can be designed. The data can then be appropriately labeled. After their early work on tax, they moved to employment.

PROMOTED
The products are aimed at lawyers who are evaluating their cases. The goal is to provide the attorneys statistical analysis about the strength and weaknesses of each case.

The Feature Engineering Challenge
It is important to note that “employment” is a category of legal issues. Each issue must be looked at separately, and each issue has its own set of features. For instance, in today’s gig economy, “Is the worker a contractor or an employee?” is a single issue. The Blue J Legal team mentioned that they found between twenty and seventy features for each issue they’ve addressed.
That makes clear that feature engineering is a larger challenge than is the training of the ML system. That has been mentioned by many people but still too many folks have focused on the inference engine because it’s cool. Turning data into information is a more critical part of the ML challenge.
MORE FOR YOUBlackRock CEO Issues ‘Massive’ Warning After Crypto Flip That Powered A Bitcoin, Ethereum And XRP Price BoomIngrid Andress’ National Anthem At 2024 Home Run Derby Draws Criticism OnlineApple iPhone 16 Pro Design Upgrade Promises Key Feature Boost, Report Says
Once the system is trained, the next challenge is to get the lawyers to provide the right information in order to analyze their current cases. They must enter (or their clerks must enter…) information about each case that match the features to be analyzed.









DailyDozen
US


Forbes Daily: Join over 1 million Forbes Daily subscribers and get our best stories, exclusive reporting and essential analysis of the day’s news in your inbox every weekday.




                Sign Up
            


By signing up, you agree to receive this newsletter, other updates about Forbes and its affiliates’ offerings, our Terms of Service (including resolving disputes on an individual basis via arbitration), and you acknowledge our Privacy Statement. Forbes is protected by reCAPTCHA, and the Google Privacy Policy and Terms of Service apply.




You’re all set! Enjoy the Daily!


                More Newsletters
            


You’re all set! Enjoy the Daily!

                More Newsletters
            



On a slightly technical note, their model uses decision trees. They did try the Random Forest model, of interest in other fields, but found their accuracy dropped.
Blue J Legal claims their early version provides 80-90% accuracy.


1/1





Skip Ad
 
Continue watchingafter the adVisit Advertiser websiteGO TO PAGE
Removing Bias: A Plus And A Minus
By removing variables that can drive bias, such as male v female, they are able to train a more general system. That’s good from a pure law point of view, but unlike the parole system mentioned above, that could cause problems in a lawyer’s analysis of a problem. For instance, if a minority candidate is treated more poorly in the legal system, a lawyer should know about that. The Blue J Legal team says they did look at bias, both in their Canadian and USA legal data, but state that the two areas they are addressing don’t see bias that would change the results in a significant way.
One area of bias they’ve also ignored is that of judges, for the same reason as above. I’m sure it’s also ignored for marketing reasons. As they move to legal areas with fewer rules and more standards, I could see a strong value for lawyers in knowing if the judge to whom the case has been assigned has strong biases based on features of the case or the plaintiff. Still, if they analyzed the judges, I could see other bias being added as judges might be biased against lawyers using the system. It’s an interesting conundrum that will have to be addressed in the future.
How The System Should Be Used By Lawyers
There is a clear ethical challenge in front of lawyers that exists regardless of bias. For instance, if the system comes back and tells the lawyer that 70% of cases that are similar go against the plaintiff, should the lawyer take the case? Law is a fluid profession with many cases being similar but not identical. How does the lawyer decide if the specific client is in the 70% or the 30%? How can a system provide information help a lawyer decide to take a case with lower probability or reject one with a higher probability? The hope is, as with any other profession, that the lawyer would carefully evaluate the results. However, as in all industries, busy people take shortcuts and far too many people have taken the old acronym of GIGO to no longer mean “garbage in, garbage out,” but rather “garbage in, gospel out.”
One way to help is to provide a legal memo. The Blue J Legal system provides a list of lawyer provided answers and similar cases for each answer. Not being a lawyer, I can’t tell how well that has been done, but it is a critical part of the system. Just as too many developers focus on the engine rather than feature engineering, they focus on the engine while minimizing the need to explain the engine. In all areas where machine learning is applied, but especially in professions, black box systems can’t be trusted. Analysis must be supported in order for lawyers to understand and evaluate how the generic decision impacts their specific cases.
Law is an interesting avenue in which to test the integration between AI and people. Automation won’t be replacing the lawyer any time soon, but as AI evolves it will be able to increasingly assist the people in the industry, to become more educated about their options and to use their time more efficiently. It’s the balance between the two that will be interesting to watch.
Follow me on Twitter or LinkedIn. Check out my website. David A. TeichFollowingFollowDavid A. Teich is interested in artificial intelligence (AI), machine learning (ML), robotics, and other advances technologies, focused on how they help... Read MoreEditorial StandardsPrintReprints & Permissions",,,,,,,,,,,,,,,,,,,,,,,,,,,,
https://news.google.com/rss/articles/CBMibGh0dHBzOi8vd3d3LmJidmFvcGVubWluZC5jb20vZW4vYXJ0aWNsZXMvYXJ0aWZpY2lhbC1pbnRlbGxpZ2VuY2UtYW5kLXRoZS1mdXR1cmUtb2Ytd29yay1jaGluZXNlLXBlcnNwZWN0aXZlL9IBAA?oc=5,Artificial Intelligence and the Future of Work: A Chinese Perspective | OpenMind - BBVA OpenMind,2020-02-16,BBVA OpenMind,https://www.bbvaopenmind.com,Artificial Intelligence will transform the labor market and increase productivity and wealth but we should not lose sight of the risks involved.,N/A,Artificial Intelligence will transform the labor market and increase productivity and wealth but we should not lose sight of the risks involved.,Artificial Intelligence will transform the labor market and increase productivity and wealth but we should not lose sight of the risks involved.,http://schema.org,WebSite,https://www.bbvaopenmind.com/en/,,,,,,,,OpenMind,,,N/A,N/A,"



Start
Artificial Intelligence and the Future of Work: A Chinese Perspective



			Economy        

			Global Economy        







Article from the book Work in the Age of Data


Artificial Intelligence and the Future of Work: A Chinese Perspective

Artificial Intelligence | Work 

		Listen    














Kai-Fu Lee



								Sinovation Ventures                            



Estimated reading time
Time

  15  
to read






























As with most technological breakthroughs, the hype when it comes to artificial intelligence (AI) has far preceded its widespread application in the real world. This article explores key challenges that need to be overcome over the next decade, at a global level, in order to ensure that AI’s potential can be successfully deployed to enhance our working lives and productivity gains. It also places the responsibility for AI advancement firmly in the court of “traditional” industries—radical impact will not come from the technology sector alone, rather from the innovative, timely, and systematic adoption of AI by established companies. While focused on AI’s global impact, the article also provides a Chinese perspective on challenges and opportunities of its adoption at scale. 
Introduction: The Age of AI
Klaus Schwab, founder and executive chairman of the World Economic Forum and author of The Fourth Industrial Revolution, characterized the era we currently live in as defined by “a fusion of technologies that is blurring the lines between the physical, digital, and biological spheres.” 1 No previous technological revolution drew upon so many different advancements all at once, and most certainly not at a comparable speed.
The velocity of innovation caused by this multimodal transformation has prompted a heated debate about the future of humanity, asking us to examine the limits of our own capacity to understand and make use of the technological breakthroughs previously never thought possible: can our understanding keep up with the changes at hand? How do we adjust? Will machines eventually rule our lives? What does it mean to be human in the age of the machines?
Our cognitive functions have not kept up with technological advancements. Human relationship with intelligent machines is still perhaps best epitomized by Arthur C. Clarke’s and Stanley Kubrick’s HAL 9000—something to admire and fear in equal measure—prompting us to defend, while at the same time question, the supremacy of human intelligence. What do we do with the machines whose limits we may not be able to imagine?
If the rate of technological change continues at this pace, it follows that humans will soon be flanked by automatons and robots, automating every aspect of our lives.
Well, maybe someday. In reality, the science trails considerably behind the futuristic visions of a society where artificial intelligence (AI) reigns supreme. In fact, if I were to make a prediction today, based on the scientific progress at hand, I would say with confidence that true machine intelligence at human level is a very distant prospect, if ever reachable.
Advancements in AI have so far been limited to single-domain tasks. As of today, AI can more efficiently process vast quantities of information about something very specific, such as playing a game, health-care diagnostics, or speech recognition. But it cannot think laterally to apply learnings to a different domain. It cannot form an opinion about what it is doing. And it most certainly does not have any feelings about what it is doing.
But, whether we realize truly intelligent machines (often referred to as Artificial General Intelligence or AGI) or not, AI is already transforming how we live and work, finding its way into most domains of human activity. While technologists and pundits debate humans’ future relationship with machines, what is not debated nearly enough is the imminent impact of various AI-powered technologies. How do we cope with job loss? How do we ensure our education systems can keep up? What about social services?
Our understanding of ourselves and our role in society is already, if slowly, being challenged. If humans will no longer be required to perform an array of jobs, and if what we have learned at school may soon no longer apply—how do we adjust our course and our expectations of our working lives? Such questions should be front-of-mind for governments, their economic advisers, education ministers, school principals and deans, and business leaders, as well as parents everywhere.
And So It Begins
We are already at the epicenter of synchronous disruption brought upon by AI across all industries. I use a “Four Waves of AI” framework to elaborate AI’s impact on the business scenario—they do not come one after the other, but rather simultaneously, transforming the way we live (fig. 1).

Fig. 1. Four waves of AI
The first wave of AI innovation, Internet AI, began around 2010, completely transforming our use of the Internet with the breakthrough brought by the invention of deep learning. Search, online advertising, social media, e-commerce—advancements in these online activities that are now part and parcel of our everyday lives—have all been predicated on advancements in AI.
In 2014, businesses, particularly those where data is readily available, started to embrace AI, creating the foundations for the advancement of industries such as AI fintech, remote education, digitization of public services, and supply chain management. I would call this second, largely software-driven, wave of innovation— Business AI.
Perception AI began to make inroads in 2016, enhancing machines’ ability to capture human senses, analyze, and make decisions based on such data. Computer vision technology has become mainstream: machines now recognize human faces, traffic patterns, or even merchandise we select from stores. Speech recognition technology can now analyze and synthesize languages, enabling simultaneous translations and machine-generated news reporting. We will see fast development of AI in software and hardware during this wave.
Most recently, in 2018, autonomous systems saw their first applications across industries, allowing us to imagine the not-so-distant future where autonomous vehicles dominate the roads, and possibly even airways. Automation AI is already transforming traditional heavy-weight players in transportation, logistics, and manufacturing, to name a few.
In what seems like the blink of an eye, we have found ourselves in possession of a multifaceted technology whose application is as pervasive as that of electricity. In fact, it may not be an exaggeration to say that we already may not know what it means to have lived without AI.
What is more, the transformation through AI has only just begun. Leaders across industries have begun to consider AI’s application for their own businesses en masse. According to Deloitte’s “State of AI in the Enterprise” 2019 report, 2 57% of business leaders believe that AI will have a transformative impact on their own company in the next three years. While fewer, 38%, believe AI will power the same transformation across their industries, the trajectory is clear: AI is permeating most domains of human endeavor. What will separate the winners from the losers is their ability to grasp the magnitude of change and adapt in time.
The fundamental truth of our time is as follows: AI is the greatest frontier facing humanity to date and we must act now to get it right.
How Prepared Are We for AI?
AI’s potential to change the way we live and work is so vast that its current uses are a mere scratch on the surface of what is yet to come. Every aspect of our lives will be affected, and every corner of the world we live in will be implicated in the change.
But, will it affect everyone in the same way?
Research shows that AI will enable the creation of unprecedented wealth: PricewaterhouseCoopers (PwC) estimates that the wide adoption of AI will add about $15.7 trillion to worldwide GDP by 2030 3—barely a decade from now. This growth will continue its exponential trajectory toward the year 2050.
There is tremendous business value to be gained through the adoption of AI, but wealth creation will not be even. As I indicate in my book—AI Superpowers: China, Silicon Valley, and the New World Order—gains from early AI innovation are akin to winner-takes-all scenario, with two economic giants—the United States and China—already leading the way, being the homes to all of the world’s corporate AI giants. In the PwC predictions I mentioned above, the most significant growth is expected to come from China, not least due to its vast population, which accounts for almost a fifth of all the world’s people.
A screen shows the SenseVideo pedestrian and vehicle recognition system developed by SenseTime Group Ltd at the company’s showroom in Beijing
Inequality between countries must be tackled through international diplomacy channels, with the US and China lending their resources and know-how to avoid exacerbating global inequality. But even more pertinently, inequality within countries—stemming from job displacement, skills gap, education inequality, and lack of access—must be made a national priority for governments and businesses across the world.
While it may take fifteen or more years for AI-powered technologies to have an impact across industries, we must act quickly to put in place the infrastructure needed to avoid massive disruption and lessen human hardship that will inevitably come in the form of vast job losses and the uneven distribution of wealth.
AI Infusion
While we are enamored by great AI companies like Deepmind, the $15.7 trillion value will not be realized through them. From today’s vantage point, AI’s biggest opportunity is infusion into traditional companies. This will be greatly enhanced by the rapid development of AI platforms, so that more and more traditional companies can implement AI, without requiring deep AI expertise.
AI’s greatest potential is in infusing existing businesses with new ways of problem-solving, new levels of speed and accuracy, new efficiencies, and new ways of working and thinking about what is possible. AI can be used to optimize existing processes (such as saving costs by up to 80% on back-office outsourcing or customer service), to improve processes (such as using AI to reshape sales forecasts, logistics, and supply chain), or to disrupt industries (such as using AI to help medical scientists discover drugs many times faster than today).
Business leaders must embrace the long view. Few can afford resistance to change, as businesses must integrate AI as part of their strategy in order to stay relevant. Referring back to the Deloitte study, many more executives believe AI to play a role in offering a more competititve edge to their own companies than that of their industries overall. This suggests that a blind spot is emerging, as the pace of innovation coming from elsewhere may catch businesses off guard. The fact is, no one can remain complacent as AI moves to the top of the agenda across the board.
Anticipating where disruption may come from and upskilling to be ready to take on the level of technological and operational change caused by AI will become a part of the business strategy playbook across all industries.
Impact on Jobs
The impact of AI on job creation and loss is largely misunderstood. The doomsday narrative would have us believe that AI will cause such a level of disruption that it will mark the end of the workplace as we know it. All jobs will be gone, spelling economic hardship for most of us. I am personally against the dystopian view of AI destructing the values of mankind.
A different interpretation of the same scenario holds that AI will spare us the drudgery of work, allowing us, instead, to lead lives of leisure in some sort of utopian state.

According to Deloitte’s “State of AI in the Enterprise” 2019 report, 57% of business leaders believe that AI will have a transformative impact on their own company in the next three years

The reality is somewhere in the middle. It is true that up to half of all jobs are likely to face extinction or disruption due to the introduction of AI. What may have surprised those in industries already starting to be affected is what kinds of jobs have started to disappear first.
It may seem counterintuitive, but manual jobs, such as those in most manufacturing fields, will not be significantly affected for the time to come.
Today’s machines are much better at grasping quantitative reasoning than basic sensorimotor skills. It is extremely difficult to achieve a level of meaningful dexterity and precision in most robotic applications. So, it is repetition-rich white-collar jobs that are already being more readily disrupted than the blue-collar ones.
Robotic Process Automation (RPA)
A lot of human activity today is focused on domain-specific tasks that, when injected with a lot of data, can be more efficiently performed by AI. It is estimated that up to one-fifth 4 of all tasks performed by humans at work is spent on repetitive computer tasks that can be automated.
Robotic Process Automation (RPA), with the use of AI and machine learning to process high-volume repetitive tasks, has started to gain traction among companies whose employees spend a significant amount of time on manual tasks, such as query handling, calculations, data entry, or record maintenance. Jobs at the forefront of disruption include those in business process outsourcing: for example, tax examiners filling numbers into cells and tables every day in order to generate data comparison and analysis.
RPA can provide significant value for businesses by freeing up their employees to focus on more complex, higher-value tasks. At the same time, it means companies can now start to reduce the number of people they employ in certain single-domain job positions.
Employers will need to understand the trade-off between efficiency gains and impact on employee morale. Communicating with transparency about the changes in business needs and implementing retraining programs where possible will help both employers and employees transition more successfully.
Is Anyone Safe?
I have established that AI can be used to perform routine work more efficiently. But AI has no creativity, no compassion, nor the ability to connect with humans and win their trust. The higher the requirement for compassion or creativity in any given job, the less likely it is for AI to replace humans in performing such tasks (fig. 2).

Some fields, such as medical diagnostics, may experience a symbiosis between people and machines. For example, doctors can rely on AI to more accurately diagnose a disease based on data at hand, while they can provide not just the treatment plan, but also the warmth and the trust that are key for human interaction. Research 5 shows that human connection can have a significant impact on the quality of health outcomes. Equally, scientists can use AI tools to discover drugs with higher accuracy. But machines cannot replace the scientists’ ability to hypothesize and apply learnings, and communicate to patients with knowledge and trust.
With this in mind, it is critical for governments, businesses, and education institutions to determine what types of jobs will give humans an edge over the machines and make a plan to create more of these. Likewise, understanding where humans will be most needed should have an impact on curricula everywhere: how should we go about preparing children for the future in work? What skills will they need to ensure employability throughout the course of their working lives?
China’s AI Competitive Edge
The sheer size of China’s population, nearly 1.4 billion, and its embrace of mobile technology as part of everyday life has given China an edge when it comes to quality data crucial for the development of AI. Mobile phones are truly at the epicenter of everyday life in China—from food ordering to peer-to-peer payments to charity donation—the Chinese of all ages rely on mobile payments for most of their transactions. The vast amount of data generated in such a way allows merchants and services platforms to adopt a targeted approach to customer acquisition—causing, in turn, massive disruption of traditional industries.
AI is already omnipresent in China—from mobile payments as already mentioned, to AI-enriched mobile applications, face-recognition authentification, autonomous retail stores, AI personalized news aggregation, to customized product recommendations. The use of AI also plays a growing role in connecting rural school children with so-called “super teachers,” who can now be connected to classrooms across the country, offering an immersive, interactive experience for the students and making quality education more accessible even in China’s remote mountain villages, given the sheer size and resource disparity between cities and regions.

While its size and abundance of data due to mobile technology maturity certainly represent China’s fundamental advantage, its rise as an AI superpower has been predicated on painstaking promotion of entrepreneurism and infrastructure development

In short, mobile-first consumer demands are fueling AI innovation and digitization of the Chinese economy fast and at scale. Adding to this is the Chinese relentlessly dedicated entrepreneurial culture, significant venture capital funding, and government incentives for the development of AI.
While its size and abundance of data due to mobile technology maturity certainly represent China’s fundamental advantage, its rise as an AI superpower has been predicated on painstaking promotion of entrepreneurism and infrastructure development. Readily available funding for AI has attracted a huge number of AI technical talents, providing a crucial advantage in the form of a qualified workforce.
All of these combined have enabled Chinese AI companies to cover competitive ground fast and catch up with, and even surpass, the pace of innovation coming out of Silicon Valley.
AI’s Impact on China’s Labor Market
Various studies of AI’s likely impact on the Chinese labor market illustrate the difficulty in predicting AI outcomes on the workforce with any degree of certainty.
PwC offers an optimistic view of AI’s impact on jobs in China, estimating that, on balance, the adoption of AI will lead to a 12%, or 93 million, increase in jobs, an income increase of 38%, and a possible GDP increase of 1.4% per year on top of current rates. 6
While some 200 million jobs are expected to be lost to automation, there is an expectation that 300 million jobs will be created. However, both job loss and creation are not expected to be spread evenly across all sectors or synchronized in time.
A customer uses his smartphone to scan a QR code for payment at a pork stall inside the Dancun Market in Nanning, Guangxi province
McKinsey and Co., 7 in turn, ranks China among countries most likely to be affected by automation, with 51% of work activities potentially being affected by automation.
On balance, China’s economy faces the same challenges as the rest of the world when it comes to AI. While its advantage when it comes to pace of innovation delivered by its AI companies is indisputable, for all countries it is the preparedness for jobs disruption, on the national level, that will be necessary to ensure successful mitigation of imminent job losses.
While having the privilege of talking to leading policy- makers around the world, it is obvious to me that most countries are keenly aware of and deeply concerned about the collective societal impact on the workforce brought by the coming AI revolution. It is also an area where I would advocate for higher international collaboration to share best practices on policy enhancement, social programs, public-private partnerships, and innovations in the public service sector to ensure successful transition to AI across our society.
Conclusion on Jobs
The age of AI, just like the earlier technology revolutions, is expected to lead to significant job creation. But, we do not know for sure what these jobs will look like, nor when they may start to appear.
When the Internet first came into being, no one could have predicted the arrival of Uber and the impact on traditional taxi companies. Or the disruption of the hospitality industry brought upon it by Airbnb. Equally, we cannot predict what innovative ideas are yet to be enabled by AI.
AI will also transform entire business models within existing companies. It is hard to imagine that, once upon a time, Microsoft had an Internet division. Nowadays, of course, the Internet is integrated into every aspect of its business.
The key challenge in dealing with the transition period already underway is the massive job disruption that will precede job creation. Unfortunately, those affected by the former may not be the benefactors of the latter. AI is unlikely to create new routine jobs that would require humans to do them. Thus, retraining will be required to prepare the displaced routine workers for non-routine jobs at a massive scale to mitigate the effects on job losses.
At the moment, very little is being done across the world to account for pending job displacement. One of the seminal challenges of our time is finding a way to prepare new generations to not only enter the workforce, but also thrive throughout their working lives. This despite the pace of technological innovation and constantly moving goalposts when it comes to demand for skills and specialized knowledge.
Improving education has never been an easy task. Redesigning it entirely to shift the center of gravity away from knowledge transfer and toward self-awareness and self-discovery is a monumental task, yet a necessary one. We must prepare our children for an entirely new relationship between humans and machines.
A visitor at the Onassis Cultural Center in Athens looks at the multimedia project Data Flux, in which Japanese artist Ryoji Ikeda challenges the limits of human perception and digital technology
Training and retraining must be a priority for business and governments, but this alone will not be enough to address the fundamental shift in what will be required to be able to ride the wave of disruption in the job market. As technology continues to disrupt existing processes and ways of working, field-specific expertise will matter less than transferable skills, adaptability, critical thinking, compassion, and self-awareness. These are the skills that will allow young people to navigate the changing world of work. What may constitute a career today may be gone tomorrow, so the ability to reskill and adapt will be more important than any domain-specific knowledge.
We must attempt to answer questions such as: what constitutes lasting knowledge and what value should we assign to it? What is the role of education in the world where ability to adapt and change ensures our survival more than holding onto what we know?
Ensuring a competitive edge in the global race to lead in AI innovation requires concerted government action: reforming education, job creation, incentivizing entrepreneurship, building the necessary infrastructure to enable innovation to thrive, enabling trustworthy data collection, and training AI application engineers should all be seen as priorities.
The End of Privacy?
It is often said that AI has put an end to privacy as we know it. With millions of digital records that we all leave behind constantly, and technologies that can differentiate our unique features, the danger of misuse is evident.
Every day, a vast quantity of personal data is being collected and stored to drive new AI technologies. On the one hand, these technologies, run by algorithms that improve themselves through consuming more and more quality data, have the potential to make our lives better and more convenient. On the other, we must ensure that personal information does not fall prey to the dangers of misuse.
In response, policy-makers across the world have sought to regulate the transfer of data, hoping to create a more transparent and trustworthy relationship between consumers and companies. Enter Europe’s General Data Protection Regulation (GDPR) and California’s Consumer Privacy Act, which both stipulate that companies must obtain consumers’ consent before collecting their data.
I do believe that these regulations play a role in protecting individual privacy; however, it is both a limiting and a limited way to deal with the issues at hand. Privacy is not binary. Any privacy regulation must proactively balance considerations of data protection with that of user convenience and value they get in return. This trade-off is largely subjective; it differs among individuals and across countries.

New data protection regulations play a role in protecting individual privacy, but it is both a limiting and a limited way to deal with the problem

How do we balance the need for scientific progress and the value (convenience, security, social good) brought about by new technologies with the need to better protect personal privacy? Policies alone will tilt the spectrum to the latter, at the expense of the former. So, while regulations are needed, we must also consider technology solutions.
We should question the hypothesis that convenience and privacy are mutually exclusive. We should investigate technologies that protect privacy yet allow the data to be used to improve AI. For example, homomorphic encryption is a method of irreversibly encrypting data to enhance privacy protection. Federated learning, a technology that allows learning to take place in trusted environments, is currently being tested in a number of places.
Consider this scenario: a thousand hospitals are interested in using the power of their collective data to train AI-powered diagnostic tools. Due to patient data privacy rules that restrict the use of data within a single health-care institution, patient information cannot be aggregated in one central place—making it impossible to train AI with sufficient data. With federated learning, AI training takes place at each of the hospitals, “federating” the resulting learnings, while “raw data” never leaves the hospital premises. These technologies are not yet perfected, but further research and testing must be encouraged.
AI as a Force for Good
AI’s impact is akin to a tidal change morphing the very axis of our lives. I fundamentally believe that AI can act as a force for good across the world. Equally, I am not oblivious to the potential for its misuse. We have a great responsibility to ensure that AI can live up to its potential—whether it be job creation, medical advancement, transformation of industry processes, access to better education, or making our everyday lives easier through countless conveniences—both big and small.
I hope that we can harness the collective concerns and enthusiasm for AI to start addressing the key questions about its impact on our world. I hope that we can tackle security concerns in a way that is sensitive to regional and cultural differences, while mindful of humanity’s future. That, as entrepreneurs, we can start shifting our business mindset from short-term profit to long-term viability by understanding AI’s transformative value and its impact on worker training and retraining. That governments can start to scrutinize education to ensure our children are equipped for the changes to come. That we can focus job creation on areas where us people, with our empathy, compassion, and creativity, will remain irreplaceable.
Regardless of global competition for technological dominance, we need concerted action across the nations to ensure that AI can live up to its potential. How we go about engaging with each other on this topic today will decide the nature of the human relationship with AI.

Notes
1. Klaus Schwab, The Fourth Industrial Revolution, World Economic Forum, 2016. Quote available at https://www.weforum.org/about/the-fourth-industrial-revolution-by-klaus-schwab.
2. Deloitte Insights, “State of AI in the Enterprise” report, 2nd ed., 2019, available at https://www2.deloitte.com/insights/us/en/focus/cognitive-technologies/ai-investment-by-country.html.
3. PricewaterhouseCoopers, “Global artificial intelligence study: Exploiting the AI revolution,” 2017, available at https://www.pwc.com/gx/en/issues/data-and-analytics/publications/artificial-intelligence-study.html.
4. SDET, “Robotic Process Automation: Statistics, business impact and future,” available at http://www.pavantestingtools.com/2017/10/robotic-process-automation-statistics.html#.WsaCtdPwbMI.
5. Julianne Holt-Lunstad, Timothy B. Smith, J. Bradley Layton, “Social relationships and mortality risk: A meta-analytic review,” July 27, 2010, available at https://doi.org/10.1371/journal.pmed.1000316.
6. PricewaterhouseCoopers, “What will be the net impact of AI and related technologies on jobs in China?” 2018, available at https://www.pwc.com/gx/en/issues/artificial-intelligence/impact-of-ai-on-jobs-in-china.pdf.
7. McKinsey Global Institute, “Artificial intelligence: Implications for China,” 2017, available at https://www.mckinsey.com/~/media/McKinsey/Featured%20Insights/China/Artificial%20intelligence%20Implications%20for%20China/MGI-Artificial-intelligence-implications-for-China.ashx.



Quote this content







    Related publications  


Predicting the Economic Future Through Convergence: The Case of China


The Past Decade and Future of AI’s Impact on Society


Provably Beneficial Artificial Intelligence









Download Kindle


            (4.0 MB)
          





Download EPUB

(1.7 MB)





Download PDF

(5.6 MB)




Download Podcast
(45.9 MB)





                See 2020 book            
Work in the Age of Data





 




",#website,OpenMind,"{'@type': 'SearchAction', 'target': 'https://www.bbvaopenmind.com/en/?s={search_term_string}', 'query-input': 'required name=search_term_string'}",,,,,,,,,,,,,,,,,,,,,,,,,
https://news.google.com/rss/articles/CBMibGh0dHBzOi8vd3d3LnZveC5jb20vcmVjb2RlLzIwMjAvMi8xOC8yMTEyMTI4Ni9hbGdvcml0aG1zLWJpYXMtZGlzY3JpbWluYXRpb24tZmFjaWFsLXJlY29nbml0aW9uLXRyYW5zcGFyZW5jedIBAA?oc=5,"Algorithms and bias, explained - Vox.com",2020-02-18,Vox.com,https://www.vox.com,A computer can make a decision faster. That doesn’t make it fair.,N/A,A computer can make a decision faster. That doesn’t make it fair.,N/A,,,,,,,,,,,,,,N/A,N/A,"TechnologyWhy algorithms can be racist and sexistA computer can make a decision faster. That doesn’t make it fair.by  Rebecca HeilweilFeb 18, 2020, 12:20 PM ESTFacebookLink Christina Animashaun/VoxRebecca Heilweil covered emerging technology, artificial intelligence, and the supply chain.FacebookLinkHumans are error-prone and biased, but that doesn’t mean that algorithms are necessarily better. Still, the tech is already making important decisions about your life and potentially ruling over which political advertisements you see, how your application to your dream job is screened, how police officers are deployed in your neighborhood, and even predicting your home’s risk of fire. But these systems can be biased based on who builds them, how they’re developed, and how they’re ultimately used. This is commonly known as algorithmic bias. It’s tough to figure out exactly how systems might be susceptible to algorithmic bias, especially since this technology often operates in a corporate black box. We frequently don’t know how a particular artificial intelligence or algorithm was designed, what data helped build it, or how it works.Typically, you only know the end result: how it has affected you, if you’re even aware that AI or an algorithm was used in the first place. Did you get the job? Did you see that Donald Trump ad on your Facebook timeline? Did a facial recognition system identify you? That makes addressing the biases of artificial intelligence tricky, but even more important to understand.Machine learning-based systems are trained on data. Lots of it.When thinking about “machine learning” tools (machine learning is a type of artificial intelligence), it’s better to think about the idea of “training.” This involves exposing a computer to a bunch of data — any kind of data — and then that computer learns to make judgments, or predictions, about the information it processes based on the patterns it notices. For instance, in a verysimplified example, let’s say you wanted to train your computer system to recognize whether an object is a book, based on a few factors, like its texture, weight, and dimensions. A human might be able to do this, but a computer could do it more quickly.To train the system, you show the computer metrics attributed to a lot of different objects. You give the computer system the metrics for every object, and tell the computer when the objects are books and when they’re not. After continuously testing and refining, the system is supposed to learn what indicates a book and, hopefully, be able to predict in the future whether an object is a book, depending on those metrics, without human assistance. That sounds relatively straightforward. And it might be, if your first batch of data was classified correctly and included a good range of metrics featuring lots of different types of books. However, these systems are often applied to situations that have much more serious consequences than this task, and in scenarios where there isn’t necessarily an “objective” answer. Often, the data on which many of these decision-making systems are trained or checked are often not complete, balanced, or selected appropriately, and that can be a major source of — although certainly not the only source — of algorithmic bias.Nicol Turner-Lee, a Center for Technology Innovation fellow at the Brookings Institution think tank, explains that we can think about algorithmic bias in two primary ways: accuracy and impact. An AI can have different accuracy rates for different demographic groups. Similarly, an algorithm can make vastly different decisions when applied to different populations.Importantly, when you think of data, you might think of formal studies in which demographics and representation are carefully considered, limitations are weighed, and then the results are peer-reviewed. That’s not necessarily the case with the AI-based systems that might be used to make a decision about you. Let’s take one source of data everyone has access to: the internet. One study found that, by teaching an artificial intelligence to crawl through the internet — and just reading what humans have already written — the system would produce prejudices against black people and women.Join the Open Sourced Reporting NetworkChristina Animashaun/VoxOpen Sourced is Recode by Vox’s year-long reporting project to demystify the world of data, personal privacy, algorithms, and artificial intelligence. And we need your help. Fill out this form to contribute to our reporting.Another example of how training data can produce sexism in an algorithm occurred a few years ago, when Amazon tried to use AI to build a résumé-screening tool. According to Reuters, the company’s hope was that technology could make the process of sorting through job applications more efficient. It built a screening algorithm using résumés the company had collected for a decade, but those résumés tended to come from men. That meant the system, in the end, learned to discriminate against women. It also ended up factoring in proxies for gender, like whether an applicant went to a women’s college. (Amazon says the tool was never used and that it was nonfunctional for several reasons.)Amid discussions of algorithmic biases, companies using AI might say they’re taking precautions, taking steps to use more representative training data and regularly auditing their systems for unintended bias and disparate impact against certain groups. But Lily Hu, a doctoral candidate at Harvard in applied mathematics and philosophy who studies AI fairness, says those aren’t assurances that your system will perform fairly in the future. “You don’t have any guarantees because your algorithm performs ‘fairly’ on your old dataset,” Hu told Recode. “That’s just a fundamental problem of machine learning. Machine learning works on old data [and] on training data. And it doesn’t work on new data, because we haven’t collected that data yet.”Still, shouldn’t we just make more representative datasets? That might be part of the solution, though it’s worth noting that not all efforts aimed at building better data sets are ethical. And it’s not just about the data. As Karen Hao of the MIT Tech Review explains, AI could also be designed to frame a problem in a fundamentally problematic way. For instance, an algorithm designed to determine “creditworthiness” that’s programmed to maximize profit could ultimately decide to give out predatory, subprime loans.Related:This AI makes you look like a masterpiece — while teaching you about its own biasHere’s another thing to keep in mind: Just because a tool is tested for bias — which assumes that engineers who are checking for bias actually understand how bias manifests and operates — against one group doesn’t mean it is tested for bias against another type of group. This is also true when an algorithm is considering several types of identity factors at the same time: A tool may deemed fairly accurate on white women, for instance, but that doesn’t necessarily mean it works with black women. In some cases, it might be impossible to find training data free of bias. Take historical data produced by the United States criminal justice system. It’s hard to imagine that data produced by an institution rife with systemic racism could be used to build out an effective and fair tool. As researchers at New York University and the AI Now Institute outline, predictive policing tools can be fed “dirty data,” including policing patterns that reflect police departments’ conscious and implicit biases, as well as police corruption.The foundational assumptions of engineers can also be biasedSo you might have the data to build an algorithm. But who designs it, and who decides how it’s deployed? Who gets to decide what level of accuracy and inaccuracy for different groups is acceptable? Who gets to decide which applications of AI are ethical and which aren’t?While there isn’t a wide range of studies on the demographics of the artificial intelligence field, we do know that AI tends to be dominated by men. And the “high tech” sector, more broadly, tends to overrepresent white people and underrepresent black and Latinx people, according to the Equal Employment Opportunity Commission. Turner-Lee emphasizes that we need to think about who gets a seat at the table when these systems are proposed, since those people ultimately shape the discussion about ethical deployments of their technology.But there’s also a broader question of what questions artificial intelligence can help us answer. Hu, the Harvard researcher, argues that for many systems, the question of building a “fair” system is essentially nonsensical, because those systems try to answer social questions that don’t necessarily have an objective answer. For instance, Hu says algorithms that claim to predict a person’s recidivism don’t ultimately address the ethical question of whether someone deserves parole.“There’s not an objective way to answer that question,” Hu says. “When you then insert an AI system, an algorithmic system, [or] a computer, that doesn’t change the fundamental context of the problem, which is that the problem has no objective answer. It’s fundamentally a question of what our values are, and what the purpose of the criminal justice system is.” That in mind, some algorithms probably shouldn’t exist, or at least they shouldn’t come with such a high risk of abuse. Just because a technology is accurate doesn’t make it fair or ethical. For instance, the Chinese government has used artificial intelligence to track and racially profile its largely Muslim Uighur minority, about 1 million of whom are believed to be living in internment camps.Transparency is a first step for accountabilityOne of the reasons algorithmic bias can seem so opaque is because, on our own, we usually can’t tell when it’s happening (or if an algorithm is even in the mix). That was one of the reasons why the controversy over a husband and wife who both applied for an Apple Card — and got widely different credit limits — attracted so much attention, Turner-Lee says. It was a rare instance in which two people, who at least appeared to be exposed to the same algorithm and could easily compare notes. The details of this case still aren’t clear, though the company’s credit card is now being investigated by regulators.Algorithmic bias is a complicated and broad subject. To learn more, check out these sources:Ruha Benjamin, Race After Technology: Abolitionist Tools for the New Jim CodeSafiya Umoja Noble, Algorithms of Oppression: How Search Engines Reinforce RacismRachel Thomas, Getting Specific About Algorithmic BiasBut consumers being able to make apples-to-apples comparisons of algorithmic results are rare, and that’s part of why advocates are demanding more transparency about how systems work and their accuracy. Ultimately, it’s probably not a problem we can solve on the individual level. Even if we do understand that algorithms can be biased, that doesn’t mean companies will be forthright in allowing outsiders to study their artificial intelligence. That’s created a challenge for those pushing for more equitable, technological systems. How can you critique an algorithm — a sort of black box — if you don’t have true access to its inner workings or the capacity to test a good number of its decisions? Companies will claim to be accurate, overall, but won’t always reveal their training data (remember, that’s the data that the artificial intelligence trains on before evaluating newdata, like, say, your job application). Many don’t appear to be subjecting themselves to audit by a third-party evaluator or publicly sharing how their systems fare when applied to different demographic groups. Some researchers, such as Joy Buolamwini and Timnit Gebru, say that sharing this demographic information about both the data used to train and the data used to check artificial intelligence should be a baseline definition of transparency.Artificial intelligence is new, but that doesn’t mean existing laws don’t applyWe will likely need new laws to regulate artificial intelligence, and some lawmakers are catching up on the issue. There’s a bill that would force companies to check their AI systems for bias through the Federal Trade Commission (FTC). And legislation has also been proposed to regulate facial recognition, and even to ban the technology from federally assisted public housing. But Turner-Lee emphasizes that new legislation doesn’t mean existing laws or agencies don’t have the power to look over these tools, even if there’s some uncertainty. For instance, the FTC oversees deceptive acts and practices, which could give the agency authority over some AI-based tools.The Equal Employment Opportunity Commission, which investigates employment discrimination, is reportedly looking into at least two cases involving algorithmic discrimination. At the same time, the White House is encouraging federal agencies that are figuring out how to regulate artificial intelligence to keep technological innovation in mind. That raises the challenge of whether the government is prepared to study and govern this technology, and figure out how existing laws apply.“You have a group of people that really understand it very well, and that would be technologists,” Turner-Lee cautions, “and a group of people who don’t really understand it at all, or have minimal understanding, and that would be policymakers.”That’s not to say there aren’t technical efforts to “de-bias” flawed artificial intelligence, but it’s important to keep in mind that the technology won’t be a solution to fundamental challenges of fairness and discrimination. And, as the examples we’ve gone through indicate, there’s no guarantee companies building or using this tech will make sure it’s not discriminatory, especially without a legal mandate to do so. It would seem it’s up to us, collectively, to push the government to rein in the tech and to make sure it helps us more than it might already be harming us. Open Sourced is made possible by Omidyar Network. All Open Sourced content is editorially independent and produced by our journalists.You’ve read 1 article in the last monthHere at Vox, we believe in helping everyone understand our complicated world, so that we can all help to shape it. Our mission is to create clear, accessible journalism to empower understanding and action.If you share our vision, please consider supporting our work by becoming a Vox Member. Your support ensures Vox a stable, independent source of funding to underpin our journalism. If you are not ready to become a Member, even small contributions are meaningful in supporting a sustainable model for journalism.Thank you for being part of our community.Swati SharmaVox Editor-in-ChiefMembershipMonthlyAnnualOne-time$5/month$10/month$25/month$50/monthOther$50/year$100/year$150/year$200/yearOther$20$50$100$250OtherJoin for $5/monthWe accept credit card, Apple Pay, and Google Pay. You can also contribute viaMore in this streamSee allOpenAI insiders are demanding a “right to warn” the public By Sigal SamuelThe double sexism of ChatGPT’s flirty “Her” voiceBy Sigal Samuel“I lost trust”: Why the OpenAI team in charge of safeguarding humanity implodedBy Sigal Samuel
1/1





Skip Ad
 
Continue watchingafter the adVisit Advertiser websiteGO TO PAGEMost PopularAmerica is not ready for what comes nextWhat J.D. Vance really believesDid Trump’s shooting save Biden’s nomination?Project 2025: The myths and the factsThis is how you get escalation
1/1





Skip Ad
 
Continue watchingafter the adVisit Advertiser websiteGO TO PAGEToday, ExplainedUnderstand the world with a daily explainer plus the most compelling stories of the day.Email (required)Sign UpBy submitting your email, you agree to our Terms and Privacy Notice. This site is protected by reCAPTCHA and the Google Privacy Policy and Terms of Service apply.",,,,,,,,,,,,,,,,,,,,,,,,,,,,
https://news.google.com/rss/articles/CBMiZ2h0dHBzOi8vYmxvZ3MubHNlLmFjLnVrL2J1c2luZXNzcmV2aWV3LzIwMjAvMDIvMTcvdGhlLXVzZS1vZi1yb2JvdHMtYW5kLWFydGlmaWNpYWwtaW50ZWxsaWdlbmNlLWluLXdhci_SAQA?oc=5,The use of robots and artificial intelligence in war - LSE Home,2020-02-17,LSE Home,https://blogs.lse.ac.uk,N/A,technology,"The nature of war has changed significantly since the end of World War 2. Battle lines have now become opaque; an attack can come from terrorists who easily blend in as civilians, drones that are u…",N/A,,,,,,,,,,,,,,N/A,N/A,"






Abhinav Kumar
Feras A. Batarseh
February 17th, 2020

The use of robots and artificial intelligence in war


4 comments
          | 76 shares
      
Estimated reading time: 5 minutes







Abhinav Kumar
Feras A. Batarseh
February 17th, 2020


The use of robots and artificial intelligence in war


4 comments
          | 76 shares
      
Estimated reading time: 5 minutes












































      76
      Shares






The nature of war has changed significantly since the end of World War 2. Battle lines have now become opaque; an attack can come from terrorists who easily blend in as civilians, drones that are undetectable to the eye, or ballistic missiles launched from 500 miles away. To account for the increased lethality of war, a vast budget is required to maintain an active duty army. Simply recruiting a soldier costs $15,000; the cost of treating an injured US solider is about $2 million a year (Bilmes, 2014). We aim to determine whether it is possible to reduce those human costs through the deployment of computational agents and artificial intelligence (AI).
Robots that can understand their context, and deal with novelty in an open world could be a viable solution. In the next big war, AI will be king! Robots that are quicker, stronger, and more accurate will determine who the victor is. Such wars, however, can be unquestionably and unprecedently destructive, maybe to the extent of a global technological meltdown. Nonetheless, such advanced technologies should not fall into the hands of the immoral or the malevolent.
The use of robotics (or other forms of intelligent agents) in warfare has existed since WW2. Many of these early robots (such as the US’s ‘Aphrodite’ drones or the Soviet’s tele-tanks) were either ineffective or only useful for specialised operations. The use of robotics for military operations took off in the 1990s when the MQB-1 Predator drone was used by the Central Intelligence Agency (CIA). Instead of painstakingly controlling drones from close-up radio signals, drones “could be controlled by satellite from any command centre to bridge intelligence gaps” (Gotera, 2003). Although there has been considerable progress in making robots intelligent, autonomous robots still “lack the flexibility to react appropriately in unforeseen situations” (Nitsch, 2013). If autonomous robots are used in the battlefield, soldiers will acquire more responsibilities, not less. Soldiers will be expected to perform normal military tasks and use robotic assets as per mission requirements (Barnes et al., 2009).
Studies show that a soldier’s performance on the battlefield worsens if a second robotic task is added to their inventory. In a simulation experiment conducted by Chen and Joyner (Chen et al., 2009), researchers tested if gunners were able to maintain local security using a semi-autonomous unmanned ground vehicle (UGV). The results indicated that “a gunner’s target detection performance degraded significantly when he or she had to concurrently monitor, manage, or tele-operate a UGV compared to the baseline (gunnery task only)” (Barnes et al., 2009). Researchers tested the ability of participants to identify equipment and personnel while operating a UGV. Authors of the study ran their experiments in a 1/35 scaled Iraqi city. The results similarly indicated that “having an additional semiautonomous robot did not offer any advantages for participants. In some cases, it added to their difficulties”.
These types of studies indicate that having context (also known as situational awareness —SA—in the military) is essential for intelligent computational agents. Defining context for an agent, however, is far more challenging than automating a manual or repetitive task. One of the biggest challenges for developing validated and verified SA is defining objects that are unfamiliar. Often, military operators identified an improvised explosive device (or other type of dangers) only because something didn’t look right. Operators rely on previous experiences to identify subtle cues like inconsistent soil texture or a missing vehicle. If an agent can similarly assist soldiers in identifying dangers via contextual data, robotic agents will be far more effective in the battlefield. We present soldier variables that are considered as conflict contextual constructs, namely: paralinguistic, demographic, visual, and physiological variables.
Paralinguistic variables: Military operations typically occur under noisy and stressful circumstances; speech recognition is highly inaccurate under these conditions. Studies consistently show speech recognition accuracies to drop by 50-60% for speech that is emotional (Rajasekaran et al., 1986). Focusing on acoustic (or paralinguistic) features, however, reduces complexities that commonly plague linguistic features, such as: speaking different languages and dialects, having varying accents, and using different speeds of speech. Some studies indicate that using acoustic variables like speech intensity, pitch, speaking rate, and spectral features (i.e. Mel frequency) are effective at recognising emotions from speech — even under noisy conditions (Tawari et al., 2010).
Demographic variables: Research has shown that accepting robots as partners is enhanced when robots possess human-like characteristics (Kiesler et al., 2008). Examples of soldiers ascribing feelings like empathy towards their robotic tools have already been found. Therefore, it is critical to understand how robotic agents will interact with human teammates in future human-agent teams. Using metrics like personality type, age, and gender, agents could help determine whether a soldier is overreacting to a situation or playing it too safe. Research into using personality tests, demographics, geographical data, and psychographics for context-based purposes is a field that is recently gaining more traction (Batarseh et al., 2018). In a study one of us conducted (Batarseh et al. 2018), we used context-aware user interfaces to build an intelligent emergency application. The study used the Myers-Briggs personality type indication to ‘know’ who the user is and what aspects identify their personality. Individuals with a ‘judger’ personality were provided with a more structured format for the app; ‘perceivers’ were presented with a ‘dynamic’ format and so on (Batarseh et al., 2017). In a military setting, an agent could similarly use personality metrics to personalise its interaction with soldiers.
Visual variables: In real world scenarios, object information is usually degraded due to peripheral vision and distance, shadows, and illumination. Within the computer vision field, a dominant approach towards scene recognition is object-based (Siagian et al., 2005). This approach works well indoors, but for outdoors “spatial simplifications such as flat walls and narrow corridors cannot be assumed” (Siagian et al., 2005). A context-based approach could analyse the scene as a whole and embody a sense of gist. Rather than focusing exclusively on objects, classifying image data as scenes would average out random noise in isolated regions. The structure of an area could be estimated by global image features, rather than relying exclusively on local image structures. Not only would this approach be more computationally efficient, but in certain studies it has also proven to be more accurate (Siagian et al., 2005). For various reasons, analysing image data as scenes is more applicable in military settings than the object-based approach. In the battlefield, video clips of an agent will not always be stable. Agents will have to parse thorough jittery image data (as a result of explosions, gunfire, etc.) and identify the context. Additionally, agents will be expected to quickly identify a scene despite having low spatial frequency.
Physiological variables: An agent can rely on soldiers’ emotions to determine if a situation requires intervention. If a squad of soldiers is clearly distressed, the agent needs to act. Monitoring the mean heart rate, heart rate variability, voice pitch, skin conductance, skin temperature, and respiratory rate are commonly used physiological markers of stress. Most studies attempt to predict the mental stress of working professionals using heart rate data (Wijsman et al., 2011). Few studies have focused on predicting physical and emotional stress in combat or physically involved settings (Kutilek, et al., 2017). Effectively predicting and monitoring the stress levels of a soldier is important to build a context that is relevant to the health of the soldier.
Context- driven intelligent agent (CIA) is a method that unifies all four soldier variables. CIA is a technique that allows agents to understand their environment and reduce uncertainty. Context is the mathematical aggregation of all these pillars (figure 1).
Figure 1. A theoretical agent reacting to uncertainty in a soldier-agent mission

To demonstrate how demographic variables could be used for contextual purposes, we collected a dataset from www.data.gov on veteran health conditions (made available by the Department of Veterans Affairs). The dataset contained multiple health and demographic features amongst VHA (Veteran Health Administration) patients in 2013. The dataset includes data on health issues by race (Asian, black, Hispanic, white, Native American, and Pacific Islander). Within each race, soldiers with general health issues are Asian (980,433), black (21,870,275), Hispanic (8,506,126), white (98,758,347), Native American (742,994), and Pacific Islander (868,330). The top three conditions veterans suffer from are hypertension, lipid disorders, and diabetes (figure 2). While genetics and age are contributing factors, lifestyle and diet are strongly correlated to whether a person will suffer from these conditions. Soldiers often “cope with the stress of battle by smoking, drinking, and eating unhealthy” (Deal, 2011). Hypertension negatively affects military readiness (Department of Defense, 2017). Agent intervention during stressful combat settings could significantly reduce the medical effort required to keep a soldier healthy.
Figure 2. Top medical issues veterans suffer from by race

Although veterans of all races suffer from various medical conditions, not all groups suffer from medical diseases uniformly. In 2013, black soldiers made up 11% of the veteran population, yet they made up 20% of all PTSD cases amongst veterans. Hispanics consisted of 8% of all PTSD cases yet represented 6.3% of all veterans in 2013. The heat-map (figure 3) also reveals differing percentages for medical conditions by race. Accounting for possible biases in healthcare outcomes should be an important consideration for agents – especially as the percentage of minorities in the military increases in the future. Physiological variables (such as stress and hypertension) affect sensor readings and other contextual constructs that create CIA outputs. For example, infrared sensors can detect high blood pressure; so if the soldier has hypertension, the agent can factor that into the context.
Traditionally, the creation of intelligent agents has focused on incorporating autonomous features without contextual intelligence. Not considering contextual intelligence has resulted in robots with sophisticated features (i.e. facial recognition) but with limited practical usage. Despite having advanced autonomous features, military forces “still perceive of robots as RC [remote-control] cars” (Singer et al., 2009). This opinion is not without cause; in many studies, participants who controlled robots under automated navigation exhibited significantly poorer SA than participants who used manual control.
Figure 3. Heat-map of soldiers’ health percentages

 
By presenting this article, we hope to push the narrative of integrating contextual intelligence for military agents. The presented method allocates patterns of context and leads to improved soldiers’ health. The holistic goal is to empower the soldier and increase the safety of military missions that eradicate evil around the world. It is most certain that wars of the future (and WW3) will be fought using AI, but that might also mean that WW4 will be fought using sticks and stones.
Authors’ note: For further reading on contextual data analytics, open data, and AI applications, please refer to the book Data Democracy.



♣♣♣
Notes:

This blog post expresses the views of its author(s), not the position of LSE Business Review or the London School of Economics.
Featured image by Defence-Imagery, under a Pixabay licence
When you leave a comment, you’re agreeing to our Comment Policy


Abhinav Kumar is post-graduate student of computer science at George Mason University (GMU), Fairfax, Virginia. His research spans the areas of robotics, deep learning, and data systems. Abhinav has developed multiple data-driven systems and published several academic papers. He is an active member of Turing Research at GMU.
 
Feras A. Batarseh is a research assistant professor with the College of Science at George Mason University (GMU), Fairfax, VA. His research spans the areas of data science, artificial intelligence, and context-aware software systems. Dr Batarseh obtained his PhD and MSc in computer engineering from the University of Central Florida (UCF) (2007, 2011) and a graduate certificate in project leadership from Cornell University (2016). He taught data science at multiple universities including George Washington U, Georgetown U, and University of Maryland, Baltimore County. His research work has been published at various prestigious journals and international conferences. Additionally, Dr Batarseh published and edited several book chapters. He is the author and editor of Federal Data Science, and Data Democracy; both books by Elsevier’s Academic Press. For more on the Turing research group, refer to their website. For more on Dr. Batarseh, refer to his page.
 



Print Friendly


About the author



Abhinav Kumar


Abhinav Kumar is an M.Sc. student of computer science at George Mason University (GMU), Fairfax, Virginia. His research spans the areas of robotics, deep learning, and data systems. Abhinav has developed multiple data-driven systems and published several academic papers. He is an active member of Turing Research at GMU.





Feras A. Batarseh


Feras A. Batarseh is a research assistant professor with the College of Science at George Mason University (GMU), Fairfax, VA. His research spans the areas of data science, artificial intelligence, and context-aware software systems. Dr Batarseh obtained his PhD and MSc in computer engineering from the University of Central Florida (UCF) (2007, 2011) and a graduate certificate in project leadership from Cornell University (2016). He taught data science at multiple universities including George Washington U, Georgetown U, and University of Maryland, Baltimore County. His research work has been published at various prestigious journals and international conferences. Additionally, Dr Batarseh published and edited several book chapters. He is the author and editor of Federal Data Science, and Data Democracy; both books by Elsevier’s Academic Press. For more on the Turing research group, refer to this page: http://turing.cos.gmu.edu/ 
For more on Dr. Batarseh, refer to his page: http://www.ferasbatarseh.com/



Posted In: 
              Technology
                          




        4 Comments
      













 Feras Batarseh says: 



								February 19, 2020 at 2:45 am							




Correction by the authors:
Abhinav Kumar is a post-graduate student of Computer Science at GMU.

Reply 





 Helena Vieira says: 



								February 19, 2020 at 6:21 am							




Done, thank you!

Reply 





				Pingback: Sempre em Busca: Capturas na Rede de 29 de Fevereiro 





 Feras Batarseh says: 



								June 16, 2020 at 1:31 am							




You are right – it is already being deployed, but we hope that it gets safer and more ethical.

Reply 





Leave a Comment Cancel reply 
Your email address will not be published. Required fields are marked *Comment Name * 
Email * 
Website 
 

 

This site uses Akismet to reduce spam. Learn how your comment data is processed. 






Related Posts






Technology



            While Bitcoin is virtual, the rewards and risks are very real
                      
January 29th, 2016

              1
              





















Technology



            Are you allowed to augment my reality?
                      
August 22nd, 2019

              1
              





















Technology



            Blockchain and bitcoin: In search of a critique
                      
October 30th, 2017

              7
              





















Economics and Finance



            Do we need programmable money?
                      
September 14th, 2020

              2
              




















",,,,,,,,,,,,,,,,,,,,,,,,,,,,
https://news.google.com/rss/articles/CBMiSmh0dHBzOi8vd3d3LmJvc2NoLmNvbS9zdG9yaWVzL2Rlbm5lcnMtdmlldy1hcnRpZmljaWFsLWludGVsbGlnZW5jZS1ldGhpY3Mv0gEA?oc=5,The ethics of artificial intelligence - Bosch Global,2020-02-19,Bosch Global,https://www.bosch.com,Bosch CEO Volkmar Denner talks about the benefits of artificial intelligence and the need to set ethical limits to the technology. Read more!,N/A,Bosch CEO Volkmar Denner talks about the benefits of artificial intelligence and the need to set ethical limits to the technology. Read more! via @BoschGlobal,Bosch CEO Volkmar Denner talks about the benefits of artificial intelligence and the need to set ethical limits to the technology. Read more! via @BoschGlobal,,,,,,,,,,,,,,N/A,N/A,"                   Denner’s view    Share this on:              “We have to not only develop AI, but build trust in AI as well” Dr. Volkmar Denner, Bosch CEO, on the ethics of artificial intelligence                             2020-02-19   It’s time to stop being hysterical about artificial intelligence. We need to focus on its benefits in everyday life. by Dr. Volkmar Denner           Artificial intelligence needs to serve people, not the other way around. Accordingly, it must not be allowed to escape human oversight. How can human and machine intelligence complement each other? The need to provide answers to such questions has prompted Bosch to draw up a code of ethics that examines both the benefits of AI and the ethical red lines it must not cross. It sets out criteria for making decisions about the development and use of intelligent systems. In the AI age, values are especially important: responsibility engenders trust. There is certainly a grain of truth here, but it doesn’t tell the whole story. After all, Europe has strengths that other countries do not — strengths in combining the internet of things with industrial processes, and especially in applying artificial intelligence to manufacturing. It’s high time for Europe to be more self-assertive, and to adopt an innovation policy that plays to our strengths.           “We want to make AI safe, robust, and explainable for people, whether in manufacturing or automated driving.”   Volkmar Denner, Bosch CEO      Share on X/Twitter           AI can move beyond preconceived opinions      Public opinion is still informed by misgivings, or even by dystopian science fiction. In such dystopian visions, AI outstrips human intelligence, cannot be controlled, and costs people their jobs, if not more. The Bosch vision is a different one: we want to make AI safe, robust, and explainable for people, whether in manufacturing or automated driving. What Bosch sees in the world of work is not only technological change but also of a lack of skilled workers — and in such a context, collaboration between people and intelligent machines takes on additional significance. This calls for companies that use customized HR and training policies to strategically shape the digital transformation — companies that invest in both the qualifications of their associates and the intelligence of their machines. Bosch too sees itself as a learning company. Over the next two years, we will be making nearly 20,000 associates fit for the development and use of AI.          AI can mitigate global warming       But the social benefits of AI go beyond everyday routine and the world of work: artificial intelligence will be a blessing for environmental protection and climate action. Even now, the Bosch energy management platform uses intelligent algorithms to detect and control individual machines’ energy consumption. Depending on the individual plant, this can reduce CO₂ by 10 percent within two years. And in the future, we will be able to use artificial intelligence to make long-term forecasts, and thus to reduce energy consumption. All this is reason enough to stop the endless debates about the risks of technology and focus on the opportunities instead.                     The Bosch energy management platform uses intelligent algorithms to detect and control individual machines’ energy consumption.          AI may be responsible for 75 million jobs being lost by 2022, but also for 133 million new jobs being created.   Forecast by World Economic Forum         AI creates markets      At the same time, artificial intelligence has huge economic potential. It is not only Bosch that sees this potential, but many different studies as well. The management consultants PwC, for example, project that between now and 2030, AI will boost GDP in China by 26 percent, by 14 percent in North America, and by around 10 percent in Europe. And according to a World Economic Forum forecast, AI may be responsible for 75 million jobs being lost by 2022, but also for 133 million new jobs being created. If such forecasts are even remotely realistic, they indicate the huge economic relevance of artificial intelligence. But we will only be able to tap this potential if we can convince people of the benefits of AI — and above all build trust in digital systems.          AI needs responsibility                    How can human and artificial intelligence work together?       Companies such as Bosch have to take two paths in order to make a success story out of AI. Developing technological conditions and solutions, and using innovations to open up new field of business, is the one path. The other is to convince society at large of the benefits of AI. It is precisely for this reason that Bosch has drawn up a code of ethics for responsible use of artificial intelligence. We have to not only develop AI, but build trust in AI as well, and the one cannot become established without the other. For success in digital business, trust will be crucial, just as quality is for our classic product business.           AI needs human oversight       As we move toward an ethics of AI, what are the decisive issues? First and foremost, people must not completely renounce control over artificially intelligent systems. Instead, they must remain involved in these systems’ decisions. Take the example of driver assistance, where AI supports and relieves drivers of burdensome tasks. Nonetheless, drivers retain responsibility and can override the system. On no account should the algorithms of AI models be a black box. They should be developed with due care, keeping everyone in the loop. Only in this way will automated decisions be fair, and understandable for experts. When it comes to the ethics of artificial intelligence, Bosch not only gives its own engineers guidance, but is also keen to take part in a open exchange of views. What decisions can we leave to machines? When and where should people intervene? Companies need to openly discuss questions such as these with policymakers, the scientific community, and society.          AI must also be “Invented for life”       In the end, the issue at stake here is the crucial balance that has to be struck between the economic and social strands of entrepreneurial responsibility. At first glance, there appears to be a paradox: we want to develop business with AI, but are defining ethical limits to technological development. Only if we observe these red lines can trust arise, and it is our belief that, in the long run, trust is the lifeblood of our business.  It’s as simple as that. And in our new AI code of ethics, we make no bones about our red lines. For example, we will not allow one life to be pitted against another. The code of ethics doesn’t take the easy way out. Instead, it makes Bosch’s strategic imperative fit for the future, and insists that artificial intelligence also be “Invented for life.”           First published in Handelsblatt on 2020/02/19          Bosch guidelines for the use of artificial intelligence          Code of ethics for AILearn more          Denner’s view Artificial intelligence        Share this on:               Explore more      StoryArtificial IntelligenceArtificial intelligence in automated driving   CEO blogDenner’s viewWhere Europe can lead the way in AI   StorySoundSeeImproving life on the International Space Station (ISS)       ",,,,,,,,,,,,,,,,,,,,,,,,,,,,
https://news.google.com/rss/articles/CBMiMmh0dHBzOi8vd3d3Lm5hdHVyZS5jb20vYXJ0aWNsZXMvZDQxNTg2LTAyMC0wMDAxOC0z0gEA?oc=5,Powerful antibiotics discovered using AI - Nature.com,2020-02-20,Nature.com,https://www.nature.com,Machine learning spots molecules that work even against ‘untreatable’ strains of bacteria.,N/A,Machine learning spots molecules that work even against ‘untreatable’ strains of bacteria.,Nature - Machine learning spots molecules that work even against ‘untreatable’ strains of bacteria.,https://schema.org,WebPage,,,,,,,,,,,,N/A,N/A,"




NEWS
20 February 2020

Powerful antibiotics discovered using AI


                    Machine learning spots molecules that work even against ‘untreatable’ strains of bacteria.
                




    By
    
        
        
                Jo Marchant0




Jo Marchant


Jo Marchant is a science journalist based in London.




View author publications

You can also search for this author in PubMed
 Google Scholar













Twitter





Facebook





Email











Access through your institution




Buy or subscribe





A pioneering machine-learning approach has identified powerful new types of antibiotic from a pool of more than 100 million molecules — including one that works against a wide range of bacteria, including tuberculosis and strains considered untreatable.

Access options





Access through your institution









Access through your institution




Change institution




Buy or subscribe



Access Nature and 54 other Nature Portfolio journalsGet Nature+, our best-value online-access subscription$29.99 / 30 dayscancel any timeLearn moreSubscribe to this journalReceive 51 print issues and online access$199.00 per yearonly $3.90 per issueLearn moreRent or buy this articlePrices vary by article typefrom$1.95to$39.95Learn morePrices may be subject to local taxes which are calculated during checkout

Additional access options:


Log in


Learn about institutional subscriptions


Read our FAQs


Contact customer support




doi: https://doi.org/10.1038/d41586-020-00018-3

ReferencesStokes, J. M. et al. Cell https://doi.org/10.1016/j.cell.2020.01.021 (2020).Article 
    
                    Google Scholar 
                Mohimani, H. et al. ACS Chem. Biol. 9, 1545–1551 (2014).Article 
    PubMed 
    
                    Google Scholar 
                Cao, L. et al. Cell Syst. 9, 600–608 (2019).Article 
    PubMed 
    
                    Google Scholar 
                Download references


Reprints and permissions

Related Articles





                        
                        The last resort
                    






                        
                        Antibiotic resistance has a language problem
                    






                        
                        Resistance to last-ditch antibiotic has spread farther than anticipated
                    



Subjects


Infection


Antibiotics



Latest on:


Infection





Can H5N1 spread through cow sneezes? Experiment offers clues
News 16 JUL 24





What drives mosquitoes’ bloodlust? Their hormones
News 01 JUL 24





Mini saunas save endangered frogs from fungal disease
News & Views 26 JUN 24






Antibiotics





Blueprints for ATP machinery will aid tuberculosis drug design
News & Views 03 JUL 24





Drug-resistant infections more likely to strike women, says WHO
News 05 JUN 24





‘Smart’ antibiotic can kill deadly bacteria while sparing the microbiome
News 29 MAY 24










Can H5N1 spread through cow sneezes? Experiment offers clues
News 16 JUL 24





What drives mosquitoes’ bloodlust? Their hormones
News 01 JUL 24





Mini saunas save endangered frogs from fungal disease
News & Views 26 JUN 24










Jobs
                





Postdoctoral Fellow

To study how a population of skeletal stem cells mediate bone regeneration and orchestrate a composite tissue regeneration program using mouse models.
Hospital for Special Surgery, New York City, New York (US)
Hospital for Special Surgery








Lecturer / Associate Professor in Advanced Cell Models

Lecturer / Associate Professor in Advanced Cell Models Cell and Developmental Biology Location: Highfield Campus Salary: £44,263 to £72,018 per ann...
Southampton, Hampshire (GB)
University of Southampton








Lecturer / Associate Professor in Biological Sciences

Lecturer / Associate Professor in Biological Sciences School of Biological Sciences Location: Highfield Campus Salary: £44,263 to £72,018 per annum...
Southampton, Hampshire (GB)
University of Southampton








Associate Professor / Professor in Microbial Biofilms

Associate Professor / Professor in Microbial Biofilms Microbiology Location: Highfield Campus Salary: Associate Professor Level 6 - £57,696 to £72,...
Southampton, Hampshire (GB)
University of Southampton








Lecturer / Associate Professor in Computational Biology

Lecturer / Associate Professor in Computational Biology School of Biological Sciences Location: Highfield Campus Salary: £44,263 to £72,018 per ann...
Southampton, Hampshire (GB)
University of Southampton








",,,,"{'headline': 'Powerful antibiotics discovered using AI', 'description': 'Machine learning spots molecules that work even against ‘untreatable’ strains of bacteria.  Machine learning spots molecules that work even against ‘untreatable’ strains of bacteria.', 'datePublished': '2020-02-20T00:00:00Z', 'dateModified': '2020-02-20T00:00:00Z', 'sameAs': 'https://doi.org/10.1038/d41586-020-00018-3', 'keywords': ['Antibiotics', 'Infection', 'Science', 'Humanities and Social Sciences', 'multidisciplinary'], 'image': ['https://images.nature.com/lw1200/magazine-assets/d41586-020-00018-3/d41586-020-00018-3_17728252.jpg'], 'isPartOf': {'name': 'Nature', '@type': ['Periodical']}, 'publisher': {'name': 'Nature Publishing Group UK', 'logo': {'url': 'https://www.springernature.com/app-sn/public/images/logo-springernature.png', '@type': 'ImageObject'}, '@type': 'Organization'}, 'author': [{'name': 'Jo Marchant', '@type': 'Person'}], 'isAccessibleForFree': True, '@type': 'NewsArticle'}",,,,,,,,,,,,,,,,,,,,,,,,
https://news.google.com/rss/articles/CBMiqwFodHRwczovL3d3dy5icnVzc2Vsc3RpbWVzLmNvbS85NTk1MC9jaGFsbGVuZ2VzLW9wcG9ydHVuaXRpZXMtYW5kLWV0aGljYWwtZGlsZW1tYXMtaG93LWFydGlmaWNpYWwtaW50ZWxsaWdlbmNlLWNvdWxkLXRyYW5zZm9ybS10aGUtZXVyb3BlYW4tZWNvbm9taWMtYW5kLXBvbGl0aWNhbC1sYW5kc2NhcGXSAQA?oc=5,How Artificial Intelligence could transform the European economic and political landscape - The Brussels Times,2020-02-19,The Brussels Times,https://www.brusselstimes.com,,,,,,,,,,,,,,,,,,N/A,N/A,N/A,,,,,,,,,,,,,,,,,,,,,,,,,,,,
https://news.google.com/rss/articles/CBMiR2h0dHBzOi8vZW1lcmouY29tL2FpLWZ1dHVyZS1vdXRsb29rL3dlYXBvbml6ZWQtYXJ0aWZpY2lhbC1pbnRlbGxpZ2VuY2Uv0gEA?oc=5,Weaponized Artificial Intelligence – Critical Dual-Use Applications - Emerj,2020-02-20,Emerj,https://emerj.com,Find out how governments and militaries can weaponize artificial intelligence applications common in business for national security initiatives and defense.,,Find out how governments and militaries can weaponize artificial intelligence applications common in business for national security initiatives and defense.,N/A,https://schema.org,Article,,https://emerj.com/wp-content/uploads/2020/02/Weaponized-Artificial-Intelligence@2x-690x327.jpg,Dylan Azulay,"{'@type': 'Organization', 'name': 'Emerj', 'url': 'https://emerj.com', 'logo': {'@type': 'ImageObject', 'url': 'https://emerj.com/wp-content/themes/emerj/src/logo/emerj-logo-w-500-min.png'}}",Weaponized Artificial Intelligence – Critical Dual-Use Applications,2020-02-17,2020-02-20,,,,,N/A,N/A," Business intelligence and analyticsGovernmentSecurity Weaponized Artificial Intelligence – Critical Dual-Use Applications Dylan AzulayLast updated on February 20, 2020  Last updated on February 20, 2020, published by Dylan Azulay Dylan is Senior Analyst of Financial Services at Emerj, conducting research on AI use-cases across banking, insurance, and wealth management. Share to: LinkedIn Twitter Facebook Email  This article is based on a presentation given by Emerj CEO Daniel Faggella in Geneva, at the 2019 New Shape Forum: Weapons Governance for the Geneva Disarmament Platform. To learn more about Emerj’s AI presentations and speaking, visit our presentations page. There are many more AI applications than there are governments and militaries experimenting with AI. But the AI products that are becoming more commonplace in the business world do have their use in national security and defense efforts.  It will take years to update physical weapons systems, such as tanks, planes, and missiles, with machine learning technology, but there are ways to weaponize artificial intelligence without mounting it on any weapons. The fast-moving world of enterprise AI will be the origin of various dual-use applications that can be repurposed for military use-cases. At Emerj, the AI Research Company, we map the capabilities of AI across security, surveillance, and defense – including dual-use AI applications. In our work with government and enterprise clients, and in presentations for organizations like United Nations and INTERPOL, we emphasize the importance of staying abreast of general AI capabilities that have significant future impacts on security and risk. From computer vision applications in retail to text summarization technology in the legal field – AI’s capabilities are being used as both weapons and defenses. In this article, we break down the dual-use applications of three prominent AI techniques, all of which will be important for weaponizing AI in the future: Computer Vision: Image and video analysis to survey physical space and respond to behavioral patterns Natural Language Processing: Text and voice analysis for real-time translation, summarization, sentiment analysis, and information extraction. Programmatically Generated Content: AI-generated 3D representations of people, places, and things. The slide deck for the original presentation is embedded below: We begin our discussion of critical dual-use applications of computer vision: Application 1: Computer Vision  Computer vision is the AI capability to analyze visual information and use it to detect changes in real-time. Computer vision capabilities include pattern detection and image analysis. Retail: Pattern Recognition Brick-and-mortar retail stores use computer vision-enabled security systems for pattern recognition, allowing them to detect shoplifting and other kinds of theft, including instances in which cashiers intentionally fail to scan an item when ringing up a customer. Computer vision applications can alert security teams when it detects a customer putting an item into their bag or coat, for example, allowing them to respond before the customer has left the building. Computer-vision enabled pattern recognition software can be repurposed for surveillance efforts. Governments and militaries could integrate computer vision software into security cameras along building perimeters or on vehicles in order to track the movements of suspicious people and enemy personnel.  Finance: Image Analysis Computer vision software can be trained to detect entities within an image or real-time video. Wealth managers might use computer vision to analyze satellite images of ports and cargo ships out at sea. The US Department of Defense’s Project MAVEN is a prominent example of computer vision in the public sector – but many private sector vision applications could be repurposed for military use. This could give them information on imports and exports, which could lead them to make better decisions about which companies to invest in for their clients. Militaries could repurpose this technology to detect the positions of key targets on a battlefield, as well as the positions of ally and enemy personnel, within satellite images and videos.  Computer vision-enabled analysis could allow militaries conducting reconnaissance missions to predict the movement of enemy vehicles, as well as the munition and fuel levels of those vehicles. Computer vision could also detect the existence of large oil containers within a satellite image, which could give militaries a better view of where they can refuel their vehicles. Healthcare: Image Analysis Similarly, in healthcare, computer vision software is starting to find its niche in diagnostics. Doctors could upload patient CT, PET, and MRI scans to a computer vision-enabled software, and the software could detect if the scans show any evidence of cancer or not. Doctors can then use this analysis in diagnosing a patient with cancer, sometimes well before they would have been able to detect a patient’s cancer had they reviewed the scans on their own. Militaries and governments could use a similar computer vision-based image analysis application to detect landmines within an image or real-time video. Militaries can integrate the software into their existing land mine-detecting robots, allowing them to more accurately find land mines before allowing their personnel to drive or run through a potentially dangerous area.  Application 2: Natural Language Processing Natural language processing (NLP) is a machine learning approach that can discern intent and sentiment from text and speech. Some of the most prominent NLP use-cases are sentiment analysis, search and discovery, summarization, and translation. Translation NLP-enabled translation tools have become ubiquitous across industries at global organizations that need to communicate with clients that speak various languages. Google Translate and similar translation applications allow employees at these companies to speak into a microphone and have their voice translated to text in another language in real-time. Alibaba has a similar application. The demonstration below shows how a supply chain manager might interact with a supplier when both speak different languages:  The most obvious use-case for translation technology in government is in diplomatic meetings. Although translators are still necessary, in the future, diplomats and other government officials may be able to communicate with each other solely through these translation apps, hearing each other’s voices in their native languages. Life Sciences: Summarization Life sciences companies looking to develop new treatments need to read through hundreds of scientific studies to determine where to focus their R&D efforts and to figure out how certain treatments might interact with each other and with different population groups. NLP-enabled summarization software serves to expedite this process by condensing studies into short snippets of information or brief abstracts. This can save researches time they can instead spend on developing and running trials for the treatments they want to test. Governments and militaries can use NLP software to summarize reports on reconnaissance efforts and other intelligence reports. They could also summarize communications between diplomats and other government officials. Pharmaceuticals: Sentiment Analysis Pharmaceutical companies use NLP-based sentiment analysis software to analyze public feedback logged on social media that can inform marketing decisions. Pharmaceutical companies may want to know which of their competitor’s drugs or generics are referenced most frequently alongside their own and how well the public is responding to their drug or pricing. This could inform how marketers at the pharmaceutical company choose to advertise and brand their drug. Similarly, governments may be able to use NLP-based sentiment analysis software to research how the public is responding to their actions by analyzing social media and news articles.  Certain governmental departments may also use sentiment analysis software to analyze the emotions laden within communications between government officials via email, text, and phone. This could better allow government officials to deescalate tense communications if necessary or push the limits of their negotiations.  Finance: Search and Discovery Wealth management firms can use search and discovery products to find all of the files the firm has on a particular customer and search the internet for news about financial markets. For example, a wealth manager could use an NLP-enabled search and discovery software to pull up all of the call center transcripts and emails that a customer has logged with the firm, allowing the wealth manager to better respond to the customer’s concerns and get a better idea of the kinds of investments that might satisfy them. The wealth manager could then use a search and discovery software to learn about acquisitions, mergers, bankruptcies, layoffs, and other events going on in the market. This could allow a wealth manager to make more informed decisions on where to invest a customer’s money. National security agencies could use search and discovery software to extract key information from text, email, and phone communications between potential bad actors, such as known international terrorists and domestic terrorists that may be plotting an attack. They could also run the software on suspicious conversations in the hopes of discovering admissions of criminal activity in order to catch criminals or intervene in the case of potential terrorism. Application 3: Programmatically Generated Content Programmatically generated content refers to computer-generated, realistic 3D representations of people, places, and things. For example, machine learning can generate “paintings” in the style of famous artists. Rembrandt never painted the piece below; an algorithm did: A Rembrandt painting generated entirely by artificial intelligence. It can also compose and arrange its own music; all a human has to do is input a music genre, and the machine learning software generates a track on its own:  Machine learning is currently the most effective technique for generating the kind of realism that has grave national security implications. Deepfakes, which involves replacing the face of one person with that of another within a video or image, is one example of machine learning-created programmatically generated content. In addition to face-swapping, machine learning is capable of generating entirely new faces. None of the people in the photos below are real. They never existed: All of these faces were generated by machine learning on ThisPersonDoesNotExist.com, courtesy of The Verge. Companies that develop machine learning for these generative purposes want to be seen as benevolent or at least ambivalent because of the technology’s potential for harm and power acquisition. Generally, they use a strategy of discouraging use and activity on other platforms while owning a large enough digital ecosystem that current users are incentivized to stay within it. There are numerous precedents for this type of strategy as outlined below: Facebook buying Oculus Rift in order to attract more attention in the virtual reality space Amazon and Google competing over the home assistant market Google and Facebook briefly competing in the social space during the advent of Google+ Both Google and Facebook also competing against Amazon within eCommerce How Countries and Governments may want to use AI A country’s goal with AI is to attain power through the means of a strong economy and military. By fostering a society that is compliant with the ethical concerns of the technology, a country’s government could encourage that society to support the goals of the ruling party. This is most effective in governments where leaders cannot be voted out. Precedents in Countries Outside the US There are numerous instances of countries taking steps to assert dominance in the digital and AI spaces. While we do not attribute these steps to any specific country, these practices indicate attempts to gain or maintain power using data acquisition and other digital methods. These practices and methods include: Countries forming their own independent internet, which can deter dissidents and inculcate society. They have also formed their own VR technology for the same reason.  Countries that are wary of relinquishing control of their virtual ecosystems to other populations have resisted outside hardware and digital ecosystems. Examples of these include 5G signal technology and social media sites like Twitter. Some countries have used digital ecosystems to interfere with the politics and societies of democratic nations with open governments. Governments that use their private virtual ecosystems can sometimes use the major players within that ecosystem as an extension of the ruling party’s will. This could be a national car manufacturer or food distribution company. A government may be able to leverage AI and machine learning to accomplish any of these tasks. The possibilities are much broader for a situation like this than would normally arise in other industries. For example, sentiment analysis may be particularly beneficial for governments looking to gain a strategic advantage in the social media domain. Its ROI in business, however, is less proven, relegated mostly to marketers that may or may not be better off directing their efforts elsewhere. Takeaways for Military Experts We hypothesize that over the course of the 21st century, all competition between the world’s most powerful nations and organizations will become more focused on controlling the computational substrate that houses human experience and AI. These organizations could be political, military, or economic in nature.  This raises concerns about how democratic nations should ethically leverage new AI capabilities. Additionally, these nations should consider how they should set up digital governance and a sense of normalcy for how this type of data acquisition should transpire. In the case of foreign policy, it is important to consider how governments will handle any malicious and abusive use of AI by autocratic states. While these concerns may not be the top priority in 2019, they will become increasingly important within the next decade. AI developers, their clients, and the governments they each answer two should consider these long term issues as they continue to move forward with AI initiatives in their business. Emerj for Security and Defense Leaders Emerj helps organizations assess the AI applications landscape for security and defense. Using Emerj’s AI Opportunity Landscapes, professionals in security and defense can identify critical AI applications, find ideal vendor partners, and find AI trends for law-enforcement, anti-money laundering, weapons systems and more. Learn more about the AI Opportunity Landscape. Related Posts All Bill Gates’ Artificial Intelligence QuotesEarlier this month we released an article featuring all of the AI risk quotes from… Conscious AI – We Aught Wake Up Before the Machines DoIn the ongoing ""pop culture"" debate as to whether or not the pursuit of AI… Artificial Intelligence: State Initiatives and C-Suite ImplicationsThis article was written and contributed by Thomas A. Campbell, Ph.D. and Jon Fetzer of… Should the United Nations Play a Role in Guiding Post-Human Artificial Intelligence?This article is the fifth installment in the AI FutureScape series, and in it, we… Can Artificial Intelligence Make the World a Better Place?My most recent TEDx is titled “Can AI Make the World a Better Place?” -… Share to: LinkedIn Twitter Facebook Email  Exclusive AI Best Practice Guides and MoreThe Emerj Plus membership gives professionals the ability to take charge of AI disruption and steer their companies (and their careers) into more opportunity and profitability. Learn more: Learn More",,,,,AI Future Outlook,2217,https://emerj.com/ai-future-outlook/weaponized-artificial-intelligence,,,,,,,,,,,,,,,,,,,,,
https://news.google.com/rss/articles/CBMiXmh0dHBzOi8vd3d3Lmpucy5vcmcvaXNyYWVsaS1sZWFkZXItaW4tYXJ0aWZpY2lhbC1pbnRlbGxpZ2VuY2UtZWFybnMtMS1taWxsaW9uLWRhbi1kYXZpZC1wcml6ZS_SAQA?oc=5,Israeli leader in artificial intelligence earns $1 million Dan David Prize - JNS.org - JNS.org,2020-02-19,JNS.org,https://www.jns.org,N/A,N/A,"Amnon Shashua, known for his work in artificial intelligence as CEO of Mobileye and co-founder of OrCam, will receive the 2020 Dan David Prize alongside Dr. Demis Hassabis, co-founder and CEO of DeepMind.",N/A,https://schema.org,,,,,,,,,,,,,N/A,N/A,"





update desk 

Israeli leader in artificial intelligence earns $1 million Dan David Prize 

Amnon Shashua, known for his work in artificial intelligence as CEO of Mobileye and co-founder of OrCam, will receive the 2020 Dan David Prize alongside Dr. Demis Hassabis, co-founder and CEO of DeepMind. 


CEO of Mobileye and co-founder of OrCam Amnon Shashua. Credit: Heinz Troll European Patent Office.  








Facebook


Twitter


WhatsApp



Email



Print




(February 19, 2020 / JNS)Israeli tech leader Amnon Shashua will be awarded the 2020 Dan David Prize for his contributions to the field of artificial intelligence (AI) as CEO of Mobileye and co-founder of OrCam, a tech company that harnesses AI-driven computer vision.
The international Dan David prize, headquartered at Tel Aviv University, is awarded annually and includes three prizes of $1 million to each of three recipients for outstanding scientific, technological, cultural or social impact on the world.
Shashua has published more than 120 papers on artificial intelligence, holds more than 45 patents and pioneered the use of tensor analysis to computer vision and machine learning. His work has resulted in safer driving and innovation in autonomous vehicles. Since Mobileye’s acquisition by Intel in 2017, he has worked as senior vice president of Intel’s executive leadership team.
Alongside Shashua, Dr. Demis Hassabis, co-founder and CEO of DeepMind, has also been named a 2020 Dan David Prize laureate in the field of AI.
A British child chess prodigy turned game-designer, he combined insights from neuroscience and machine learning with the latest developments in computer hardware to publish nearly 1,000 papers, archiving breakthrough results in challenging AI domains from gaming to medicine.

Co-founder and CEO of DeepMind Demis Hassabis in London, July 2018. Credit: Wikimedia Commons.

Upon being named 2020 Dan David Prize recipient, Shashua said: “It is with great honor and gratitude that I receive the 2020 Dan David Prize in the field of AI, together with Dr. Hassabis. I am very fortunate to be affiliated with its distinguished list of laureates.
“Transforming modern life for the better, using artificial intelligence, has always been my primary motivation, and this prize holds an excellent opportunity to increase awareness to the great promise of AI for the benefit of humanity,” he explained.
Hassabis said “it’s such an honor to have been chosen to receive the 2020 Dan David Prize alongside my colleague, Professor Shashua, and so many other luminaries over the years. At DeepMind, we believe AI could be one of humanity’s most useful inventions—acting as a multiplier for human ingenuity and ushering in a new renaissance of scientific discovery.
“This award is a great recognition of the work we have done so far, and hopefully, a sign of the impact we aspire to achieve in the future.”
Laureates donate 10 percent of their award money to scholarships for graduate and post-graduate researches in their respective fields.
Past recipients of the Dan David prize have included authors A.B. Yehoshua (2017), Margaret Atwood (2010), filmmaking duo the Coen Brothers (2011), former U.S. Vice President Al Gore (2008) and former British Prime Minister Tony Blair (2009), among many others.
Ariel David, director of the Dan David Foundation and son of the prize founder, said: “We are very proud of the model the Dan David Prize applies in turning the spotlight on endeavors that often do not fall under traditional prize categories, yet result in outstanding contributions to humanity, defining who we are and shaping our future.”


You have read 3 articles this month. 
Register to receive full access to JNS.

Register for free

Already registered? Log in for full access 






Just before you scroll on...

Israel is at war.
JNS is combating the stream of misinformation on Israel with real, honest and factual reporting. In order to deliver this in-depth, unbiased coverage of Israel and the Jewish world, we rely on readers like you.
The support you provide allows our journalists to deliver the truth, free from bias and hidden agendas.
Can we count on your support?
Every contribution, big or small, helps JNS.org remain a trusted source of news you can rely on.


Become a part of our mission by donating today


Already a member? Log in to stop seeing this






Facebook


Twitter


WhatsApp



Email



Print




Republish this article in your newspaper or website


Topics

Artificial IntelligenceMobileyeTechnologyIsraeli High-TechDan David Prize 


 CommentsJoin the conversation.Register here to post your comment. Already have an account? Login here.Post a commentsubmitNo comment yet. Leave a comment so your voice will be heard first.


Load more





",,,,,,,,"[{'@type': 'Article', '@id': 'https://www.jns.org/israeli-leader-in-artificial-intelligence-earns-1-million-dan-david-prize/#article', 'isPartOf': {'@id': 'https://www.jns.org/israeli-leader-in-artificial-intelligence-earns-1-million-dan-david-prize/'}, 'author': {'name': 'Eliana Rudee', '@id': 'https://www.jns.org/#/schema/person/d65e0409c0993d0403ff6458b67c157d'}, 'headline': 'Israeli leader in artificial intelligence earns $1 million Dan David Prize', 'datePublished': '2020-02-19T17:57:35+00:00', 'dateModified': '2020-02-19T17:57:35+00:00', 'mainEntityOfPage': {'@id': 'https://www.jns.org/israeli-leader-in-artificial-intelligence-earns-1-million-dan-david-prize/'}, 'wordCount': 505, 'publisher': {'@id': 'https://www.jns.org/#organization'}, 'image': {'@id': 'https://www.jns.org/israeli-leader-in-artificial-intelligence-earns-1-million-dan-david-prize/#primaryimage'}, 'thumbnailUrl': 'https://cdn.jns.org/uploads/2020/02/Amnon-S.-PHOTO-Credit-Heinz-Troll-European-Patent-Office-scaled.jpg', 'keywords': ['Artificial Intelligence', 'Mobileye', 'Technology', 'Israeli High-Tech', 'Dan David Prize'], 'articleSection': ['JNS'], 'inLanguage': 'en-US', 'copyrightYear': '2020', 'copyrightHolder': {'@id': 'https://www.jns.org/#organization'}}, {'@type': 'WebPage', '@id': 'https://www.jns.org/israeli-leader-in-artificial-intelligence-earns-1-million-dan-david-prize/', 'url': 'https://www.jns.org/israeli-leader-in-artificial-intelligence-earns-1-million-dan-david-prize/', 'name': 'Israeli leader in artificial intelligence earns $1 million Dan David Prize - JNS.org', 'isPartOf': {'@id': 'https://www.jns.org/#website'}, 'primaryImageOfPage': {'@id': 'https://www.jns.org/israeli-leader-in-artificial-intelligence-earns-1-million-dan-david-prize/#primaryimage'}, 'image': {'@id': 'https://www.jns.org/israeli-leader-in-artificial-intelligence-earns-1-million-dan-david-prize/#primaryimage'}, 'thumbnailUrl': 'https://cdn.jns.org/uploads/2020/02/Amnon-S.-PHOTO-Credit-Heinz-Troll-European-Patent-Office-scaled.jpg', 'datePublished': '2020-02-19T17:57:35+00:00', 'dateModified': '2020-02-19T17:57:35+00:00', 'inLanguage': 'en-US', 'potentialAction': [{'@type': 'ReadAction', 'target': ['https://www.jns.org/israeli-leader-in-artificial-intelligence-earns-1-million-dan-david-prize/']}]}, {'@type': 'ImageObject', 'inLanguage': 'en-US', '@id': 'https://www.jns.org/israeli-leader-in-artificial-intelligence-earns-1-million-dan-david-prize/#primaryimage', 'url': 'https://cdn.jns.org/uploads/2020/02/Amnon-S.-PHOTO-Credit-Heinz-Troll-European-Patent-Office-scaled.jpg', 'contentUrl': 'https://cdn.jns.org/uploads/2020/02/Amnon-S.-PHOTO-Credit-Heinz-Troll-European-Patent-Office-scaled.jpg', 'width': 2560, 'height': 1707, 'caption': 'CEO of Mobileye and co-founder of OrCam Amnon Shashua. Credit: Heinz Troll European Patent Office.'}, {'@type': 'WebSite', '@id': 'https://www.jns.org/#website', 'url': 'https://www.jns.org/', 'name': 'JNS.org', 'description': 'Jewish News Syndicate', 'publisher': {'@id': 'https://www.jns.org/#organization'}, 'potentialAction': [{'@type': 'SearchAction', 'target': {'@type': 'EntryPoint', 'urlTemplate': 'https://www.jns.org/?s={search_term_string}'}, 'query-input': 'required name=search_term_string'}], 'inLanguage': 'en-US'}, {'@type': 'Organization', '@id': 'https://www.jns.org/#organization', 'name': 'JNS.org', 'url': 'https://www.jns.org/', 'logo': {'@type': 'ImageObject', 'inLanguage': 'en-US', '@id': 'https://www.jns.org/#/schema/logo/image/', 'url': 'https://cdn.jns.org/uploads/2023/10/logo_desktop-1.png', 'contentUrl': 'https://cdn.jns.org/uploads/2023/10/logo_desktop-1.png', 'width': 170, 'height': 130, 'caption': 'JNS.org'}, 'image': {'@id': 'https://www.jns.org/#/schema/logo/image/'}}, {'@type': 'Person', '@id': 'https://www.jns.org/#/schema/person/d65e0409c0993d0403ff6458b67c157d', 'name': 'Eliana Rudee', 'url': 'https://www.jns.org/author/eliana-rudee/'}]",,,,,,,,,,,,,,,,,,,,
https://news.google.com/rss/articles/CBMiaGh0dHBzOi8vcmFkaW9sb2d5YnVzaW5lc3MuY29tL3RvcGljcy9hcnRpZmljaWFsLWludGVsbGlnZW5jZS93YWl0LXdpbGwtYWktcmVwbGFjZS1yYWRpb2xvZ2lzdHMtYWZ0ZXItYWxs0gEA?oc=5,Wait. Will AI Replace Radiologists After All? - Radiology Business,2020-02-18,Radiology Business,https://radiologybusiness.com,"Despite authoritative voices reassuring radiologists that artificial intelligence will never seriously cull their workforce, speculation to the contrary continues. In fact, some of the prognosticators most certain about likely job losses are radiologists themselves.",Artificial Intelligence,"Despite authoritative voices reassuring radiologists that artificial intelligence will never seriously cull their workforce, speculation to the contrary continues. In fact, some of the prognosticators most certain about likely job losses are radiologists themselves.","Despite authoritative voices reassuring radiologists that artificial intelligence will never seriously cull their workforce, speculation to the contrary continues. In fact, some of the prognosticators most certain about likely job losses are radiologists themselves.",https://schema.org,,,,,,,,,,,,,N/A,N/A,"  Wait. Will AI Replace Radiologists After All?Roxanna Guilford-Blake | February 18, 2020 | Artificial Intelligencetweetprintsharesharemail   YES. NO. MAYBE. IT DEPENDS.Polarizing debate continues to simmer over where artificial intelligence will take radiology. On one side are those who believe AI will—maybe not soon but eventually—render diagnostic radiologists obsolete. On the other are those who see any and all doomsday scenarios as so much science fiction.  To be sure, there’s plenty of middle ground between the two extremes. But don’t all arguments, if followed to their logical ends, lead to one of them as a final landing point? As of early 2020, it’s unlikely a clear debate winner will emerge before some future development makes all points and counterpoints moot. But proponents of both viewpoint categories have much to say that’s worth hearing. Robert Schier, MD, RadNet Northern CaliforniaFor starters, consider the doomsayers. In commentary published in the July 2018 edition of JACR, Robert Schier, MD, a neuroradiologist with RadNet Northern California, described the divide  this way: “There are vastly differing opinions [on AI in radiology], from the apocalyptic claim that AI will make all radiologists extinct to the delusional assertion that computers will always merely assist—and never replace—radiologists. Both extremes are mistaken, but the truth is in the direction of the first. … Unless radiologists do things other than interpret imaging studies, there will be need for far fewer of them.”While he’s not quite predicting a radiological apocalypse, Schier describes himself as an alarmist. (He emphasizes that his opinions do not reflect those of RadNet.) And he does indeed believe that the end is coming. “My guess is that in 10 to 20 years, most imaging studies will be read only by machine,” he tells RBJ. “The results will be transmitted directly to the referring physician without input from a human radiologist.” This arrangement will produce faster, better and more accurate diagnostics, Schier believes. And everyone will receive equally excellent diagnostic care. “There will be no difference,” he says, “between an exceptional radiologist and a mediocre one.”What’s good for patients will be traumatic for the practice of medicine—and, as AI expands, perhaps for all of humanity, Schier says. But that’s a different article for a different day. Shreyas Vasanawala, MD, PhD, Stanford Medicine By contrast, Shreyas Vasanawala, MD, PhD, professor of radiology at Stanford, remains optimistic, seeing AI as assistive, not at all adversarial. He agrees AI will change the way radiologists practice, butAI allows radiologists to pull information that would otherwise be left on the table, Vasanawala explains. “AI enhances the value of medical imaging,” he says, “which is great for patients as well as the field of radiology.”Resistance Can Cost Technological advances have always raised concerns among the potentially affected. Vasanawala points to the fussing and fretting that accompanied the field’s migration from films on lightboxes to images on screens. Having experienced the efficiencies of PACS, “no one is hoping to go back to film,” he notes. Falgun Chokshi, MD, MBA, a neuroradiologist formerly with Emory University who’s now on his own as a speaker and advisor, sees AI as another notable milestone on that timeline. “As with all technologies that have been introduced into our practice, from cross-sectional modalities and PACS to voice dictation-based reporting, those radiologists who have adapted and integrated the technology have fared much better than their more obstinate counterparts,” Chokshi says. Falgun Chokshi, MD, MBA, independent speaker and advisorSince AI technology is inherently neither good nor bad, he adds, many negative reactions to it are misdirected.“Its eventual uses, direct consequences and collateral effects are all based on how humans use it,” he says.The question is how the human/computer collaboration will play out. And only time can supply an answer.Known UnknownsNobody really knows what AI is capable of, Maciej Mazurowski, PhD, of Duke points out. “I think a significant disruption is a real possibility,” he tells RBJ. “However, many things have to align for this to happen.”For one thing, AI needs to perform at the level of a radiologist for a broad range of tasks. “I believe there are signals showing that this is possible,” he says. “However, we don’t know yet if that is true due to a still limited clinical validation of algorithms.”In an opinion piece published in the August 2019 JACR, Mazurowski staked out a spot in the aforementioned middle ground, suggesting AI could well displace more than a few radiologists. Maciej Mazurowski, PhD, Duke Health “[S]uch disruption is a real possibility,” he writes. “Although the radiology specialty has shown an astonishing ability to adapt to the changing technology, the future is uncertain, and an honest, in-depth discussion is needed to guide development of the field.”The radiology specialty “was born of technology and has grown around technology,” Mazurowski continues. “It has shown the ability to evolve. It is possible that AI will transform radiology into a substantially altered specialty in which a human specialist will still play an important role.” Permanently In Pointing to the mass of scientific literature published to date, Chokshi forecasts AI will increasingly focus on classification and rudimentary prediction of abnormal findings in medical images. But that doesn’t mean diagnostic radiologists will completely stop tackling those tasks themselves. Human readers “use multiple levels of nuanced perception and interpretation of images that the machines have not been able to rival to date,” Choksi says. “I believe—and some studies have shown this—that human-machine assistive hybrid teams are better for specific findings than just machines.”Vasanawala’s Stanford colleague, Curtis Langlotz, MD, PhD, has consistently insisted that radiologists’ role is eminently augmentable but will never be replaceable. At conferences he’s often noted that very few airline passengers would ever board a plane with no human pilot even though autopilot technology already handles upwards of 90% of every flight. And in commentary published in 2019 by Radiology: Artificial Intelligence, Langlotz makes this compelling point: “We often compare AI algorithms to radiology experts based on the ability to identify a single disease or a small set of diseases. But that oversimplifies things. A radiologist may be looking for numerous conditions and … anything else suspicious that might show up in a patient’s test results. That requires a human.”Eventually Out Shier, the alarmist, also sees AI as assistive—in the short term.He’s certainly correct that AI systems are constantly getting smarter and faster, steadily approaching a point at which their rewards may yet outweigh their risks. “It may help to imagine these systems not as a collection of circuits in a console but as an army of fellowship-trained radiologists with photographic memories, IQs of 500 and no need for food or sleep,” Shier writes in his JACR essay. AI will initially make radiologists more accurate and efficient, he explains to RBJ. Then AI systems will take over the reading of certain simple cases, expanding the range and complexity of cases they interpret on their own. Whether it takes another 20 years or 50, the day will arrive when machines “won’t need us,” Schier says. “The evidence that computers will become better than humans in interpreting all imaging studies and in reporting those interpretations to other physicians is, in my view, convincing.” He sees no fundamental physical or theoretical reason why computers won’t be able to do radiologists’ jobs faster, better and cheaper than humans.“I think the profession of radiology, as described by physicians who interpret diagnostic images, is going to be mostly gone at some point,” Schier adds. “Radiologists, if they exist, will have to do something else.” What about the argument that AI will open the field to new screenings and diagnostic tests currently based in non-imaging protocols? “Perhaps it will,” Schier allows. “But what role will radiologists play? It may expand the field of diagnostic imaging and at the same time contract the field of diagnostic imagers.”On the bright side of Schier’s vision, humans and machines together will continue to be better than humans or machines alone—for a few more decades or years, anyway. Tireless Assistant If Schier is overly alarmist, and humans remain in the picture throughout the lifetime of rads working in 2020, what will these human-machine assistive hybrid teams look like?Vasanawala surely speaks for many when he answers that AI will allow radiologists to work at the top of their license and to “focus on the most value-added and rewarding parts of the job.”At present, radiologists don’t have enough time in the day to get through all items on their clinical worklists—or, at least, with minimal distractions drawing eyes from images. AI can help carve out time for clinical concentration by automating dictation and report editing, gathering clinical histories, finding relevant prior imaging, making careful measurements of lesions and correlating current lesions with those from multiple prior studies. Radiologists can then increase their level of attention to detail on the complex cases, integrate the full clinical story and look up the relevant literature, Vasanawala says. They can spend more time diagnosing diseases, preparing for and participating in multidisciplinary team conferences and consultations with patients.  Beyond Reads Current discussions of AI largely focus on automated interpretation of images, such as chest x-rays. But there also are opportunities for using AI to optimize practices’ fiscal performance.Radiology practices, like other businesses, have many moving parts—intersecting workflows, bottlenecks, key performance indicators and significant resource and financial allocation and uses. “AI can help optimize many aspects of the radiology business as long as the users are cognizant of the technol-ogies’ limitations and capacities,” Chokshi notes. He adds, however, that, like any technology, “AI is only as good as its intended use.”Vasanawala, too, stresses “upstream” benefits of AI. He rattles off a handful of these: improved patient scheduling and protocoling of exams, better management of radiation dose and reconstruction of higher quality images, prioritization of studies to read and automated extraction of quantitative information imaging that is currently too time-consuming to perform routinely. “AI will enhance the value of radiology in healthcare, but the entire medical imaging department—schedulers, technologists, nurses, administrators—needs to embrace it,” Vasanawala says. Some of this is already happening “under the hood” in ways that aren’t always evident. And new areas are emerging. One of these is automated segmentation, Vasanawala points out. For example, in cardiac imaging, fully automated, highly accurate segmentation of ventricles is leading to greater radiologist efficiency. And with that is coming greater reproducibility of quantitative results. Aligned Interests Evaluating AI’s most exciting opportunities and most daunting threats, Chokshi says, comes down to asking two questions: Does the technology help improve patient care? And does it “help maintain our own sanity and mitigate burnout?” He’s wary about all the promises being made on AI’s behalf around efficiency and productivity. “I hear a lot of talk about using AI to make radiologists faster and more efficient,” Chokshi says. “I would be very cautious about such dubious notions of what AI should be doing for us.” A better opportunity, he says, is using AI to become more specific about interpretation, triage acute findings and decrease the variability of reads for different kinds of studies.“The goal should be alignment of better patient care with better radiologist care,” Chokshi say. “The threat of AI is not the technology itself. It’s using it to squeeze in more work with diminishing long-term rewards.” Misaligned Incentives Regardless of one’s position—pessimist, optimist or somewhere in between—radiologists must come together to address the relevant issues even more than they have already. That seems to be a widely held opinion, based on the literature and the interviews conducted for this report.The need for profession-wide cooperation around AI has been coming to the fore as the topic gets attention at regional, national and international conferences. As a result of the presentations, exhibits and discussions, Vasanawala, points out, viewpoints are evolving rapidly.Schier suggests there’s no time like the present to build on the momentum. He hopes one of the major academic journals serving radiology will devote a full issue to radiology thought leaders reasoning together on the question “Will intelligent computers ever replace radiologists?”  (He fleshes out his own opinion here.)But it’s not just radiologists who need to come to the table. Rads will evolve and adapt to AI being integrated into workflows and practice settings, Chokshi says, while developers, researchers and regulators work with radiologists to tap AI for streamlining workflows and optimizing outcomes. Mazurowski calls on radiologists to collaborate with AI developers in industry on ensuring that priority No. 1 remains improving patient care while holding the line on costs.And that’s not just a technology challenge, he warns. The best-case future scenario for patients is having AI interpret medical images with the highest possible accuracy and the lowest possible turnaround times—all for the lowest possible price. However, Mazurowski says, even if AI proves capable of superhuman performance across a broad spectrum of radiology tasks, that vision may not come to fruition. “One of the most challenging hurdles with implementation of imaging AI in clinical practice in the U.S. will be the complex and suboptimal structure of the healthcare system,” he says. “The incentives in the system are often misaligned with the interests of the patient.”Here to Stay Now is the time to figure out how to align systemic incentives with patient interests, the experts agree. “As with any new technology, there’s a period where the technology becomes better understood and refined, leading to a progressive uptake in that technology,” Vasanawala says.  Langlotz contends that the only radiologists who should worry about losing their jobs to AI are those who don’t use AI. (He makes his full case in a piece published online last May in Radiology: Artificial Intelligence titled “Will Artificial Intelligence Replace Radiologists?”)Meanwhile Schier exhorts radiologists to embrace AI as readily as they can. “It will make your reading of studies faster, more accurate and less stressful,” he says. “You will provide better patient care, be more valuable and do a better job.”It’s reasonable to expect those benefits to continue building for the next 10 to 15 years, he says. “Embrace AI because it will be good for your patients,” Schier concludes. “Embrace AI because it will make you a better, more efficient and happier radiologist. Embrace AI because if you don’t, you will be replaced by radiologists who do. Embrace AI because, even if you refuse to embrace AI, you will nevertheless be embraced by it.”That series of imperatives may not settle the debate over radiology’s eventual fate at the hands of AI, but the soundness of its wisdom would be hard to argue against. Roxanna Guilford-BlakeRelated ContentRayus Radiology launches whole-body MRI service in Seattle, SimonMed expands, RadNet touts legislation, plus more company newsACR opens doors of AI quality-assurance center AI critical care software revolutionizes emergency responseStrategic Radiology signs on with Qure.ai ASNC supports AMA effort to limit use of AI in prior authorization decisionsAmerican College of Radiology asks CMS to create new alternative payment pathway for high-value AI",,,,,,,,"[{'@type': 'NewsArticle', 'headline': 'Wait. Will AI Replace Radiologists After All?', 'name': 'Wait. Will AI Replace Radiologists After All?', 'image': {'@type': 'ImageObject', 'url': 'https://radiologybusiness.com/sites/default/files/styles/facebook/public/2020-02/ai-radiologists_ci.jpg?h=d05b598f&itok=PYPYKTgN', 'width': '1200', 'height': '630'}, 'datePublished': '2020-02-18T20:44:14+0000', 'dateModified': '2022-02-11T04:22:31+0000', 'publisher': {'@type': 'Organization', 'name': 'Radiology Business', 'url': 'https://radiologybusiness.com/'}}]",,,,,,,,,,,,,,,,,,,,
https://news.google.com/rss/articles/CBMigAFodHRwczovL3d3dy5tY2tpbnNleS5jb20vZmVhdHVyZWQtaW5zaWdodHMvYXNpYS1wYWNpZmljL2F1dG9tYXRpb24tYW5kLWFkYXB0YWJpbGl0eS1ob3ctbWFsYXlzaWEtY2FuLW5hdmlnYXRlLXRoZS1mdXR1cmUtb2Ytd29ya9IBAA?oc=5,Automation and adaptability: How Malaysia can navigate the future of work - McKinsey,2020-02-17,McKinsey,https://www.mckinsey.com,"Amid an age of automation, Malaysia’s jobs outlook is ultimately promising. But the future of work will also create new needs for skills and long-term learning in nearly every part of the workforce.",N/A,"Amid an age of automation, Malaysia’s jobs outlook is ultimately promising. But the future of work will also create new needs for skills and long-term learning in nearly every part of the workforce.","Amid an age of automation, Malaysia’s jobs outlook is ultimately promising. But the future of work will also create new needs for skills and long-term learning in nearly every part of the workforce.",https://schema.org,Article,https://www.mckinsey.com,https://www.mckinsey.com/~/media/mckinsey/locations/asia/malaysia/our%20insights/automation%20and%20adaptability%20how%20malaysia%20can%20navigate%20the%20future%20of%20work/hero-automation-and-adaptability.png,"[{'@type': 'Person', 'name': 'Ee Huei Koh'}, {'@type': 'Person', 'name': 'Nimal Manuel', 'url': 'https://www.mckinsey.com/our-people/nimal-manuel'}]","{'@type': 'Organization', 'name': 'McKinsey & Company', 'logo': {'@type': 'ImageObject', 'url': 'https://www.mckinsey.com/~/media/Thumbnails/Mck_Logo'}}",,2020-02-17T00:00:00Z,2020-02-17T00:00:00Z,,,,,N/A,N/A,N/A,,,,,,,"{'@type': 'WebPage', '@id': 'https://www.mckinsey.com/featured-insights/asia-pacific/automation-and-adaptability-how-malaysia-can-navigate-the-future-of-work'}",,2020-01-24T02:27:51Z,Automation and adaptability: How Malaysia can navigate the future of work,,,,,,,,,,,,,,,,,,
https://news.google.com/rss/articles/CBMiWWh0dHBzOi8vd3d3LmNic25ld3MuY29tL25ld3Mvam9iLWh1bnRpbmctYWktaXMtanVkZ2luZy15b3UtYnV0LWNyaXRpY3Mtc2F5LWl0cy1zbmFrZS1vaWwv0gFdaHR0cHM6Ly93d3cuY2JzbmV3cy5jb20vYW1wL25ld3Mvam9iLWh1bnRpbmctYWktaXMtanVkZ2luZy15b3UtYnV0LWNyaXRpY3Mtc2F5LWl0cy1zbmFrZS1vaWwv?oc=5,Job hunters face a new hurdle: Impressing AI - CBS News,2020-02-20,CBS News,https://www.cbsnews.com,"Artificial intelligence is increasingly deciding whether you're fit for a job, but some experts call it ""snake oil.""",,"Artificial intelligence is increasingly deciding whether you're fit for a job, but some experts call it ""snake oil.""","Artificial intelligence is increasingly deciding whether you're fit for a job, but some experts call it ""snake oil.""",https://schema.org,BreadcrumbList,https://www.cbsnews.com/news/job-hunting-ai-is-judging-you-but-critics-say-its-snake-oil/,"{'@context': 'https://schema.org', '@type': 'ImageObject', 'height': 630, 'width': 1200, 'url': 'https://assets3.cbsnewsstatic.com/hub/i/r/2018/11/15/aab6f7aa-648e-4d55-8ea9-b6500aebc498/thumbnail/1200x630/e8d230a763c1ccec2da525361e857c29/hal-9000-2001-a-space-odyssey-promo.jpg?v=5710b2ed1cee1bdfd30cb9c02455b43d'}","[{'@type': 'Person', 'familyName': 'Picchi', 'givenName': 'Aimee', 'name': 'Aimee Picchi', 'jobTitle': 'Associate Managing Editor, MoneyWatch', 'description': ""Aimee Picchi is associate managing editor for CBS MoneyWatch, where she covers business and personal finance. She previously worked at Bloomberg News and has been published by national news outlets including USA Today and Consumer Reports. Aimee frequently writes about retirement, and has been a National Press Foundation fellow for reporting on retirement and Columbia University's Age Boom Academy. She's also the editor of the Institutional Investor book &quot;Cultivating the Affluent II,&quot; with noted wealth consultant Russ Alan Prince."", 'sameAs': 'https://x.com/@aimeepicchi', 'knowsAbout': ['Economy', 'Product Recall', 'Finance', 'Stock Market', 'Money'], 'workLocation': {'@type': 'Place', 'name': 'New York'}, 'affiliation': {'@type': 'Organization', 'name': 'CBS News'}, 'worksFor': [{'@type': 'Organization', 'name': 'CBS News'}], 'publishingPrinciples': 'https://www.cbsnews.com/news/cbs-news-publishing-principles/'}]","{'@context': 'https://schema.org', '@type': 'NewsMediaOrganization', '@id': 'https://www.cbsnews.com/', 'name': 'CBS News', 'foundingDate': '1927-09-18', 'sameAs': ['https://www.cbsnews.com/', 'https://www.facebook.com/CBSNews/', 'https://instagram.com/cbsnews/', 'https://twitter.com/CBSNews', 'https://www.youtube.com/CBSNews', 'https://en.wikipedia.org/wiki/CBS_News'], 'logo': [{'@context': 'https://schema.org', '@type': 'ImageObject', 'height': 60, 'width': 600, 'url': 'https://www.cbsnews.com/assets/standalone/cbsnews-logo-white-600x60.png'}], 'url': 'https://www.cbsnews.com/', 'parentOrganization': {'@type': 'Organization', 'name': 'Paramount Global', '@id': 'https://www.paramount.com/', 'sameAs': 'https://www.paramount.com/', 'legalName': 'Paramount Global'}, 'actionableFeedbackPolicy': 'https://www.cbsnews.com/news/cbs-news-publishing-principles/#1d4ed2b9-ade8-4203-a4e4-115dd34c0735', 'correctionsPolicy': 'https://www.cbsnews.com/news/cbs-news-publishing-principles/#751608ae-9468-457c-9dbe-1f9400a7f428', 'ethicsPolicy': 'https://www.cbsnews.com/news/cbs-news-publishing-principles/#a0060f90-73b0-4a57-b756-ca7a7f26cc7d', 'Masthead': 'https://www.cbsnews.com/news/cbs-news-publishing-principles/#5fd9a80d-2c6c-4d38-8b1e-4144650d5963', 'missionCoveragePrioritiesPolicy': 'https://www.cbsnews.com/news/cbs-news-publishing-principles/#4ffda755-6b47-49e1-b98c-24b737906aca', 'ownershipFundingInfo': 'https://www.paramount.com/company-history', 'unnamedSourcesPolicy': 'https://www.cbsnews.com/news/cbs-news-publishing-principles/#de41886e-07ed-4887-ad05-4b2c79edf857', 'publishingPrinciples': 'https://www.cbsnews.com/news/cbs-news-publishing-principles/'}",Job hunters face a new hurdle: Impressing AI,2020-02-20T09:38:00-0500,2020-02-20T13:27:00-0500,['MoneyWatch'],Job hunters face a new hurdle: Impressing AI,,"[{'@type': 'ListItem', 'position': 1, 'item': {'@id': 'https://www.cbsnews.com/', '@type': 'WebPage', '@name': 'CBSNews.com'}}, {'@type': 'ListItem', 'position': 2, 'name': 'MoneyWatch', 'item': {'@id': 'https://www.cbsnews.com/moneywatch', '@type': 'CollectionPage', '@name': 'MoneyWatch'}}, {'@type': 'ListItem', 'position': 3, 'name': 'Job hunters face a new hurdle: Impressing AI', 'item': {'@id': 'https://www.cbsnews.com/news/job-hunting-ai-is-judging-you-but-critics-say-its-snake-oil/', '@name': 'Job hunters face a new hurdle: Impressing AI'}}]",N/A,N/A,"


MoneyWatch

Job hunters face a new hurdle: Impressing AI






    By
                        
                      Aimee Picchi


Updated on:  February 20, 2020 / 1:27 PM EST
          / MoneyWatch
        



















Businesses turning to AI for job interviews 











Businesses turning to AI for job interviews
06:07

If you're on the hunt for a new job, there's a new twist to the hiring process that's increasingly common: Getting judged by artificial intelligence. Major businesses like Unilever and Ikea are turning to AI programs to sniff out suitable applicants — and predict future job performance — partly as a way to cut down on the time needed to hire employees. Supporters say the tech can help companies find better job candidates and eliminate some of the inherent bias that executives may not even be aware of, such as leaning toward candidates who are white or male. 






But critics say there are issues with relying on algorithms to make complex decisions. One Princeton professor, Arvind Narayanan, is questioning whether AI can accurately predict job success, calling such claims ""snake oil."" And Electronic Privacy Information Center counsel John Davisson calls the AI programs are a ""nightmarish combination of privacy violations and outcomes that aren't based on any easily understood criteria."" His group earlier this month petitioned the Federal Trade Commission to start regulating AI's use in the job market and other business applications.


At stake are the roughly 7 million job openings that employers seek to fill each month. Traditional gatekeepers such as human resources professionals are increasingly turning to AI to review resumes — no small task when employment site Glassdoor says the average job opening receives about 250 resumes. Some are also relying on AI programs to score applicants' video interviews, with the goal of skimming the cream from the top. 






CEO speaks out about Clearview AI's controversial facial recognition technology
07:57

Some companies say they see results, with one case study from Unilever finding that an AI analysis from a company called HireVue saved the company $1 million by cutting down on the time needed to sort through 250,000 applications. Relying on AI to cull the applicant pool also helped diversify new hires by 16%, it found. Yet the lack of transparency about the inner workings of these AI applications, as well as the vast amount of data they collect, are raising concerns among lawmakers and privacy experts. Of particular concern — that these programs could unfairly evaluate certain types of applicants, such as minorities and women.""It's like anything else — wine, music and food. Some of it is really good and some of it is really bad,"" said Tomas Chamorro-Premuzic, chief talent scientist at staffing and recruitment company ManpowerGroup, which is also an adviser to HireVue. ""The big challenge and question of AI in the world of talent is: Will algorithms be better at knowing us than we do ourselves?""


Gaining traction in workplaceSo far, there appears to be more questions than answers, even as the technology gains traction in the workplace. While there's no federal government tracking or oversight of AI, surveys of human resource executives provide insight into AI's usage in the job market. Almost 7 in 10 recruiters and hiring managers told LinkedIn in 2018 that AI applications help them save time, according to a survey of 8,800 executives, while about 4 in 10 said AI tools help guard against bias in the hiring process. And employment site Glassdoor says it's increasingly likely that job candidates will encounter AI when they search for work today. It's a growing field with dozens of companies offering different AI flavors to businesses. It's also attracting venture capital, with hundreds of millions of investments plugged into firms such as HireVue, Pymetrics and Mya, according to CrunchBase.How it worksSome job applicants might not even realize they've been given the once-over by artificial intelligence. At the most basic level, AI programs analyze resumes and job applications to screen candidates, winnowing the field to top candidates. Other AI programs are more interactive, although some applicants still might not know they're dealing with an algorithm. Consignment shop ThredUp, for example, uses an AI program to text job candidates to schedule job interviews, according to Glassdoor. Other companies ask candidates to play online games, including one exercise that asks applicants to click on objects that are red balls. The data are then fed through an AI program that analyzes responses to assess a candidate's abilities. The AI program that's sparking perhaps the most concern is the video interview, where candidates are taped as they respond to recruitment questions posed via webcam. An AI tool then examines the video, analyzing everything from facial gestures to vocabulary, to determine whether the candidate is a good fit. 






Millions are connecting with chatbots and AI companions like Replika
06:09

HireVue, one of the biggest companies in the field, said its AI assessment is partially based on data from companies' top performers: By analyzing vocabulary used by top workers, for instance, the AI program can pick out candidates whose word choices and expressions best match those high performers. It also relies on years of research into industrial and organizational psychology, which focuses on how people behave within organizations.


""We are judging the answers that the interviewee is giving,"" said Kevin Parker, CEO of HireVue. ""In a 20-minute interview, we can collect a lot of data. We have no idea who the candidate is, but we can collect a lot of data about vocal variation, personal pronouns"" and other information to make an assessment, he added. Parker said HireVue's AI programs are screened for bias, which helps level the playing field for job applicants. The AI models tend to be most effective for jobs where there's a lot of data to draw from, he added.In other words, AI isn't designed to find the best CEO — since C-suite executives are relatively uncommon in the workforce — but for rank-and-file workers like salespeople. Is it accurate?Companies in the AI space say their programs save time by weeding out low-quality applicants and singling out the best potential hires. But artificial intelligence has its limits — and probably isn't more accurate at predicting job performance than tried-and-true methods, according to Princeton's Narayanan, an associate professor of computer science. Narayanan points to an academic study that relied on family data to predict future outcomes in a number of areas, such as a child's likely academic performance and future material hardship. But the study's AI analysis failed to outperform old-fashioned linear regression in predicting future struggles or successes, he said. While AI can prove useful for simpler perception-based tasks, such as speech-to-text translation or identifying plagiarized material, it ""can't predict social outcomes,"" Narayanan concluded. At the same time, he warned, AI creates risks by transferring massive amounts of personal data to tech firms and placing a greater reliance on applications that lack transparency. 
Academic scholars writing about AI screening have taken the companies' bait and focus on ""bias"". But a random number generator that doesn't have disparate impact is still a random number generator—arbitrary, unaccountable, and demeaning to candidates. No semblance of due process.— Arvind Narayanan (@random_walker) November 15, 2019

Those concerns are echoed by EPIC, which in November asked the Federal Trade Commission to investigate HireVue. It claims HireVue's algorithms are ""opaque"" and that its ""secret analysis of biometric data thus causes substantial privacy harms to job candidates.""


The FTC told CBS MoneyWatch it had received both the letter and the petition, but declined additional comment. HireVue said it believes the complaint is without merit. ""The company upholds the highest levels of rigor and ethics as its employees work every day to increase fairness and objectivity in the hiring process,"" it told CBS MoneyWatch. ""Disappointed""HireVue CEO Parker said he was ""disappointed"" with Narayanan's assessment, and said his company reached out to him to discuss his concerns but was ""rebuffed.""Asked whether he rebuffed HireVue's overture, Narayanan forwarded his email exchange with the company to CBS MoneyWatch. Instead of a private discussion, he wrote, he urged HireVue to publish its research, ""ideally in a peer-reviewed forum, and discuss it openly."" He added in the email, ""I'm not sure a private conversation is the best medium. There's a high level of public interest in AI bias since the issue affects everyone.""In a statement, HireVue said it ""was surprised that Dr. Narayanan would not welcome the opportunity for a one-on-one discussion on the facts and established science supporting HireVue's approach to assessments and AI before making public claims about efficacy and validity.""






Facial and emotional recognition; how one man is advancing artificial intelligence
12:54

The issue of AI in hiring is gaining more attention from lawmakers. In January, a new Illinois law went into effect that requires companies to disclose that artificial intelligence will be used to assess candidates' video interviews. Employers also must explain how the AI tool works, ask for consent from the job candidate, and destroy the video and any copies within 30 days if a job applicant requests it.Illinois State Rep. Jaime Andrade Jr., who sponsored the bill, told the Chicago Tribune last month: ""The technology hasn't been vetted fully yet. There are some concerns regarding bias. [The software] is only as good as the data it is given.""


Is it really less biased?HireVue and other hiring experts say AI has the potential to be less biased than human interviewers. Algorithms can strip out gender, race or any other protected group when analyzing candidates. Yet when algorithms go wrong, they can go very wrong, such as in the case of Amazon's recruitment engine. In that now-infamous instance, Amazon scrapped the AI application in 2018 after realizing that the program was excluding women applicants from the pool because the model was based on 10 years of data from job applicants, who tended to be men. In other words, the AI ""learned"" the biased view that men were a better fit than women, reinforcing gender stereotypes in tech. ""Even if it doesn't look at sensitive attributes, like names that can be a proxy for gender, programs can pick up on this unknowingly,"" said Glen Cathey, senior vice president and head of digital strategy and innovation at Randstad, a recruitment agency.  ""Being responsible and ethical in AI, not just in recruitment, is the measurement element.""EEOC standardCompanies that rely on AI need to measure and test for bias, and that's something HireVue studies closely, said Lindsey Anderson Zuloaga, director of data science at the company. ""Whatever biases it has, it could affect a lot of people — and that's true of who gets credit, who gets parole,"" she said, referring to other fields where AI has been used to make determinations. ""In any pre-hire assessments, you need to look at how different demographic groups are being scored, and if there are differences that may be evidence of adverse impact.""






Racial Profiling 2.0
23:22

HireVue screens for results where any group, such as different genders or races, score less than 80% of the top-scoring group, which is a yardstick for bias used by the U.S. Equal Employment Opportunity Commission. For example, that would happen if an AI program singles out 50 men as solid candidates, but only 30 women. ""We're lucky in this space in that our notion of what is fair is defined by law,"" Zuloaga said. ""We build the model, then we train the algorithm, then look at how is it scoring people within the group.""


Hacks for AI?Job applicants are perhaps justifiably nervous about facing an AI in a job interview, which can be nerve-wracking even with other humans. It's no surprise that YouTube tutorials have sprung up to help job candidates learn how to ace pre-recorded interviews by HireVue and others. The tips include how to set up your webcam, how to look good on the video and how to keep cool under pressure — not exactly different advice than what a job hunter would hear about an interview with a real person. In the end, there may be no secret sauce for acing an AI interview, partly because the algorithm is a black box. Even so, human judgment is typically involved in the hiring process after AI programs have screened for the best candidates, HireVue's Parker said. ""We're the first step in a process — the next step is an in-person interview,"" he added. ""It's our desire that there is always a human involved.""


Tech Security & Privacy

              More
              






EU says Elon Musk's X violating Digital Services Act with blue checks







CDK Global calls recent cyberattack a ""ransom event""







CDK cyberattack leaves thousands of car dealers spinning their wheels







CDK cyberattack shuts down auto dealerships across the U.S.







Nissan data breach exposes Social Security numbers of nearly 53,000





            More
            

Aimee Picchi


Aimee Picchi is the associate managing editor for CBS MoneyWatch, where she covers business and personal finance. She previously worked at Bloomberg News and has written for national news outlets including USA Today and Consumer Reports.



                      Twitter
                    





© 2020 CBS Interactive Inc. All Rights Reserved.

",https://www.cbsnews.com/,,,,,,"{'@type': 'WebPage', '@id': 'https://www.cbsnews.com/news/job-hunting-ai-is-judging-you-but-critics-say-its-snake-oil/'}",,,,https://assets3.cbsnewsstatic.com/hub/i/r/2018/11/15/aab6f7aa-648e-4d55-8ea9-b6500aebc498/thumbnail/1200x630/e8d230a763c1ccec2da525361e857c29/hal-9000-2001-a-space-odyssey-promo.jpg?v=5710b2ed1cee1bdfd30cb9c02455b43d,"{'@context': 'https://schema.org', '@type': 'ImageObject', 'height': 630, 'width': 1200, 'url': 'https://assets3.cbsnewsstatic.com/hub/i/r/2018/11/15/aab6f7aa-648e-4d55-8ea9-b6500aebc498/thumbnail/1200x630/e8d230a763c1ccec2da525361e857c29/hal-9000-2001-a-space-odyssey-promo.jpg?v=5710b2ed1cee1bdfd30cb9c02455b43d'}","If you're on the hunt for a new job, there's a new twist to the hiring process that's increasingly common: Getting judged by artificial intelligence. Major businesses like Unilever and Ikea are turning to AI programs to sniff out suitable applicants — and predict future job performance — partly as a way to cut down on the time needed to hire employees. Supporters say the tech can help companies find better job candidates and eliminate some of the inherent bias that executives may not even be aware of, such as leaning toward candidates who are white or male.But critics say there are issues with relying on algorithms to make complex decisions. One Princeton professor, Arvind Narayanan, is questioning whether AI can accurately predict job success, calling such claims ""snake oil."" And Electronic Privacy Information Center counsel John Davisson calls the AI programs are a ""nightmarish combination of privacy violations and outcomes that aren't based on any easily understood criteria."" His group earlier this month petitioned the Federal Trade Commission to start regulating AI's use in the job market and other business applications.At stake are the roughly 7 million job openings that employers seek to fill each month. Traditional gatekeepers such as human resources professionals are increasingly turning to AI to review resumes — no small task when employment site Glassdoor says the average job opening receives about 250 resumes. Some are also relying on AI programs to score applicants' video interviews, with the goal of skimming the cream from the top. Some companies say they see results, with one case study from Unilever finding that an AI analysis from a company called HireVue saved the company $1 million by cutting down on the time needed to sort through 250,000 applications. Relying on AI to cull the applicant pool also helped diversify new hires by 16%, it found. Yet the lack of transparency about the inner workings of these AI applications, as well as the vast amount of data they collect, are raising concerns among lawmakers and privacy experts. Of particular concern — that these programs could unfairly evaluate certain types of applicants, such as minorities and women.""It's like anything else — wine, music and food. Some of it is really good and some of it is really bad,"" said Tomas Chamorro-Premuzic, chief talent scientist at staffing and recruitment company ManpowerGroup, which is also an adviser to HireVue. ""The big challenge and question of AI in the world of talent is: Will algorithms be better at knowing us than we do ourselves?""Gaining traction in workplaceSo far, there appears to be more questions than answers, even as the technology gains traction in the workplace. While there's no federal government tracking or oversight of AI, surveys of human resource executives provide insight into AI's usage in the job market. Almost 7 in 10 recruiters and hiring managers told LinkedIn in 2018 that AI applications help them save time, according to a survey of 8,800 executives, while about 4 in 10 said AI tools help guard against bias in the hiring process. And employment site Glassdoor says it's increasingly likely that job candidates will encounter AI when they search for work today. It's a growing field with dozens of companies offering different AI flavors to businesses. It's also attracting venture capital, with hundreds of millions of investments plugged into firms such as HireVue, Pymetrics and Mya, according to CrunchBase.How it worksSome job applicants might not even realize they've been given the once-over by artificial intelligence. At the most basic level, AI programs analyze resumes and job applications to screen candidates, winnowing the field to top candidates. Other AI programs are more interactive, although some applicants still might not know they're dealing with an algorithm. Consignment shop ThredUp, for example, uses an AI program to text job candidates to schedule job interviews, according to Glassdoor. Other companies ask candidates to play online games, including one exercise that asks applicants to click on objects that are red balls. The data are then fed through an AI program that analyzes responses to assess a candidate's abilities. The AI program that's sparking perhaps the most concern is the video interview, where candidates are taped as they respond to recruitment questions posed via webcam. An AI tool then examines the video, analyzing everything from facial gestures to vocabulary, to determine whether the candidate is a good fit. HireVue, one of the biggest companies in the field, said its AI assessment is partially based on data from companies' top performers: By analyzing vocabulary used by top workers, for instance, the AI program can pick out candidates whose word choices and expressions best match those high performers. It also relies on years of research into industrial and organizational psychology, which focuses on how people behave within organizations.""We are judging the answers that the interviewee is giving,"" said Kevin Parker, CEO of HireVue. ""In a 20-minute interview, we can collect a lot of data. We have no idea who the candidate is, but we can collect a lot of data about vocal variation, personal pronouns"" and other information to make an assessment, he added. Parker said HireVue's AI programs are screened for bias, which helps level the playing field for job applicants. The AI models tend to be most effective for jobs where there's a lot of data to draw from, he added.In other words, AI isn't designed to find the best CEO — since C-suite executives are relatively uncommon in the workforce — but for rank-and-file workers like salespeople. Is it accurate?Companies in the AI space say their programs save time by weeding out low-quality applicants and singling out the best potential hires. But artificial intelligence has its limits — and probably isn't more accurate at predicting job performance than tried-and-true methods, according to Princeton's Narayanan, an associate professor of computer science. Narayanan points to an academic study that relied on family data to predict future outcomes in a number of areas, such as a child's likely academic performance and future material hardship. But the study's AI analysis failed to outperform old-fashioned linear regression in predicting future struggles or successes, he said. While AI can prove useful for simpler perception-based tasks, such as speech-to-text translation or identifying plagiarized material, it ""can't predict social outcomes,"" Narayanan concluded. At the same time, he warned, AI creates risks by transferring massive amounts of personal data to tech firms and placing a greater reliance on applications that lack transparency. Those concerns are echoed by EPIC, which in November asked the Federal Trade Commission to investigate HireVue. It claims HireVue's algorithms are ""opaque"" and that its ""secret analysis of biometric data thus causes substantial privacy harms to job candidates.""The FTC told CBS MoneyWatch it had received both the letter and the petition, but declined additional comment. HireVue said it believes the complaint is without merit. ""The company upholds the highest levels of rigor and ethics as its employees work every day to increase fairness and objectivity in the hiring process,"" it told CBS MoneyWatch. ""Disappointed""HireVue CEO Parker said he was ""disappointed"" with Narayanan's assessment, and said his company reached out to him to discuss his concerns but was ""rebuffed.""Asked whether he rebuffed HireVue's overture, Narayanan forwarded his email exchange with the company to CBS MoneyWatch. Instead of a private discussion, he wrote, he urged HireVue to publish its research, ""ideally in a peer-reviewed forum, and discuss it openly."" He added in the email, ""I'm not sure a private conversation is the best medium. There's a high level of public interest in AI bias since the issue affects everyone.""In a statement, HireVue said it ""was surprised that Dr. Narayanan would not welcome the opportunity for a one-on-one discussion on the facts and established science supporting HireVue's approach to assessments and AI before making public claims about efficacy and validity.""The issue of AI in hiring is gaining more attention from lawmakers. In January, a new Illinois law went into effect that requires companies to disclose that artificial intelligence will be used to assess candidates' video interviews. Employers also must explain how the AI tool works, ask for consent from the job candidate, and destroy the video and any copies within 30 days if a job applicant requests it.Illinois State Rep. Jaime Andrade Jr., who sponsored the bill, told the Chicago Tribune last month: ""The technology hasn't been vetted fully yet. There are some concerns regarding bias. [The software] is only as good as the data it is given.""Is it really less biased?HireVue and other hiring experts say AI has the potential to be less biased than human interviewers. Algorithms can strip out gender, race or any other protected group when analyzing candidates. Yet when algorithms go wrong, they can go very wrong, such as in the case of Amazon's recruitment engine. In that now-infamous instance, Amazon scrapped the AI application in 2018 after realizing that the program was excluding women applicants from the pool because the model was based on 10 years of data from job applicants, who tended to be men. In other words, the AI ""learned"" the biased view that men were a better fit than women, reinforcing gender stereotypes in tech. ""Even if it doesn't look at sensitive attributes, like names that can be a proxy for gender, programs can pick up on this unknowingly,"" said Glen Cathey, senior vice president and head of digital strategy and innovation at Randstad, a recruitment agency.  ""Being responsible and ethical in AI, not just in recruitment, is the measurement element.""EEOC standardCompanies that rely on AI need to measure and test for bias, and that's something HireVue studies closely, said Lindsey Anderson Zuloaga, director of data science at the company. ""Whatever biases it has, it could affect a lot of people — and that's true of who gets credit, who gets parole,"" she said, referring to other fields where AI has been used to make determinations. ""In any pre-hire assessments, you need to look at how different demographic groups are being scored, and if there are differences that may be evidence of adverse impact.""HireVue screens for results where any group, such as different genders or races, score less than 80% of the top-scoring group, which is a yardstick for bias used by the U.S. Equal Employment Opportunity Commission. For example, that would happen if an AI program singles out 50 men as solid candidates, but only 30 women. ""We're lucky in this space in that our notion of what is fair is defined by law,"" Zuloaga said. ""We build the model, then we train the algorithm, then look at how is it scoring people within the group.""Hacks for AI?Job applicants are perhaps justifiably nervous about facing an AI in a job interview, which can be nerve-wracking even with other humans. It's no surprise that YouTube tutorials have sprung up to help job candidates learn how to ace pre-recorded interviews by HireVue and others. The tips include how to set up your webcam, how to look good on the video and how to keep cool under pressure — not exactly different advice than what a job hunter would hear about an interview with a real person. In the end, there may be no secret sauce for acing an AI interview, partly because the algorithm is a black box. Even so, human judgment is typically involved in the hiring process after AI programs have screened for the best candidates, HireVue's Parker said. ""We're the first step in a process — the next step is an in-person interview,"" he added. ""It's our desire that there is always a human involved.""","{'@context': 'https://schema.org', '@type': 'VideoObject', 'mainEntityOfPage': {'@type': 'WebPage', '@id': 'https://www.cbsnews.com/video/businesses-turning-to-ai-for-job-interviews/'}, 'name': 'Businesses turning to AI for job interviews', 'description': ""If you're on the job hunt, there's a new twist in the hiring process – artificial intelligence. Major companies like Ikea are turning to AI programs to screen suitable applicants and predict future job performance. Alan Butler, the general counsel at the Electronic Privacy Information Center, joined CBSN to discuss the technique and the criticism it's facing."", 'thumbnail': {'@context': 'https://schema.org', '@type': 'ImageObject', 'height': 630, 'width': 1200, 'url': 'https://assets2.cbsnewsstatic.com/hub/i/r/2020/02/20/d6e9f9ea-fac5-4d19-a234-a45206e41f81/thumbnail/1200x630/70cb9d4ba776188acdea08b11dddc029/0220-cbsn-businessesai-ete-2031263-640x360.jpg?v=5710b2ed1cee1bdfd30cb9c02455b43d'}, 'thumbnailUrl': 'https://assets2.cbsnewsstatic.com/hub/i/r/2020/02/20/d6e9f9ea-fac5-4d19-a234-a45206e41f81/thumbnail/1200x630/70cb9d4ba776188acdea08b11dddc029/0220-cbsn-businessesai-ete-2031263-640x360.jpg?v=5710b2ed1cee1bdfd30cb9c02455b43d', 'uploadDate': '2020-02-20T10:47:07-0500', 'contentUrl': 'https://prod.vodvideo.cbsnews.com/cbsnews/vr/hls/2020/02/20/1700385859618/2031264_hls/master.m3u8', 'publisher': {'@context': 'https://schema.org', '@type': 'NewsMediaOrganization', '@id': 'https://www.cbsnews.com/', 'name': 'CBS News', 'foundingDate': '1927-09-18', 'sameAs': ['https://www.cbsnews.com/', 'https://www.facebook.com/CBSNews/', 'https://instagram.com/cbsnews/', 'https://twitter.com/CBSNews', 'https://www.youtube.com/CBSNews', 'https://en.wikipedia.org/wiki/CBS_News'], 'logo': [{'@context': 'https://schema.org', '@type': 'ImageObject', 'height': 60, 'width': 600, 'url': 'https://www.cbsnews.com/assets/standalone/cbsnews-logo-white-600x60.png'}], 'url': 'https://www.cbsnews.com/', 'parentOrganization': {'@type': 'Organization', 'name': 'Paramount Global', '@id': 'https://www.paramount.com/', 'sameAs': 'https://www.paramount.com/', 'legalName': 'Paramount Global'}, 'actionableFeedbackPolicy': 'https://www.cbsnews.com/news/cbs-news-publishing-principles/#1d4ed2b9-ade8-4203-a4e4-115dd34c0735', 'correctionsPolicy': 'https://www.cbsnews.com/news/cbs-news-publishing-principles/#751608ae-9468-457c-9dbe-1f9400a7f428', 'ethicsPolicy': 'https://www.cbsnews.com/news/cbs-news-publishing-principles/#a0060f90-73b0-4a57-b756-ca7a7f26cc7d', 'Masthead': 'https://www.cbsnews.com/news/cbs-news-publishing-principles/#5fd9a80d-2c6c-4d38-8b1e-4144650d5963', 'missionCoveragePrioritiesPolicy': 'https://www.cbsnews.com/news/cbs-news-publishing-principles/#4ffda755-6b47-49e1-b98c-24b737906aca', 'ownershipFundingInfo': 'https://www.paramount.com/company-history', 'unnamedSourcesPolicy': 'https://www.cbsnews.com/news/cbs-news-publishing-principles/#de41886e-07ed-4887-ad05-4b2c79edf857', 'publishingPrinciples': 'https://www.cbsnews.com/news/cbs-news-publishing-principles/'}, 'duration': 'PT0H06M07S', 'embedUrl': 'https://www.cbsnews.com/video/businesses-turning-to-ai-for-job-interviews/?embed=1'}",1927-09-18,"['https://www.cbsnews.com/', 'https://www.facebook.com/CBSNews/', 'https://instagram.com/cbsnews/', 'https://twitter.com/CBSNews', 'https://www.youtube.com/CBSNews', 'https://en.wikipedia.org/wiki/CBS_News']","[{'@context': 'https://schema.org', '@type': 'ImageObject', 'height': 60, 'width': 600, 'url': 'https://www.cbsnews.com/assets/standalone/cbsnews-logo-white-600x60.png'}]","{'@type': 'Organization', 'name': 'Paramount Global', '@id': 'https://www.paramount.com/', 'sameAs': 'https://www.paramount.com/', 'legalName': 'Paramount Global'}",https://www.cbsnews.com/news/cbs-news-publishing-principles/#1d4ed2b9-ade8-4203-a4e4-115dd34c0735,https://www.cbsnews.com/news/cbs-news-publishing-principles/#751608ae-9468-457c-9dbe-1f9400a7f428,https://www.cbsnews.com/news/cbs-news-publishing-principles/#a0060f90-73b0-4a57-b756-ca7a7f26cc7d,https://www.cbsnews.com/news/cbs-news-publishing-principles/#5fd9a80d-2c6c-4d38-8b1e-4144650d5963,https://www.cbsnews.com/news/cbs-news-publishing-principles/#4ffda755-6b47-49e1-b98c-24b737906aca,https://www.paramount.com/company-history,https://www.cbsnews.com/news/cbs-news-publishing-principles/#de41886e-07ed-4887-ad05-4b2c79edf857,https://www.cbsnews.com/news/cbs-news-publishing-principles/,,
https://news.google.com/rss/articles/CBMifWh0dHBzOi8vd3d3LmZpZXJjZWhlYWx0aGNhcmUuY29tL3RlY2gvYXJ0aWZpY2lhbC1pbnRlbGxpZ2VuY2UtaW5jcmVhc2luZy1wYXRpZW50LWFjY2Vzcy10by1jYXJlLWJ1dC1pdC1zLWFsc28tZHJpdmluZy11cC1jb3N00gEA?oc=5,"Healthcare CEOs say AI progress stymied by high costs, privacy risks - Fierce healthcare",2020-02-19,Fierce healthcare,https://www.fiercehealthcare.com,Executives are bullish on the potential of artificial intelligence to improve healthcare.,"Artificial Intelligence,electronic health records (EHRs),Finance,investment,machine learning,Privacy and Security,Workforce,Google,KPMG,Fierce Healthcare Homepage,Hospitals,Payers,Finance,AI and Machine Learning,Health Tech","Executives are bullish on the potential of artificial intelligence to improve healthcare. | Executives are bullish on the potential of artificial intelligence to improve healthcare. But they say adoption is not happening quickly enough and called out several reasons why, according to a survey by KPMG.","Executives are bullish on the potential of artificial intelligence to improve healthcare. | Executives are bullish on the potential of artificial intelligence to improve healthcare. But they say adoption is not happening quickly enough and called out several reasons why, according to a survey by KPMG.",https://schema.org/,,,,,,,,,,,,,"Fierce Healthcare Homepage,Hospitals,Payers,Finance,AI and Machine Learning",N/A,"

































Fierce Pharma


Fierce Biotech


Fierce Healthcare


Fierce Life Sciences Events






Advertise


About Us








 

 


























 










Providers



Hospitals


Practices


Retail




Health Tech



AI and Machine Learning


Digital Health


Telehealth




Payers


Regulatory


Finance


Special Reports


Fierce 50



Special Report


Awards Gala








Resources



Webinars


Fierce Events


Industry Events


Podcasts


Survey


Whitepapers



 Events 

Subscribe
















 




Subscribe





























Providers



Hospitals


Practices


Retail




Health Tech



AI and Machine Learning


Digital Health


Telehealth




Payers


Regulatory


Finance


Special Reports


Fierce 50



Special Report


Awards Gala








Resources



Webinars


Fierce Events


Industry Events


Podcasts


Survey


Whitepapers



 Events 

Subscribe










Fierce Pharma


Fierce Biotech


Fierce Healthcare


Fierce Life Sciences Events






Advertise


About Us








 

 













































Health Tech




Healthcare CEOs say AI progress stymied by high costs, privacy risks





By 
Heather Landi





Feb 19, 2020 12:14pm




Artificial Intelligence
electronic health records (EHRs)
Finance
investment














Most healthcare executives are confident that AI will improve the patient experience with the greatest impacts being found on diagnostics, electronic records management and incorporating robotics into tasks. (monsitj/Getty Images)
Executives are bullish on the potential of artificial intelligence to improve healthcare. But they say adoption is not happening quickly enough due to a lack of workforce training, high costs, and privacy risks, according to a survey by audit, tax, and advisory services firm KPMG.KPMG's survey of healthcare leaders was part of a larger study of how executives across five industries view the future of AI in their sectors, and the steps they are taking to maximize its benefits and mitigate its challenges.""The pace with which hospital systems have adopted AI and automation programs has dramatically increased since 2017. Virtually all major healthcare providers are moving ahead with pilots or programs in these areas. The medical literature is showing support of AI’s power as a tool to help clinicians,"" Melissa Edwards, managing director, digital enablement, KPMG, said in the report.An overwhelming majority of healthcare respondents (89%) think AI is already creating efficiencies in their systems, and 91% believe it is increasing patient access to care.RELATED: Study: Google AI can outdo the experts in finding breast cancerMany of the AI-related services and solutions being advanced in healthcare today are largely in the clinical, patient-facing space.""Basic forms of automation are proving to be the ‘gateway drug’ to advanced forms of AI—such as scanning documents to determine the urgency of a referral. Applying AI to make earlier diagnoses of critical illnesses is a key area,"" Edwards said.Nine out of 10 healthcare executives are confident that AI will improve the patient experience with the greatest impacts being found on diagnostics, electronic records management and incorporating robotics into tasks.  More than two-thirds of healthcare stakeholders (68%) are confident AI will eventually be effective in diagnosing patient illnesses and conditions, and close to half (47%) believe that diagnostics will have a significant impact soon—within the next two years.  Healthcare executives also anticipate gains in process automation, with 40% seeing X-rays and CT scans being handled robotically.RELATED: Investors poured $4B into healthcare AI startups in 2019Recent findings indicate that function may be close to reality. Google Health reported that an AI model developed and deployed by its DeepMind subsidiary was more effective in screening patients for breast cancer than human doctors using recent X-rays only, despite having access to patients’ previous records.But the pace of progress is too slow, according to one-third of executives, citing barriers such as a lack of workforce talent and the high cost of implementing AI tools.To date, only 44% of healthcare insiders say their employees are prepared for AI adoption, which is substantially lower than some of the other industries surveyed. Less than half of healthcare organizations (47%) offer AI training courses to employees.Just 67% of healthcare insiders say their employees support AI adoption, the lowest ranking of any industry, according to KPMG.Many healthcare institutions lack a breadth of individuals who “speak” the language of AI, Edwards said.""Comprehending the full range of AI technology, and how best to apply it in a healthcare setting, is a learned skill that grows out of pilots and tests. Building an AI-ready workforce requires a wholesale change in the approach to training and how to acquire talent. Having people who understand how AI can solve big, complex problems is critical,"" she said.RELATED: Microsoft launches $40M AI for Health program to accelerate medical researchHealth systems have already made significant capital investments to meet electronic health records (EHR) requirements. To get AI off the ground requires even more of an investment, and, as a result, some health systems are slower to allocate full funding for AI.More than half of executives (54%) believe that AI to date has actually increased rather than decreased the overall cost of healthcare. Decision-makers are struggling to determine where to place their AI best bets.""The question is, ‘Where do I put my AI efforts to get the greatest gain for the business?' Trying to assess what ROI will look like is a very relevant point as they embark on their AI journey,"" Edwards said.Healthcare executives also are concerned that AI could threaten the security and privacy of patient data. Relatedly, 86% say their organizations are taking care to protect patient privacy as it implements AI.

Artificial Intelligence
electronic health records (EHRs)
Finance
investment
machine learning
Privacy and Security
Workforce
Google
KPMG
Hospitals
Payers
Finance
AI and Machine Learning
Health Tech












Related ContentUnitedHealth reaffirms guidance as it posts $4.2B in Q2 profitJul 16, 2024 07:34amNo Surprises Act audit finds inaccurate calculations by Aetna of TexasJul 15, 2024 05:10pmFTC probing DaVita, Fresenius Medical Care's noncompetes for dialysis clinic medical directorsJul 15, 2024 04:00pmChicago safety-net hospital's former CFO charged in $15M embezzlement schemeJul 15, 2024 04:00pm







See more articles










 



 

 








Connect



The Team


Advertise




Join Us



Newsletters


Resources


RSS Feeds


Editorial Advisory Council




Our Brands



Fierce Pharma


Fierce Biotech


Fierce Healthcare




Our Events



Life Sciences Events

















©2024 Questex LLC All rights reserved.
Terms of use
Privacy Policy
Privacy Settings











",,,,,,,,"{'@type': 'NewsArticle', 'headline': 'AI adoption slowed by lack of worker training, high costs', 'articleSection': None, 'keywords': 'Health Tech', 'description': 'Executives are bullish on the potential of artificial intelligence to improve healthcare but think adoption needs to happen faster.\r\n', 'datePublished': '2020-02-19T17:14:09', 'isAccessibleForFree': True, 'dateModified': '1648105029', 'author': [[{'@type': 'Person', 'name': 'Heather Landi', 'url': 'https://www.fiercehealthcare.com/person/heather-landi'}]], 'publisher': {'@type': 'Organization', 'name': 'FierceHealthcare', 'url': 'https://www.fiercehealthcare.com'}, 'mainEntityOfPage': {'@type': 'WebPage', '@id': 'https://www.fiercehealthcare.com/tech/artificial-intelligence-increasing-patient-access-to-care-but-it-s-also-driving-up-cost'}, 'image': 'https://qtxasset.com/quartz/qcloud5/media/image/fiercehealthcare/1582063472/GettyImages-932559358.jpg/GettyImages-932559358.jpg?VersionId=OKnioXbMZbw1Q9YwgecpVaYq2X18Hfld'}",,,,,,,,,,,,,,,,,,,,
https://news.google.com/rss/articles/CBMieWh0dHBzOi8vamVyc2V5ZXZlbmluZ3Bvc3QuY29tL21vcmVuZXdzL3dvcmxkbmV3cy8yMDIwLzAyLzE5L2V1LXByb3Bvc2VzLXJ1bGVzLWZvci1hcnRpZmljaWFsLWludGVsbGlnZW5jZS10by1saW1pdC1yaXNrcy_SAQA?oc=5,EU proposes rules for artificial intelligence to limit risks - Jersey Evening Post,2020-02-19,Jersey Evening Post,https://jerseyeveningpost.com,The European Union has unveiled proposals to regulate artificial intelligence that call for strict rules and safeguards on risky applications of the rapidly developing technology.The report […],N/A,The European Union has unveiled proposals to regulate artificial intelligence that call for strict rules and safeguards on risky applications of the rapidly developing technology.The report […],The European Union has unveiled proposals to regulate artificial intelligence that call for strict rules and safeguards on risky applications of the rapidly developing technology.The report […],https://schema.org,,,,,,,,,,,,,N/A,N/A,"

 


										UK News									


										Killer giving evidence in private at parole hearing ‘a farce’ – victim’s mother									


										16 July, 2024									

",,,,,,,,"[{'@type': 'Article', '@id': 'https://jerseyeveningpost.com/morenews/worldnews/2020/02/19/eu-proposes-rules-for-artificial-intelligence-to-limit-risks/#article', 'isPartOf': {'@id': 'https://jerseyeveningpost.com/morenews/worldnews/2020/02/19/eu-proposes-rules-for-artificial-intelligence-to-limit-risks/'}, 'author': {'name': 'Newsdesk', '@id': 'https://jerseyeveningpost.com/#/schema/person/acb2d1340e814b2ed48cabceaa6f744d'}, 'headline': 'EU proposes rules for artificial intelligence to limit risks', 'datePublished': '2020-02-19T12:13:34+00:00', 'dateModified': '2020-02-19T12:13:34+00:00', 'mainEntityOfPage': {'@id': 'https://jerseyeveningpost.com/morenews/worldnews/2020/02/19/eu-proposes-rules-for-artificial-intelligence-to-limit-risks/'}, 'wordCount': 951, 'commentCount': 0, 'publisher': {'@id': 'https://jerseyeveningpost.com/#organization'}, 'articleSection': ['More News', 'World News'], 'inLanguage': 'en-GB', 'potentialAction': [{'@type': 'CommentAction', 'name': 'Comment', 'target': ['https://jerseyeveningpost.com/morenews/worldnews/2020/02/19/eu-proposes-rules-for-artificial-intelligence-to-limit-risks/#respond']}], 'image': {'@id': 'https://jerseyeveningpost.com/morenews/worldnews/2020/02/19/eu-proposes-rules-for-artificial-intelligence-to-limit-risks/#primaryimage'}, 'thumbnailUrl': 'https://jerseyeveningpost.com/wp-content/themes/jerseyeveningpost-fse/includes/images/placeholder.png'}, {'@type': 'WebPage', '@id': 'https://jerseyeveningpost.com/morenews/worldnews/2020/02/19/eu-proposes-rules-for-artificial-intelligence-to-limit-risks/', 'url': 'https://jerseyeveningpost.com/morenews/worldnews/2020/02/19/eu-proposes-rules-for-artificial-intelligence-to-limit-risks', 'name': 'EU proposes rules for artificial intelligence to limit risks - Jersey Evening Post', 'isPartOf': {'@id': 'https://jerseyeveningpost.com/#website'}, 'datePublished': '2020-02-19T12:13:34+00:00', 'dateModified': '2020-02-19T12:13:34+00:00', 'breadcrumb': {'@id': 'https://jerseyeveningpost.com/#breadcrumb'}, 'inLanguage': 'en-GB', 'potentialAction': [{'@type': 'ReadAction', 'target': ['https://jerseyeveningpost.com/morenews/worldnews/2020/02/19/eu-proposes-rules-for-artificial-intelligence-to-limit-risks/']}], 'thumbnailUrl': 'https://jerseyeveningpost.com/wp-content/themes/jerseyeveningpost-fse/includes/images/placeholder.png', 'about': {'@id': 'https://jerseyeveningpost.com/#organization'}, 'primaryImageOfPage': {'@id': 'https://jerseyeveningpost.com/wp-content/themes/jerseyeveningpost-fse/includes/images/placeholder.png'}}, {'@type': 'BreadcrumbList', '@id': 'https://jerseyeveningpost.com/morenews/worldnews/2020/02/19/eu-proposes-rules-for-artificial-intelligence-to-limit-risks/#breadcrumb', 'itemListElement': [{'@type': 'ListItem', 'position': 1, 'name': 'Home', 'item': 'https://www.jerseyeveningpost.com/'}, {'@type': 'ListItem', 'position': 2, 'name': 'EU proposes rules for artificial intelligence to limit risks'}]}, {'@type': 'WebSite', '@id': 'https://jerseyeveningpost.com/#website', 'url': 'https://jerseyeveningpost.com', 'name': 'Jersey Evening Post', 'description': 'Jersey Evening Post', 'publisher': {'@id': 'https://jerseyeveningpost.com/#organization'}, 'potentialAction': [{'@type': 'SearchAction', 'target': {'@type': 'EntryPoint', 'urlTemplate': 'https://jerseyeveningpost.com/?s={search_term_string}'}, 'query-input': 'required name=search_term_string'}], 'inLanguage': 'en-GB'}, {'@type': 'Organization', '@id': 'https://jerseyeveningpost.com/#organization', 'name': 'Jersey Evening Post', 'url': 'https://jerseyeveningpost.com', 'logo': {'@type': 'ImageObject', 'inLanguage': 'en-GB', '@id': 'https://jerseyeveningpost.com/#/schema/logo/image/', 'url': 'https://d3gvyx4eg3tne0.cloudfront.net/wp-content/uploads/2021/05/Jersey_Logo.png', 'contentUrl': 'https://d3gvyx4eg3tne0.cloudfront.net/wp-content/uploads/2021/05/Jersey_Logo.png', 'width': 486, 'height': 70, 'caption': 'Jersey Evening Post'}, 'image': {'@id': 'https://jerseyeveningpost.com/#/schema/logo/image/'}, 'sameAs': ['https://www.facebook.com/jerseyeveningpost', 'https://twitter.com/JEPnews', 'https://www.instagram.com/jepnews/', 'https://www.linkedin.com/company/jerseyeveningpost']}, {'@type': 'Person', '@id': 'https://jerseyeveningpost.com/#/schema/person/acb2d1340e814b2ed48cabceaa6f744d', 'name': 'Newsdesk', 'image': {'@type': 'ImageObject', 'inLanguage': 'en-GB', '@id': 'https://jerseyeveningpost.com/#/schema/person/image/', 'url': 'https://secure.gravatar.com/avatar/a276796e40d13d491ef836d3baa7d1d1?s=96&d=mm&r=g', 'contentUrl': 'https://secure.gravatar.com/avatar/a276796e40d13d491ef836d3baa7d1d1?s=96&d=mm&r=g', 'caption': 'Newsdesk'}, 'sameAs': ['http://jerseyeveningpost-develop.eba-mpbckazn.eu-west-1.elasticbeanstalk.com'], 'url': 'https://jerseyeveningpost.com/author/admin/'}]",,,,,,,,,,,,,,,,,,,,
https://news.google.com/rss/articles/CBMiamh0dHBzOi8vY2VkLm5jc3UuZWR1L25ld3MvMjAyMC8wMi8xOC9ncmFudC1mcm9tLXRoZS11LXMtZGVwYXJ0bWVudC1vZi1sYWJvci10by1zdXBwb3J0LWFpLWFwcHJlbnRpY2VzaGlwcy_SAQA?oc=5,Grant from the U.S. Department of Labor to Support AI Apprenticeships - NC State College of Education News,2020-02-18,NC State College of Education News,https://ced.ncsu.edu,"A new four-year, $6 million project led by North Carolina State University and funded by the U.S. Department of Labor will support 5,000 workers with training, college coursework and certification to work in the emerging field of artificial intelligence (AI). Carla C. Johnson, senior faculty fellow and professor of science education at NC State, is the principal investigator of the project “Artificial Intelligence Academy (AIA): North Carolina Apprenticeships for Innovation,” which will be affiliated with the NC State College of Education’s Friday Institute for Educational Innovation.",N/A,"A new four-year, $6 million project led by North Carolina State University and funded by the U.S. Department of Labor will support 5,000 workers with training, college coursework and certification to work in the emerging field of artificial intelligence (AI). Carla C. Johnson, senior faculty fellow and professor of science education at NC State, is the principal investigator of the project “Artificial Intelligence Academy (AIA): North Carolina Apprenticeships for Innovation,” which will be affiliated with the NC State College of Education’s Friday Institute for Educational Innovation.","A new four-year, $6 million project led by North Carolina State University and funded by the U.S. Department of Labor will support 5,000 workers with training, college coursework and certification to work in the emerging field of artificial intelligence (AI). Carla C. Johnson, senior faculty fellow and professor of science education at NC State, is the principal investigator of the project “Artificial Intelligence Academy (AIA): North Carolina Apprenticeships for Innovation,” which will be affiliated with the NC State College of Education’s Friday Institute for Educational Innovation.",,,,,,,,,,,,,,N/A,N/A,"

Grant from the U.S. Department of Labor to Support AI Apprenticeships

February 18, 2020

Staff


				3-min. read
			



Left to right: N.C. Lt. Gov. Dan Forest, Labor Secretary Eugene Scalia and NC State Chancellor Randy Woodson during a press conference Tuesday, Feb. 18, when they announced NC State will receive a $6 million grant to prepare 5,000 new artificial intelligence (AI) professionals for North Carolina and beyond.



A new four-year, $6 million project led by North Carolina State University and funded by the U.S. Department of Labor will support 5,000 workers with training, college coursework and certification to work in the emerging field of artificial intelligence (AI).
Carla C. Johnson
U.S. Secretary of Labor Eugene Scalia announced the project today alongside NC State Chancellor Randy Woodson during an event held at NC State’s Hunt Library on Centennial Campus. The grant is one of the labor department’s 28 public-private apprenticeship partnerships totaling nearly $100 million. The grants will support large-scale expansions of apprenticeships in industries including advanced manufacturing, healthcare and information technology.
“This project really exemplifies NC State’s ‘Think and Do’ mentality,” Woodson said. “This grant will fuel collaboration between industry and education, create new on-the-job training for students and play an important role in workforce development in a burgeoning field in North Carolina and across the nation.”
Carla C. Johnson, professor of science education at NC State, is the principal investigator of the project “Artificial Intelligence Academy (AIA): North Carolina Apprenticeships for Innovation.” The project aims to assist current information technology employees in North Carolina as well as across the U.S. who are underemployed or are seeking an opportunity to move into a different career. It will also target underrepresented workers and those from military populations.
“The greatest strength of our AIA project is the exceptional industry partnerships we have formed,” Johnson said. “Our consortium will lead and inform the important work of building a pipeline of highly qualified and well prepared AI talent for North Carolina and beyond.”
Johnson also serves as the co-principal investigator for another U.S. Dept. of Labor grant, announced last July, for cybersecurity apprenticeships in partnership with Purdue University.
“Apprenticeship: Closing the Skills Gap grants are a major investment to support the expansion of apprenticeships that lead to good paying careers and make the American workforce even stronger,” Scalia said. “Across America, I hear about the need for more skilled American workers. This funding will bolster America’s competitiveness by adding more skilled workers to fill millions of open jobs today and in the future.”
The AIA program will have multiple pathways and will prepare participants for AI careers that are in high demand nationwide. It will include two levels of training and associated certifications: Basic AI (artificial intelligence and data mining focus) and Advanced AI (machine learning and analytics focus). Apprentices will complete the entire program in one year. Industry partners will pay apprentices for at least part-time work during the program and will also pay apprentice tuition and fees for the AI credential program. Companies will benefit from additional workers in their organizations and will have the option to hire the apprentice upon completion of program.
The project will include partners from a variety of sectors. Industry partners include IBM, CISCO, Citrix, Pentair, Hazardous Software, Diveplane, Randstad Technologies, Battelle Memorial Institute and MCNC. Educational partners include N.C. Community Colleges/Apprenticeship NC, Purdue Global, MACUL and Metriks Amerique. Veterans and other recruitment-related affiliated agencies involved in the project include FASTPORT, VetsinTech, Warrior Maven, Paradigm Shift, Monster Jobs, Dice, Industrial Internet Consortium, Crosby Communications and Clearance Jobs. The NC Chamber will serve as a workforce development partner on the project.



Categories:
          

News





Tags:
          

AI


Artificial Intelligence


Carla C. Johnson


Carla Johnson


Friday Institute


grants


homepage-news


news


research


science education


STEM Ed


STEM Education





",,,,,,,,,,,,,,,,,,,,,,,,,,,,
https://news.google.com/rss/articles/CBMiaWh0dHBzOi8vd3d3LmRpZ2l0YWx0cmVuZHMuY29tL2Nvb2wtdGVjaC9maXZlcnItYXJ0aWZpY2lhbC1pbnRlbGxpZ2VuY2UtbG9nby1kZXNpZ25lci1oZXJlcy13aGF0LWhhcHBlbmVkL9IBbWh0dHBzOi8vd3d3LmRpZ2l0YWx0cmVuZHMuY29tL2Nvb2wtdGVjaC9maXZlcnItYXJ0aWZpY2lhbC1pbnRlbGxpZ2VuY2UtbG9nby1kZXNpZ25lci1oZXJlcy13aGF0LWhhcHBlbmVkLz9hbXA?oc=5,We used an A.I. design tool to come up with a new logo. Here’s what happened - Digital Trends,2020-02-18,Digital Trends,https://www.digitaltrends.com,Can A.I. replace human creativity in graphic design? We tried Fiverr's new A.I.-powered Logo Maker to see if it could whip up a better logo for Digital Trends.,"Emerging Tech,ai,Artificial intelligence",Can A.I. replace human creativity in graphic design? We tried Fiverr's new A.I.-powered Logo Maker to see if it could whip up a better logo for Digital Trends.,Can A.I. replace human creativity in graphic design? We tried Fiverr's new A.I.-powered Logo Maker to see if it could whip up a better logo for Digital Trends.,,,,,,,,,,,,,,Emerging Tech,N/A,"
Image used with permission by copyright holder
No matter what industry you work in, you’ve probably heard that artificial intelligence is coming for your job. Factory workers, news reporters, even stock brokers have all seen A.I. move into their fields, automating some of their roles. Proponents of automation point out that it tackles the menial, repetitive tasks, freeing workers to focus on more creative aspects.

Contents
All the logos you need in two shakes of a lamb’s tailThe experts weigh inAll around me are familiar logos


Now, gig economy marketplace Fiverr recently announced a new A.I.-powered tool that helps businesses create a logo.


			Recommended Videos		


1/1





Skip Ad
 
Continue watchingafter the adVisit Advertiser websiteGO TO PAGE4K 240Hz OLED Gaming Monitor for Under $1K! | MSI...
HD Hyundai’s Robotic Machinery Is Transforming the...
This AI robot dog is cute, weird, and a little terrifying
New MLA OLED Gaming Monitor Slays, Affordable...
I saw Verizon's adorable (and important) 5G...


As the company puts it in its press release, “There is a specter haunting the future of work in the form of A.I. and automation enabling machines to displace people’s jobs.”
Rather than offer Andrew Yang-esque worries about the future of work, Fiverr takes an optimistic view. “The future of work is one where A.I. supports more people, to create more with less effort,” CEO Micha Kaufman explains in a statement.
The tool begins with a collection of assets made by Fiverr “community members,” the uses A.I. to quickly select and customize logos tailored to the mood of a specific business. How well does it work in practice? We spent some time playing around with it to create a “new” logo for Digital Trends.
All the logos you need in two shakes of a lamb’s tail
To start, you provide your company’s name and slogan (we took some liberties with the latter for this exercise). You then provide some industries you work in, and any keywords that can help the A.I. narrow down your business model. After that, you’ll see sliders for concepts like Fun/Serious or Simple/Sophisticated. Tune these to your liking and you’re off to the races.
The Logo Maker will spit out a selection of logos, and you can then customize them manually. In our first attempt, we went light on the keywords, and the results, to this writer’s eyes, ranged from decent to incredibly dull (one of the best had a color palette eerily evocative of The Verge, as if we’d skinned their visage and fashioned it into an ill-fitting mask). There was even a knockoff Pokéball!
Image used with permission by copyright holder
The experts weigh in
Seeking expert opinions, we decided to consult the graphic designers in our office to see what they think.
First impressions? “Passable, if a bit generic, and the typefaces are pretty uninspiring,” said Digital Trends Content Specialist Chris DeGraw, adding that it’s a “good place to start, though. And hey, I’ve seen many businesses with much much worse in the real world.”
Image used with permission by copyright holder
They look “like clean, modern logos, but they aren’t very company-specific and feel a bit disconnected/generic,” said Content Manager Genevieve Poblano. “Still decent but lacking that custom fit. But like I said, if you want something quick and generic or a template to base your stuff off of, this works.”
“If you want something quick and generic or a template to base your stuff off of, this works.”

Senior Designer Will Hawkins said the design reminded him of clip art in terms of “the overall inconsistency. [There are] varying line weights in the illustrations, the illustration style doesn’t necessarily match the fonts being used, and they are all so generic that they become ambiguous, which is why they can’t vary from brand to brand.”
Adding to this, Poblano referenced the logos’ “lack of soul.” [Note: She actually used Slack’s Giphy function to post a GIF for the phrase “lack of soul.”] “I think if you want something quick and generic, this might work. I would be curious to see what it does with a different industry like a restaurant.”
All around me are familiar logos
After consulting Digital Trends’ design oracles, we ventured once more into Fiverr’s underworld of bland but serviceable designs. We decided to test it out with some fake companies from various industries.
Image used with permission by copyright holder
Our fake ad firm Mad Men at Work got some interesting designs (including some sort of eldritch octopus), but we noticed some repetitive themes. There was some overlap with the fake Digital Trends logos, with some even using the same colors.
The generic quality became even more apparent when we ran a search for our new sci-fi themed, royalty-free sandwich shop, The Sandolorian. Despite only using “sandwich” and “sandwiches” for tags, we got logos promising a variety of dishes including shrimp, noodles, and pizza. Most inexplicable was the nightmare octopus from our ad agency, this time with creepy, pupil-less eyes.
Image used with permission by copyright holder
For now, at least, the graphic designers of the world can relax. Like all artistic pursuits, graphic design rewards a personal, creative touch that Fiverr’s tool isn’t yet ready to offer, although the app “also provides buyers the option to work with the designer who created the original logo template on any special enhancements that can’t be modified through the A.I.”
It’s possible that a tool like this will one day surpass human artists, but until then, The Sandolorian will take its business elsewhere.


		Editors’ Recommendations	



						You may want to stop using the Rabbit R1					



						Security robots could be coming to a school near you					



 












",,,,,,,,,,,,,,,,,,,,,,,,,,,,
https://news.google.com/rss/articles/CBMicmh0dHBzOi8vd3d3LmFuYWx5dGljc2luc2lnaHQubmV0L2FydGlmaWNpYWwtaW50ZWxsaWdlbmNlL2NvbWJpbmF0aW9uLWh1bWFucy1hcnRpZmljaWFsLWludGVsbGlnZW5jZS1jeWJlci1zZWN1cml0edIBfGh0dHBzOi8vd3d3LmFuYWx5dGljc2luc2lnaHQubmV0L2FtcC9zdG9yeS9hcnRpZmljaWFsLWludGVsbGlnZW5jZS9jb21iaW5hdGlvbi1odW1hbnMtYXJ0aWZpY2lhbC1pbnRlbGxpZ2VuY2UtY3liZXItc2VjdXJpdHk?oc=5,The Combination of Humans and Artificial Intelligence in Cyber Security - Analytics Insight,2020-02-16,Analytics Insight,https://www.analyticsinsight.net,,"Cybersecurity,Humans,Artificial Intelligence,Security,AI","Artificial intelligence has transformed pretty much every industry in which it's been embraced, including healthcare, the stock markets, and, increasingly, cybe","Artificial intelligence has transformed pretty much every industry in which it's been embraced, including healthcare, the stock markets, and, increasingly, cybe",http://schema.org,NewsArticle,https://www.analyticsinsight.net/artificial-intelligence/combination-humans-artificial-intelligence-cyber-security,"{'@type': 'ImageObject', 'url': 'https://media.assettype.com/analyticsinsight/import/wp-content/uploads/2020/02/brain.jpg?w=1200&h=675&auto=format%2Ccompress&fit=max&enlarge=true', 'width': '1200', 'height': '675'}","[{'@type': 'Person', 'givenName': 'Priya Dialani', 'name': 'Priya Dialani', 'url': 'https://www.analyticsinsight.net/author/priya-dialani'}]","{'@type': 'Organization', '@context': 'http://schema.org', 'name': 'Analytics Insight', 'url': 'https://www.analyticsinsight.net', 'logo': {'@context': 'http://schema.org', '@type': 'ImageObject', 'author': 'analyticsinsight', 'contentUrl': 'https://images.assettype.com/analyticsinsight/2024-05/2df9abcd-45d0-437f-9a36-167417fe7202/AI_logo_white (2).png', 'url': 'https://images.assettype.com/analyticsinsight/2024-05/2df9abcd-45d0-437f-9a36-167417fe7202/AI_logo_white (2).png', 'name': 'logo', 'width': '', 'height': ''}, 'sameAs': ['https://www.linkedin.com/company/analytics-insight/', 'https://www.facebook.com/analyticsinsight.net', 'https://twitter.com/analyticsinme', 'https://www.youtube.com/channel/UCgF2J0b46YP0vvVEbgL_GuQ', 'https://www.instagram.com/analyticsinsightmagazine/', 'https://in.pinterest.com/analyticsinsightsubmissions/_created/'], 'id': 'https://www.analyticsinsight.net'}",The Combination of Humans and Artificial Intelligence in Cyber Security,2020-02-16T02:58:10Z,2020-02-16T02:58:10Z,Artificial Intelligence,The Combination of Humans and Artificial Intelligence in Cyber Security,,"[{'@type': 'ListItem', 'position': 1, 'name': 'Home', 'item': 'https://www.analyticsinsight.net'}, {'@type': 'ListItem', 'position': 2, 'name': 'Artificial Intelligence', 'item': 'https://www.analyticsinsight.net/artificial-intelligence'}, {'@type': 'ListItem', 'position': 3, 'name': 'The Combination of Humans and Artificial Intelligence in Cyber Security', 'item': 'https://www.analyticsinsight.net/artificial-intelligence/combination-humans-artificial-intelligence-cyber-security'}]",N/A,N/A,"Ready for iOS 18? Here's How to Install the Public Beta
",,,,,,,"{'@type': 'WebPage', '@id': 'https://www.analyticsinsight.net/artificial-intelligence/combination-humans-artificial-intelligence-cyber-security'}",,2020-02-16T02:58:10Z,,https://media.assettype.com/analyticsinsight/import/wp-content/uploads/2020/02/brain.jpg?w=1200&h=675&auto=format%2Ccompress&fit=max&enlarge=true,,"Artificial intelligence has transformed pretty much every industry in which it's been embraced, including healthcare, the stock markets, and, increasingly, cybersecurity, where it's being utilized to both enhance human work and strengthen defenses. As a result of recent improvements in machine learning, the dreary work that was once done by people, filtering through apparently unlimited amounts of information searching for threat indicators and anomalies would now be able to be automated. Present day AI's ability to understand threats, risks and relationships enable it to sift through a generous amount of the noise burdening cybersecurity divisions and surface just the pointers destined to be legitimate..Indeed, even as AI innovation changes some aspects of cybersecurity, the crossing point of the two remains significantly human. In spite of the fact that it's maybe unreasonable, humans are upfront in all pieces of the cybersecurity triad: the terrible actors who look to do hurt, the gullible soft targets, and the great on-screen characters who retaliate..Indeed, even without the approaching phantom of AI, the cybersecurity war zone is frequently hazy to average users and the technologically savvy alike. Including a layer of AI, which contains various innovations that can likewise feel unexplainable to many people, may appear to be doubly unmanageable as well as indifferent. That is on the grounds that in spite of the fact that the cybersecurity battle is once in a while profoundly personal, it's once in a while pursued face to face..With an expected 3.5 million cybersecurity positions expected to go unfilled by 2021 and with security ruptures increasing some 80% every year, infusing human knowledge with AI and machine learning tools gets critical to shutting the talent availability gap..That is one of the recommendations of a report called Trust at Scale, as of late released by cybersecurity organization Synack and citing job and breach data from Cybersecurity Ventures and Verizon reports, individually. Indeed, when ethical human hackers were upheld by AI and machine learning, they became 73% increasingly proficient at identifying and evaluating IT risks and threats..The advantages of this are twofold: Threats never again slip through the cracks because of fatigue or boredom, and cybersecurity experts are liberated to accomplish more strategic tasks, for example, remediation. Artificial intelligence can likewise be utilized to increase perceivability over the network. It can examine phishing by simulating clicks on email links and analyzing word choice and grammar. It can monitor network communications for endeavored installation of malware, command and control communications, and the presence of suspicious packets. What's more, it's changed virus detection from an exclusively signature-based framework which was entangled by issues with reaction time, proficiency, and storage requirements to the period of behavioral analysis, which can distinguish signatureless malware, zero-day exploits, and previously unidentified threats..In any case, while the conceivable outcomes with AI appear to be unfathomable, the possibility that they could wipe out the role of people in cybersecurity divisions is about as unrealistic as the possibility of a phalanx of Baymaxes supplanting the nation's doctors. While the ultimate objective of AI is to simulate human functions, for example, problem-solving, learning, planning, and intuition, there will consistently be things that AI can't deal with (yet), as well as things AI should not handle..The principal classification incorporates things like creativity, which can't be viably instructed or customized, and therefore will require the guiding hand of a human. Anticipating that AI should viably and reliably decide the context of an attack may likewise be an unconquerable ask, at any rate for the time being, just like the idea that AI could make new solutions for security issues. At the end of the day, while AI can unquestionably add speed and exactness to tasks generally handled by people, it is poor at extending the scope of such tasks..As it were, AI's impact on the field of cybersecurity is the same as its effect on different disciplines, in that individuals frequently terribly overestimate what AI can do. They don't comprehend that AI often works best when it has a restricted application, similar to anomaly detection, versus a broader one, like engineering a solution to a threat. In contrast to people, AI needs inventiveness. It isn't inventive. It isn't cunning. It regularly neglects to consider context and memory, leaving it incapable to decipher occasions like a human mind does..In a meeting with VentureBeat, LogicHub CEO and cofounder Kumar Saurabh showed the requirement for human analysts with a kind of John Henry test for automated threat detection. &quot;A few years ago, we did an examination,&quot; he said. This included arranging a specific amount of information, a trifling sum for an AI model to filter through, yet a sensibly huge sum for a human analyst to perceive how teams utilizing automated frameworks would pass against people in threat detection..The eventual fate of cybersecurity will be loaded with threats we can't consider today. Yet, with vigilance and hard work, the blend of man and machine can do what neither can do alone, structure an integral team equipped for upholding order and fighting the forces of evil..Disclaimer: Analytics Insight does not provide financial advice or guidance. Also note that the cryptocurrencies mentioned/listed on the website could potentially be scams, i.e. designed to induce you to invest financial resources that may be lost forever and not be recoverable once investments are made. You are responsible for conducting your own research (DYOR) before making any investments. Read more here.",,,,,,,,,,,,,,"{'@type': 'WebPage', 'url': 'https://www.analyticsinsight.net/artificial-intelligence/combination-humans-artificial-intelligence-cyber-security', 'primaryImageOfPage': {'@type': 'ImageObject', 'url': 'https://media.assettype.com/analyticsinsight/import/wp-content/uploads/2020/02/brain.jpg?w=1200&h=675&auto=format%2Ccompress&fit=max&enlarge=true', 'width': '1200', 'height': '675'}}",
https://news.google.com/rss/articles/CBMiYmh0dHBzOi8vcmFkaW9sb2d5YnVzaW5lc3MuY29tL3RvcGljcy9hcnRpZmljaWFsLWludGVsbGlnZW5jZS9oZWxsby1haS1nb29kYnllLXJhZGlvbG9neS13ZS1rbm93LWl00gEA?oc=5,"Hello AI, Goodbye Radiology as We Know It - Radiology Business",2020-02-18,Radiology Business,https://radiologybusiness.com,"A machine able to interpret diagnostic imaging studies better than radiologists has long been foreseen, yet its arrival comes almost as a surprise. We have underestimated the potential of AI to perform the kinds of work we do.",Artificial Intelligence,"A machine able to interpret diagnostic imaging studies better than radiologists has long been foreseen, yet its arrival comes almost as a surprise. We have underestimated the potential of AI to perform the kinds of work we do.","A machine able to interpret diagnostic imaging studies better than radiologists has long been foreseen, yet its arrival comes almost as a surprise. We have underestimated the potential of AI to perform the kinds of work we do.",https://schema.org,,,,,,,,,,,,,N/A,N/A,"  Hello AI, Goodbye Radiology as We Know ItRobert Schier, MD | February 18, 2020 | Artificial Intelligencetweetprintsharesharemail   What Will Radiologists Do When They’re the Augmenters?How long will it be before artificial intelligence replaces the first radiologist? A paper published Jan. 1 in Nature suggests this day will come sooner than many of us thought. The article, “International evaluation of an AI system for breast cancer screening,” authored by Google machine learning engineer Scott Mayer McKinney and colleagues, describes an AI system able to interpret screening mammograms more accurately than radiologists. (It’s probably no accident that this article was published online on the first day of a new decade.)Until now, AI has outperformed radiologists only in limited aspects of a larger imaging study—counting and measuring lung nodules on CT, for example, or detecting pneumothoraxes on chest X-rays. But the system described in Nature is a major advancement: It’s the first system able to interpret an entire type of study better than radiologists. The appearance of this system marks the beginning of the end of the practice of diagnostic radiology.Intelligent EnoughA machine able to interpret diagnostic imaging studies better than radiologists has long been foreseen, yet its arrival comes almost as a surprise. We have underestimated the potential of AI to perform the kinds of work we do. We continue to overestimate the amount of control we as radiologists will have over either the development of AI or the application of that technology to radiology. We’ve underestimated the potential of AI for perfectly good reasons. Our experience with the AI of 20 years ago—awkward, error-filled systems that often made radiologists’ work harder rather than easier and didn’t improve the quality of reports—was discouraging. And the term artificial made it easy to believe that the intelligence produced by machines always would be a somehow false and inferior kind of intelligence. This was a mistaken assumption. Just as in physics power is a measure of the ability to perform work, so intelligence, in cognitive science, is a measure of the ability to solve problems. Machines can be built to produce both. We are not talking here about machines becoming human. We’re talking about machines with the intelligence to solve the kinds of imaging puzzles radiologists face every day. Qualified for Our Jobs? The first commercial steam engine in 1698 sat on a platform and slowly pumped water out of a mine. Who at that time could have imagined that the descendants of that immobile machine would haul freight cross-country or fly from New York to London? Similarly, anyone who had to deal with early mammographic CAD might find it hard to believe that computers would eventually perform the varied and complex work of diagnostic imaging—analyzing images, comparing studies across modalities and time, correlating patient records and lab values, and producing clear and definitive reports. Yet these are all tasks at which computers are beginning to excel. Cognitive and computer scientists are in broad agreement on the forecast that, as machines became stronger than we are, machines will become more intelligent than we are.Radiologists are not controlling the development of artificial intelligence. Most of this work is being done by government and business. We can modify these AI systems to help us in specific tasks, but we are generally not creating the underlying hardware and software any more than farmers 100 years ago built the tractors that replaced their horses and oxen. And we will not ultimately control the use of AI in our own profession. The use of artificial intelligence in radiology will be controlled by governments, insurance companies and imaging providers who will push for ever-greater accuracy and efficiency and ever-lower costs. Picking on RadiologyAI does not need to be perfect in order to replace a radiologist. It simply needs to be better than a radiologist. If using AI allows radiologists to produce more accurate reports, then radiologists will be required to use AI. If AI by itself reads a study better than do AI and a radiologist working together—and this can happen even now, with the input of a radiologist dragging down the performance of the AI—then AI will be required to read that study alone.Diagnostic imaging studies have been increasing in number, complexity and amount of information. During the next few years AI will be a great help to radiologists in handling that difficult and sometimes overwhelming amount of work. At some point, however, the increasing use of AI will begin to reduce the number of studies that will require a radiologist to interpret them.All this raises difficult and contentious questions which so far do not have clear answers: ▲ What will this replacement process look like?▲ How should radiologists now in practice begin to prepare for this change?▲ How many radiologists are likely to be needed in five, 10 or 20 years?▲ How many radiology residents will be needed and what kind of training should they be given?No other medical profession has yet faced this kind of challenge. The radiology community is trying to find a path forward without a map. Uncertain Identity If we overestimate the speed at which AI will advance, and radiologists leave for other specialties and too many radiology residency positions go unfilled, we may end up with a shortage of radiologists. If we downplay the speed and impact of AI too much, we may end up training radiologists who will not be able to find work.The widespread use of artificial intelligence will be good for medicine. Patient care will be better, faster, less expensive and more equitable. This is our goal as physicians. But AI will not end up being good for the specialty of radiology. So, when will AI replace the first radiologist? If that experimental system described in Nature were currently being used in clinical practice, the answer would be “now.” AI will not replace every radiologist, nor will computers learn to read every type of imaging study all at once. But as computers begin to handle an ever-larger number of studies, radiologists will spend less time working in front of monitors and more time dealing directly with patients. As physicians, we can certainly do this. What is not at all clear is whether we will still be called radiologists.Dr. Schier is a radiologist with multistate, Los Angeles-based RadNet. The views expressed here are his own. Robert Schier, MDRelated ContentRayus Radiology launches whole-body MRI service in Seattle, SimonMed expands, RadNet touts legislation, plus more company newsACR opens doors of AI quality-assurance center AI critical care software revolutionizes emergency responseStrategic Radiology signs on with Qure.ai ASNC supports AMA effort to limit use of AI in prior authorization decisionsAmerican College of Radiology asks CMS to create new alternative payment pathway for high-value AI",,,,,,,,"[{'@type': 'NewsArticle', 'headline': 'Hello AI, Goodbye Radiology as We Know It', 'name': 'Hello AI, Goodbye Radiology as We Know It', 'image': {'@type': 'ImageObject', 'url': 'https://radiologybusiness.com/sites/default/files/styles/facebook/public/2020-02/ai.jpg?h=4a7d1ed4&itok=o8Wd74lN', 'width': '1200', 'height': '630'}, 'datePublished': '2020-02-18T22:57:24+0000', 'dateModified': '2022-02-11T04:22:29+0000', 'publisher': {'@type': 'Organization', 'name': 'Radiology Business', 'url': 'https://radiologybusiness.com/'}}]",,,,,,,,,,,,,,,,,,,,
https://news.google.com/rss/articles/CBMiQWh0dHBzOi8vY2lpYmxvZy5pbi9hcnRpZmljaWFsLWludGVsbGlnZW5jZS1pbi1pbmRpYW4tYWdyaWN1bHR1cmUv0gEA?oc=5,Artificial Intelligence in Indian Agriculture - CII Blog,2020-02-20,CII Blog,https://ciiblog.in,N/A,N/A,"20 Feb 2020 The agriculture and allied sectors are considered the bedrock of India’s economy. With farming employing almost half of India’s workforce, Agri Gross Domestic Product (GDP) can be considered the engine of growth for the economy. The global need to produce 50% more food by 2050 cannot be…",N/A,https://schema.org,,,,,,,,,,,,,N/A,N/A,"


 
Economy, Technology 
Artificial Intelligence in Indian Agriculture



 









 



 20 Feb 2020The agriculture and allied sectors are considered the bedrock of India’s economy. With farming employing almost half of India’s workforce, Agri Gross Domestic Product (GDP) can be considered the engine of growth for the economy.The global need to produce 50% more food by 2050 cannot be accomplished if only 4% of the land is under cultivation.The vulnerabilities arising from climate change, coupled with the risk of increased dependency on unsustainable agriculture practices, can lead to agricultural distress.Artificial Intelligence (AI), along with other digital technologies, will play a key role in modernizing agricultural activities and realising the goal of doubling the farmer’s income by 2022. The global ‘AI in agriculture’ market size is expected to be worth USD 2.6 billion by 2025.India’s national AI strategy also identifies agriculture as one of the key areas where AI can enable development and greater inclusion. AI-enabled solutions in agriculture help farmers improve crop productivity and reduce wastage. The Confederation of Indian Industry (CII) is working towards developing the agriculture sector in line with the country’s aspiration. Upgrading the technology quotient in agriculture is a key focus area. A CII-Deloitte report on ‘Artificial Intelligence – Augmenting Human Intelligence’ also highlights the role of AI in agriculture.So how can AI help in agriculture?Improving crop productivity – Climate change has resulted in making traditional agricultural know-how outdated, especially for forecasting weather patterns that determine farming practices for the season. The usage of predictive analysis with the help of AI could be extremely helpful for farmers. It could help determine appropriate crops to grow in a favourable climate on a productive terrain and the sowing methodology to enhance productivity and reduce costs.In Andhra Pradesh, India, with the help of a sowing app powered by AI developed by International Crops Research Institute for the Semiarid Tropics and Microsoft, a 30% higher average in yield per hectare has been seen.Soil health monitoring – Along with favourable weather conditions, soil health comprising of an adequate level of moisture and nutrient holds the key to getting the best yield. Distributed soil monitoring performed via image recognition and deep learning models can be used to take corrective measures to restore soil health.Historical data about monsoons, local snapshots of the farm, crop-output information, history of soil health, and more serve as inputs for the creation of AI models. These models provide vital information about the farmland, assisting farmers in planning activities related to soil restoration, crop growth, farm watering, etc.Optimization of pest and weed management – AI can be used for predicting the behaviour of pests which can be beneficial for advanced planning of pest control. Efficient pest management leads to lower crop and environmental damage. A combination of remotely sensed data, efficient image classification tools, weather data, and other relevant data points can be used to distinguish the weed from the crop. This will confine the usage of weedicide only to the areas that require treatment.Remote satellites can monitor crop health and also warn against pest attacks. An AI-supported technology called ‘See & Spray’ developed by a US company is a weed controlling technology that can reduce expenditure on weedicides by 90%.Water Management – Efficient water management in agriculture can have a huge impact on the looming problem of water scarcity. Water usage in agricultural land can be optimized by using thermal imaging cameras that continuously monitor if crops are getting sufficient amount of water.AI, coupled with appropriate image classification models, when used in agriculture can result in improving yield production, reducing manual intervention, and decreasing instances of crop diseases.Price realization for farmers – Only about 6 percent of farmers in India get benefits of Minimum Selling Prices (MSP). A better price realization for farmers is possible through an effective price discovery model. Predictive modelling using AI can be instrumental in presenting more accurate demand-supply information and predicting demand for agricultural produce to farmers.With more than 500+ AgriTech start-ups in India, the agritech momentum is gaining pace in India. Many of these start-ups are leveraging technologies like AI, machine learning, etc. for improving efficiency, yield, speeding up agricultural finance, and other functions that are vital for India’s agricultural growth. 






XFacebookLinkedInCopyEmailShare



20/02/202012/04/2024Economy, Technology 




Dealing with The Plastic Problem: The Un-Plastic CollectivePrev PostHow govt can protect India Inc from catching the China virusNext Post


Prev Post Next Post 






Related Posts






 

Robotic Process Automation: Transforming the Telecom Industry
24/11/2021







 

Unleashing Of Gaming
24/07/2023







 

People-friendly Budget strikes the right note
11/02/2019







",,,,,,,,"[{'@type': 'WebPage', '@id': 'https://ciiblog.in/artificial-intelligence-in-indian-agriculture/', 'url': 'https://ciiblog.in/artificial-intelligence-in-indian-agriculture/', 'name': 'Artificial Intelligence in Indian Agriculture - CII Blog', 'isPartOf': {'@id': 'https://ciiblog.in/#website'}, 'primaryImageOfPage': {'@id': 'https://ciiblog.in/artificial-intelligence-in-indian-agriculture/#primaryimage'}, 'image': {'@id': 'https://ciiblog.in/artificial-intelligence-in-indian-agriculture/#primaryimage'}, 'thumbnailUrl': 'https://ciiblog.in/wp-content/uploads/2024/03/Artificial-Intelligence-in-Indian-Agriculture.gif', 'datePublished': '2020-02-20T06:47:00+00:00', 'dateModified': '2024-04-12T11:15:35+00:00', 'author': {'@id': 'https://ciiblog.in/#/schema/person/d48be8addd4623ca72670dadea3523f8'}, 'breadcrumb': {'@id': 'https://ciiblog.in/artificial-intelligence-in-indian-agriculture/#breadcrumb'}, 'inLanguage': 'en-US', 'potentialAction': [{'@type': 'ReadAction', 'target': ['https://ciiblog.in/artificial-intelligence-in-indian-agriculture/']}]}, {'@type': 'ImageObject', 'inLanguage': 'en-US', '@id': 'https://ciiblog.in/artificial-intelligence-in-indian-agriculture/#primaryimage', 'url': 'https://ciiblog.in/wp-content/uploads/2024/03/Artificial-Intelligence-in-Indian-Agriculture.gif', 'contentUrl': 'https://ciiblog.in/wp-content/uploads/2024/03/Artificial-Intelligence-in-Indian-Agriculture.gif', 'width': 1280, 'height': 350}, {'@type': 'BreadcrumbList', '@id': 'https://ciiblog.in/artificial-intelligence-in-indian-agriculture/#breadcrumb', 'itemListElement': [{'@type': 'ListItem', 'position': 1, 'name': 'Home', 'item': 'https://ciiblog.in/'}, {'@type': 'ListItem', 'position': 2, 'name': 'Artificial Intelligence in Indian Agriculture'}]}, {'@type': 'WebSite', '@id': 'https://ciiblog.in/#website', 'url': 'https://ciiblog.in/', 'name': 'CII Blog', 'description': 'Confederation of Indian Industry', 'potentialAction': [{'@type': 'SearchAction', 'target': {'@type': 'EntryPoint', 'urlTemplate': 'https://ciiblog.in/?s={search_term_string}'}, 'query-input': 'required name=search_term_string'}], 'inLanguage': 'en-US'}, {'@type': 'Person', '@id': 'https://ciiblog.in/#/schema/person/d48be8addd4623ca72670dadea3523f8', 'name': 'CII Team .', 'image': {'@type': 'ImageObject', 'inLanguage': 'en-US', '@id': 'https://ciiblog.in/#/schema/person/image/', 'url': 'https://secure.gravatar.com/avatar/a9d61712d3ad24361e7996fcc48257c4?s=96&d=mm&r=g', 'contentUrl': 'https://secure.gravatar.com/avatar/a9d61712d3ad24361e7996fcc48257c4?s=96&d=mm&r=g', 'caption': 'CII Team .'}, 'sameAs': ['https://www.ciiblog.in'], 'url': 'https://ciiblog.in/author/admin/'}]",,,,,,,,,,,,,,,,,,,,

URL link,Title,Date,Source,Source Link,description,keywords,og:description,twitter:description,article:section,article:summary,article text,@context,@type,headline,datePublished,dateModified,isAccessibleForFree,isPartOf,alternativeHeadline,image,author,articleBody,wordCount,publisher,itemListElement,name,alternateName,url,thumbnailUrl,mainEntityOfPage,@graph,editor,articleSection,hasPart,startDate,endDate,duration,associatedMedia,video,@id,foundingDate,sameAs,logo,parentOrganization,actionableFeedbackPolicy,correctionsPolicy,ethicsPolicy,Masthead,missionCoveragePrioritiesPolicy,ownershipFundingInfo,unnamedSourcesPolicy,publishingPrinciples,uploadDate,embedUrl,creator,provider,location,email,potentialAction,genre,about,copyrightYear,discussionURL,inLanguage,isFamilyFriendly,person,timeRequired
https://news.google.com/rss/articles/CBMiU2h0dHBzOi8vY2Vwci5vcmcvdm94ZXUvY29sdW1ucy9pbXBhY3QtYXJ0aWZpY2lhbC1pbnRlbGxpZ2VuY2UtZ3Jvd3RoLWFuZC1lbXBsb3ltZW500gEA?oc=5,The impact of artificial intelligence on growth and employment - CEPR,2023-06-20,CEPR,https://cepr.org,"The use of artificial intelligence for day-to-day tasks has increased rapidly over the last decade. The May 2023 CfM-CEPR survey asked the members of its European panel to predict the impact of AI on global economic growth and unemployment rates in high-income countries over the upcoming decade. Most panellists think that AI is likely to boost global growth to 4–6% per annum (relative to an average of 4% over the past few decades). Most of the panel also believes that AI is unlikely to affect employment rates in high-income countries, with the remainder split between predicting an increase and a decrease in unemployment rates. Notably, most panellists indicate a great degree of uncertainty regarding their predictions, because AI is still in its infancy.",N/A,"The use of artificial intelligence for day-to-day tasks has increased rapidly over the last decade. The May 2023 CfM-CEPR survey asked the members of its European panel to predict the impact of AI on global economic growth and unemployment rates in high-income countries over the upcoming decade. Most panellists think that AI is likely to boost global growth to 4–6% per annum (relative to an average of 4% over the past few decades). Most of the panel also believes that AI is unlikely to affect employment rates in high-income countries, with the remainder split between predicting an increase and a decrease in unemployment rates. Notably, most panellists indicate a great degree of uncertainty regarding their predictions, because AI is still in its infancy.","The use of artificial intelligence for day-to-day tasks has increased rapidly over the last decade. The May 2023 CfM-CEPR survey asked the members of its European panel to predict the impact of AI on global economic growth and unemployment rates in high-income countries over the upcoming decade. Most panellists think that AI is likely to boost global growth to 4–6% per annum (relative to an average of 4% over the past few decades). Most of the panel also believes that AI is unlikely to affect employment rates in high-income countries, with the remainder split between predicting an increase and a decrease in unemployment rates. Notably, most panellists indicate a great degree of uncertainty regarding their predictions, because AI is still in its infancy.",N/A,N/A,"




















VoxEU Column

        Labour Markets
          

        Productivity and Innovation
          

The impact of artificial intelligence on growth and employment



Ethan Ilzetzki


Suryaansh Jain


/ 


20 Jun 2023

  The use of artificial intelligence for day-to-day tasks has increased rapidly over the last decade. The May 2023 CfM-CEPR survey asked the members of its European panel to predict the impact of AI on global economic growth and unemployment rates in high-income countries over the upcoming decade. Most panellists think that AI is likely to boost global growth to 4–6% per annum (relative to an average of 4% over the past few decades). Most of the panel also believes that AI is unlikely to affect employment rates in high-income countries, with the remainder split between predicting an increase and a decrease in unemployment rates. Notably, most panellists indicate a great degree of uncertainty regarding their predictions, because AI is still in its infancy.






Share






Twitter







Facebook







LinkedIn





Authors




















 Ethan Ilzetzki


Associate Professor of Economics (with Tenure)
London School Of Economics And Political Science 






















 Suryaansh Jain


BSc Economics student
London School Of Economics And Political Science 





",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
https://news.google.com/rss/articles/CBMiP2h0dHBzOi8vd3d3LmZ0LmNvbS9jb250ZW50L2IzNGVmOTU4LWRmMjgtNDFhMS1iMzBmLWRmYWY0NmZmMmE4MNIBAA?oc=5,AI shakes up way we work in three key industries - Financial Times,2023-06-17,Financial Times,https://www.ft.com,"Professional services, filmmaking and coding are among the first to use the technology in everyday operations   ",N/A,"Professional services, filmmaking and coding are among the first to use the technology in everyday operations   ",N/A,N/A,N/A,"AI shakes up way we work in three key industries on x (opens in a new window)AI shakes up way we work in three key industries on facebook (opens in a new window)AI shakes up way we work in three key industries on linkedin (opens in a new window)AI shakes up way we work in three key industries on whatsapp (opens in a new window)



Save

current progress 0%AI shakes up way we work in three key industries on x (opens in a new window)AI shakes up way we work in three key industries on facebook (opens in a new window)AI shakes up way we work in three key industries on linkedin (opens in a new window)AI shakes up way we work in three key industries on whatsapp (opens in a new window)



Save

Sarah O’Connor, Christopher Grimes and Cristina CriddleJune 18 202360Print this pageUnlock the Editor’s Digest for freeRoula Khalaf, Editor of the FT, selects her favourite stories in this weekly newsletter.A revolution that will free workers from gruelling tasks or the destroyer of millions of jobs? New artificial intelligence capabilities have simultaneously prompted huge excitement around workplace productivity and dire warnings for employees. The Financial Times has selected three industries that are among the first to adopt the technology to analyse how it is being used in everyday work.Professional servicesAI tools enhanced so they are easy to access and can assist practical legal case work Biggest time savings on tasks assigned to junior staffAdoption has been swift but has limitations — it is not always correctRather than replacing jobs, AI could intensify work It has been a strange year for lawyers such as Alex Shandro and Karishma Brahmbhatt. All around them, economists, technologists and journalists have been making predictions about what new advances in AI might mean for professional workers. Headlines warning that “AI is coming for lawyers” have been everywhere. But Shandro and Brahmbhatt have a different vantage point — not from the top down but from the shop floor. As lawyers at Allen & Overy in London, they are already using the new generative AI tools in their everyday work. Roughly 3,500 employees at A&O have access to Harvey, an AI platform built on a version of OpenAI’s latest models, which have been enhanced for legal work. Shandro, a commercial intellectual property lawyer, says he used Harvey recently to prepare for a transaction that involved property rights in the metaverse. “So, what are the advertising regulations in the UK that might apply in augmented reality? I asked Harvey and got a really nice list. Before, I would have asked my trainee or a junior lawyer to go and find that out, and it would have taken that much longer.” Brahmbatt, too, says she and her juniors use the technology regularly — albeit with mixed results. “I actually asked it a question last night and it completely made up the cases,” she laughs. “If you approach it from the basis of, ‘I’m going to have to read through and check it all anyway’ then it’s useful. I don’t think it’s quite something you can just take and run with.”Alex Shandro and Karishma Brahmbhatt, lawyers at Allen & Overy, are already using the new generative AI tools in their work  David Wakeling, head of A&O’s markets innovation group, says the workforce has adopted Harvey fairly quickly since the law firm began trials in November, although it is not yet being used by everyone every day. “I checked last night — roughly 800 people used it in the last 24 hours, and they asked three to four questions each on average, in different languages and different practice groups,” he says. For Wakeling, one of the most important things is not to allow staff to believe the tool is more capable than it really is. “We say Harvey is like a very confident, very articulate 13-year-old. It doesn’t know what it doesn’t know. It has some fabulous knowledge, but incomplete knowledge. You wouldn’t trust a 13-year-old to do your tax return.” Rather than a black box with “magic” written on the lid, the law firm considers the technology “a boring productivity gain. We know it has issues, we know it makes errors, we know it will be out of date. But that’s OK, because we’re trying to save an hour or two a week across 3,500 people who have access today.”Across London, the young workforce at PwC (the average age is about 31) has also started to use new AI tools, including Harvey, in their work. One system allows them to drop in documents — a pile of legal contracts or a company’s articles of association, for example — and ask questions about them. The fluently written answers come with source notes that link back to the precise parts of the documents from which the AI drew its conclusions.Euan Cameron, PwC’s UK AI leader, says the biggest difference with these new tools is that they democratise access. “Previously . . . it was like being in a world of horses and having a car with a one litre engine, but controls like a Boeing 747. So you needed to get really smart, specialist people to make it go. Now, you have tools that can be integrated into the sidebar of Office 365 or the Google Suite.”He likens the latest AI technology to a Swiss army knife with 500 tools. “If you want to work out all the places you can use that in your organisation, you can either create a small team and put them in an ivory tower and they can come up with ideas, or you can give everyone a Swiss army knife and they’ll find their own use cases, as long as you’ve got guardrails around it.” Those guardrails include “first draft only; humans in the loop; use it for cases with a low cost of failure”.It is still early days, but so far the biggest time-savings for professional firms appear to be on tasks that would usually be assigned to more junior staff. Does that mean law and consultancy firms will not need those roles any more, and if so, who will train the senior professionals of the future, and how? Bivek Sharma, PwC’s chief technology officer for the tax, legal and people business, insists the firm will still want — and need — to train people to be “subject matter experts”, but the way they do that and how quickly will soon change. “The expectations for them are going to grow,” he predicts.For the law sector, there is also the question of whether it makes sense to economise on human labour, given many firms charge for lawyers’ time by the hour. But by that logic, argues Wakeling, “we could have kept going with fax machines” and typewriters. “It’s coming anyway so we’re thinking embrace it and do it safely.” As for the fears that AI will replace a swath of professions such as lawyers and accountants completely, the people who have started to use the tools seem sanguine for now. Shandro talks about the “context heavy” art of negotiating a contract that relies as much on “instinct” and “experience” as knowledge of the law. At KPMG, global head of people Nhlamu Dlomu is more worried that work could intensify. “What is it that can help us not fall into that trap? What are the real guardrails we need to put around work so we can actually ensure we get the benefit [from AI], not just for organisations but for individuals as well?”PwC’s Sharma has the same prediction. “What’s going to happen in a year’s time is that our clients . . . are going to expect us to deliver higher value insights in much much shorter timeframes. If we were to meet again in a year’s time, I think you could find an even older looking version of me.”FilmmakingScreenwriters striking over fears AI could reduce available workDubbing technology could expand reach of foreign-language filmsPotential upsides for actors include hiring out “digital doubles”Hollywood directors’ tentative deal with movie studios this month included a clause that would have flummoxed golden age filmmakers such as Billy Wilder or Frank Capra. Artificial intelligence, the two sides declared, “cannot replace the duties” performed by directors.The statement was a landmark in the annals of Hollywood labour agreements, even if few were worried about directors being replaced by AI anytime soon. “I don’t think anyone can say we’re really at a point where a robot can direct,” notes a veteran Hollywood dealmaker.The concerns are more pressing for others in Hollywood, from screenwriters — who have been on strike since May 1 — to actors and voice artists. Screenwriters fear there will be less well-paid work for them in a world where book adaptations or first drafts can be written by AI. Actors worry they will lose control of their images, while voice dubbers are concerned new AI technologies that match mouth movements to different languages will eliminate their jobs.The TV and film writers’ strike outside Paramount Studios in LA in May. Screenwriters fear there will be less well-paid work for them when book adaptations or first drafts can be written by AI © Frederic J Brown/AFP/Getty ImagesSome hot AI start-ups have already introduced dubbing technology that they say saves time and money on set — without killing jobs. Flawless, for example, has produced a tool that enables filmmakers to use generative AI to insert new dialogue into already captured scenes, eliminating the need for rebuilding sets and flying actors in for a reshoot. The actor will record the new dialogue in a studio and the AI technology will adapt the actor’s “mouth shape” from the original shot in a way that makes the words look natural.Join AI editor, Madhumita Murgia, and colleagues as they answer your questions on the opportunities and risks of AI in this webinar exclusively for FT subscribers. Register to attend on 22 June at 15:30 GMT+ 1Flawless has developed a tool that solves the problem of dubbed films in which mouth movements do not match the voiceover. Last month Flawless launched a partnership with XYZ Films and Tea Shop Productions to buy rights to foreign-language films, convert them to English using AI and distribute them in English-speaking markets. UK-based AI start-up Papercup is also using AI to automate the translation and dubbing process. Such deals have the potential to greatly expand the reach of foreign language films, but some actors may worry it could cost them work. “The concern there is . . . are you taking jobs from voiceover actors who dub foreign language films?” said the Hollywood dealmaker.People close to the company say such fears are unfounded, since they use professional voice artists and actors for the dubbing and the AI technology matches the mouth movements to the new language.Hilary Krane, chief legal officer at Creative Artists Agency, said she believes AI creates more opportunity than risk for Hollywood. The trick, she says, will be to “favour the creative thinkers and humans who actually put out the work without constraining the use of the new tool”.Hollywood labour unions had initially been focused on the effects of a different technological disruption: streaming.But the Hollywood veteran noted that AI was “the issue that caught fire in the zeitgeist”. “If a producer can use AI to shoot out a 100-page script, then they can go to the writer and say, ‘I’ll pay you $50,000 to rewrite this instead of the $200,000 for you to write it on the page’.”Under the Writers Guild of America’s proposals, such a scenario would be forbidden. The union wants to prevent AI programmes from being used to write scripts or to rewrite work created by a human. The only acceptable use for AI at this point, the WGA says, is for research purposes.The technology does have some potential benefits for screenwriters: AI could make them more efficient, allowing them to write more screenplays in a year. Such opportunities may be offset by cost-conscious studios that use the technology to hire fewer writers, however.The upsides to AI technology may be more apparent for actors, who could hire out their “digital doubles” to, for example, act in an advertisement while they were shooting a feature film.The key to making this work is for the industry to enforce basic ethical concepts, including that “people own their name, image and likeness and that they should be in control of when and how it is used,” says Krane.CodingGenerative AI can suggest lines of code that programmers can run and testTechnology can analyse existing code and search for vulnerabilities AI can boost productivity but struggles with complex softwareCoders have benefited from developments in generative AI to drive efficiencies and save time, using tools such as ChatGPT to help write software.If given specific instructions, generative AI chatbots can suggest lines of code that programmers can run and test. But data experts warn there are still clear limitations.“It is very helpful and does speed things up a lot, but you should know what an answer should look like for it to work,” says Edward Rushton, data scientist and co-founder of the Efficient Data Group consultancy.He says there is a lot of trial and error, so understanding how to fix what the AI has generated is crucial. “It does just get stuff wrong, and it does just make stuff up. It will invent a function that doesn’t exist, it all looks perfectly plausible, but it is not correct and won’t work,” he warns.Archana Vaidheeswaran, a data product manager at the non-profit Women Who Code, used ChatGPT to build a Google Chrome extension tool that helps non-native English speakers translate text and adjust the tone to a more natural conversational style. OpenAI’s chatbot generated the code for the front end of the product, the part that users can see and interact with, while Vaidheeswaran wrote the background technology.“ChatGPT can write something very specific, then you have to work with it,” she says.Matt Shumer, chief executive and co-founder of Otherside AI, a start-up with a product for writing emails, says his staff use AI to assist with programming and that a large portion of the company’s code has been written this way. “It’s not technically a requirement, but I doubt anyone who wasn’t using it would be able to keep up with the rest of the team,” he says.RecommendedFT SeriesAI in the workplaceHowever, he highlights the need for experienced engineers to judge and validate the AI’s results and “coax” out the correct answers. “AI has profoundly transformed the role of coders. Instead of focusing solely on manual coding, they now spend more time defining the problem, designing the structure and directing AI to do the heavy lifting,” he says, adding that it frees up staff from “mundane tasks”.The British Computing Society says that as well as using generative AI tools to write code, it can be used to analyse existing code and search for errors or vulnerabilities hackers might exploit. It echoes the need for developers to review responses critically and consider how data input into generative AI systems may be used.“The professionals have to understand the level of competence needed [when using AI] because they’re taking on a huge responsibility,” says Rashik Parmar, chief executive of the British Computing Society. “They need to understand the ethics of what they’re doing and have accountability if this thing screws up.”As the needs of the code become more complex, the limitations of generative AI increase. A top executive at one large Silicon Valley-based company says they are looking closely at the potential for AI to boost its developers’ productivity, but it is “not efficient yet”. While it works well for simple coding, this executive says, it struggles with the complicated software architecture inside a large company. Still, coding is one of the top areas in which companies are looking to implement generative AI.“For many developers, generative AI will become the most valuable coding partner they will ever know,” according to KPMG.This article has been changed to clarify that Papercup uses AI to automate the translation and dubbing process. Copyright The Financial Times Limited 2024. All rights reserved.Reuse this content (opens in new window) CommentsJump to comments section














Promoted ContentExplore the seriesREAD MOREArtificial intelligenceGenerative AI will upend the professionsCurrently reading:AI shakes up way we work in three key industriesAI in recruitment: the death knell of the CV?Generative AI will upend the professionsBored at work? How AI could come to the rescueWill generative AI boost productivity?

					Follow the topics in this article
			



						Future of work
					



Add to myFT




						Technology sector
					



Add to myFT




						Work & Careers
					



Add to myFT




						Artificial intelligence
					



Add to myFT




						Christopher Grimes
					



Add to myFT



Comments",http://schema.org,WebSite,AI shakes up way we work in three key industries,2023-06-18T04:00:59.029Z,2023-06-18T04:00:59.029Z,False,"{'@type': ['CreativeWork', 'Product'], 'name': 'Financial Times', 'productID': 'ft.com:subscribed'}",AI shakes up way we work in three key industries,"{'@type': 'ImageObject', '@context': 'http://schema.org', 'url': 'https://www.ft.com/__origami/service/image/v2/images/raw/https%3A%2F%2Fd1e00ek4ebabms.cloudfront.net%2Fproduction%2Fbbc9c9a7-4873-4f3c-b93f-b0378dcc22e1.jpg?source=next-article&fit=scale-down&quality=highest&width=700&dpr=1', 'width': 2048, 'height': 1152}","[{'@type': 'Person', '@context': 'http://schema.org', 'name': 'Christopher Grimes', 'url': 'https://www.ft.com/christopher-grimes', 'worksFor': {'@type': 'Organization', '@context': 'http://schema.org', 'name': 'Financial Times', 'legalName': 'The Financial Times Ltd.', 'logo': {'@type': 'ImageObject', '@context': 'http://schema.org', 'url': 'https://im.ft-static.com/m/img/masthead_main.jpg', 'width': 435, 'height': 36}, 'url': 'https://www.ft.com', 'sameAs': ['https://www.twitter.com/FT', 'https://www.facebook.com/financialtimes', 'https://www.linkedin.com/company/financial-times', 'https://www.youtube.com/user/FinancialTimesVideos', 'https://www.instagram.com/financialtimes']}}, {'@type': 'Person', '@context': 'http://schema.org', 'name': 'Cristina Criddle', 'url': 'https://www.ft.com/cristina-criddle', 'worksFor': {'@type': 'Organization', '@context': 'http://schema.org', 'name': 'Financial Times', 'legalName': 'The Financial Times Ltd.', 'logo': {'@type': 'ImageObject', '@context': 'http://schema.org', 'url': 'https://im.ft-static.com/m/img/masthead_main.jpg', 'width': 435, 'height': 36}, 'url': 'https://www.ft.com', 'sameAs': ['https://www.twitter.com/FT', 'https://www.facebook.com/financialtimes', 'https://www.linkedin.com/company/financial-times', 'https://www.youtube.com/user/FinancialTimesVideos', 'https://www.instagram.com/financialtimes']}}, {'@type': 'Person', '@context': 'http://schema.org', 'name': ""Sarah O'Connor"", 'url': 'https://www.ft.com/sarah-o-connor', 'worksFor': {'@type': 'Organization', '@context': 'http://schema.org', 'name': 'Financial Times', 'legalName': 'The Financial Times Ltd.', 'logo': {'@type': 'ImageObject', '@context': 'http://schema.org', 'url': 'https://im.ft-static.com/m/img/masthead_main.jpg', 'width': 435, 'height': 36}, 'url': 'https://www.ft.com', 'sameAs': ['https://www.twitter.com/FT', 'https://www.facebook.com/financialtimes', 'https://www.linkedin.com/company/financial-times', 'https://www.youtube.com/user/FinancialTimesVideos', 'https://www.instagram.com/financialtimes']}}]","A revolution that will free workers from gruelling tasks or the destroyer of millions of jobs? New artificial intelligence capabilities have simultaneously prompted huge excitement around workplace productivity and dire warnings for employees. The Financial Times has selected three industries that are among the first to adopt the technology to analyse how it is being used in everyday work.

It has been a strange year for lawyers such as Alex Shandro and Karishma Brahmbhatt. All around them, economists, technologists and journalists have been making predictions about what new advances in AI might mean for professional workers. Headlines warning that “AI is coming for lawyers” have been everywhere.

But Shandro and Brahmbhatt have a different vantage point — not from the top down but from the shop floor. As lawyers at Allen & Overy in London, they are already using the new generative AI tools in their everyday work. Roughly 3,500 employees at A&O have access to Harvey, an AI platform built on a version of OpenAI’s latest models, which have been enhanced for legal work.

Shandro, a commercial intellectual property lawyer, says he used Harvey recently to prepare for a transaction that involved property rights in the metaverse. “So, what are the advertising regulations in the UK that might apply in augmented reality? I asked Harvey and got a really nice list. Before, I would have asked my trainee or a junior lawyer to go and find that out, and it would have taken that much longer.”

Brahmbatt, too, says she and her juniors use the technology regularly — albeit with mixed results. “I actually asked it a question last night and it completely made up the cases,” she laughs. “If you approach it from the basis of, ‘I’m going to have to read through and check it all anyway’ then it’s useful. I don’t think it’s quite something you can just take and run with.”

David Wakeling, head of A&O’s markets innovation group, says the workforce has adopted Harvey fairly quickly since the law firm began trials in November, although it is not yet being used by everyone every day. “I checked last night — roughly 800 people used it in the last 24 hours, and they asked three to four questions each on average, in different languages and different practice groups,” he says.

For Wakeling, one of the most important things is not to allow staff to believe the tool is more capable than it really is. “We say Harvey is like a very confident, very articulate 13-year-old. It doesn’t know what it doesn’t know. It has some fabulous knowledge, but incomplete knowledge. You wouldn’t trust a 13-year-old to do your tax return.”

Rather than a black box with “magic” written on the lid, the law firm considers the technology “a boring productivity gain. We know it has issues, we know it makes errors, we know it will be out of date. But that’s OK, because we’re trying to save an hour or two a week across 3,500 people who have access today.”

Across London, the young workforce at PwC (the average age is about 31) has also started to use new AI tools, including Harvey, in their work. One system allows them to drop in documents — a pile of legal contracts or a company’s articles of association, for example — and ask questions about them. The fluently written answers come with source notes that link back to the precise parts of the documents from which the AI drew its conclusions.

Euan Cameron, PwC’s UK AI leader, says the biggest difference with these new tools is that they democratise access. “Previously . . . it was like being in a world of horses and having a car with a one litre engine, but controls like a Boeing 747. So you needed to get really smart, specialist people to make it go. Now, you have tools that can be integrated into the sidebar of Office 365 or the Google Suite.”

He likens the latest AI technology to a Swiss army knife with 500 tools. “If you want to work out all the places you can use that in your organisation, you can either create a small team and put them in an ivory tower and they can come up with ideas, or you can give everyone a Swiss army knife and they’ll find their own use cases, as long as you’ve got guardrails around it.” Those guardrails include “first draft only; humans in the loop; use it for cases with a low cost of failure”.

It is still early days, but so far the biggest time-savings for professional firms appear to be on tasks that would usually be assigned to more junior staff. Does that mean law and consultancy firms will not need those roles any more, and if so, who will train the senior professionals of the future, and how?

Bivek Sharma, PwC’s chief technology officer for the tax, legal and people business, insists the firm will still want — and need — to train people to be “subject matter experts”, but the way they do that and how quickly will soon change. “The expectations for them are going to grow,” he predicts.

For the law sector, there is also the question of whether it makes sense to economise on human labour, given many firms charge for lawyers’ time by the hour. But by that logic, argues Wakeling, “we could have kept going with fax machines” and typewriters. “It’s coming anyway so we’re thinking embrace it and do it safely.”

As for the fears that AI will replace a swath of professions such as lawyers and accountants completely, the people who have started to use the tools seem sanguine for now. Shandro talks about the “context heavy” art of negotiating a contract that relies as much on “instinct” and “experience” as knowledge of the law.

At KPMG, global head of people Nhlamu Dlomu is more worried that work could intensify. “What is it that can help us not fall into that trap? What are the real guardrails we need to put around work so we can actually ensure we get the benefit [from AI], not just for organisations but for individuals as well?”

PwC’s Sharma has the same prediction. “What’s going to happen in a year’s time is that our clients . . . are going to expect us to deliver higher value insights in much much shorter timeframes. If we were to meet again in a year’s time, I think you could find an even older looking version of me.”

Hollywood directors’ tentative deal with movie studios this month included a clause that would have flummoxed golden age filmmakers such as Billy Wilder or Frank Capra. Artificial intelligence, the two sides declared, “cannot replace the duties” performed by directors.

The statement was a landmark in the annals of Hollywood labour agreements, even if few were worried about directors being replaced by AI anytime soon. “I don’t think anyone can say we’re really at a point where a robot can direct,” notes a veteran Hollywood dealmaker.

The concerns are more pressing for others in Hollywood, from screenwriters — who have been on strike since May 1 — to actors and voice artists. Screenwriters fear there will be less well-paid work for them in a world where book adaptations or first drafts can be written by AI. Actors worry they will lose control of their images, while voice dubbers are concerned new AI technologies that match mouth movements to different languages will eliminate their jobs.

Some hot AI start-ups have already introduced dubbing technology that they say saves time and money on set — without killing jobs. Flawless, for example, has produced a tool that enables filmmakers to use generative AI to insert new dialogue into already captured scenes, eliminating the need for rebuilding sets and flying actors in for a reshoot. The actor will record the new dialogue in a studio and the AI technology will adapt the actor’s “mouth shape” from the original shot in a way that makes the words look natural.

Flawless has developed a tool that solves the problem of dubbed films in which mouth movements do not match the voiceover. Last month Flawless launched a partnership with XYZ Films and Tea Shop Productions to buy rights to foreign-language films, convert them to English using AI and distribute them in English-speaking markets. UK-based AI start-up Papercup is also using AI to automate the translation and dubbing process.

Such deals have the potential to greatly expand the reach of foreign language films, but some actors may worry it could cost them work. “The concern there is . . . are you taking jobs from voiceover actors who dub foreign language films?” said the Hollywood dealmaker.

People close to the company say such fears are unfounded, since they use professional voice artists and actors for the dubbing and the AI technology matches the mouth movements to the new language.

Hilary Krane, chief legal officer at Creative Artists Agency, said she believes AI creates more opportunity than risk for Hollywood. The trick, she says, will be to “favour the creative thinkers and humans who actually put out the work without constraining the use of the new tool”.

Hollywood labour unions had initially been focused on the effects of a different technological disruption: streaming.

But the Hollywood veteran noted that AI was “the issue that caught fire in the zeitgeist”. “If a producer can use AI to shoot out a 100-page script, then they can go to the writer and say, ‘I’ll pay you $50,000 to rewrite this instead of the $200,000 for you to write it on the page’.”

Under the Writers Guild of America’s proposals, such a scenario would be forbidden. The union wants to prevent AI programmes from being used to write scripts or to rewrite work created by a human. The only acceptable use for AI at this point, the WGA says, is for research purposes.

The technology does have some potential benefits for screenwriters: AI could make them more efficient, allowing them to write more screenplays in a year. Such opportunities may be offset by cost-conscious studios that use the technology to hire fewer writers, however.

The upsides to AI technology may be more apparent for actors, who could hire out their “digital doubles” to, for example, act in an advertisement while they were shooting a feature film.

The key to making this work is for the industry to enforce basic ethical concepts, including that “people own their name, image and likeness and that they should be in control of when and how it is used,” says Krane.

Coders have benefited from developments in generative AI to drive efficiencies and save time, using tools such as ChatGPT to help write software.

If given specific instructions, generative AI chatbots can suggest lines of code that programmers can run and test. But data experts warn there are still clear limitations.

“It is very helpful and does speed things up a lot, but you should know what an answer should look like for it to work,” says Edward Rushton, data scientist and co-founder of the Efficient Data Group consultancy.

He says there is a lot of trial and error, so understanding how to fix what the AI has generated is crucial. “It does just get stuff wrong, and it does just make stuff up. It will invent a function that doesn’t exist, it all looks perfectly plausible, but it is not correct and won’t work,” he warns.

Archana Vaidheeswaran, a data product manager at the non-profit Women Who Code, used ChatGPT to build a Google Chrome extension tool that helps non-native English speakers translate text and adjust the tone to a more natural conversational style. OpenAI’s chatbot generated the code for the front end of the product, the part that users can see and interact with, while Vaidheeswaran wrote the background technology.

“ChatGPT can write something very specific, then you have to work with it,” she says.

Matt Shumer, chief executive and co-founder of Otherside AI, a start-up with a product for writing emails, says his staff use AI to assist with programming and that a large portion of the company’s code has been written this way. “It’s not technically a requirement, but I doubt anyone who wasn’t using it would be able to keep up with the rest of the team,” he says.

However, he highlights the need for experienced engineers to judge and validate the AI’s results and “coax” out the correct answers. “AI has profoundly transformed the role of coders. Instead of focusing solely on manual coding, they now spend more time defining the problem, designing the structure and directing AI to do the heavy lifting,” he says, adding that it frees up staff from “mundane tasks”.

The British Computing Society says that as well as using generative AI tools to write code, it can be used to analyse existing code and search for errors or vulnerabilities hackers might exploit. It echoes the need for developers to review responses critically and consider how data input into generative AI systems may be used.

“The professionals have to understand the level of competence needed [when using AI] because they’re taking on a huge responsibility,” says Rashik Parmar, chief executive of the British Computing Society. “They need to understand the ethics of what they’re doing and have accountability if this thing screws up.”

As the needs of the code become more complex, the limitations of generative AI increase. A top executive at one large Silicon Valley-based company says they are looking closely at the potential for AI to boost its developers’ productivity, but it is “not efficient yet”. While it works well for simple coding, this executive says, it struggles with the complicated software architecture inside a large company.

Still, coding is one of the top areas in which companies are looking to implement generative AI.

“For many developers, generative AI will become the most valuable coding partner they will ever know,” according to KPMG.

This article has been changed to clarify that Papercup uses AI to automate the translation and dubbing process.",2399,"{'@type': 'Organization', '@context': 'http://schema.org', 'name': 'Financial Times', 'legalName': 'The Financial Times Ltd.', 'logo': {'@type': 'ImageObject', '@context': 'http://schema.org', 'url': 'https://im.ft-static.com/m/img/masthead_main.jpg', 'width': 435, 'height': 36}, 'url': 'https://www.ft.com', 'sameAs': ['https://www.twitter.com/FT', 'https://www.facebook.com/financialtimes', 'https://www.linkedin.com/company/financial-times', 'https://www.youtube.com/user/FinancialTimesVideos', 'https://www.instagram.com/financialtimes']}","[{'@type': 'ListItem', 'position': 1, 'name': 'Companies', 'item': 'https://www.ft.com/companies'}, {'@type': 'ListItem', 'position': 2, 'name': 'Technology', 'item': 'https://www.ft.com/technology'}, {'@type': 'ListItem', 'position': 3, 'name': 'Artificial intelligence', 'item': 'https://www.ft.com/artificial-intelligence'}]",Financial Times,FT.com,http://www.ft.com,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
https://news.google.com/rss/articles/CBMiLGh0dHBzOi8vd3d3LmJiYy5jby51ay9uZXdzL2J1c2luZXNzLTY1OTA2NTIx0gEwaHR0cHM6Ly93d3cuYmJjLmNvLnVrL25ld3MvYnVzaW5lc3MtNjU5MDY1MjEuYW1w?oc=5,The workers already replaced by artificial intelligence - BBC,2023-06-16,BBC,https://www.bbc.co.uk,Some workers are already finding that they have been replaced by artificial intelligence systems.,N/A,Some workers are already finding that they have been replaced by artificial intelligence systems.,Some workers are already finding that they have been replaced by artificial intelligence systems.,N/A,N/A,"The workers already replaced by artificial intelligence15 June 2023ShareIan RoseBusiness reporter, BBC NewsShareDean MeadowcroftDean Meadowcroft never thought that AI would replace himUntil recently Dean Meadowcroft was a copywriter in a small marketing department.His duties included writing press releases, social media posts and other content for his company.But then, late last year, his firm introduced an Artificial Intelligence (AI) system.""At the time the idea was that it would be working alongside human lead copywriters to help speed up the process, essentially streamline things a little bit more,"" he says.Mr Meadowcroft was not particularly impressed with the AI's work.""It just kind of made everybody sound middle of the road, on the fence, and exactly the same, and therefore nobody really stands out.""The content also had to be checked by human staff to make sure it had not been lifted from anywhere else.But the AI was fast. What might take a human copywriter between 60 and 90 minutes to write, the AI could do in 10 minutes or less.Around four months after the AI was introduced, Mr Meadowcroft's four-strong team was laid off.Mr Meadowcroft can't be certain, but he's pretty sure the AI replaced them.""I did laugh-off the idea of AI replacing writers, or affecting my job, until it did,"" he said.The latest wave of AI hit late last year when OpenAI launched ChatGPT.Backed by Microsoft, ChatGPT can give human-like responses to questions and can, in minutes, generate essays, speeches, even recipes.Other tech giants are scrambling to launch their own systems - Google launched Bard in March.While not perfect, such systems are trained on the ocean of data available on the internet - an amount of information impossible for even a team of humans to digest.So that's left many wondering which jobs might be at risk.More technology of business:Can Amsterdam make the circular economy work?The 'exploding' demand for giant heat pumpsThe chip maker that became an AI superpowerWhy car parks are the hottest space in solar powerProtein's power is being uncovered and unleashedEarlier this year, a report from Goldman Sachs said that AI could potentially replace the equivalent of 300 million full-time jobs.Any job losses would not fall equally across the economy. According to the report, 46% of tasks in administrative and 44% in legal professions could be automated, but only 6% in construction and 4% in maintenance.The report also points out that the introduction of AI could boost productivity and growth and might create new jobs.There is some evidence of that already. Getty ImagesIKEA has retrained thousands of call centre workers as design advisersThis month IKEA said that, since 2021, it has retrained 8,500 staff who worked in its call centres as design advisers.The furniture giant says that 47% of customer calls are now handled by an AI called Billie. While IKEA does not see any job losses resulting from its use of AI, such developments are making many people worried.A recent survey by Boston Consulting Group (BCG), which polled 12,000 workers from around the world, found that a third were worried that they would be replaced at work by AI, with frontline staff more concerned than managers. Jessica Apotheker from BCG says that's partly due to fear of the unknown. ""When you look at leaders and managers, we have more than 80% of them that use AI at least on a weekly basis. When you look at frontline staff, that number drops to 20% so with the lack of familiarity with the tech comes much more anxiety and concern on the outcomes for them.""But perhaps there is good reason to be anxious.Alejandro GraueAlejandro Graue lost voiceover work to an AI systemFor three months last year, Alejandro Graue had been doing voiceover work for a popular YouTube channel.It seemed to be a promising line of work, a whole YouTube channel in English had to be re-voiced in Spanish. Mr Graue went on holiday late last year confident that there would be work when he returned.""I was expecting to have that money to live with - I have two daughters, so I need the money,"" he says.But to his surprise, before he returned to work, the YouTube channel uploaded a new video in Spanish - one he had not worked on.""When I clicked on it, what I heard was not my voice, but an AI generated voice - a very badly synced voiceover. It was terrible. And I was like, What is this? Is this like going to be my new partner in crime like the channel? Or is this going to replace me?"" he says.A phone call to the studio he worked for confirmed the worst. The client wanted to experiment with AI because it was cheaper and faster.That experiment turned out to be a failure. Viewers complained about the quality of the voiceover and eventually the channel took down the videos that featured the AI-generated voice.But Mr Graue did not find that very comforting. He thinks the technology will only improve and wonders where that will leave voiceover artists like him.""If this starts to happen in every job that I have, what should I do? Should I buy a farm? I don't know.  What other job could I look for that is not going to be replaced as well in the future? It's very complicated,"" he says.If AI is not coming for your job then it is likely you might have to start working with one in some way.After a few months of freelance work, former copywriter Dean Meadowcroft took a new direction.He now works for an employee assistance provider, which gives wellbeing and mental health advice to staff. Working with AI is now part of his job.""I think that is where the future is for AI, giving quick access to human-led content, as opposed to completely eliminating that human aspect,"" he says.You can see the full interviews with Dean Meadowcroft and Alejandro Graue on Talking Business with Aaron Heslehurst on BBC News.Viewers in the UK can watch on BBC iPlayer from 11:30 on Saturday. In other countries it will be on at 10:30 & 23:30 GMT on Saturday, 05:30 and 16:30 GMT on Sunday and 07:30 GMT on Monday.If you work with Artificial Intelligence, how is it changing how you do your job? You can share your experience by emailing haveyoursay@bbc.co.uk.Please include a contact number if you are willing to speak to a BBC journalist. You can also get in touch in the following ways:WhatsApp: +44 7756 165803Tweet: @BBC_HaveYourSayUpload pictures or videoPlease read our terms & conditions and privacy policy0/500Your contact infoI accept the Terms of Service
SubmitIn some cases a selection of your comments and questions will be published, displaying your name and location as you provide it unless you state otherwise. Your contact details will never be published. 
At no time should you endanger yourself or others, take any unnecessary risks or infringe any laws.
The BBC retains the right to select from these contributions based on editorial requirements and subject to online terms and conditions and  BBC editorial guidelines. For more information about how the BBC handles your personal data,  see here.
Made with Hearken | Terms of Service | Privacy PolicyIf you are reading this page and can't see the form you will need to visit the mobile version of the BBC website to submit your question or comment or you can email us at HaveYourSay@bbc.co.uk. Please include your name, age and location with any submission. Artificial intelligenceEmployment",http://schema.org,ReportageNewsArticle,The workers already replaced by artificial intelligence,2023-06-15T23:04:48.000Z,2023-06-15T23:04:48.000Z,,,,"{'@type': 'ImageObject', 'width': 1024, 'height': 576, 'url': 'https://ichef.bbci.co.uk/news/1024/branded_news/F708/production/_130104236_dsc_0040.jpg'}","[{'@type': 'Person', 'name': 'By Ian Rose'}]",,,"{'@type': 'NewsMediaOrganization', 'name': 'BBC News', 'publishingPrinciples': 'http://www.bbc.co.uk/news/help-41670342', 'logo': {'@type': 'ImageObject', 'url': 'https://static.files.bbci.co.uk/ws/simorgh-assets/public/news/images/metadata/poster-1024x576.png'}}",,,,https://www.bbc.com/news/business-65906521,https://ichef.bbci.co.uk/news/1024/branded_news/F708/production/_130104236_dsc_0040.jpg,https://www.bbc.com/news/business-65906521,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
https://news.google.com/rss/articles/CBMiY2h0dHBzOi8vd3d3LnRoZWd1YXJkaWFuLmNvbS9oZWxwL2luc2lkZWd1YXJkaWFuLzIwMjMvanVuLzE2L3RoZS1ndWFyZGlhbnMtYXBwcm9hY2gtdG8tZ2VuZXJhdGl2ZS1hadIBY2h0dHBzOi8vYW1wLnRoZWd1YXJkaWFuLmNvbS9oZWxwL2luc2lkZWd1YXJkaWFuLzIwMjMvanVuLzE2L3RoZS1ndWFyZGlhbnMtYXBwcm9hY2gtdG8tZ2VuZXJhdGl2ZS1haQ?oc=5,The Guardian’s approach to generative AI - The Guardian,2023-06-16,The Guardian,https://www.theguardian.com,"Over the last three months, colleagues from our editorial, creative, engineering, product, legal, commercial and partnerships teams have set up a Guardian AI working group to consider how we respond to these risks and opportunities and to draft a set of Guardian-wide AI principles.",N/A,"Over the last three months, colleagues from our editorial, creative, engineering, product, legal, commercial and partnerships teams have set up a Guardian AI working group to consider how we respond to these risks and opportunities and to draft a set of Guardian-wide AI principles.",N/A,Help,N/A,"Inside the Guardian This article is more than 1 year oldThe Guardian’s approach to generative AIThis article is more than 1 year oldKatharine Viner and Anna BatesonFri 16 Jun 2023 05.50 EDTLast modified on Fri 16 Jun 2023 06.31 EDTShareOver the last three months, colleagues from our editorial, creative, engineering, product, legal, commercial and partnerships teams have set up a Guardian AI working group to consider how we respond to these risks and opportunities and to draft a set of Guardian-wide AI principles. We’ve also been studying other media organisations’ statements and approaches with interest.So today we’re publishing three broad principles setting out how we will and won’t use GenAI tools, as follows:For the benefit of readersGenAI tools are exciting but are currently unreliable. There is no room for unreliability in our journalism, nor our marketing, creative and engineering work. At a simple level, this means that the use of genAI requires human oversight. We will seek to use genAI tools editorially only where it contributes to the creation and distribution of original journalism. We will guard against the dangers of bias embedded within generative tools and their underlying training sets. If we wish to include significant elements generated by AI in a piece of work, we will only do so with clear evidence of a specific benefit, human oversight, and the explicit permission of a senior editor. We will be open with our readers when we do this.For the benefit of our mission, our staff and the wider organisationThe Guardian has always been a fast adopter of emerging technologies that support our mission, our journalism and our staff, and we are more than the sum of our parts. When we use genAI, we will focus on situations where it can improve the quality of our work, for example by helping journalists interrogate large data sets, assisting colleagues through corrections or suggestions, creating ideas for marketing campaigns, or reducing the bureaucracy of time-consuming business processes. Any use of these tools will focus on what is valuable and worth protecting at the Guardian: “serious reporting that takes time and effort, carefully uncovers the facts, holds the powerful to account, and interrogates ideas and arguments”.With respect for those who create and own contentMany genAI models are opaque systems trained on material that is harvested without the knowledge or consent of its creators. Our investment in journalism generates revenues as we license that material for reuse around the world. A guiding principle for the tools and models we consider using will be the degree to which they have considered key issues such as permissioning, transparency and fair reward. Any use we make of genAI tools does not mean a waiver of any rights in our underlying content.The Guardian was born 202 years ago in a world of huge technological change and innovation and has prospered since through a series of fundamental changes to the way we produce and distribute our journalism. We don’t yet know the full impact that these new technologies will have on our society, but we feel sure that trusted media organisations which prioritise intelligent original reporting, uncovering facts, holding the powerful to account, and interrogating ideas will be as important as ever before.Explore more on these topicsInside the GuardianShareReuse this content",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
https://news.google.com/rss/articles/CBMiX2h0dHBzOi8vYWlidXNpbmVzcy5jb20vbmxwL292ZXItdHdvLXRoaXJkcy1vZi1lbXBsb3llZXMtYmFjay1nZW5lcmF0aXZlLWFpLXRvLWhlbHAtaW1wcm92ZS13b3Jr0gEA?oc=5,Over Two-Thirds of Employees Back Generative AI to Help Improve Work - AI Business,2023-06-20,AI Business,https://aibusiness.com,A new survey from Salesforce found 68% of employees said generative AI will help them better serve their customers.,N/A,A new survey from Salesforce found 68% of employees said generative AI will help them better serve their customers.,N/A,N/A,N/A,N/A,https://schema.org,BreadcrumbList,Over Two-Thirds of Employees Back Generative AI to Help Improve Work,2023-06-20T09:33:00.000Z,2023-06-20T09:34:12.684Z,,,,"{'@type': 'ImageObject', 'url': 'https://eu-images.contentstack.com/v3/assets/blt6b0f74e5591baa03/blteb419bbae27bc4bb/6491725aa4e88a6b8293b27c/Untitled_design_(12).jpg', 'caption': '', 'creditText': 'Getty Images'}","[{'@type': 'Person', 'name': 'Ben Wodecki', 'image': 'https://eu-images.contentstack.com/v3/assets/blt6b0f74e5591baa03/bltd753a480b70b50e1/65d77cb4995891040ad423d9/Discord_Server_Image.jpg', 'url': 'https://aibusiness.com/author/ben-wodecki'}]",,,"{'@type': ['NewsMediaOrganization', 'Organization', 'OnlineBusiness'], 'identifier': 'https://aibusiness.com', 'name': 'AI Business', 'url': 'https://aibusiness.com', 'sameAs': ['https://twitter.com/business_ai', 'https://www.linkedin.com/company/ai-business/', 'https://www.facebook.com/aibusinessnews', 'https://www.youtube.com/@AIBTV', 'https://news.google.com/publications/CAAqBwgKMOi0lgswi9qtAw'], 'foundingDate': '2015', 'description': 'To provide an objective view of the AI space to enable better strategic decisions and our editorial content focuses on the practical applications of AI technologies rather than hype, buzzwords and high-level technology updates.', 'logo': {'@type': 'ImageObject', 'url': 'https://aibusiness.com/build/_assets/AiBusiness-QDDGSPKW.svg', 'width': {'@type': 'QuantitativeValue', 'value': 431}, 'height': {'@type': 'QuantitativeValue', 'value': 112}}}","[{'@type': 'ListItem', 'position': 1, 'name': 'Home', 'item': 'https://aibusiness.com'}, {'@type': 'ListItem', 'position': 2, 'name': 'NLP', 'item': 'https://aibusiness.com/nlp'}]",,,,,https://aibusiness.com/nlp/over-two-thirds-of-employees-back-generative-ai-to-help-improve-work,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
https://news.google.com/rss/articles/CBMieGh0dHBzOi8vd3d3LmV1cm9uZXdzLmNvbS9uZXh0LzIwMjMvMDYvMTYvbW9yZS10aGFuLWhhbGYtb2YtZnJlbmNoLWVtcGxveWVycy1kby1ub3QtcGxhbi1vbi11c2luZy1hcnRpZmljaWFsLWludGVsbGlnZW5jZdIBAA?oc=5,More than half of French employers do not plan on using AI - Euronews,2023-06-16,Euronews,https://www.euronews.com,Around 31% of French employers already use the technology in the workplace.,"Artificial intelligence,employees,work",Around 31% of French employers already use the technology in the workplace.,Around 31% of French employers already use the technology in the workplace.,N/A,N/A,"
                Now playing
                
              Next
          
                          Europe News
                        
                                                    
                              Borrell accuses Orbán of disloyalty, joins boycott against presidency
                          ",https://schema.org,BreadcrumbList,,,,,,,,,,,,"[{'@type': 'ListItem', 'position': 1, 'name': 'Home', 'item': 'https://www.euronews.com/'}, {'@type': 'ListItem', 'position': 2, 'name': 'Next', 'item': 'https://www.euronews.com/next'}, {'@type': 'ListItem', 'position': 3, 'name': 'Tech&#x20;News', 'item': 'https://www.euronews.com/next/tech-news'}, {'@type': 'ListItem', 'position': 4, 'name': ""Banning Chinese companies Huawei and ZTE from 5G networks 'justified', EU says""}]",,,,,,"[{'@type': 'NewsArticle', 'mainEntityOfPage': {'@type': 'Webpage', 'url': 'https://www.euronews.com/next/2023/06/16/more-than-half-of-french-employers-do-not-plan-on-using-artificial-intelligence'}, 'headline': 'More than half of French employers do not plan on using artificial intelligence', 'description': 'Around 31% of French employers already use the technology in the workplace.', 'articleBody': 'More than half of French employers said they were not using artificial intelligence (AI) and did not plan to do so in the future, according  to a poll released  by France\'s job search agency Pôle Emploi. Among those who do not use AI, 78% said their activity was incompatible with the technology. Another one-third of the employers not using it said they lacked the skills to do so, and nearly one in three said they did not have the financial means for it. Some 15% of employers who are not using AI said they were afraid of the technology. Meanwhile, roughly 35% of employers said they were already using artificial intelligence or were in the middle of rolling it out in the workplace, the poll, conducted for the government agency by the BVA institute, also found. It surveyed 3,000 companies with ten or more employees by telephone in May 2023. Which companies are more likely to use AI? The sectors most likely to use artificial intelligence included agriculture, industry, finance, and commerce. Companies with more than 200 employees were more likely to be using the technology, the poll showed. While around 34% of companies with fewer than 100 employees used the technology, some 45% of companies with more than 200 employees did. What is its impact on these companies? Those who use AI were positive about its impact, with around 74% saying there was a positive effect on the evolution of people\'s skill sets. Some 73% of employers using the technology said there was a positive effect on employees\' performance, while 66% said it had a positive effect on staff health and safety. Around 63% of these employers said it reduced tedious tasks. Tools capable of answering questions or performing diagnostics to support decision-making were the most used by employers using AI. This was followed by language processing and robotics. Voice or visual recognition tools were the least used by companies. AI was most often used in accounting, communication and human resources, the poll showed. Two-thirds of the companies using AI said they had trained staff within their companies, while 22% recruited those in AI-related jobs. Two-thirds of the companies using AI also said that it had increased employees\' autonomy. AI technology has experienced a recent boom since the chatbot ChatGPT, released last November, reportedly became the fastest-growing application. Experts, including AI developers, have  recently issued stark warnings  including that regulating AI should be a ""global priority"" to mitigate the ""risk of extinction"". Many have also expressed concerns that the technology could replace jobs. ', 'dateCreated': '2023-06-15 14:43:56 +02:00', 'dateModified': '2023-06-16 06:00:41 +02:00', 'datePublished': '2023-06-16 06:00:03 +02:00', 'image': {'@type': 'ImageObject', 'url': 'https://static.euronews.com/articles/stories/07/67/94/66/1440x810_cmsv2_663ac18b-d5ba-51a5-ad2a-70a3b4a7bc13-7679466.jpg', 'width': '1440px', 'height': '810px', 'caption': 'The ChatGPT app is displayed on an iPhone in New York, May 18, 2023.', 'thumbnail': 'https://static.euronews.com/articles/stories/07/67/94/66/385x202_cmsv2_663ac18b-d5ba-51a5-ad2a-70a3b4a7bc13-7679466.jpg', 'publisher': {'@type': 'Organization', 'name': 'euronews', 'url': 'https://static.euronews.com/website/images/euronews-logo-main-blue-403x60.png'}}, 'author': {'@type': 'Person', 'name': 'Lauren Chadwick', 'url': 'chadwick', 'sameAs': 'https://twitter.com/euronews'}, 'publisher': {'@type': 'Organization', 'name': 'Euronews', 'legalName': 'Euronews', 'url': 'https://www.euronews.com/', 'logo': {'@type': 'ImageObject', 'url': 'https://static.euronews.com/website/images/euronews-logo-main-blue-403x60.png', 'width': '403px', 'height': '60px'}, 'sameAs': ['https://www.facebook.com/euronews', 'https://twitter.com/euronews', 'https://flipboard.com/@euronews', 'https://www.instagram.com/euronews.tv/', 'https://www.linkedin.com/company/euronews']}, 'isAccessibleForFree': 'False', 'hasPart': {'@type': 'WebPageElement', 'isAccessibleForFree': 'False', 'cssSelector': '.poool-content'}, 'speakable': {'@type': 'SpeakableSpecification', 'xPath': ['/html/head/title', ""/html/head/meta[@name='description']/@content""], 'url': 'https://www.euronews.com/next/2023/06/16/more-than-half-of-french-employers-do-not-plan-on-using-artificial-intelligence'}}, {'@type': 'WebSite', 'name': 'Euronews.com', 'url': 'https://www.euronews.com/', 'potentialAction': {'@type': 'SearchAction', 'target': 'https://www.euronews.com/search?query={search_term_string}', 'query-input': 'required name=search_term_string'}, 'sameAs': ['https://www.facebook.com/euronews', 'https://twitter.com/euronews', 'https://flipboard.com/@euronews', 'https://www.instagram.com/euronews.tv/', 'https://www.linkedin.com/company/euronews']}]",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
https://news.google.com/rss/articles/CBMigQFodHRwczovL3d3dy5tZXJjZXIuY29tL2VuLWF1L2luc2lnaHRzL3Blb3BsZS1zdHJhdGVneS9mdXR1cmUtb2Ytd29yay9uYXZpZ2F0aW5nLXRoZS1pbXBhY3Qtb2YtZ2VuZXJhdGl2ZS1haS1pbi10aGUtd29ybGQtb2Ytd29yay_SAQA?oc=5,Navigating the impact of generative AI in the world of work - Mercer,2023-06-19,Mercer,https://www.mercer.com,"As we enter a new age of generative AI, companies should consider a new set of guardrails for the future of work. It’s true strength lies in augmenting — rather than replacing — the work of employees.","Change management,Consideration,Work design,Human Resources,Career,Adapting to the New Shape of Work,English,Future of work,Attract & retain talent,Skills-based organisations,CHRO,Global All,CEO,Operations,Director,Digital strategy,Accelerating digitalisation,HR function,Global All,Article","As we enter a new age of generative AI, companies should consider a new set of guardrails for the future of work.",N/A,N/A,N/A,"







Workforce & careers

Organisation design  
Mercer’s organisation design consulting can help you transition from a traditional multilayered organisation to a simple, agile and distributed structure.




",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
https://news.google.com/rss/articles/CBMif2h0dHBzOi8vd3d3LnRoZXZlcmdlLmNvbS9mZWF0dXJlcy8yMzc2NDU4NC9haS1hcnRpZmljaWFsLWludGVsbGlnZW5jZS1kYXRhLW5vdGF0aW9uLWxhYm9yLXNjYWxlLXN1cmdlLXJlbW90YXNrcy1vcGVuYWktY2hhdGJvdHPSAQA?oc=5,Inside the AI Factory: the humans that make tech seem human - The Verge,2023-06-20,The Verge,https://www.theverge.com,"How many humans does it take to make tech seem human? Millions to support OpenAI, Google, Meta, and every other major tech company. As AI becomes ubiquitous, a vast tasker underclass is emerging — and not going anywhere.",N/A,How many humans does it take to make tech seem human? Millions.,N/A,N/A,N/A,"Artificial IntelligenceAI Is a Lot of WorkAs the technology becomes ubiquitous, a vast tasker underclass is emerging — and not going anywhere.By  Josh Dzieza, an investigations editor covering tech, business, and climate change. Since joining The Verge in 2014, he’s won a Loeb Award for feature writing, among others.Illustrations by Richard Parry for The Verge Jun 20, 2023, 8:05 AM EDTShare this story23 Comments / 23 NewThis article is a collaboration between New York Magazine and The Verge.A few months after graduating from college in Nairobi, a 30-year-old I’ll call Joe got a job as an annotator — the tedious work of processing the raw information used to train artificial intelligence. AI learns by finding patterns in enormous quantities of data, but first that data has to be sorted and tagged by people, a vast workforce mostly hidden behind the machines. In Joe’s case, he was labeling footage for self-driving cars — identifying every vehicle, pedestrian, cyclist, anything a driver needs to be aware of — frame by frame and from every possible camera angle. It’s difficult and repetitive work. A several-second blip of footage took eight hours to annotate, for which Joe was paid about $10.Then, in 2019, an opportunity arose: Joe could make four times as much running an annotation boot camp for a new company that was hungry for labelers. Every two weeks, 50 new recruits would file into an office building in Nairobi to begin their apprenticeships. There seemed to be limitless demand for the work. They would be asked to categorize clothing seen in mirror selfies, look through the eyes of robot vacuum cleaners to determine which rooms they were in, and draw squares around lidar scans of motorcycles. Over half of Joe’s students usually dropped out before the boot camp was finished. “Some people don’t know how to stay in one place for long,” he explained with gracious understatement. Also, he acknowledged, “it is very boring.”This article is a collaboration between New York Magazine and The Verge.But it was a job in a place where jobs were scarce, and Joe turned out hundreds of graduates. After boot camp, they went home to work alone in their bedrooms and kitchens, forbidden from telling anyone what they were working on, which wasn’t really a problem because they rarely knew themselves. Labeling objects for self-driving cars was obvious, but what about categorizing whether snippets of distorted dialogue were spoken by a robot or a human? Uploading photos of yourself staring into a webcam with a blank expression, then with a grin, then wearing a motorcycle helmet? Each project was such a small component of some larger process that it was difficult to say what they were actually training AI to do. Nor did the names of the projects offer any clues: Crab Generation, Whale Segment, Woodland Gyro, and Pillbox Bratwurst. They were non sequitur code names for non sequitur work.As for the company employing them, most knew it only as Remotasks, a website offering work to anyone fluent in English. Like most of the annotators I spoke with, Joe was unaware until I told him that Remotasks is the worker-facing subsidiary of a company called Scale AI, a multibillion-dollar Silicon Valley data vendor that counts OpenAI and the U.S. military among its customers. Neither Remotasks’ or Scale’s website mentions the other.Much of the public response to language models like OpenAI’s ChatGPT has focused on all the jobs they appear poised to automate. But behind even the most impressive AI system are people — huge numbers of people labeling data to train it and clarifying data when it gets confused. Only the companies that can afford to buy this data can compete, and those that get it are highly motivated to keep it secret. The result is that, with few exceptions, little is known about the information shaping these systems’ behavior, and even less is known about the people doing the shaping.For Joe’s students, it was work stripped of all its normal trappings: a schedule, colleagues, knowledge of what they were working on or whom they were working for. In fact, they rarely called it work at all — just “tasking.” They were taskers.The anthropologist David Graeber defines “bullshit jobs” as employment without meaning or purpose, work that should be automated but for reasons of bureaucracy or status or inertia is not. These AI jobs are their bizarro twin: work that people want to automate, and often think is already automated, yet still requires a human stand-in. The jobs have a purpose; it’s just that workers often have no idea what it is.The current AI boom — the convincingly human-sounding chatbots, the artwork that can be generated from simple prompts, and the multibillion-dollar valuations of the companies behind these technologies — began with an unprecedented feat of tedious and repetitive labor.In 2007, the AI researcher Fei-Fei Li, then a professor at Princeton, suspected the key to improving image-recognition neural networks, a method of machine learning that had been languishing for years, was training on more data — millions of labeled images rather than tens of thousands. The problem was that it would take decades and millions of dollars for her team of undergrads to label that many photos.Li found thousands of workers on Mechanical Turk, Amazon’s crowdsourcing platform where people around the world complete small tasks for cheap. The resulting annotated dataset, called ImageNet, enabled breakthroughs in machine learning that revitalized the field and ushered in a decade of progress.Annotation remains a foundational part of making AI, but there is often a sense among engineers that it’s a passing, inconvenient prerequisite to the more glamorous work of building models. You collect as much labeled data as you can get as cheaply as possible to train your model, and if it works, at least in theory, you no longer need the annotators. But annotation is never really finished. Machine-learning systems are what researchers call “brittle,” prone to fail when encountering something that isn’t well represented in their training data. These failures, called “edge cases,” can have serious consequences. In 2018, an Uber self-driving test car killed a woman because, though it was programmed to avoid cyclists and pedestrians, it didn’t know what to make of someone walking a bike across the street. The more AI systems are put out into the world to dispense legal advice and medical help, the more edge cases they will encounter and the more humans will be needed to sort them. Already, this has given rise to a global industry staffed by people like Joe who use their uniquely human faculties to help the machines.Is that a red shirt with white stripes or a white shirt with red stripes? Is a wicker bowl a “decorative bowl” if it’s full of apples? What color is leopard print?Over the past six months, I spoke with more than two dozen annotators from around the world, and while many of them were training cutting-edge chatbots, just as many were doing the mundane manual labor required to keep AI running. There are people classifying the emotional content of TikTok videos, new variants of email spam, and the precise sexual provocativeness of online ads. Others are looking at credit-card transactions and figuring out what sort of purchase they relate to or checking e-commerce recommendations and deciding whether that shirt is really something you might like after buying that other shirt. Humans are correcting customer-service chatbots, listening to Alexa requests, and categorizing the emotions of people on video calls. They are labeling food so that smart refrigerators don’t get confused by new packaging, checking automated security cameras before sounding alarms, and identifying corn for baffled autonomous tractors.“There’s an entire supply chain,” said Sonam Jindal, the program and research lead of the nonprofit Partnership on AI. “The general perception in the industry is that this work isn’t a critical part of development and isn’t going to be needed for long. All the excitement is around building artificial intelligence, and once we build that, it won’t be needed anymore, so why think about it? But it’s infrastructure for AI. Human intelligence is the basis of artificial intelligence, and we need to be valuing these as real jobs in the AI economy that are going to be here for a while.”The data vendors behind familiar names like OpenAI, Google, and Microsoft come in different forms. There are private outsourcing companies with call-center-like offices, such as the Kenya- and Nepal-based CloudFactory, where Joe annotated for $1.20 an hour before switching to Remotasks. There are also “crowdworking” sites like Mechanical Turk and Clickworker where anyone can sign up to perform tasks. In the middle are services like Scale AI. Anyone can sign up, but everyone has to pass qualification exams and training courses and undergo performance monitoring. Annotation is big business. Scale, founded in 2016 by then-19-year-old Alexandr Wang, was valued in 2021 at $7.3 billion, making him what Forbes called “the youngest self-made billionaire,” though the magazine noted in a recent profile that his stake has fallen on secondary markets since then.This tangled supply chain is deliberately hard to map. According to people in the industry, the companies buying the data demand strict confidentiality. (This is the reason Scale cited to explain why Remotasks has a different name.) Annotation reveals too much about the systems being developed, and the huge number of workers required makes leaks difficult to prevent. Annotators are warned repeatedly not to tell anyone about their jobs, not even their friends and co-workers, but corporate aliases, project code names, and, crucially, the extreme division of labor ensure they don’t have enough information about them to talk even if they wanted to. (Most workers requested pseudonyms for fear of being booted from the platforms.) Consequently, there are no granular estimates of the number of people who work in annotation, but it is a lot, and it is growing. A recent Google Research paper gave an order-of-magnitude figure of “millions” with the potential to become “billions.”Automation often unfolds in unexpected ways. Erik Duhaime, CEO of medical-data-annotation company Centaur Labs, recalled how, several years ago, prominent machine-learning engineers were predicting AI would make the job of radiologist obsolete. When that didn’t happen, conventional wisdom shifted to radiologists using AI as a tool. Neither of those is quite what he sees occurring. AI is very good at specific tasks, Duhaime said, and that leads work to be broken up and distributed across a system of specialized algorithms and to equally specialized humans. An AI system might be capable of spotting cancer, he said, giving a hypothetical example, but only in a certain type of imagery from a certain type of machine; so now, you need a human to check that the AI is being fed the right type of data and maybe another human who checks its work before passing it to another AI that writes a report, which goes to another human, and so on. “AI doesn’t replace work,” he said. “But it does change how work is organized.”You might miss this if you believe AI is a brilliant, thinking machine. But if you pull back the curtain even a little, it looks more familiar, the latest iteration of a particularly Silicon Valley division of labor, in which the futuristic gleam of new technologies hides a sprawling manufacturing apparatus and the people who make it run. Duhaime reached back farther for a comparison, a digital version of the transition from craftsmen to industrial manufacturing: coherent processes broken into tasks and arrayed along assembly lines with some steps done by machines and some by humans but none resembling what came before.Worries about AI-driven disruption are often countered with the argument that AI automates tasks, not jobs, and that these tasks will be the dull ones, leaving people to pursue more fulfilling and human work. But just as likely, the rise of AI will look like past labor-saving technologies, maybe like the telephone or typewriter, which vanquished the drudgery of message delivering and handwriting but generated so much new correspondence, commerce, and paperwork that new offices staffed by new types of workers — clerks, accountants, typists — were required to manage it. When AI comes for your job, you may not lose it, but it might become more alien, more isolating, more tedious.Earlier this year, I signed up for Scale AI’s Remotasks. The process was straightforward. After entering my computer specs, internet speed, and some basic contact information, I found myself in the “training center.” To access a paying task, I first had to complete an associated (unpaid) intro course.The training center displayed a range of courses with inscrutable names like Glue Swimsuit and Poster Macadamia. I clicked on something called GFD Chunking, which revealed itself to be labeling clothing in social-media photos.The instructions, however, were odd. For one, they basically consisted of the same direction reiterated in the idiosyncratically colored and capitalized typography of a collaged bomb threat.“DO LABEL items that are real and can be worn by humans or are intended to be worn by real people,” it read.“All items below SHOULD be labeled because they are real and can be worn by real-life humans,” it reiterated above photos of an Air Jordans ad, someone in a Kylo Ren helmet, and mannequins in dresses, over which was a lime-green box explaining, once again, “DO Label real items that can be worn by real people.”Remotasks instructions for labeling clothing.I skimmed to the bottom of the manual, where the instructor had written in the large bright-red font equivalent of grabbing someone by the shoulders and shaking them, “THE FOLLOWING ITEMS SHOULD NOT BE LABELED because a human could not actually put wear any of these items!” above a photo of C-3PO, Princess Jasmine from Aladdin, and a cartoon shoe with eyeballs.Feeling confident in my ability to distinguish between real clothes that can be worn by real people and not-real clothes that cannot, I proceeded to the test. Right away, it threw an ontological curveball: a picture of a magazine depicting photos of women in dresses. Is a photograph of clothing real clothing? No, I thought, because a human cannot wear a photograph of clothing. Wrong! As far as AI is concerned, photos of real clothes are real clothes. Next came a photo of a woman in a dimly lit bedroom taking a selfie before a full-length mirror. The blouse and shorts she’s wearing are real. What about their reflection? Also real! Reflections of real clothes are also real clothes.After an embarrassing amount of trial and error, I made it to the actual work, only to make the horrifying discovery that the instructions I’d been struggling to follow had been updated and clarified so many times that they were now a full 43 printed pages of directives: Do NOT label open suitcases full of clothes; DO label shoes but do NOT label flippers; DO label leggings but do NOT label tights; do NOT label towels even if someone is wearing it; label costumes but do NOT label armor. And so on.There has been general instruction disarray across the industry, according to Milagros Miceli, a researcher at the Weizenbaum Institute in Germany who studies data work. It is in part a product of the way machine-learning systems learn. Where a human would get the concept of “shirt” with a few examples, machine-learning programs need thousands, and they need to be categorized with perfect consistency yet varied enough (polo shirts, shirts being worn outdoors, shirts hanging on a rack) that the very literal system can handle the diversity of the real world. “Imagine simplifying complex realities into something that is readable for a machine that is totally dumb,” she said.Once, Victor stayed up 36 hours straight labeling elbows and knees and heads in photographs of crowds — he has no idea why.The act of simplifying reality for a machine results in a great deal of complexity for the human. Instruction writers must come up with rules that will get humans to categorize the world with perfect consistency. To do so, they often create categories no human would use. A human asked to tag all the shirts in a photo probably wouldn’t tag the reflection of a shirt in a mirror because they would know it is a reflection and not real. But to the AI, which has no understanding of the world, it’s all just pixels and the two are perfectly identical. Fed a dataset with some shirts labeled and other (reflected) shirts unlabeled, the model won’t work. So the engineer goes back to the vendor with an update: DO label reflections of shirts. Soon, you have a 43-page guide descending into red all-caps.“When you start off, the rules are relatively simple,” said a former Scale employee who requested anonymity because of an NDA. “Then they get back a thousand images and then they’re like, Wait a second, and then you have multiple engineers and they start to argue with each other. It’s very much a human thing.”The job of the annotator often involves putting human understanding aside and following instructions very, very literally — to think, as one annotator said, like a robot. It’s a strange mental space to inhabit, doing your best to follow nonsensical but rigorous rules, like taking a standardized test while on hallucinogens. Annotators invariably end up confronted with confounding questions like, Is that a red shirt with white stripes or a white shirt with red stripes? Is a wicker bowl a “decorative bowl” if it’s full of apples? What color is leopard print? When instructors said to label traffic-control directors, did they also mean to label traffic-control directors eating lunch on the sidewalk? Every question must be answered, and a wrong guess could get you banned and booted to a new, totally different task with its own baffling rules.Most of the work on Remotasks is paid at a piece rate with a single task earning anywhere from a few cents to several dollars. Because tasks can take seconds or hours, wages are hard to predict. When Remotasks first arrived in Kenya, annotators said it paid relatively well — averaging about $5 to $10 per hour depending on the task — but the amount fell as time went on.Scale AI spokesperson Anna Franko said that the company’s economists analyze the specifics of a project, the skills required, the regional cost of living, and other factors “to ensure fair and competitive compensation.” Former Scale employees also said pay is determined through a surge-pricing-like mechanism that adjusts for how many annotators are available and how quickly the data is needed.According to workers I spoke with and job listings, U.S.-based Remotasks annotators generally earn between $10 and $25 per hour, though some subject-matter experts can make more. By the beginning of this year, pay for the Kenyan annotators I spoke with had dropped to between $1 and $3 per hour.That is, when they were making any money at all. The most common complaint about Remotasks work is its variability; it’s steady enough to be a full-time job for long stretches but too unpredictable to rely on. Annotators spend hours reading instructions and completing unpaid trainings only to do a dozen tasks and then have the project end. There might be nothing new for days, then, without warning, a totally different task appears and could last anywhere from a few hours to weeks. Any task could be their last, and they never know when the next one will come.This boom-and-bust cycle results from the cadence of AI development, according to engineers and data vendors. Training a large model requires an enormous amount of annotation followed by more iterative updates, and engineers want it all as fast as possible so they can hit their target launch date. There may be monthslong demand for thousands of annotators, then for only a few hundred, then for a dozen specialists of a certain type, and then thousands again. “The question is, Who bears the cost for these fluctuations?” said Jindal of Partnership on AI. “Because right now, it’s the workers.”“I really am wasting my life here if I made somebody a billionaire and I’m earning a couple of bucks a week.”To succeed, annotators work together. When I told Victor, who started working for Remotasks while at university in Nairobi, about my struggles with the traffic-control-directors task, he told me everyone knew to stay away from that one: too tricky, bad pay, not worth it. Like a lot of annotators, Victor uses unofficial WhatsApp groups to spread the word when a good task drops. When he figures out a new one, he starts impromptu Google Meets to show others how it’s done. Anyone can join and work together for a time, sharing tips. “It’s a culture we have developed of helping each other because we know when on your own, you can’t know all the tricks,” he said.Because work appears and vanishes without warning, taskers always need to be on alert. Victor has found that projects pop up very late at night, so he is in the habit of waking every three hours or so to check his queue. When a task is there, he’ll stay awake as long as he can to work. Once, he stayed up 36 hours straight labeling elbows and knees and heads in photographs of crowds — he has no idea why. Another time, he stayed up so long his mother asked him what was wrong with his eyes. He looked in the mirror to discover they were swollen.Annotators generally know only that they are training AI for companies located vaguely elsewhere, but sometimes the veil of anonymity drops — instructions mentioning a brand or a chatbot say too much. “I read and I Googled and found I am working for a 25-year-old billionaire,” said one worker, who, when we spoke, was labeling the emotions of people calling to order Domino’s pizza. “I really am wasting my life here if I made somebody a billionaire and I’m earning a couple of bucks a week.”Victor is a self-proclaimed “fanatic” about AI and started annotating because he wants to help bring about a fully automated post-work future. But earlier this year, someone dropped a Time story into one of his WhatsApp groups about workers training ChatGPT to recognize toxic content who were getting paid less than $2 an hour by the vendor Sama AI. “People were angry that these companies are so profitable but paying so poorly,” Victor said. He was unaware until I told him about Remotasks’ connection to Scale. Instructions for one of the tasks he worked on were nearly identical to those used by OpenAI, which meant he had likely been training ChatGPT as well, for approximately $3 per hour.“I remember that someone posted that we will be remembered in the future,” he said. “And somebody else replied, ‘We are being treated worse than foot soldiers. We will be remembered nowhere in the future.’ I remember that very well. Nobody will recognize the work we did or the effort we put in.”Identifying clothing and labeling customer-service conversations are just some of the annotation gigs available. Lately, the hottest on the market has been chatbot trainer. Because it demands specific areas of expertise or language fluency and wages are often adjusted regionally, this job tends to pay better. Certain types of specialist annotation can go for $50 or more per hour.A woman I’ll call Anna was searching for a job in Texas when she stumbled across a generic listing for online work and applied. It was Remotasks, and after passing an introductory exam, she was brought into a Slack room of 1,500 people who were training a project code-named Dolphin, which she later discovered to be Google DeepMind’s chatbot, Sparrow, one of the many bots competing with ChatGPT. Her job is to talk with it all day. At about $14 an hour, plus bonuses for high productivity, “it definitely beats getting paid $10 an hour at the local Dollar General store,” she said.Also, she enjoys it. She has discussed science-fiction novels, mathematical paradoxes, children’s riddles, and TV shows. Sometimes the bot’s responses make her laugh; other times, she runs out of things to talk about. “Some days, my brain is just like, I literally have no idea what on earth to ask it now,” she said. “So I have a little notebook, and I’ve written about two pages of things — I just Google interesting topics — so I think I’ll be good for seven hours today, but that’s not always the case.”Each time Anna prompts Sparrow, it delivers two responses and she picks the best one, thereby creating something called “human-feedback data.” When ChatGPT debuted late last year, its impressively natural-seeming conversational style was credited to its having been trained on troves of internet data. But the language that fuels ChatGPT and its competitors is filtered through several rounds of human annotation. One group of contractors writes examples of how the engineers want the bot to behave, creating questions followed by correct answers, descriptions of computer programs followed by functional code, and requests for tips on committing crimes followed by polite refusals. After the model is trained on these examples, yet more contractors are brought in to prompt it and rank its responses. This is what Anna is doing with Sparrow. Exactly which criteria the raters are told to use varies — honesty, or helpfulness, or just personal preference. The point is that they are creating data on human taste, and once there’s enough of it, engineers can train a second model to mimic their preferences at scale, automating the ranking process and training their AI to act in ways humans approve of. The result is a remarkably human-seeming bot that mostly declines harmful requests and explains its AI nature with seeming self-awareness.Put another way, ChatGPT seems so human because it was trained by an AI that was mimicking humans who were rating an AI that was mimicking humans who were pretending to be a better version of an AI that was trained on human writing.This circuitous technique is called “reinforcement learning from human feedback,” or RLHF, and it’s so effective that it’s worth pausing to fully register what it doesn’t do. When annotators teach a model to be accurate, for example, the model isn’t learning to check answers against logic or external sources or about what accuracy as a concept even is. The model is still a text-prediction machine mimicking patterns in human writing, but now its training corpus has been supplemented with bespoke examples, and the model has been weighted to favor them. Maybe this results in the model extracting patterns from the part of its linguistic map labeled as accurate and producing text that happens to align with the truth, but it can also result in it mimicking the confident style and expert jargon of the accurate text while writing things that are totally wrong. There is no guarantee that the text the labelers marked as accurate is in fact accurate, and when it is, there is no guarantee that the model learns the right patterns from it.This dynamic makes chatbot annotation a delicate process. It has to be rigorous and consistent because sloppy feedback, like marking material that merely sounds correct as accurate, risks training models to be even more convincing bullshitters. An early OpenAI and DeepMind joint project using RLHF, in this case to train a virtual robot hand to grab an item, resulted in also training the robot to position its hand between the object and its raters and wiggle around such that it only appeared to its human overseers to grab the item. Ranking a language model’s responses is always going to be somewhat subjective because it’s language. A text of any length will have multiple elements that could be right or wrong or, taken together, misleading. OpenAI researchers ran into this obstacle in another early RLHF paper. Trying to get their model to summarize text, the researchers found they agreed only 60 percent of the time that a summary was good. “Unlike many tasks in [machine learning] our queries do not have unambiguous ground truth,” they lamented.When Anna rates Sparrow’s responses, she’s supposed to be looking at their accuracy, helpfulness, and harmlessness while also checking that the model isn’t giving medical or financial advice or anthropomorphizing itself or running afoul of other criteria. To be useful training data, the model’s responses have to be quantifiably ranked against one another: Is a bot that helpfully tells you how to make a bomb “better” than a bot that’s so harmless it refuses to answer any questions? In one DeepMind paper, when Sparrow’s makers took a turn annotating, four researchers wound up debating whether their bot had assumed the gender of a user who asked it for relationship advice. According to Geoffrey Irving, one of DeepMind’s research scientists, the company’s researchers hold weekly annotation meetings in which they rerate data themselves and discuss ambiguous cases, consulting with ethical or subject-matter experts when a case is particularly tricky.There are people classifying the emotional content of TikTok videos, new variants of email spam, and the precise sexual provocativeness of online ads.Anna often finds herself having to choose between two bad options. “Even if they’re both absolutely, ridiculously wrong, you still have to figure out which one is better and then write words explaining why,” she said. Sometimes, when both responses are bad, she’s encouraged to write a better response herself, which she does about half the time.Because feedback data is difficult to collect, it fetches a higher price. Basic preferences of the sort Anna is producing sell for about $1 each, according to people with knowledge of the industry. But if you want to train a model to do legal research, you need someone with training in law, and this gets expensive. Everyone involved is reluctant to say how much they’re spending, but in general, specialized written examples can go for hundreds of dollars, while expert ratings can cost $50 or more. One engineer told me about buying examples of Socratic dialogues for up to $300 a pop. Another told me about paying $15 for a “darkly funny limerick about a goldfish.”OpenAI, Microsoft, Meta, and Anthropic did not comment about how many people contribute annotations to their models, how much they are paid, or where in the world they are located. Irving of DeepMind, which is a subsidiary of Google, said the annotators working on Sparrow are paid “at least the hourly living wage” based on their location. Anna knows “absolutely nothing” about Remotasks, but Sparrow has been more open. She wasn’t the only annotator I spoke with who got more information from the AI they were training than from their employer; several others learned whom they were working for by asking their AI for its company’s terms of service. “I literally asked it, ‘What is your purpose, Sparrow?’” Anna said. It pulled up a link to DeepMind’s website and explained that it’s an AI assistant and that its creators trained it using RLHF to be helpful and safe.Until recently, it was relatively easy to spot bad output from a language model. It looked like gibberish. But this gets harder as the models get better — a problem called “scalable oversight.” Google inadvertently demonstrated how hard it is to catch the errors of a modern-language model when one made it into the splashy debut of its AI assistant, Bard. (It stated confidently that the James Webb Space Telescope “took the very first pictures of a planet outside of our own solar system,” which is wrong.) This trajectory means annotation increasingly requires specific skills and expertise.Last year, someone I’ll call Lewis was working on Mechanical Turk when, after completing a task, he received a message inviting him to apply for a platform he hadn’t heard of. It was called Taskup.ai, and its website was remarkably basic: just a navy background with text reading GET PAID FOR TASKS ON DEMAND. He applied.The work paid far better than anything he had tried before, often around $30 an hour. It was more challenging, too: devising complex scenarios to trick chatbots into giving dangerous advice, testing a model’s ability to stay in character, and having detailed conversations about scientific topics so technical they required extensive research. He found the work “satisfying and stimulating.” While checking one model’s attempts to code in Python, Lewis was learning too. He couldn’t work for more than four hours at a stretch, lest he risk becoming mentally drained and making mistakes, and he wanted to keep the job.“If there was one thing I could change, I would just like to have more information about what happens on the other end,” he said. “We only know as much as we need to know to get work done, but if I could know more, then maybe I could get more established and perhaps pursue this as a career.”I spoke with eight other workers, most based in the U.S., who had similar experiences of answering surveys or completing tasks on other platforms and finding themselves recruited for Taskup.ai or several similarly generic sites, such as DataAnnotation.tech or Gethybrid.io. Often their work involved training chatbots, though with higher-quality expectations and more specialized purposes than other sites they had worked for. One was demonstrating spreadsheet macros. Another was just supposed to have conversations and rate responses according to whatever criteria she wanted. She often asked the chatbot things that had come up in conversations with her 7-year-old daughter, like “What is the largest dinosaur?” and “Write a story about a tiger.” “I haven’t fully gotten my head around what they’re trying to do with it,” she told me.Taskup.ai, DataAnnotation.tech, and Gethybrid.io all appear to be owned by the same company: Surge AI. Its CEO, Edwin Chen, would neither confirm nor deny the connection, but he was willing to talk about his company and how he sees annotation evolving.“I’ve always felt the annotation landscape is overly simplistic,” Chen said over a video call from Surge’s office. He founded Surge in 2020 after working on AI at Google, Facebook, and Twitter convinced him that crowdsourced labeling was inadequate. “We want AI to tell jokes or write really good marketing copy or help me out when I need therapy or whatnot,” Chen said. “You can’t ask five people to independently come up with a joke and combine it into a majority answer. Not everybody can tell a joke or solve a Python program. The annotation landscape needs to shift from this low-quality, low-skill mind-set to something that’s much richer and captures the range of human skills and creativity and values that we want AI systems to possess.”Last year, Surge relabeled Google’s dataset classifying Reddit posts by emotion. Google had stripped each post of context and sent them to workers in India for labeling. Surge employees familiar with American internet culture found that 30 percent of the labels were wrong. Posts like “hell yeah my brother” had been classified as annoyance and “Yay, cold McDonald’s. My favorite” as love.Surge claims to vet its workers for qualifications — that people doing creative-writing tasks have experience with creative writing, for example — but exactly how Surge finds workers is “proprietary,” Chen said. As with Remotasks, workers often have to complete training courses, though unlike Remotasks, they are paid for it, according to the annotators I spoke with. Having fewer, better-trained workers producing higher-quality data allows Surge to compensate better than its peers, Chen said, though he declined to elaborate, saying only that people are paid “fair and ethical wages.” The workers I spoke with earned between $15 and $30 per hour, but they are a small sample of all the annotators, a group Chen said now consists of 100,000 people. The secrecy, he explained, stems from clients’ demands for confidentiality.Surge’s customers include OpenAI, Google, Microsoft, Meta, and Anthropic. Surge specializes in feedback and language annotation, and after ChatGPT launched, it got an influx of requests, Chen said: “I thought everybody knew the power of RLHF, but I guess people just didn’t viscerally understand.”The new models are so impressive they’ve inspired another round of predictions that annotation is about to be automated. Given the costs involved, there is significant financial pressure to do so. Anthropic, Meta, and other companies have recently made strides in using AI to drastically reduce the amount of human annotation needed to guide models, and other developers have started using GPT-4 to generate training data. However, a recent paper found that GPT-4-trained models may be learning to mimic GPT’s authoritative style with even less accuracy, and so far, when improvements in AI have made one form of annotation obsolete, demand for other, more sophisticated types of labeling has gone up. This debate spilled into the open earlier this year, when Scale’s CEO, Wang, tweeted that he predicted AI labs will soon be spending as many billions of dollars on human data as they do on computing power; OpenAI’s CEO, Sam Altman, responded that data needs will decrease as AI improves.“I mean, what it can do is amazing,” she said of the chatbot. “But it still does some really weird shit.”Chen is skeptical AI will reach a point where human feedback is no longer needed, but he does see annotation becoming more difficult as models improve. Like many researchers, he believes the path forward will involve AI systems helping humans oversee other AI. Surge recently collaborated with Anthropic on a proof of concept, having human labelers answer questions about a lengthy text with the help of an unreliable AI assistant, on the theory that the humans would have to feel out the weaknesses of their AI assistant and collaborate to reason their way to the correct answer. Another possibility has two AIs debating each other and a human rendering the final verdict on which is correct. “We still have yet to see really good practical implementations of this stuff, but it’s starting to become necessary because it’s getting really hard for labelers to keep up with the models,” said OpenAI research scientist John Schulman in a recent talk at Berkeley.“I think you always need a human to monitor what AIs are doing just because they are this kind of alien entity,” Chen said. Machine-learning systems are just too strange ever to fully trust. The most impressive models today have what, to a human, seems like bizarre weaknesses, he added, pointing out that though GPT-4 can generate complex and convincing prose, it can’t pick out which words are adjectives: “Either that or models get so good that they’re better than humans at all things, in which case, you reach your utopia and who cares?”As 2022 ended, Joe started hearing from his students that their task queues were often empty. Then he got an email informing him the boot camps in Kenya were closing. He continued training taskers online, but he began to worry about the future.“There were signs that it was not going to last long,” he said. Annotation was leaving Kenya. From colleagues he had met online, he heard tasks were going to Nepal, India, and the Philippines. “The companies shift from one region to another,” Joe said. “They don’t have infrastructure locally, so it makes them flexible to shift to regions that favor them in terms of operation cost.”One way the AI industry differs from manufacturers of phones and cars is in its fluidity. The work is constantly changing, constantly getting automated away and replaced with new needs for new types of data. It’s an assembly line but one that can be endlessly and instantly reconfigured, moving to wherever there is the right combination of skills, bandwidth, and wages.Lately, the best-paying work is in the U.S. In May, Scale started listing annotation jobs on its own website, soliciting people with experience in practically every field AI is predicted to conquer. There were listings for AI trainers with expertise in health coaching, human resources, finance, economics, data science, programming, computer science, chemistry, biology, accounting, taxes, nutrition, physics, travel, K-12 education, sports journalism, and self-help. You can make $45 an hour teaching robots law or make $25 an hour teaching them poetry. There were also listings for people with security clearance, presumably to help train military AI. Scale recently launched a defense-oriented language model called Donovan, which Wang called “ammunition in the AI war,” and won a contract to work on the Army’s robotic-combat-vehicle program.Anna is still training chatbots in Texas. Colleagues have been turned into reviewers and Slack admins — she isn’t sure why, but it has given her hope that the gig could be a longer-term career. One thing she isn’t worried about is being automated out of a job. “I mean, what it can do is amazing,” she said of the chatbot. “But it still does some really weird shit.”When Remotasks first arrived in Kenya, Joe thought annotation could be a good career. Even after the work moved elsewhere, he was determined to make it one. There were thousands of people in Nairobi who knew how to do the work, he reasoned — he had trained many of them, after all. Joe rented office space in the city and began sourcing contracts: a job annotating blueprints for a construction company, another labeling fruits despoiled by insects for some sort of agricultural project, plus the usual work of annotating for self-driving cars and e-commerce.But he has found his vision difficult to achieve. He has just one full-time employee, down from two. “We haven’t been having a consistent flow of work,” he said. There are weeks with nothing to do because customers are still collecting data, and when they’re done, he has to bring in short-term contractors to meet their deadlines: “Clients don’t care whether we have consistent work or not. So long as the datasets have been completed, then that’s the end of that.”Rather than let their skills go to waste, other taskers decided to chase the work wherever it went. They rented proxy servers to disguise their locations and bought fake IDs to pass security checks so they could pretend to work from Singapore, the Netherlands, Mississippi, or wherever the tasks were flowing. It’s a risky business. Scale has become increasingly aggressive about suspending accounts caught disguising their location, according to multiple taskers. It was during one of these crackdowns that my account got banned, presumably because I had been using a VPN to see what workers in other countries were seeing, and all $1.50 or so of my earnings were seized.“These days, we have become a bit cunning because we noticed that in other countries they are paying well,” said Victor, who was earning double the Kenyan rate by tasking in Malaysia. “You do it cautiously.”Another Kenyan annotator said that after his account got suspended for mysterious reasons, he decided to stop playing by the rules. Now, he runs multiple accounts in multiple countries, tasking wherever the pay is best. He works fast and gets high marks for quality, he said, thanks to ChatGPT. The bot is wonderful, he said, letting him speed through $10 tasks in a matter of minutes. When we spoke, he was having it rate another chatbot’s responses according to seven different criteria, one AI training the other.Comments23 Comments / 23 NewFeatured Videos From The VergeSamsung’s new folds, flips, and Apple clones | The Vergecast
1/1





Skip Ad
 
Continue watchingafter the adVisit Advertiser websiteGO TO PAGEThe Verge's Nilay Patel, David Pierce, and Alex Cranz discuss the announcements from Samsung's Galaxy Unpacked event, Redbox shutting down, and more tech news from this week.Most PopularMost PopularMicrosoft releases recovery tool to help repair Windows machines hit by CrowdStrike issueTwo new must-have Android appsSuunto’s new headphones finally made me appreciate bone conductionBy endorsing Trump, Elon Musk is gambling with Tesla’s futureNotchNook gives MacBooks their own Dynamic Island Verge Deals / Sign up for Verge Deals to get deals on products we've tested sent to your inbox weekly.Email (required)Sign upBy submitting your email, you agree to our Terms and Privacy Notice. This site is protected by reCAPTCHA and the Google Privacy Policy and Terms of Service apply.From our sponsorAdvertiser Content From",http://schema.org/,NewsArticle,Inside the AI Factory: the humans that make tech seem human,2023-06-20T12:05:00.000Z,2023-06-20T12:05:00.000Z,,,,"[{'@type': 'ImageObject', 'url': 'https://cdn.vox-cdn.com/thumbor/MFiURNjiF1enowJ5t0oyd0gkPlU=/0x0:2048x1365/1400x788/filters:focal(1024x683:1025x684)/cdn.vox-cdn.com/uploads/chorus_asset/file/24737787/236709_ai_data_notation_labor_scale_surge_remotasks_openai_chatbots_RParry_001.jpg', 'width': 1400, 'height': 788}, {'@type': 'ImageObject', 'url': 'https://cdn.vox-cdn.com/thumbor/aD8beUZUaAWE-Xp9Nxghr39hEc8=/0x0:2048x1365/1400x1050/filters:focal(1024x683:1025x684)/cdn.vox-cdn.com/uploads/chorus_asset/file/24737787/236709_ai_data_notation_labor_scale_surge_remotasks_openai_chatbots_RParry_001.jpg', 'width': 1400, 'height': 1050}, {'@type': 'ImageObject', 'url': 'https://cdn.vox-cdn.com/thumbor/3DumuHSwStBgrpK3v23C-ipMVRE=/0x0:2048x1365/1400x1400/filters:focal(1024x683:1025x684)/cdn.vox-cdn.com/uploads/chorus_asset/file/24737787/236709_ai_data_notation_labor_scale_surge_remotasks_openai_chatbots_RParry_001.jpg', 'width': 1400, 'height': 1400}]","[{'@type': 'Person', 'name': 'Josh Dzieza', 'url': 'https://www.theverge.com/authors/josh-dzieza'}]","This article is a collaboration between New York Magazine and The Verge.

---

A few months after graduating from college in Nairobi, a 30-year-old I’ll call Joe got a job as an annotator — the tedious work of processing the raw information used to train artificial intelligence. AI learns by finding patterns in enormous quantities of data, but first that data has to be sorted and tagged by people, a vast workforce mostly hidden behind the machines. In Joe’s case, he was labeling footage for self-driving cars — identifying every vehicle, pedestrian, cyclist, anything a driver needs to be aware of — frame by frame and from every possible camera angle. It’s difficult and repetitive work. A several-second blip of footage took eight hours to annotate, for which Joe was paid about $10.

Then, in 2019, an opportunity arose: Joe could make four times as much running an annotation boot camp for a new company that was hungry for labelers. Every two weeks, 50 new recruits would file into an office building in Nairobi to begin their apprenticeships. There seemed to be limitless demand for the work. They would be asked to categorize clothing seen in mirror selfies, look through the eyes of robot vacuum cleaners to determine which rooms they were in, and draw squares around lidar scans of motorcycles. Over half of Joe’s students usually dropped out before the boot camp was finished. “Some people don’t know how to stay in one place for long,” he explained with gracious understatement. Also, he acknowledged, “it is very boring.”

---
[Image: https://cdn.vox-cdn.com/thumbor/bqRhb5A3myLSYGiXMDOshxcrXCE=/0x0:2400x3000/2400x3000/filters:focal(1200x1500:1201x1501)/cdn.vox-cdn.com/uploads/chorus_asset/file/24734352/1323Cov4x5_AI_Factory.jpg]

This article is a collaboration between New York Magazine and The Verge.
---

But it was a job in a place where jobs were scarce, and Joe turned out hundreds of graduates. After boot camp, they went home to work alone in their bedrooms and kitchens, forbidden from telling anyone what they were working on, which wasn’t really a problem because they rarely knew themselves. Labeling objects for self-driving cars was obvious, but what about categorizing whether snippets of distorted dialogue were spoken by a robot or a human? Uploading photos of yourself staring into a webcam with a blank expression, then with a grin, then wearing a motorcycle helmet? Each project was such a small component of some larger process that it was difficult to say what they were actually training AI to do. Nor did the names of the projects offer any clues: Crab Generation, Whale Segment, Woodland Gyro, and Pillbox Bratwurst. They were non sequitur code names for non sequitur work.

As for the company employing them, most knew it only as Remotasks, a website offering work to anyone fluent in English. Like most of the annotators I spoke with, Joe was unaware until I told him that Remotasks is the worker-facing subsidiary of a company called Scale AI, a multibillion-dollar Silicon Valley data vendor that counts OpenAI and the U.S. military among its customers. Neither Remotasks’ or Scale’s website mentions the other.

Much of the public response to language models like OpenAI’s ChatGPT has focused on all the jobs they appear poised to automate. But behind even the most impressive AI system are people — huge numbers of people labeling data to train it and clarifying data when it gets confused. Only the companies that can afford to buy this data can compete, and those that get it are highly motivated to keep it secret. The result is that, with few exceptions, little is known about the information shaping these systems’ behavior, and even less is known about the people doing the shaping.

For Joe’s students, it was work stripped of all its normal trappings: a schedule, colleagues, knowledge of what they were working on or whom they were working for. In fact, they rarely called it work at all — just “tasking.” They were taskers.

The anthropologist David Graeber defines “bullshit jobs” as employment without meaning or purpose, work that should be automated but for reasons of bureaucracy or status or inertia is not. These AI jobs are their bizarro twin: work that people want to automate, and often think is already automated, yet still requires a human stand-in. The jobs have a purpose; it’s just that workers often have no idea what it is.

---

The current AI boom — the convincingly human-sounding chatbots, the artwork that can be generated from simple prompts, and the multibillion-dollar valuations of the companies behind these technologies — began with an unprecedented feat of tedious and repetitive labor.

In 2007, the AI researcher Fei-Fei Li, then a professor at Princeton, suspected the key to improving image-recognition neural networks, a method of machine learning that had been languishing for years, was training on more data — millions of labeled images rather than tens of thousands. The problem was that it would take decades and millions of dollars for her team of undergrads to label that many photos.

Li found thousands of workers on Mechanical Turk, Amazon’s crowdsourcing platform where people around the world complete small tasks for cheap. The resulting annotated dataset, called ImageNet, enabled breakthroughs in machine learning that revitalized the field and ushered in a decade of progress.

Annotation remains a foundational part of making AI, but there is often a sense among engineers that it’s a passing, inconvenient prerequisite to the more glamorous work of building models. You collect as much labeled data as you can get as cheaply as possible to train your model, and if it works, at least in theory, you no longer need the annotators. But annotation is never really finished. Machine-learning systems are what researchers call “brittle,” prone to fail when encountering something that isn’t well represented in their training data. These failures, called “edge cases,” can have serious consequences. In 2018, an Uber self-driving test car killed a woman because, though it was programmed to avoid cyclists and pedestrians, it didn’t know what to make of someone walking a bike across the street. The more AI systems are put out into the world to dispense legal advice and medical help, the more edge cases they will encounter and the more humans will be needed to sort them. Already, this has given rise to a global industry staffed by people like Joe who use their uniquely human faculties to help the machines.

""Is that a red shirt with white stripes or a white shirt with red stripes? Is a wicker bowl a “decorative bowl” if it’s full of apples? What color is leopard print?""

Over the past six months, I spoke with more than two dozen annotators from around the world, and while many of them were training cutting-edge chatbots, just as many were doing the mundane manual labor required to keep AI running. There are people classifying the emotional content of TikTok videos, new variants of email spam, and the precise sexual provocativeness of online ads. Others are looking at credit-card transactions and figuring out what sort of purchase they relate to or checking e-commerce recommendations and deciding whether that shirt is really something you might like after buying that other shirt. Humans are correcting customer-service chatbots, listening to Alexa requests, and categorizing the emotions of people on video calls. They are labeling food so that smart refrigerators don’t get confused by new packaging, checking automated security cameras before sounding alarms, and identifying corn for baffled autonomous tractors.

“There’s an entire supply chain,” said Sonam Jindal, the program and research lead of the nonprofit Partnership on AI. “The general perception in the industry is that this work isn’t a critical part of development and isn’t going to be needed for long. All the excitement is around building artificial intelligence, and once we build that, it won’t be needed anymore, so why think about it? But it’s infrastructure for AI. Human intelligence is the basis of artificial intelligence, and we need to be valuing these as real jobs in the AI economy that are going to be here for a while.”

The data vendors behind familiar names like OpenAI, Google, and Microsoft come in different forms. There are private outsourcing companies with call-center-like offices, such as the Kenya- and Nepal-based CloudFactory, where Joe annotated for $1.20 an hour before switching to Remotasks. There are also “crowdworking” sites like Mechanical Turk and Clickworker where anyone can sign up to perform tasks. In the middle are services like Scale AI. Anyone can sign up, but everyone has to pass qualification exams and training courses and undergo performance monitoring. Annotation is big business. Scale, founded in 2016 by then-19-year-old Alexandr Wang, was valued in 2021 at $7.3 billion, making him what Forbes called “the youngest self-made billionaire,” though the magazine noted in a recent profile that his stake has fallen on secondary markets since then.

[Image: https://cdn.vox-cdn.com/thumbor/tzXNAIWOaBlv7KbHabZQPNgOKvU=/0x0:2048x1500/2048x1500/filters:focal(1024x750:1025x751)/cdn.vox-cdn.com/uploads/chorus_asset/file/24738135/236709_ai_data_notation_labor_scale_surge_remotasks_openai_chatbots_RParry_003_2.jpg]

This tangled supply chain is deliberately hard to map. According to people in the industry, the companies buying the data demand strict confidentiality. (This is the reason Scale cited to explain why Remotasks has a different name.) Annotation reveals too much about the systems being developed, and the huge number of workers required makes leaks difficult to prevent. Annotators are warned repeatedly not to tell anyone about their jobs, not even their friends and co-workers, but corporate aliases, project code names, and, crucially, the extreme division of labor ensure they don’t have enough information about them to talk even if they wanted to. (Most workers requested pseudonyms for fear of being booted from the platforms.) Consequently, there are no granular estimates of the number of people who work in annotation, but it is a lot, and it is growing. A recent Google Research paper gave an order-of-magnitude figure of “millions” with the potential to become “billions.”

Automation often unfolds in unexpected ways. Erik Duhaime, CEO of medical-data-annotation company Centaur Labs, recalled how, several years ago, prominent machine-learning engineers were predicting AI would make the job of radiologist obsolete. When that didn’t happen, conventional wisdom shifted to radiologists using AI as a tool. Neither of those is quite what he sees occurring. AI is very good at specific tasks, Duhaime said, and that leads work to be broken up and distributed across a system of specialized algorithms and to equally specialized humans. An AI system might be capable of spotting cancer, he said, giving a hypothetical example, but only in a certain type of imagery from a certain type of machine; so now, you need a human to check that the AI is being fed the right type of data and maybe another human who checks its work before passing it to another AI that writes a report, which goes to another human, and so on. “AI doesn’t replace work,” he said. “But it does change how work is organized.”

You might miss this if you believe AI is a brilliant, thinking machine. But if you pull back the curtain even a little, it looks more familiar, the latest iteration of a particularly Silicon Valley division of labor, in which the futuristic gleam of new technologies hides a sprawling manufacturing apparatus and the people who make it run. Duhaime reached back farther for a comparison, a digital version of the transition from craftsmen to industrial manufacturing: coherent processes broken into tasks and arrayed along assembly lines with some steps done by machines and some by humans but none resembling what came before.

Worries about AI-driven disruption are often countered with the argument that AI automates tasks, not jobs, and that these tasks will be the dull ones, leaving people to pursue more fulfilling and human work. But just as likely, the rise of AI will look like past labor-saving technologies, maybe like the telephone or typewriter, which vanquished the drudgery of message delivering and handwriting but generated so much new correspondence, commerce, and paperwork that new offices staffed by new types of workers — clerks, accountants, typists — were required to manage it. When AI comes for your job, you may not lose it, but it might become more alien, more isolating, more tedious.

---

Earlier this year, I signed up for Scale AI’s Remotasks. The process was straightforward. After entering my computer specs, internet speed, and some basic contact information, I found myself in the “training center.” To access a paying task, I first had to complete an associated (unpaid) intro course.

The training center displayed a range of courses with inscrutable names like Glue Swimsuit and Poster Macadamia. I clicked on something called GFD Chunking, which revealed itself to be labeling clothing in social-media photos.

The instructions, however, were odd. For one, they basically consisted of the same direction reiterated in the idiosyncratically colored and capitalized typography of a collaged bomb threat.

“DO LABEL items that are real and can be worn by humans or are intended to be worn by real people,” it read.

“All items below SHOULD be labeled because they are real and can be worn by real-life humans,” it reiterated above photos of an Air Jordans ad, someone in a Kylo Ren helmet, and mannequins in dresses, over which was a lime-green box explaining, once again, “DO Label real items that can be worn by real people.”

[Image: Remotasks instructions for labeling clothing. https://cdn.vox-cdn.com/thumbor/MHHrTeYM1ECpMGl9kVhgPdVy6QM=/0x0:2083x2083/2083x2083/filters:focal(1042x1042:1043x1043)/cdn.vox-cdn.com/uploads/chorus_asset/file/24737331/AI_Secondary.jpeg]

I skimmed to the bottom of the manual, where the instructor had written in the large bright-red font equivalent of grabbing someone by the shoulders and shaking them, “THE FOLLOWING ITEMS SHOULD NOT BE LABELED because a human could not actually put wear any of these items!” above a photo of C-3PO, Princess Jasmine from Aladdin, and a cartoon shoe with eyeballs.

Feeling confident in my ability to distinguish between real clothes that can be worn by real people and not-real clothes that cannot, I proceeded to the test. Right away, it threw an ontological curveball: a picture of a magazine depicting photos of women in dresses. Is a photograph of clothing real clothing? No, I thought, because a human cannot wear a photograph of clothing. Wrong! As far as AI is concerned, photos of real clothes are real clothes. Next came a photo of a woman in a dimly lit bedroom taking a selfie before a full-length mirror. The blouse and shorts she’s wearing are real. What about their reflection? Also real! Reflections of real clothes are also real clothes.

After an embarrassing amount of trial and error, I made it to the actual work, only to make the horrifying discovery that the instructions I’d been struggling to follow had been updated and clarified so many times that they were now a full 43 printed pages of directives: Do NOT label open suitcases full of clothes; DO label shoes but do NOT label flippers; DO label leggings but do NOT label tights; do NOT label towels even if someone is wearing it; label costumes but do NOT label armor. And so on.

There has been general instruction disarray across the industry, according to Milagros Miceli, a researcher at the Weizenbaum Institute in Germany who studies data work. It is in part a product of the way machine-learning systems learn. Where a human would get the concept of “shirt” with a few examples, machine-learning programs need thousands, and they need to be categorized with perfect consistency yet varied enough (polo shirts, shirts being worn outdoors, shirts hanging on a rack) that the very literal system can handle the diversity of the real world. “Imagine simplifying complex realities into something that is readable for a machine that is totally dumb,” she said.

""Once, Victor stayed up 36 hours straight labeling elbows and knees and heads in photographs of crowds — he has no idea why.""

The act of simplifying reality for a machine results in a great deal of complexity for the human. Instruction writers must come up with rules that will get humans to categorize the world with perfect consistency. To do so, they often create categories no human would use. A human asked to tag all the shirts in a photo probably wouldn’t tag the reflection of a shirt in a mirror because they would know it is a reflection and not real. But to the AI, which has no understanding of the world, it’s all just pixels and the two are perfectly identical. Fed a dataset with some shirts labeled and other (reflected) shirts unlabeled, the model won’t work. So the engineer goes back to the vendor with an update: DO label reflections of shirts. Soon, you have a 43-page guide descending into red all-caps.

“When you start off, the rules are relatively simple,” said a former Scale employee who requested anonymity because of an NDA. “Then they get back a thousand images and then they’re like, Wait a second, and then you have multiple engineers and they start to argue with each other. It’s very much a human thing.”

The job of the annotator often involves putting human understanding aside and following instructions very, very literally — to think, as one annotator said, like a robot. It’s a strange mental space to inhabit, doing your best to follow nonsensical but rigorous rules, like taking a standardized test while on hallucinogens. Annotators invariably end up confronted with confounding questions like, Is that a red shirt with white stripes or a white shirt with red stripes? Is a wicker bowl a “decorative bowl” if it’s full of apples? What color is leopard print? When instructors said to label traffic-control directors, did they also mean to label traffic-control directors eating lunch on the sidewalk? Every question must be answered, and a wrong guess could get you banned and booted to a new, totally different task with its own baffling rules.

[Image: https://cdn.vox-cdn.com/thumbor/kQBljfwrhkJGYtW8XWVY30BSM1k=/0x0:2048x1737/2048x1737/filters:focal(1024x869:1025x870)/cdn.vox-cdn.com/uploads/chorus_asset/file/24738137/236709_ai_data_notation_labor_scale_surge_remotasks_openai_chatbots_RParry_005_2.jpg]

Most of the work on Remotasks is paid at a piece rate with a single task earning anywhere from a few cents to several dollars. Because tasks can take seconds or hours, wages are hard to predict. When Remotasks first arrived in Kenya, annotators said it paid relatively well — averaging about $5 to $10 per hour depending on the task — but the amount fell as time went on.

Scale AI spokesperson Anna Franko said that the company’s economists analyze the specifics of a project, the skills required, the regional cost of living, and other factors “to ensure fair and competitive compensation.” Former Scale employees also said pay is determined through a surge-pricing-like mechanism that adjusts for how many annotators are available and how quickly the data is needed.

According to workers I spoke with and job listings, U.S.-based Remotasks annotators generally earn between $10 and $25 per hour, though some subject-matter experts can make more. By the beginning of this year, pay for the Kenyan annotators I spoke with had dropped to between $1 and $3 per hour.

That is, when they were making any money at all. The most common complaint about Remotasks work is its variability; it’s steady enough to be a full-time job for long stretches but too unpredictable to rely on. Annotators spend hours reading instructions and completing unpaid trainings only to do a dozen tasks and then have the project end. There might be nothing new for days, then, without warning, a totally different task appears and could last anywhere from a few hours to weeks. Any task could be their last, and they never know when the next one will come.

This boom-and-bust cycle results from the cadence of AI development, according to engineers and data vendors. Training a large model requires an enormous amount of annotation followed by more iterative updates, and engineers want it all as fast as possible so they can hit their target launch date. There may be monthslong demand for thousands of annotators, then for only a few hundred, then for a dozen specialists of a certain type, and then thousands again. “The question is, Who bears the cost for these fluctuations?” said Jindal of Partnership on AI. “Because right now, it’s the workers.”

""“I really am wasting my life here if I made somebody a billionaire and I’m earning a couple of bucks a week.”""

To succeed, annotators work together. When I told Victor, who started working for Remotasks while at university in Nairobi, about my struggles with the traffic-control-directors task, he told me everyone knew to stay away from that one: too tricky, bad pay, not worth it. Like a lot of annotators, Victor uses unofficial WhatsApp groups to spread the word when a good task drops. When he figures out a new one, he starts impromptu Google Meets to show others how it’s done. Anyone can join and work together for a time, sharing tips. “It’s a culture we have developed of helping each other because we know when on your own, you can’t know all the tricks,” he said.

Because work appears and vanishes without warning, taskers always need to be on alert. Victor has found that projects pop up very late at night, so he is in the habit of waking every three hours or so to check his queue. When a task is there, he’ll stay awake as long as he can to work. Once, he stayed up 36 hours straight labeling elbows and knees and heads in photographs of crowds — he has no idea why. Another time, he stayed up so long his mother asked him what was wrong with his eyes. He looked in the mirror to discover they were swollen.

Annotators generally know only that they are training AI for companies located vaguely elsewhere, but sometimes the veil of anonymity drops — instructions mentioning a brand or a chatbot say too much. “I read and I Googled and found I am working for a 25-year-old billionaire,” said one worker, who, when we spoke, was labeling the emotions of people calling to order Domino’s pizza. “I really am wasting my life here if I made somebody a billionaire and I’m earning a couple of bucks a week.”

Victor is a self-proclaimed “fanatic” about AI and started annotating because he wants to help bring about a fully automated post-work future. But earlier this year, someone dropped a Time story into one of his WhatsApp groups about workers training ChatGPT to recognize toxic content who were getting paid less than $2 an hour by the vendor Sama AI. “People were angry that these companies are so profitable but paying so poorly,” Victor said. He was unaware until I told him about Remotasks’ connection to Scale. Instructions for one of the tasks he worked on were nearly identical to those used by OpenAI, which meant he had likely been training ChatGPT as well, for approximately $3 per hour.

“I remember that someone posted that we will be remembered in the future,” he said. “And somebody else replied, ‘We are being treated worse than foot soldiers. We will be remembered nowhere in the future.’ I remember that very well. Nobody will recognize the work we did or the effort we put in.”

---

Identifying clothing and labeling customer-service conversations are just some of the annotation gigs available. Lately, the hottest on the market has been chatbot trainer. Because it demands specific areas of expertise or language fluency and wages are often adjusted regionally, this job tends to pay better. Certain types of specialist annotation can go for $50 or more per hour.

A woman I’ll call Anna was searching for a job in Texas when she stumbled across a generic listing for online work and applied. It was Remotasks, and after passing an introductory exam, she was brought into a Slack room of 1,500 people who were training a project code-named Dolphin, which she later discovered to be Google DeepMind’s chatbot, Sparrow, one of the many bots competing with ChatGPT. Her job is to talk with it all day. At about $14 an hour, plus bonuses for high productivity, “it definitely beats getting paid $10 an hour at the local Dollar General store,” she said.

Also, she enjoys it. She has discussed science-fiction novels, mathematical paradoxes, children’s riddles, and TV shows. Sometimes the bot’s responses make her laugh; other times, she runs out of things to talk about. “Some days, my brain is just like, I literally have no idea what on earth to ask it now,” she said. “So I have a little notebook, and I’ve written about two pages of things — I just Google interesting topics — so I think I’ll be good for seven hours today, but that’s not always the case.”

Each time Anna prompts Sparrow, it delivers two responses and she picks the best one, thereby creating something called “human-feedback data.” When ChatGPT debuted late last year, its impressively natural-seeming conversational style was credited to its having been trained on troves of internet data. But the language that fuels ChatGPT and its competitors is filtered through several rounds of human annotation. One group of contractors writes examples of how the engineers want the bot to behave, creating questions followed by correct answers, descriptions of computer programs followed by functional code, and requests for tips on committing crimes followed by polite refusals. After the model is trained on these examples, yet more contractors are brought in to prompt it and rank its responses. This is what Anna is doing with Sparrow. Exactly which criteria the raters are told to use varies — honesty, or helpfulness, or just personal preference. The point is that they are creating data on human taste, and once there’s enough of it, engineers can train a second model to mimic their preferences at scale, automating the ranking process and training their AI to act in ways humans approve of. The result is a remarkably human-seeming bot that mostly declines harmful requests and explains its AI nature with seeming self-awareness.

Put another way, ChatGPT seems so human because it was trained by an AI that was mimicking humans who were rating an AI that was mimicking humans who were pretending to be a better version of an AI that was trained on human writing.

[Image: https://cdn.vox-cdn.com/thumbor/BJ1voW9GJtnRC0ZSvYAl9KHBH-c=/0x0:2048x1514/2048x1514/filters:focal(1024x757:1025x758)/cdn.vox-cdn.com/uploads/chorus_asset/file/24738136/236709_ai_data_notation_labor_scale_surge_remotasks_openai_chatbots_RParry_004_2.jpg]

This circuitous technique is called “reinforcement learning from human feedback,” or RLHF, and it’s so effective that it’s worth pausing to fully register what it doesn’t do. When annotators teach a model to be accurate, for example, the model isn’t learning to check answers against logic or external sources or about what accuracy as a concept even is. The model is still a text-prediction machine mimicking patterns in human writing, but now its training corpus has been supplemented with bespoke examples, and the model has been weighted to favor them. Maybe this results in the model extracting patterns from the part of its linguistic map labeled as accurate and producing text that happens to align with the truth, but it can also result in it mimicking the confident style and expert jargon of the accurate text while writing things that are totally wrong. There is no guarantee that the text the labelers marked as accurate is in fact accurate, and when it is, there is no guarantee that the model learns the right patterns from it.

This dynamic makes chatbot annotation a delicate process. It has to be rigorous and consistent because sloppy feedback, like marking material that merely sounds correct as accurate, risks training models to be even more convincing bullshitters. An early OpenAI and DeepMind joint project using RLHF, in this case to train a virtual robot hand to grab an item, resulted in also training the robot to position its hand between the object and its raters and wiggle around such that it only appeared to its human overseers to grab the item. Ranking a language model’s responses is always going to be somewhat subjective because it’s language. A text of any length will have multiple elements that could be right or wrong or, taken together, misleading. OpenAI researchers ran into this obstacle in another early RLHF paper. Trying to get their model to summarize text, the researchers found they agreed only 60 percent of the time that a summary was good. “Unlike many tasks in [machine learning] our queries do not have unambiguous ground truth,” they lamented.

When Anna rates Sparrow’s responses, she’s supposed to be looking at their accuracy, helpfulness, and harmlessness while also checking that the model isn’t giving medical or financial advice or anthropomorphizing itself or running afoul of other criteria. To be useful training data, the model’s responses have to be quantifiably ranked against one another: Is a bot that helpfully tells you how to make a bomb “better” than a bot that’s so harmless it refuses to answer any questions? In one DeepMind paper, when Sparrow’s makers took a turn annotating, four researchers wound up debating whether their bot had assumed the gender of a user who asked it for relationship advice. According to Geoffrey Irving, one of DeepMind’s research scientists, the company’s researchers hold weekly annotation meetings in which they rerate data themselves and discuss ambiguous cases, consulting with ethical or subject-matter experts when a case is particularly tricky.

""There are people classifying the emotional content of TikTok videos, new variants of email spam, and the precise sexual provocativeness of online ads.""

Anna often finds herself having to choose between two bad options. “Even if they’re both absolutely, ridiculously wrong, you still have to figure out which one is better and then write words explaining why,” she said. Sometimes, when both responses are bad, she’s encouraged to write a better response herself, which she does about half the time.

Because feedback data is difficult to collect, it fetches a higher price. Basic preferences of the sort Anna is producing sell for about $1 each, according to people with knowledge of the industry. But if you want to train a model to do legal research, you need someone with training in law, and this gets expensive. Everyone involved is reluctant to say how much they’re spending, but in general, specialized written examples can go for hundreds of dollars, while expert ratings can cost $50 or more. One engineer told me about buying examples of Socratic dialogues for up to $300 a pop. Another told me about paying $15 for a “darkly funny limerick about a goldfish.”

OpenAI, Microsoft, Meta, and Anthropic did not comment about how many people contribute annotations to their models, how much they are paid, or where in the world they are located. Irving of DeepMind, which is a subsidiary of Google, said the annotators working on Sparrow are paid “at least the hourly living wage” based on their location. Anna knows “absolutely nothing” about Remotasks, but Sparrow has been more open. She wasn’t the only annotator I spoke with who got more information from the AI they were training than from their employer; several others learned whom they were working for by asking their AI for its company’s terms of service. “I literally asked it, ‘What is your purpose, Sparrow?’” Anna said. It pulled up a link to DeepMind’s website and explained that it’s an AI assistant and that its creators trained it using RLHF to be helpful and safe.

---

Until recently, it was relatively easy to spot bad output from a language model. It looked like gibberish. But this gets harder as the models get better — a problem called “scalable oversight.” Google inadvertently demonstrated how hard it is to catch the errors of a modern-language model when one made it into the splashy debut of its AI assistant, Bard. (It stated confidently that the James Webb Space Telescope “took the very first pictures of a planet outside of our own solar system,” which is wrong.) This trajectory means annotation increasingly requires specific skills and expertise.

Last year, someone I’ll call Lewis was working on Mechanical Turk when, after completing a task, he received a message inviting him to apply for a platform he hadn’t heard of. It was called Taskup.ai, and its website was remarkably basic: just a navy background with text reading GET PAID FOR TASKS ON DEMAND. He applied.

The work paid far better than anything he had tried before, often around $30 an hour. It was more challenging, too: devising complex scenarios to trick chatbots into giving dangerous advice, testing a model’s ability to stay in character, and having detailed conversations about scientific topics so technical they required extensive research. He found the work “satisfying and stimulating.” While checking one model’s attempts to code in Python, Lewis was learning too. He couldn’t work for more than four hours at a stretch, lest he risk becoming mentally drained and making mistakes, and he wanted to keep the job.

“If there was one thing I could change, I would just like to have more information about what happens on the other end,” he said. “We only know as much as we need to know to get work done, but if I could know more, then maybe I could get more established and perhaps pursue this as a career.”

I spoke with eight other workers, most based in the U.S., who had similar experiences of answering surveys or completing tasks on other platforms and finding themselves recruited for Taskup.ai or several similarly generic sites, such as DataAnnotation.tech or Gethybrid.io. Often their work involved training chatbots, though with higher-quality expectations and more specialized purposes than other sites they had worked for. One was demonstrating spreadsheet macros. Another was just supposed to have conversations and rate responses according to whatever criteria she wanted. She often asked the chatbot things that had come up in conversations with her 7-year-old daughter, like “What is the largest dinosaur?” and “Write a story about a tiger.” “I haven’t fully gotten my head around what they’re trying to do with it,” she told me.

Taskup.ai, DataAnnotation.tech, and Gethybrid.io all appear to be owned by the same company: Surge AI. Its CEO, Edwin Chen, would neither confirm nor deny the connection, but he was willing to talk about his company and how he sees annotation evolving.

“I’ve always felt the annotation landscape is overly simplistic,” Chen said over a video call from Surge’s office. He founded Surge in 2020 after working on AI at Google, Facebook, and Twitter convinced him that crowdsourced labeling was inadequate. “We want AI to tell jokes or write really good marketing copy or help me out when I need therapy or whatnot,” Chen said. “You can’t ask five people to independently come up with a joke and combine it into a majority answer. Not everybody can tell a joke or solve a Python program. The annotation landscape needs to shift from this low-quality, low-skill mind-set to something that’s much richer and captures the range of human skills and creativity and values that we want AI systems to possess.”

[Image: https://cdn.vox-cdn.com/thumbor/Qe4htQ4VivRXnS0BWZowjTY8hE8=/0x0:2048x1572/2048x1572/filters:focal(1024x786:1025x787)/cdn.vox-cdn.com/uploads/chorus_asset/file/24738134/236709_ai_data_notation_labor_scale_surge_remotasks_openai_chatbots_RParry_002_2.jpg]

Last year, Surge relabeled Google’s dataset classifying Reddit posts by emotion. Google had stripped each post of context and sent them to workers in India for labeling. Surge employees familiar with American internet culture found that 30 percent of the labels were wrong. Posts like “hell yeah my brother” had been classified as annoyance and “Yay, cold McDonald’s. My favorite” as love.

Surge claims to vet its workers for qualifications — that people doing creative-writing tasks have experience with creative writing, for example — but exactly how Surge finds workers is “proprietary,” Chen said. As with Remotasks, workers often have to complete training courses, though unlike Remotasks, they are paid for it, according to the annotators I spoke with. Having fewer, better-trained workers producing higher-quality data allows Surge to compensate better than its peers, Chen said, though he declined to elaborate, saying only that people are paid “fair and ethical wages.” The workers I spoke with earned between $15 and $30 per hour, but they are a small sample of all the annotators, a group Chen said now consists of 100,000 people. The secrecy, he explained, stems from clients’ demands for confidentiality.

Surge’s customers include OpenAI, Google, Microsoft, Meta, and Anthropic. Surge specializes in feedback and language annotation, and after ChatGPT launched, it got an influx of requests, Chen said: “I thought everybody knew the power of RLHF, but I guess people just didn’t viscerally understand.”

The new models are so impressive they’ve inspired another round of predictions that annotation is about to be automated. Given the costs involved, there is significant financial pressure to do so. Anthropic, Meta, and other companies have recently made strides in using AI to drastically reduce the amount of human annotation needed to guide models, and other developers have started using GPT-4 to generate training data. However, a recent paper found that GPT-4-trained models may be learning to mimic GPT’s authoritative style with even less accuracy, and so far, when improvements in AI have made one form of annotation obsolete, demand for other, more sophisticated types of labeling has gone up. This debate spilled into the open earlier this year, when Scale’s CEO, Wang, tweeted that he predicted AI labs will soon be spending as many billions of dollars on human data as they do on computing power; OpenAI’s CEO, Sam Altman, responded that data needs will decrease as AI improves.

""“I mean, what it can do is amazing,” she said of the chatbot. “But it still does some really weird shit.”""

Chen is skeptical AI will reach a point where human feedback is no longer needed, but he does see annotation becoming more difficult as models improve. Like many researchers, he believes the path forward will involve AI systems helping humans oversee other AI. Surge recently collaborated with Anthropic on a proof of concept, having human labelers answer questions about a lengthy text with the help of an unreliable AI assistant, on the theory that the humans would have to feel out the weaknesses of their AI assistant and collaborate to reason their way to the correct answer. Another possibility has two AIs debating each other and a human rendering the final verdict on which is correct. “We still have yet to see really good practical implementations of this stuff, but it’s starting to become necessary because it’s getting really hard for labelers to keep up with the models,” said OpenAI research scientist John Schulman in a recent talk at Berkeley.

“I think you always need a human to monitor what AIs are doing just because they are this kind of alien entity,” Chen said. Machine-learning systems are just too strange ever to fully trust. The most impressive models today have what, to a human, seems like bizarre weaknesses, he added, pointing out that though GPT-4 can generate complex and convincing prose, it can’t pick out which words are adjectives: “Either that or models get so good that they’re better than humans at all things, in which case, you reach your utopia and who cares?”

---

As 2022 ended, Joe started hearing from his students that their task queues were often empty. Then he got an email informing him the boot camps in Kenya were closing. He continued training taskers online, but he began to worry about the future.

“There were signs that it was not going to last long,” he said. Annotation was leaving Kenya. From colleagues he had met online, he heard tasks were going to Nepal, India, and the Philippines. “The companies shift from one region to another,” Joe said. “They don’t have infrastructure locally, so it makes them flexible to shift to regions that favor them in terms of operation cost.”

One way the AI industry differs from manufacturers of phones and cars is in its fluidity. The work is constantly changing, constantly getting automated away and replaced with new needs for new types of data. It’s an assembly line but one that can be endlessly and instantly reconfigured, moving to wherever there is the right combination of skills, bandwidth, and wages.

Lately, the best-paying work is in the U.S. In May, Scale started listing annotation jobs on its own website, soliciting people with experience in practically every field AI is predicted to conquer. There were listings for AI trainers with expertise in health coaching, human resources, finance, economics, data science, programming, computer science, chemistry, biology, accounting, taxes, nutrition, physics, travel, K-12 education, sports journalism, and self-help. You can make $45 an hour teaching robots law or make $25 an hour teaching them poetry. There were also listings for people with security clearance, presumably to help train military AI. Scale recently launched a defense-oriented language model called Donovan, which Wang called “ammunition in the AI war,” and won a contract to work on the Army’s robotic-combat-vehicle program.

Anna is still training chatbots in Texas. Colleagues have been turned into reviewers and Slack admins — she isn’t sure why, but it has given her hope that the gig could be a longer-term career. One thing she isn’t worried about is being automated out of a job. “I mean, what it can do is amazing,” she said of the chatbot. “But it still does some really weird shit.”

When Remotasks first arrived in Kenya, Joe thought annotation could be a good career. Even after the work moved elsewhere, he was determined to make it one. There were thousands of people in Nairobi who knew how to do the work, he reasoned — he had trained many of them, after all. Joe rented office space in the city and began sourcing contracts: a job annotating blueprints for a construction company, another labeling fruits despoiled by insects for some sort of agricultural project, plus the usual work of annotating for self-driving cars and e-commerce.

But he has found his vision difficult to achieve. He has just one full-time employee, down from two. “We haven’t been having a consistent flow of work,” he said. There are weeks with nothing to do because customers are still collecting data, and when they’re done, he has to bring in short-term contractors to meet their deadlines: “Clients don’t care whether we have consistent work or not. So long as the datasets have been completed, then that’s the end of that.”

Rather than let their skills go to waste, other taskers decided to chase the work wherever it went. They rented proxy servers to disguise their locations and bought fake IDs to pass security checks so they could pretend to work from Singapore, the Netherlands, Mississippi, or wherever the tasks were flowing. It’s a risky business. Scale has become increasingly aggressive about suspending accounts caught disguising their location, according to multiple taskers. It was during one of these crackdowns that my account got banned, presumably because I had been using a VPN to see what workers in other countries were seeing, and all $1.50 or so of my earnings were seized.

“These days, we have become a bit cunning because we noticed that in other countries they are paying well,” said Victor, who was earning double the Kenyan rate by tasking in Malaysia. “You do it cautiously.”

Another Kenyan annotator said that after his account got suspended for mysterious reasons, he decided to stop playing by the rules. Now, he runs multiple accounts in multiple countries, tasking wherever the pay is best. He works fast and gets high marks for quality, he said, thanks to ChatGPT. The bot is wonderful, he said, letting him speed through $10 tasks in a matter of minutes. When we spoke, he was having it rate another chatbot’s responses according to seven different criteria, one AI training the other.
",,"{'@type': 'Organization', 'name': 'The Verge', 'logo': {'@type': 'ImageObject', 'url': 'https://cdn.vox-cdn.com/uploads/chorus_asset/file/24015294/verge_duet_google_news.png', 'width': 250, 'height': 50}}",,,,https://www.theverge.com/features/23764584/ai-artificial-intelligence-data-notation-labor-scale-surge-remotasks-openai-chatbots,https://cdn.vox-cdn.com/thumbor/MFiURNjiF1enowJ5t0oyd0gkPlU=/0x0:2048x1365/1400x788/filters:focal(1024x683:1025x684)/cdn.vox-cdn.com/uploads/chorus_asset/file/24737787/236709_ai_data_notation_labor_scale_surge_remotasks_openai_chatbots_RParry_001.jpg,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
https://news.google.com/rss/articles/CBMiX2h0dHBzOi8vc2xvYW5yZXZpZXcubWl0LmVkdS9hcnRpY2xlL3RoZS1pbXBhY3Qtb2YtZ2VuZXJhdGl2ZS1haS1vbi1ob2xseXdvb2QtYW5kLWVudGVydGFpbm1lbnQv0gEA?oc=5,The Impact of Generative AI on Hollywood and Entertainment - MIT Sloan Management Review,2023-06-19,MIT Sloan Management Review,https://sloanreview.mit.edu,"New AI tools can produce text, audio, and images. What does that mean for creative professionals? Two experts weigh in.",N/A,"New AI tools can produce text, audio, and images. What does that mean for creative professionals? Two experts weigh in.","New AI tools can produce text, audio, and images. What does that mean for creative professionals? Two experts weigh in.",N/A,N/A,"


AI in Action The Impact of Generative AI on Hollywood and Entertainment

 



Thomas H. Davenport and Randy Bean

June 19, 2023

Reading Time: 7 min 





Topics


Data, AI, & Machine Learning


Managing Technology


AI & Machine Learning


IT Governance & Leadership




AI in Action

            This column series looks at the biggest data and analytics challenges facing modern companies and dives deep into successful use cases that can help other organizations accelerate their AI progress.        

              
           More in this series
                      




 subscribe-icon

Subscribe
 










Share



 Twitter



Facebook







Linkedin










What to Read Next

 Three Questions to Ask About Your Digital Strategy
 How Auditor Working Conditions Limit Supply Chain Transparency
 Where To Next? Opportunity on the Edge
 Will AI Help or Hurt Sustainability? Yes | Andrew Winston













Carolyn Geason-Beissel/MIT SMR | Getty Images

One of the many topics involving generative AI that is receiving a lot of attention is its potential effects on Hollywood and the entertainment industry. It’s an obvious concern because generative AI can create the types of outputs that the industry uses — text (in the form of stories, scripts, ad copy, and reviews), marketing campaigns, and moving and static images. Segments of the industry are facing economic pressures, which increases the demand for productivity and less-expensive “product.” And a high percentage of current entertainment is derivative of past content, which makes it well suited for generative technologies that are trained on … past content. 
It’s still early days for generative AI-created entertainment, but it’s clear that something big is happening. A recent Wall Street Journal article noted that widely available AI tools can suggest storylines, character arcs, and dialogue; it even includes an interactive module that lets readers see for themselves how easily ChatGPT can write a basic script when given a few prompts. The article also raises questions about image intellectual property: “If a user prompts an AI tool to build a new character influenced by say, SpongeBob, should the original creators have to grant permission? Who owns it? Can the new work itself be copyrighted?” 


Get Updates on Leading With AI and Data

Get monthly insights on how artificial intelligence impacts your organization and what it means for your company and customers.


















                sign up            




Please enter a valid email address
Thank you for signing up
Privacy Policy


Generative AI was used in making the 2022 film Everything Everywhere All at Once, and we know how that turned out. Tom recently wrote about the use of generative AI to create movie and TV backdrop images. There are already generative AI systems that can create videos, although they are short and relatively primitive. AI is being used to provide data-driven predictions about how unusual storylines will land with viewers.
So, what does this mean for the industry? There are many different components to this question, as a new report from Variety Intelligence Platform suggests. In May, the Writers Guild of America (WGA) went on strike, primarily over film and TV writers’ income from streaming services programming, but it also demanded that production companies “regulate use of material produced using artificial intelligence or similar technologies.” Because there are so many uncertainties about what will happen when and how with the technology, we spoke with two experts on the topic. Both are based in — not surprisingly — Los Angeles, and both are involved with centers at the University of Southern California (USC). However, they don’t work together, and they have very different approaches to the technology. 









Resolutely Against Generative AI
Jonathan Taplin is director emeritus at the Annenberg Innovation Lab at USC. He’s had a long career in the entertainment industry and was previously a tour manager for musicians, including Bob Dylan and The Band. In addition, he’s been a film producer, a banker, and a writer. His latest book, The End of Reality: How Four Billionaires Are Selling a Fantasy Future of the Metaverse, Mars, and Crypto, will be released in September. As you might infer from the title, he’s not a fan of how big tech firms’ generative AI tools are being developed or promulgated. 
“The way they train their models is by ingesting everything on the internet, with no concern for copyright,” Taplin told us. “Google has a music-generation AI trained on every audio file on YouTube. You can issue a prompt like ‘Write me a song that sounds like Taylor Swift, sad ending, up-tempo,’ and the resulting song sounds somewhat like her. Someone could include it in a video game or a bar scene in a movie for free.” Generative AI could do the same kind of repurposing with video content owned by the studios, he added. 
Taplin’s primary concern is that generative AI will replace some of the work done by human writers, artists, photographers, and other creative professionals in the arts and entertainment industry. He also believes that it will exacerbate problems that are already bringing the film and TV industry down. “The biggest problem in the movies is too many formulas. There is a lack of originality, and that’s why the industry isn’t performing,” he said. Generative AI, he added, is only capable of producing even more formulaic content and will make the predictability worse. “Entertainment relies on new ideas, and this technology can’t produce them,” Taplin added.
He said he’s concerned that generative AI will continue to reduce the number of performers who can make a living in their fields. The majority of entertainment revenue already goes to a very small percentage of artists. This is the reality for musicians, especially on streaming services, and is echoed in Hollywood in the huge box office revenues generated by a handful of leading actors in blockbuster films. When you get an “algorithmic economy,” Taplin said, “the algorithms narrow the funnel, with outsize paychecks for a few.” He’s hopeful that a collective licensing regime — similar to what’s in place for music sampling — will emerge to protect artists when their content is used to train generative AI. 
Embracing Generative AI, With Some Concerns
Yves Bergquist is director of the AI & Neuroscience in Media Project at USC’s Entertainment Technology Center, which is funded by Hollywood studios. You can guess that his opinion of generative AI is probably much more favorable than Taplin’s. It is, although he said he does have some concerns about AI’s potential effects on the media and entertainment industry: “It’s a completely revolutionary technology” characterized by misinformation and “some insanity.” 
We asked Bergquist whether movie studios would embrace generative AI. Parts of them are already doing so, he said. “Some groups within the studios are highly technologically savvy, such as the chief technology officers and all of the visual effects artists and technicians. They are very sophisticated and are already working with generative AI companies. The studios do a lot of the postproduction work in films — particularly in animation — and there is a lot of pressure to bring costs down. The postproduction companies have a software development culture, so they will embrace generative AI.”
He also believes that many production companies will embrace the technology because they are already shooting on large LED-based screens and will need generative images for them. Bergquist said he expects that tools offering virtual actors and voice synthesis will be most aggressively adopted by short-form creators who distribute their work on TikTok or YouTube and by video game producers. “Streaming channels, digital ads, games — that’s what kids watch these days,” he noted. “The media industry no longer has a monopoly on entertainment.” Makers of hardware (such as cameras) are experimenting with generative in-camera visual effects as well.


					“The postproduction companies have a software development culture, so they will embrace generative AI.”
					Yves BergquistEntertainment Technology Center, USC
The business side of traditional movie studios is sometimes more reluctant to embrace AI, Bergquist observed, simply because they don’t have the same kind of culture of data or software. “It’s being bolted onto organizations and people who aren’t ready,” he said. Even the new streaming studios, like Netflix and Prime Video, have experienced a lot of growing pains in their AI journeys. 
Bergquist said that before the WGA strike started in May, many screenwriters told him that they view the likes of ChatGPT as a “great creative assistant tool” but not something that will replace human writers. “It’s good at brainstorming ideas, but it will output only average content,” Bergquist asserted. “It’s nowhere near capable of the symbolic abstraction necessary for script development, and it can’t output a script with narrative structure and character arcs.” At least not now. Future language models with higher levels of intelligence and new paradigms for AI might be able to do so.
Related Articles         Five Key Trends in AI and Data Science for 2024 | Thomas H. Davenport and Randy Bean              Generative AI at Mastercard: Governance Takes Center Stage | Thomas H. Davenport and Randy Bean              Mayo Clinic’s Healthy Model for AI Success | Thomas H. Davenport and Randy Bean              AI Ethics at Unilever: From Policy to Process | Thomas H. Davenport and Randy Bean     
Bergquist thinks generative AI will have enormous effects not only on entertainment but also on education. He believes that schools, including the School of Cinematic Arts at USC, need to quickly ramp up their teaching to keep pace with the frenzy of new generative AI tools that are released nearly every week. Bergquist is preparing courses himself on the technology for the Society of Motion Pictures and Television Engineers, an organization that represents technologists in media.
Are Both Experts Right?
Although Taplin and Bergquist seem to have very different views on generative AI, they might both be right about its impacts. Economic pressures may entice the industry — at least some sectors of it — to embrace these new tools. Generative AI will lead to dramatic changes in production and postproduction, distribution, and intellectual property ownership. The technology may not be good for traditional artists and the companies that employ them, but it is likely to lead to significant changes in the industry over the next few years — hopefully some for the better along with some for the worse. Perhaps the only purely good news is that neither expert expects that humans will be entirely replaced anytime soon. 












Topics


Data, AI, & Machine Learning


Managing Technology


AI & Machine Learning


IT Governance & Leadership




AI in Action

            This column series looks at the biggest data and analytics challenges facing modern companies and dives deep into successful use cases that can help other organizations accelerate their AI progress.        

              
           More in this series
                      



About the Authors
Thomas H. Davenport (@tdav) is the President’s Distinguished Professor of Information Technology and Management at Babson College, a visiting professor at Oxford’s Saïd Business School, and a fellow of the MIT Initiative on the Digital Economy. He is coauthor of Working With AI: Real Stories of Human-Machine Collaboration (MIT Press, 2022). Randy Bean (@randybeannvp) is an industry thought leader, author, founder, and CEO and currently serves as innovation fellow, data strategy for global consultancy Wavestone. He is the author of Fail Fast, Learn Faster: Lessons in Data-Driven Leadership in an Age of Disruption, Big Data, and AI (Wiley, 2021).



Tags: 

AI Strategy
Analytics & Organizational Culture
Artificial Intelligence
Generative AI
Knowledge Workers





More Like This
         Will AI Help or Hurt Sustainability? Yes | Andrew Winston                How Auditor Working Conditions Limit Supply Chain Transparency                Three Questions to Ask About Your Digital Strategy              Banish the Harmful Creatures of COVID-Era Work | Melissa Swift     
 


Add a comment Cancel replyYou must sign in to post a comment.First time here? Sign up for a free account: Comment on articles and get access to many more articles. 

",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
https://news.google.com/rss/articles/CBMiR2h0dHBzOi8vYmVybmFyZG1hcnIuY29tL2Etc2ltcGxlLWd1aWRlLXRvLXRoZS1oaXN0b3J5LW9mLWdlbmVyYXRpdmUtYWkv0gEA?oc=5,A Simple Guide To The History Of Generative AI - Bernard Marr,2023-06-16,Bernard Marr,https://bernardmarr.com,"Unlike traditional AI systems that follow predetermined patterns and rules, Generative AI has the unique ability to create.",N/A,"Unlike traditional AI systems that follow predetermined patterns and rules, Generative AI has the unique ability to create.",N/A,N/A,N/A,N/A,https://schema.org,,,,,,,,,,,,,,,,,,,"[{'@type': 'Article', '@id': 'https://bernardmarr.com/a-simple-guide-to-the-history-of-generative-ai/#article', 'isPartOf': {'@id': 'https://bernardmarr.com/a-simple-guide-to-the-history-of-generative-ai/'}, 'author': {'name': 'Bernard Marr', '@id': 'https://bernardmarr.com/#/schema/person/b3c3cb90b331ffc7b13f30fc74daead0'}, 'headline': 'A Simple Guide To The History Of Generative AI', 'datePublished': '2023-06-16T08:07:55+00:00', 'dateModified': '2023-06-16T08:10:20+00:00', 'mainEntityOfPage': {'@id': 'https://bernardmarr.com/a-simple-guide-to-the-history-of-generative-ai/'}, 'wordCount': 1886, 'commentCount': 0, 'publisher': {'@id': 'https://bernardmarr.com/#organization'}, 'image': {'@id': 'https://bernardmarr.com/a-simple-guide-to-the-history-of-generative-ai/#primaryimage'}, 'thumbnailUrl': 'https://bernardmarr.com/wp-content/uploads/2023/06/A-Simple-Guide-To-The-History-Of-Generative-AI.jpg', 'keywords': ['Articles'], 'articleSection': ['AR, VR, MR &amp; The Metaverse', 'Artificial Intelligence &amp; Machine Learning', 'Early Tech Innovations', 'IT Perspective'], 'inLanguage': 'en-GB', 'potentialAction': [{'@type': 'CommentAction', 'name': 'Comment', 'target': ['https://bernardmarr.com/a-simple-guide-to-the-history-of-generative-ai/#respond']}]}, {'@type': 'WebPage', '@id': 'https://bernardmarr.com/a-simple-guide-to-the-history-of-generative-ai/', 'url': 'https://bernardmarr.com/a-simple-guide-to-the-history-of-generative-ai/', 'name': 'A Simple Guide To The History Of Generative AI | Bernard Marr', 'isPartOf': {'@id': 'https://bernardmarr.com/#website'}, 'primaryImageOfPage': {'@id': 'https://bernardmarr.com/a-simple-guide-to-the-history-of-generative-ai/#primaryimage'}, 'image': {'@id': 'https://bernardmarr.com/a-simple-guide-to-the-history-of-generative-ai/#primaryimage'}, 'thumbnailUrl': 'https://bernardmarr.com/wp-content/uploads/2023/06/A-Simple-Guide-To-The-History-Of-Generative-AI.jpg', 'datePublished': '2023-06-16T08:07:55+00:00', 'dateModified': '2023-06-16T08:10:20+00:00', 'description': 'Unlike traditional AI systems that follow predetermined patterns and rules, Generative AI has the unique ability to create.', 'breadcrumb': {'@id': 'https://bernardmarr.com/a-simple-guide-to-the-history-of-generative-ai/#breadcrumb'}, 'inLanguage': 'en-GB', 'potentialAction': [{'@type': 'ReadAction', 'target': ['https://bernardmarr.com/a-simple-guide-to-the-history-of-generative-ai/']}]}, {'@type': 'ImageObject', 'inLanguage': 'en-GB', '@id': 'https://bernardmarr.com/a-simple-guide-to-the-history-of-generative-ai/#primaryimage', 'url': 'https://bernardmarr.com/wp-content/uploads/2023/06/A-Simple-Guide-To-The-History-Of-Generative-AI.jpg', 'contentUrl': 'https://bernardmarr.com/wp-content/uploads/2023/06/A-Simple-Guide-To-The-History-Of-Generative-AI.jpg', 'width': 1400, 'height': 934}, {'@type': 'BreadcrumbList', '@id': 'https://bernardmarr.com/a-simple-guide-to-the-history-of-generative-ai/#breadcrumb', 'itemListElement': [{'@type': 'ListItem', 'position': 1, 'name': 'Home', 'item': 'https://bernardmarr.com/'}, {'@type': 'ListItem', 'position': 2, 'name': 'A Simple Guide To The History Of Generative AI'}]}, {'@type': 'WebSite', '@id': 'https://bernardmarr.com/#website', 'url': 'https://bernardmarr.com/', 'name': 'Bernard Marr', 'description': 'Intelligent Business Performance', 'publisher': {'@id': 'https://bernardmarr.com/#organization'}, 'potentialAction': [{'@type': 'SearchAction', 'target': {'@type': 'EntryPoint', 'urlTemplate': 'https://bernardmarr.com/?s={search_term_string}'}, 'query-input': 'required name=search_term_string'}], 'inLanguage': 'en-GB'}, {'@type': 'Organization', '@id': 'https://bernardmarr.com/#organization', 'name': 'Bernard Marr', 'url': 'https://bernardmarr.com/', 'logo': {'@type': 'ImageObject', 'inLanguage': 'en-GB', '@id': 'https://bernardmarr.com/#/schema/logo/image/', 'url': 'https://bernardmarr.com/wp-content/uploads/2021/06/Bernard-Marr-Intelligent-Business-Performance-Logo.png', 'contentUrl': 'https://bernardmarr.com/wp-content/uploads/2021/06/Bernard-Marr-Intelligent-Business-Performance-Logo.png', 'width': 337, 'height': 49, 'caption': 'Bernard Marr'}, 'image': {'@id': 'https://bernardmarr.com/#/schema/logo/image/'}, 'sameAs': ['https://en-gb.facebook.com/BernardWMarr/', 'https://x.com/BernardMarr', 'https://www.instagram.com/bernard.marr', 'https://www.linkedin.com/in/bernardmarr/', 'https://www.youtube.com/channel/UCWstLaT61QUc-TvfxOjNpFw']}, {'@type': 'Person', '@id': 'https://bernardmarr.com/#/schema/person/b3c3cb90b331ffc7b13f30fc74daead0', 'name': 'Bernard Marr', 'image': {'@type': 'ImageObject', 'inLanguage': 'en-GB', '@id': 'https://bernardmarr.com/#/schema/person/image/', 'url': 'https://secure.gravatar.com/avatar/daffd79db4879d38c053435ac089ef02?s=96&d=mm&r=g', 'contentUrl': 'https://secure.gravatar.com/avatar/daffd79db4879d38c053435ac089ef02?s=96&d=mm&r=g', 'caption': 'Bernard Marr'}, 'description': 'Bernard Marr is a world-renowned futurist, influencer and thought leader in the field of business and technology. He is the author of 18 best-selling books, writes a regular column for Forbes and advises and coaches many of the world’s best-known organisations. He has 2 million social media followers and was ranked by LinkedIn as one of the top 5 business influencers in the world and the No 1 influencer in the UK.', 'sameAs': ['https://bernardmarr.com/', 'https://en-gb.facebook.com/BernardWMarr/', 'https://www.instagram.com/bernard.marr', 'https://www.linkedin.com/in/bernardmarr/', 'https://x.com/BernardMarr', 'https://www.youtube.com/channel/UCWstLaT61QUc-TvfxOjNpFw'], 'url': 'https://bernardmarr.com/author/123internet/'}]",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
https://news.google.com/rss/articles/CBMidGh0dHBzOi8vd3d3LmJ1c2luZXNzaW5zaWRlci5jb20vZ2VuZXJhdGl2ZS1haS1hcnRpZmljaWFsLWludGVsbGlnZW5jZS1qb2JzLXdvcmstY2FyZWVycy1oaWdoLWVhcm5lcnMtbWNraW5zZXktMjAyMy020gF4aHR0cHM6Ly93d3cuYnVzaW5lc3NpbnNpZGVyLmNvbS9nZW5lcmF0aXZlLWFpLWFydGlmaWNpYWwtaW50ZWxsaWdlbmNlLWpvYnMtd29yay1jYXJlZXJzLWhpZ2gtZWFybmVycy1tY2tpbnNleS0yMDIzLTY_YW1w?oc=5,Generative AI could have biggest impacts on high earners: McKinsey - Business Insider,2023-06-16,Business Insider,https://www.businessinsider.com,"Recent generative AI iterations have focused on improving the cognitive skills needed for knowledge work in high-paid jobs, McKinsey's analysts wrote.","AI, Artificial Intelligence, Tech, Technology","Recent generative AI iterations have focused on improving the cognitive skills needed for knowledge work in high-paid jobs, McKinsey's analysts wrote.",N/A,N/A,N/A,"




                                    Tech
                                  
 
Generative AI could have the biggest impacts on high earners, not people in low-paid jobs, McKinsey analysis finds








Grace Dean 
Jun 16, 2023, 7:46 AM EDT 







Share icon
An curved arrow pointing right.

 Share





Facebook Icon
The letter F.


Facebook
 



Email icon
An envelope. It indicates the ability to send an email.


Email
 



Twitter icon
A stylized bird with an open mouth, tweeting.


Twitter
 



LinkedIn icon


LinkedIn
 



Link icon
An image of a chain link. It symobilizes a website link url.


Copy Link
 





lighning bolt icon
An icon in the shape of a lightning bolt.

 
Impact Link

 
 



Save Article Icon
A bookmark

 Save





 
                                    Read in app
                                













Angle down icon
An icon in the shape of an angle pointing down.

 

The McKinsey analysts said generative AI would have ""a significant impact across all industry sectors.""
 
                            Maskot/Getty Images
                          





This story is available exclusively to Business Insider
                      subscribers.
                      Become an Insider
                      and start reading now.
Have an account? Log in.







Generative AI could have the biggest workplace impacts on high earners, per a McKinsey report.
This is because recent iterations have focused on improving cognitive skills, the analysts wrote.
They said AI could substantially boost labor productivity but workers would need help retraining.











 


                                    Sign up to get the inside scoop on today’s biggest stories in markets, tech, and business — delivered daily. Read preview








 















Thanks for signing up!


                              Access your favorite topics in a personalized feed while you're on the go.
                              
                                download the app
                               





Email address





                                      Sign up
                                     



                                  By clicking “Sign Up”, you accept our Terms of Service and Privacy Policy. You can opt-out at any time by visiting our Preferences page or by clicking ""unsubscribe"" at the bottom of the email.
                              








 


Advertisement

Generative AI could have the biggest workplace impacts on high earners, and especially people in knowledge work with activities involving decision-making and collaboration, research by consultancy giant McKinsey has found.Because of improvements in generative AI's ability to understand natural language and advances in technical automation potential, generative AI and other technologies have the potential to automate work activities that consume between 60% and 70% of employees' time, McKinsey analysts wrote in the report. At some point between 2030 and 2060, half of today's work activities could be automated, they wrote.
This story is available exclusively to Business Insider
                            subscribers.
                            Become an Insider
                            and start reading now.
Have an account? Log in.
Generative AI creates content, which can include text, audio, images, and videos, based on a user prompt. The technology has exploded in popularity since OpenAI released its AI chatbot ChatGPT in November.People have been using generative AI for personal, professional, and academic purposes including writing letters, drafting work emails, and summarizing research for college assignments, but some critics fear it could spread misinformation, be used for malicious purposes, and take away jobs.
Advertisement

Previous generations of automation technology often had the biggest mid-term impact on occupations with lower-middle wages, the McKinsey analysts wrote. Lower-wage occupations were more immune from automation because their employers paid them lower salaries in the first place. In those cases, the cost savings of automation wouldn't be as big, whereas the skills required for higher-wage roles were harder to automate.With recent generative AI developments, however, the focus has shifted away from automating physical work activities to cognitive tasks such as decision-making and collaboration, the McKinsey analysts wrote. ""Thus, generative AI has more impact on knowledge work associated with occupations that have higher wages and educational requirements than on other types of work,"" the analysts wrote.


                                Related stories
                              


Goldman Sachs previously said generative AI systems could impact 300 million full-time jobs worldwide, with administrative and legal roles some of the most at risk.The McKinsey analysts said generative AI would have ""a significant impact across all industry sectors,"" with banking, high tech, and life sciences among the industries that could see the biggest impact as a percentage of their revenues from generative AI.
Advertisement

One way generative AI could help workers is by acting as a ""virtual expert"" who helps them quickly access internal information, the analysts wrote. One study found that when customer-service agents in the Philippines were given AI assistants, they became happier, more productive, and less likely to quit.The McKinsey analysts said AI could substantially increase labor productivity but that workers could need help moving to different work activities or even retraining to another job. ""The era of generative AI is just beginning,"" they wrote.


 







                                Read next
                              





Watch: What is ChatGPT, and should we be afraid of AI chatbots?








 



AI
Artificial Intelligence
Tech

                        More...
                      


 



 


Close icon
Two crossed lines that form an 'X'. It indicates a way to close an interaction, or dismiss a notification.
                    



",http://schema.org,BreadcrumbList,Generative AI could have biggest impacts on high earners: McKinsey,2023-06-16T11:46:49Z,2023-06-16T19:20:40Z,False,,"Generative AI could have the biggest impacts on high earners, not people in low-paid jobs, McKinsey analysi...","{'@type': 'ImageObject', 'url': 'https://i.insider.com/648c2a6120f78100189fba83?width=1136&format=jpeg', 'width': 1136, 'height': 852}","{'@type': 'Person', 'name': 'Grace Dean', 'sameAs': 'https://www.businessinsider.com/author/grace-dean'}","Generative AI could have the biggest workplace impacts on high earners, and especially people in knowledge work with activities involving decision-making and collaboration, research by consultancy giant McKinsey has found.Because of improvements in generative AI's ability to understand natural language and advances in technical automation potential, generative AI and other technologies have the potential to automate work activities that consume between 60% and 70% of employees' time, McKinsey analysts wrote in the report. At some point between 2030 and 2060, half of today's work activities could be automated, they wrote.Generative AI creates content, which can include text, audio, images, and videos, based on a user prompt. The technology has exploded in popularity since OpenAI released its AI chatbot ChatGPT in November.People have been using generative AI for personal, professional, and academic purposes including writing letters, drafting work emails, and summarizing research for college assignments, but some critics fear it could spread misinformation, be used for malicious purposes, and take away jobs.Previous generations of automation technology often had the biggest mid-term impact on occupations with lower-middle wages, the McKinsey analysts wrote. Lower-wage occupations were more immune from automation because their employers paid them lower salaries in the first place. In those cases, the cost savings of automation wouldn't be as big, whereas the skills required for higher-wage roles were harder to automate.With recent generative AI developments, however, the focus has shifted away from automating physical work activities to cognitive tasks such as decision-making and collaboration, the McKinsey analysts wrote. ""Thus, generative AI has more impact on knowledge work associated with occupations that have higher wages and educational requirements than on other types of work,"" the analysts wrote.Goldman Sachs previously said generative AI systems could impact 300 million full-time jobs worldwide, with administrative and legal roles some of the most at risk.The McKinsey analysts said generative AI would have ""a significant impact across all industry sectors,"" with banking, high tech, and life sciences among the industries that could see the biggest impact as a percentage of their revenues from generative AI.One way generative AI could help workers is by acting as a ""virtual expert"" who helps them quickly access internal information, the analysts wrote. One study found that when customer-service agents in the Philippines were given AI assistants, they became happier, more productive, and less likely to quit.The McKinsey analysts said AI could substantially increase labor productivity but that workers could need help moving to different work activities or even retraining to another job. ""The era of generative AI is just beginning,"" they wrote.",,"{'@context': 'http://schema.org', '@type': 'Organization', 'name': 'Insider', 'legalName': 'Insider Inc.', 'foundingDate': '2007', 'url': 'www.businessinsider.com', 'sameAs': ['https://www.instagram.com/insiderbusiness', 'https://www.twitter.com/businessinsider', 'https://www.facebook.com/businessinsider', 'https://www.linkedin.com/company/businessinsider', 'https://www.youtube.com/@InsiderBusiness'], 'founder': {'@type': 'Person', 'name': 'Henry Blodget'}, 'logo': {'@type': 'ImageObject', 'url': 'https://www.businessinsider.com/public/assets/logos/structured-data.png', 'width': 305, 'height': 60}}","[{'@type': 'ListItem', 'position': 1, 'item': {'@id': 'https://www.businessinsider.com/', 'name': 'Business Insider'}}, {'@type': 'ListItem', 'position': 2, 'item': {'@id': 'https://www.businessinsider.com/tech', 'name': 'Tech'}}, {'@type': 'ListItem', 'position': 3, 'item': {'@id': 'https://www.businessinsider.com/generative-ai-artificial-intelligence-jobs-work-careers-high-earners-mckinsey-2023-6', 'name': 'Generative AI could have the biggest impacts on high earners, not people in low-paid jobs, McKinsey analysis finds'}}]","Generative AI could have the biggest impacts on high earners, not people in low-paid jobs, McKinsey analysis finds",,,,"{'@type': 'WebPage', '@id': 'https://www.businessinsider.com/generative-ai-artificial-intelligence-jobs-work-careers-high-earners-mckinsey-2023-6'}",,"{'@type': 'Person', 'name': 'Grace Dean'}",Tech,"[{'@type': 'WebPageElement', 'isAccessibleForFree': False, 'cssSelector': '.content-lock-content'}]",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
https://news.google.com/rss/articles/CBMiU2h0dHBzOi8vd3d3LnpkbmV0LmNvbS9hcnRpY2xlL2dlbmVyYXRpdmUtYWktc2hvdWxkLWJlLW1vcmUtaW5jbHVzaXZlLWFzLWl0LWV2b2x2ZXMv0gEA?oc=5,"Generative AI should be more inclusive as it evolves, according to OpenAI's CEO - ZDNet",2023-06-19,ZDNet,https://www.zdnet.com,How should generative artificial intelligence (AI) tools such as ChatGPT adapt so that they can be accepted by a wider global population?,N/A,How should generative artificial intelligence (AI) tools such as ChatGPT adapt so that they can be accepted by a wider global population?,How should generative artificial intelligence (AI) tools such as ChatGPT adapt so that they can be accepted by a wider global population?,N/A,N/A,N/A,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
https://news.google.com/rss/articles/CBMicmh0dHBzOi8vd3d3LmdhcnRuZXIuY29tL2VuL25ld3Nyb29tL3ByZXNzLXJlbGVhc2VzLzIwMjMtMDYtMjAtZ2VuZXJhdGl2ZS1taWNyb2FwcHMtY2FuLWF1Z21lbnQtdGhlLWh1bWFuLXdvcmtmb3JjZdIBAA?oc=5,Generative Microapps Can Augment the Human Workforce - Gartner,2023-06-20,Gartner,https://www.gartner.com,"Generative microapps are an emerging technology that can enable organizations to demonstrate the value of generative AI while minimizing the business’s risk exposures. Generative microapps are applications that act as a proxy between a user and an LLM, such as ChatGPT or Bard.","Press Release,Q&A,Information Technology","Generative microapps can enable organizations to leverage #GenerativeAI to augment the human workforce, while minimizing risk. See more insights from Gartner's Nader Henein here. #GartnerIT #AI","Generative microapps can enable organizations to leverage #GenerativeAI to augment the human workforce, while minimizing risk. See more insights from @Gartner_inc's Nader Henein here. #GartnerIT #AI",N/A,N/A,"
Generative artificial intelligence (AI), and specifically large language models (LLMs), will change how organizations design jobs, resource tasks and allocate responsibilities across the enterprise. However, LLMs come with a unique set of risks when compared with other AI implementations. 
Generative microapps are an emerging technology that can enable organizations to demonstrate the value of generative AI while minimizing the business’s risk exposures. Generative microapps are applications that act as a proxy between a user and an LLM, such as ChatGPT or Bard.
We spoke with Nader Henein, VP Analyst at Gartner, to learn how enterprises can leverage microapps to augment knowledge workers using generative AI and boost employee productivity.
Q: How could generative microapps augment the human workforce? 
A: Gartner predicts that by 2026, 50% of office workers in Fortune 100 companies will be AI-augmented in one form or another, either to boost productivity or to raise the average quality of work.
For example, consider an LLM that is supplemented with a proprietary research database. As an author drafts a new piece of research, a microapp embedded in the word processing program would read each section and use its prebuilt prompt library to ask the LLM for examples of supporting research and data, as well as examples of contradicting research. Responses would be verified for accuracy by the microapp and then provided in the form of suggestions or comments in the word processor.
This augment would boost the author’s capabilities beyond what is humanly possible. No one person could be aware of every piece of published research in the database, but an LLM supplemented with enterprise data can provide that capability.
General-purpose microapps will become commonplace within the applications used every day in the workforce, such as word processors, email and conferencing tools. Organizations will develop specialized microapps, initially as augments for their high-value employees. These will become commoditized for all knowledge workers within a few years. A new industry focused on developing specialized generative microapps will grow and thrive. 
Q: Can you provide a bit more insight into generative microapps?
A: Rather than a user interfacing directly with an LLM, a microapp has a preprogrammed set of prompts that address a focused number of tasks on behalf of the user. There is no conversational/chat interface. The prompts are used to query the model and receive responses in a predefined format. This makes it easier for the logic within the microapp to validate each response before passing it back to the user. 
Generative microapps can be stand-alone, but in most instances, they will be embedded as extensions to productivity platforms commonly used by knowledge workers. 
Q: How do generative microapps mitigate key risks of LLMs? 
A: There are three key risks that are unique to LLMs: access control, accuracy and devaluation. Microapps address each of these:

Access control: Organizations have come to rely on access control, in which an access rule is created and applied 100% of the time. If the rule fails, the system simply denies access. However, if an LLM is supplemented with different types of enterprise data, there is no guarantee that access rules will be followed. Generative microapps act as a proxy for the enterprise LLM, so they do not allow the user to directly interact with the model through chat. As such, they cannot be coerced into exposing restricted data.


Accuracy: “Hallucinations” is the term describing how models will occasionally provide fictitious – yet confident and convincing – answers. Through rigorous prompt engineering, the preset prompts embedded in microapps can limit hallucinations. Furthermore, the microapp can enforce that the answers provided are in a format that the app can validate before passing onto the user.


Devaluation: Organizations may not be willing to pay the same amount for products and services provided by an LLM rather than a group of trained and seasoned professionals. Purpose-built microapps are developed to act as augments for knowledge workers. This will improve the average quality of the work and boost productivity, thereby helping mitigate skills shortages. Since the work is still carried out by professionals, the business model is shielded from devaluation risks. 


Additional analysis on enterprise use of generative AI will be presented during Gartner IT Symposium/Xpo, the world's most important conferences for CIOs and other IT executives. Gartner analysts and attendees will explore the technology, insights and trends shaping the future of IT and business, including how to unleash the possibility of generative AI, business transformation, cybersecurity, customer experience, data analytics, executive leadership and more. Follow news and updates from the conferences on Twitter using #GartnerSYM.
To register for a complimentary press pass to Gartner IT Symposium/Xpo, please contact meghan.rimol@gartner.com. 
Upcoming dates and locations for Gartner IT Symposium/Xpo include:
September 11-13 | Gold Coast, Australia
October 16-19 | Orlando, FL
November 6-9 | Barcelona, Spain
November 13-15 | Tokyo, Japan
November 28-30 | Kochi, India
Journalists who would like to speak with Nader regarding this topic can contact Meghan.Rimol@Gartner.com. Members of the media can reference this material in articles with proper attribution to Gartner.

",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
https://news.google.com/rss/articles/CBMiogFodHRwczovL3d3dy5leS5jb20vZW5faW4vcG9kY2FzdHMvZ2VuZXJhdGl2ZS1haS8yMDIzLzA2L2VwaXNvZGUtMS1mcm9tLWF1dG9tYXRpb24tdG8tYXVnbWVudGF0aW9uLXRoZS1yb2xlLW9mLWdlbmVyYXRpdmUtYWktaW4tc2hhcGluZy10aGUtd29ya2ZvcmNlLW9mLXRoZS1mdXR1cmXSAQA?oc=5,From automation to augmentation: The role of Generative AI in shaping the workforce of the future - EY,2023-06-19,EY,https://www.ey.com,"In our first episode of  ‘Generative AI unplugged’ podcast series, we speak to Alpana Dutta, EY EMEIA Culture and People Experience Leader on the transformative impact of Generative AI on workforce.","AI,Technology,Workforce","Explore how generative AI shapes the future workforce, from automation to augmentation, on EY&#39;s podcast. Prepare for the future. Listen now!","Explore how generative AI shapes the future workforce, from automation to augmentation, on EY&#39;s podcast. Prepare for the future. Listen now!",N/A,N/A,"
Related topics
AI
Workforce
Technology
",http://schema.org,OnDemandEvent,,,,,,,https://assets.ey.com/content/dam/ey-sites/ey-com/en_in/podcasts/2023/generative-ai/ey-generative-ai-podcast-series-01.jpg,,,,,,From automation to augmentation: The role of Generative AI in shaping the workforce of the future,,/content/ey-sites/ey-com/en_in/home/podcasts/generative-ai/2023/06/episode-1-from-automation-to-augmentation-the-role-of-generative-ai-in-shaping-the-workforce-of-the-future.html,,,,,,,2023-06-21T09:30:00+0000,,P0Y0M0DT0H14M6.000S,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
https://news.google.com/rss/articles/CBMiVmh0dHBzOi8vd3d3LmNic25ld3MuY29tL25ld3MvYWktam9iLWludGVydmlldy10aXBzLXRvLXByZXBhcmUtYXJ0aWZpY2lhbC1pbnRlbGxpZ2VuY2Uv0gFaaHR0cHM6Ly93d3cuY2JzbmV3cy5jb20vYW1wL25ld3MvYWktam9iLWludGVydmlldy10aXBzLXRvLXByZXBhcmUtYXJ0aWZpY2lhbC1pbnRlbGxpZ2VuY2Uv?oc=5,Your next job interview might be with AI. Here's how to ace it. - CBS News,2023-06-16,CBS News,https://www.cbsnews.com,Interviewing for a job can be stressful in the best of circumstances. But would you know how to impress a bot?,,Interviewing for a job can be stressful in the best of circumstances. But would you know how to impress a bot?,Interviewing for a job can be stressful in the best of circumstances. But would you know how to impress a bot?,N/A,N/A,"


MoneyWatch

Your next job interview might be with AI. Here's how to ace it.






    By
                        
                      Megan Cerullo


    Edited By
                        
                      Anne Marie Lee, 
                              
              Alain Sherter


June 16, 2023 / 5:00 AM EDT
          / MoneyWatch
        



















AI job interviews becoming more common 











AI job interviews are becoming more common. Here's how to ace them.
05:02

Looking for a job? You may find yourself ""face to face"" with an artificial intelligence bot, rather than a person.Corporate recruiters have long used AI to quickly scan job applications and whittle down the number of applicants. Now, companies are increasingly using the technology to conduct the job interview itself. This presents job candidates with a range of new challenges in what can often be a stressful situation, not the least of which is this emerging consideration: How exactly do you impress a bot?""Employers understand that using AI can save them time, so we expect to see more of them using it in some way in the pre-screening interview process,"" Keith Spencer, a career expert at FlexJobs, told CBS MoneyWatch. ""From the candidate's perspective it can be intimidating. You're not interacting with a human — you're interacting with AI, which can feel kind of strange."" 






A recent survey from Resume Builder projected that by 2024, roughly four in 10 companies will use AI for job interviews. Of that number, 15% of employers said they will rely on AI to make hiring decisions without any human input.What is an AI job interview?Although virtual job interviews were used before the COVID-19 pandemic, the public health crisis made the process a necessity. Now that they are more commonplace, businesses are increasingly using AI to screen candidates.


""For years human resources departments have been using AI to automatically screen for resumes and applications. Now that virtual interviews have taken center stage, it's being used as a first screening, especially in non-complex jobs where you have clear parameters,"" Zahira Jaser, associate professor at the University of Sussex Business School, who focuses on how humans experience technology, told CBS MoneyWatch. There are different types of  AI interviews. In an AI-assisted interview,  a job candidate is presented with questions on screen in text form that they answer and submit via either text or video. A recruiter or other company staffer involved in hiring then evaluates the submission to assess if the applicant is a good fit.""Some have just an element of artificial intelligence so the candidate is recorded and someone watches their video,"" Jaser said. In that scenario, AI might help cull an applicant pool and recommend standout candidates. Notably, the technology could also inadvertently nix highly qualified job applicants, experts noted.


""The truth is it is still eliminating some candidates before a human makes the final decision,"" said Stacie Haller, career adviser at Resume Builder.""Existential dread""Then there are those interviews that are AI-led and ""completely automated,"" according to Jaser. The experience is a little bit like videoconferencing with yourself. In CBS MoneyWatch's test of AI interview software, the platform presented text-based questions on a screen above a live video box into which the candidate spoke. Their answers were recorded and submitted for review by AI. 
CBS News reporter Megan Cerullo submitted to a AI job interview without a human on the other end of the videoconference. 

            
                interview.ai

                          
In practice, an algorithm reviews and judges the candidate's video submission based on verbal data, including the words they use, and vocal data, including a person's manner of speech and delivery. In most instances, by contrast, privacy laws prohibit companies from collecting facial data. ""The candidate is in front of a screen that has questions that appear and the candidate has limited time to answer these questions,"" Jaser explained, adding that the experience can be jarring. ""People who have sat in these interviews find it difficult because they almost all fall into an existential dread when, at a very important time in your life, you're not facing a human and you're not seeing cues coming to you.""How to impress a botUnlike a personal interaction with a human hiring manager either in the flesh or on a computer screen, conversational bots don't give interviewees on-the-spot feedback or other cues on how they're doing. ""The beauty of having an in-person interview, which is already a stressful experience, is that there is a human encounter. You meet a human, then you have an exchange, and if you sense a good emotion in the other person it's a way to measure ourselves,"" Jaser said. ""We're always looking for positive cues, and in this case you're not getting any. So you have to be confident you're saying the right thing without any cues.""That said, experts offer some tips on how to ace an AI job interview.


1. Pretend you're talking to a human. Spencer of FlexJobs recommends that candidates pretend they are interacting with a human, while acknowledging that can be difficult while responding to digital prompts.""It's like having a videoconferencing conversation with someone, but there's no one there. You don't see another face,"" he said of the AI interview experience. As a result, candidates sometimes inadvertently end up mimicking the software and can become robotic in their responses, which is something to avoid.






Exploring the human-like side of artificial intelligence at Google | 60 Minutes
27:12

""They get more rigid, their facial expressions become more stoic and they aren't conscious of their non-verbals as much as their verbals. And AI programs are assessing non-verbals,"" Spencer said.Instead, pretend you're interviewing with a person. ""Maintain eye contact [with the camera], dress professionally, smile, and project confidence and friendliness,"" he added.2. Mine the job description for key words — and use them. Companies instruct AI to assess job applicants based on predefined criteria related to their overall goals or a particular role they're trying to fill. So as with any job interview, it's wise to research the company and read the job description closely beforehand. In an AI interview, though, it's even more important to use words and phrases that correspond to the duties and qualifications of the job.""There is a good chance the AI-interview tool will be ranking you based on your use of keywords and phrases from the job description,"" Spencer explained. ""If you're gregarious, don't rely completely on your charm. You want to have your facts straight and also have a clear understanding of the industry position, and be able to provide solid, tangible examples of your work.""


3. Practice, practice, practice. The best way to become more at ease interviewing while speaking to a screen is to practice. Jaser recommends a three-step approach. Start by practicing by videoconferencing with another person. Have them ask you generic as well as tailored interview questions.It can also be useful to use a tool like Prepper from job search site Adzuna, billed as an ""AI interview coach,"" that generates questions related to whatever job description you feed it. ""It's incredibly helpful to have someone — or some thing — chuck you a bunch of questions to get you thinking,"" said James Neave, head of data science at Adzuna and one of the developers behind Prepper. ""You'll know if you're prepared if you can answer those questions in a confident and accurate manner."" Next, have your interviewer turn their camera off to simulate interviewing while addressing a blank screen. Then eliminate the human factor altogether and record yourself using a videoconferencing tool. Watch and review the recording. Keep a script in mind that includes key words you want to use. ""If you learn keywords, you'll have quicker mental shortcuts to get to the info you want when the screen asks you the information,"" Jaser said. 


More from CBS News






 Transcript: Sen. Joe Manchin on ""Face the Nation,"" July 21, 2024







 Why you should open a long-term CD before the July Fed meeting







 Here's what some Olympic athletes get instead of cash prizes







 Best wireless outdoor security cameras 2024







 Dozens reportedly killed amid Bangladesh protests over job allocation





Megan Cerullo


Megan Cerullo is a New York-based reporter for CBS MoneyWatch covering small business, workplace, health care, consumer spending and personal finance topics. She regularly appears on CBS News 24/7 to discuss her reporting.






© 2023 CBS Interactive Inc. All Rights Reserved.

",https://schema.org,BreadcrumbList,Your next job interview might be with AI. Here's how to ace it.,2023-06-16T05:00:00-0400,2023-06-16T18:32:14-0400,,,,"{'@context': 'https://schema.org', '@type': 'ImageObject', 'height': 630, 'width': 1200, 'url': 'https://assets3.cbsnewsstatic.com/hub/i/r/2023/06/15/eed55fb0-c5cb-45e8-892f-a6aedfa9b8ab/thumbnail/1200x630/5c2578710dc51c6e3549b2c1dfd34c80/gettyimages-924555488.jpg?v=e2b758f558b9b19612f3e16bc7fd9fcc'}","[{'@type': 'Person', 'familyName': 'Cerullo', 'givenName': 'Megan', 'name': 'Megan Cerullo', 'jobTitle': 'Reporter, MoneyWatch', 'description': ""Megan Cerullo is a New York-based reporter for CBS MoneyWatch covering small business, workplace, health care, consumer spending and personal finance topics. She regularly appears on CBS News 24/7 to discuss her reporting.\r\n\r\nPreviously, she worked as a breaking news reporter for the New York Daily News. She traveled to Puerto Rico after Hurricane Maria devastated the island and again on the storm's one year anniversary. Her reporting was cited by numerous outlets, including NY1.\r\n\r\nAs a student at the Craig Newmark Graduate School of Journalism at CUNY, she was awarded the Dennis Duggan prize for her outstanding coverage of ordinary New Yorkers by the Silurians Press Club.\r\n\r\nShe holds an MA in journalism from CUNY and a BA from Brown University. She is fluent in French, Spanish and Italian."", 'award': 'Silurians Press Club Dennis Duggan Award', 'knowsAbout': ['Small Business', 'Economy', 'Consumer News', 'Finance', 'Health Care'], 'workLocation': {'@type': 'Place', 'name': 'New York'}, 'affiliation': {'@type': 'Organization', 'name': 'CBS News'}, 'worksFor': [{'@type': 'Organization', 'name': 'CBS News'}], 'publishingPrinciples': 'https://www.cbsnews.com/news/cbs-news-publishing-principles/'}]","Looking for a job? You may find yourself ""face to face"" with an artificial intelligence bot, rather than a person.Corporate recruiters have long used AI to quickly scan job applications and whittle down the number of applicants. Now, companies are increasingly using the technology to conduct the job interview itself. This presents job candidates with a range of new challenges in what can often be a stressful situation, not the least of which is this emerging consideration: How exactly do you impress a bot?""Employers understand that using AI can save them time, so we expect to see more of them using it in some way in the pre-screening interview process,"" Keith Spencer, a career expert at FlexJobs, told CBS MoneyWatch. ""From the candidate's perspective it can be intimidating. You're not interacting with a human — you're interacting with AI, which can feel kind of strange.""A recent survey from Resume Builder projected that by 2024, roughly four in 10 companies will use AI for job interviews. Of that number, 15% of employers said they will rely on AI to make hiring decisions without any human input.What is an AI job interview?Although virtual job interviews were used before the COVID-19 pandemic, the public health crisis made the process a necessity. Now that they are more commonplace, businesses are increasingly using AI to screen candidates.""For years human resources departments have been using AI to automatically screen for resumes and applications. Now that virtual interviews have taken center stage, it's being used as a first screening, especially in non-complex jobs where you have clear parameters,"" Zahira Jaser, associate professor at the University of Sussex Business School, who focuses on how humans experience technology, told CBS MoneyWatch. There are different types of  AI interviews. In an AI-assisted interview,  a job candidate is presented with questions on screen in text form that they answer and submit via either text or video. A recruiter or other company staffer involved in hiring then evaluates the submission to assess if the applicant is a good fit.""Some have just an element of artificial intelligence so the candidate is recorded and someone watches their video,"" Jaser said. In that scenario, AI might help cull an applicant pool and recommend standout candidates. Notably, the technology could also inadvertently nix highly qualified job applicants, experts noted.""The truth is it is still eliminating some candidates before a human makes the final decision,"" said Stacie Haller, career adviser at Resume Builder.""Existential dread""Then there are those interviews that are AI-led and ""completely automated,"" according to Jaser. The experience is a little bit like videoconferencing with yourself. In CBS MoneyWatch's test of AI interview software, the platform presented text-based questions on a screen above a live video box into which the candidate spoke. Their answers were recorded and submitted for review by AI. In practice, an algorithm reviews and judges the candidate's video submission based on verbal data, including the words they use, and vocal data, including a person's manner of speech and delivery. In most instances, by contrast, privacy laws prohibit companies from collecting facial data. ""The candidate is in front of a screen that has questions that appear and the candidate has limited time to answer these questions,"" Jaser explained, adding that the experience can be jarring. ""People who have sat in these interviews find it difficult because they almost all fall into an existential dread when, at a very important time in your life, you're not facing a human and you're not seeing cues coming to you.""How to impress a botUnlike a personal interaction with a human hiring manager either in the flesh or on a computer screen, conversational bots don't give interviewees on-the-spot feedback or other cues on how they're doing. ""The beauty of having an in-person interview, which is already a stressful experience, is that there is a human encounter. You meet a human, then you have an exchange, and if you sense a good emotion in the other person it's a way to measure ourselves,"" Jaser said. ""We're always looking for positive cues, and in this case you're not getting any. So you have to be confident you're saying the right thing without any cues.""That said, experts offer some tips on how to ace an AI job interview.1. Pretend you're talking to a human. Spencer of FlexJobs recommends that candidates pretend they are interacting with a human, while acknowledging that can be difficult while responding to digital prompts.""It's like having a videoconferencing conversation with someone, but there's no one there. You don't see another face,"" he said of the AI interview experience. As a result, candidates sometimes inadvertently end up mimicking the software and can become robotic in their responses, which is something to avoid.""They get more rigid, their facial expressions become more stoic and they aren't conscious of their non-verbals as much as their verbals. And AI programs are assessing non-verbals,"" Spencer said.Instead, pretend you're interviewing with a person. ""Maintain eye contact [with the camera], dress professionally, smile, and project confidence and friendliness,"" he added.2. Mine the job description for key words — and use them. Companies instruct AI to assess job applicants based on predefined criteria related to their overall goals or a particular role they're trying to fill. So as with any job interview, it's wise to research the company and read the job description closely beforehand. In an AI interview, though, it's even more important to use words and phrases that correspond to the duties and qualifications of the job.""There is a good chance the AI-interview tool will be ranking you based on your use of keywords and phrases from the job description,"" Spencer explained. ""If you're gregarious, don't rely completely on your charm. You want to have your facts straight and also have a clear understanding of the industry position, and be able to provide solid, tangible examples of your work.""3. Practice, practice, practice. The best way to become more at ease interviewing while speaking to a screen is to practice. Jaser recommends a three-step approach. Start by practicing by videoconferencing with another person. Have them ask you generic as well as tailored interview questions.It can also be useful to use a tool like Prepper from job search site Adzuna, billed as an ""AI interview coach,"" that generates questions related to whatever job description you feed it. ""It's incredibly helpful to have someone — or some thing — chuck you a bunch of questions to get you thinking,"" said James Neave, head of data science at Adzuna and one of the developers behind Prepper. ""You'll know if you're prepared if you can answer those questions in a confident and accurate manner."" Next, have your interviewer turn their camera off to simulate interviewing while addressing a blank screen. Then eliminate the human factor altogether and record yourself using a videoconferencing tool. Watch and review the recording. Keep a script in mind that includes key words you want to use. ""If you learn keywords, you'll have quicker mental shortcuts to get to the info you want when the screen asks you the information,"" Jaser said. ",,"{'@context': 'https://schema.org', '@type': 'NewsMediaOrganization', '@id': 'https://www.cbsnews.com/', 'name': 'CBS News', 'foundingDate': '1927-09-18', 'sameAs': ['https://www.cbsnews.com/', 'https://www.facebook.com/CBSNews/', 'https://instagram.com/cbsnews/', 'https://twitter.com/CBSNews', 'https://www.youtube.com/CBSNews', 'https://en.wikipedia.org/wiki/CBS_News'], 'logo': [{'@context': 'https://schema.org', '@type': 'ImageObject', 'height': 60, 'width': 600, 'url': 'https://www.cbsnews.com/assets/standalone/cbsnews-logo-white-600x60.png'}], 'url': 'https://www.cbsnews.com/', 'parentOrganization': {'@type': 'Organization', 'name': 'Paramount Global', '@id': 'https://www.paramount.com/', 'sameAs': 'https://www.paramount.com/', 'legalName': 'Paramount Global'}, 'actionableFeedbackPolicy': 'https://www.cbsnews.com/news/cbs-news-publishing-principles/#1d4ed2b9-ade8-4203-a4e4-115dd34c0735', 'correctionsPolicy': 'https://www.cbsnews.com/news/cbs-news-publishing-principles/#751608ae-9468-457c-9dbe-1f9400a7f428', 'ethicsPolicy': 'https://www.cbsnews.com/news/cbs-news-publishing-principles/#a0060f90-73b0-4a57-b756-ca7a7f26cc7d', 'Masthead': 'https://www.cbsnews.com/news/cbs-news-publishing-principles/#5fd9a80d-2c6c-4d38-8b1e-4144650d5963', 'missionCoveragePrioritiesPolicy': 'https://www.cbsnews.com/news/cbs-news-publishing-principles/#4ffda755-6b47-49e1-b98c-24b737906aca', 'ownershipFundingInfo': 'https://www.paramount.com/company-history', 'unnamedSourcesPolicy': 'https://www.cbsnews.com/news/cbs-news-publishing-principles/#de41886e-07ed-4887-ad05-4b2c79edf857', 'publishingPrinciples': 'https://www.cbsnews.com/news/cbs-news-publishing-principles/'}","[{'@type': 'ListItem', 'position': 1, 'item': {'@id': 'https://www.cbsnews.com/', '@type': 'WebPage', '@name': 'CBSNews.com'}}, {'@type': 'ListItem', 'position': 2, 'name': 'MoneyWatch', 'item': {'@id': 'https://www.cbsnews.com/moneywatch', '@type': 'CollectionPage', '@name': 'MoneyWatch'}}, {'@type': 'ListItem', 'position': 3, 'name': ""Your next job interview might be with AI. Here's how to ace it."", 'item': {'@id': 'https://www.cbsnews.com/news/ai-job-interview-tips-to-prepare-artificial-intelligence/', '@name': ""Your next job interview might be with AI. Here's how to ace it.""}}]",Your next job interview might be with AI. Here's how to ace it.,,https://www.cbsnews.com/news/ai-job-interview-tips-to-prepare-artificial-intelligence/,https://assets3.cbsnewsstatic.com/hub/i/r/2023/06/15/eed55fb0-c5cb-45e8-892f-a6aedfa9b8ab/thumbnail/1200x630/5c2578710dc51c6e3549b2c1dfd34c80/gettyimages-924555488.jpg?v=e2b758f558b9b19612f3e16bc7fd9fcc,"{'@type': 'WebPage', '@id': 'https://www.cbsnews.com/news/ai-job-interview-tips-to-prepare-artificial-intelligence/'}",,"[{'@type': 'Person', 'familyName': 'Lee', 'givenName': 'Anne Marie', 'name': 'Anne Marie Lee'}, {'@type': 'Person', 'familyName': 'Sherter', 'givenName': 'Alain', 'name': 'Alain Sherter'}]",['MoneyWatch'],,,,,"{'@context': 'https://schema.org', '@type': 'ImageObject', 'height': 630, 'width': 1200, 'url': 'https://assets3.cbsnewsstatic.com/hub/i/r/2023/06/15/eed55fb0-c5cb-45e8-892f-a6aedfa9b8ab/thumbnail/1200x630/5c2578710dc51c6e3549b2c1dfd34c80/gettyimages-924555488.jpg?v=e2b758f558b9b19612f3e16bc7fd9fcc'}","{'@context': 'https://schema.org', '@type': 'VideoObject', 'mainEntityOfPage': {'@type': 'WebPage', '@id': 'https://www.cbsnews.com/video/ai-job-interviews-are-becoming-more-common-heres-how-to-ace-them/'}, 'name': ""AI job interviews are becoming more common. Here's how to ace them."", 'description': 'Your next job interview may be with an artificial intelligence bot, not a person. A recent survey from Resume Builder projected that by 2024, roughly 4 in 10 companies will use AI for job interviews. CBS MoneyWatch reporter Megan Cerullo shares tips for how to handle it.', 'thumbnail': {'@context': 'https://schema.org', '@type': 'ImageObject', 'height': 630, 'width': 1200, 'url': 'https://assets3.cbsnewsstatic.com/hub/i/r/2023/06/16/5c55f7b0-677f-455a-a83f-d806bff0f6f2/thumbnail/1200x630/9a8631fdac88460fee3f48c19b7ebfe3/cbsn-fusion-ai-job-interviews-are-becoming-more-common-heres-how-to-ace-them-thumbnail-2057169-640x360.jpg?v=e2b758f558b9b19612f3e16bc7fd9fcc'}, 'thumbnailUrl': 'https://assets3.cbsnewsstatic.com/hub/i/r/2023/06/16/5c55f7b0-677f-455a-a83f-d806bff0f6f2/thumbnail/1200x630/9a8631fdac88460fee3f48c19b7ebfe3/cbsn-fusion-ai-job-interviews-are-becoming-more-common-heres-how-to-ace-them-thumbnail-2057169-640x360.jpg?v=e2b758f558b9b19612f3e16bc7fd9fcc', 'uploadDate': '2023-06-16T16:10:47-0400', 'contentUrl': 'https://prod.vodvideo.cbsnews.com/cbsnews/vr/hls/2023/06/16/2228806723962/2057167_hls/master.m3u8', 'publisher': {'@context': 'https://schema.org', '@type': 'NewsMediaOrganization', '@id': 'https://www.cbsnews.com/', 'name': 'CBS News', 'foundingDate': '1927-09-18', 'sameAs': ['https://www.cbsnews.com/', 'https://www.facebook.com/CBSNews/', 'https://instagram.com/cbsnews/', 'https://twitter.com/CBSNews', 'https://www.youtube.com/CBSNews', 'https://en.wikipedia.org/wiki/CBS_News'], 'logo': [{'@context': 'https://schema.org', '@type': 'ImageObject', 'height': 60, 'width': 600, 'url': 'https://www.cbsnews.com/assets/standalone/cbsnews-logo-white-600x60.png'}], 'url': 'https://www.cbsnews.com/', 'parentOrganization': {'@type': 'Organization', 'name': 'Paramount Global', '@id': 'https://www.paramount.com/', 'sameAs': 'https://www.paramount.com/', 'legalName': 'Paramount Global'}, 'actionableFeedbackPolicy': 'https://www.cbsnews.com/news/cbs-news-publishing-principles/#1d4ed2b9-ade8-4203-a4e4-115dd34c0735', 'correctionsPolicy': 'https://www.cbsnews.com/news/cbs-news-publishing-principles/#751608ae-9468-457c-9dbe-1f9400a7f428', 'ethicsPolicy': 'https://www.cbsnews.com/news/cbs-news-publishing-principles/#a0060f90-73b0-4a57-b756-ca7a7f26cc7d', 'Masthead': 'https://www.cbsnews.com/news/cbs-news-publishing-principles/#5fd9a80d-2c6c-4d38-8b1e-4144650d5963', 'missionCoveragePrioritiesPolicy': 'https://www.cbsnews.com/news/cbs-news-publishing-principles/#4ffda755-6b47-49e1-b98c-24b737906aca', 'ownershipFundingInfo': 'https://www.paramount.com/company-history', 'unnamedSourcesPolicy': 'https://www.cbsnews.com/news/cbs-news-publishing-principles/#de41886e-07ed-4887-ad05-4b2c79edf857', 'publishingPrinciples': 'https://www.cbsnews.com/news/cbs-news-publishing-principles/'}, 'duration': 'PT0H05M02S', 'embedUrl': 'https://www.cbsnews.com/video/ai-job-interviews-are-becoming-more-common-heres-how-to-ace-them/?embed=1'}",https://www.cbsnews.com/,1927-09-18,"['https://www.cbsnews.com/', 'https://www.facebook.com/CBSNews/', 'https://instagram.com/cbsnews/', 'https://twitter.com/CBSNews', 'https://www.youtube.com/CBSNews', 'https://en.wikipedia.org/wiki/CBS_News']","[{'@context': 'https://schema.org', '@type': 'ImageObject', 'height': 60, 'width': 600, 'url': 'https://www.cbsnews.com/assets/standalone/cbsnews-logo-white-600x60.png'}]","{'@type': 'Organization', 'name': 'Paramount Global', '@id': 'https://www.paramount.com/', 'sameAs': 'https://www.paramount.com/', 'legalName': 'Paramount Global'}",https://www.cbsnews.com/news/cbs-news-publishing-principles/#1d4ed2b9-ade8-4203-a4e4-115dd34c0735,https://www.cbsnews.com/news/cbs-news-publishing-principles/#751608ae-9468-457c-9dbe-1f9400a7f428,https://www.cbsnews.com/news/cbs-news-publishing-principles/#a0060f90-73b0-4a57-b756-ca7a7f26cc7d,https://www.cbsnews.com/news/cbs-news-publishing-principles/#5fd9a80d-2c6c-4d38-8b1e-4144650d5963,https://www.cbsnews.com/news/cbs-news-publishing-principles/#4ffda755-6b47-49e1-b98c-24b737906aca,https://www.paramount.com/company-history,https://www.cbsnews.com/news/cbs-news-publishing-principles/#de41886e-07ed-4887-ad05-4b2c79edf857,https://www.cbsnews.com/news/cbs-news-publishing-principles/,,,,,,,,,,,,,,,
https://news.google.com/rss/articles/CBMiTGh0dHBzOi8vd3d3LmRydWdkaXNjb3Zlcnl0cmVuZHMuY29tL2dlbmVyYXRpdmUtYWktZHJ1Zy1kZXZlbG9wbWVudC1pbnNpZ2h0cy_SAQA?oc=5,Exploring role of generative AI in reshaping drug development - Drug Discovery & Development,2023-06-16,Drug Discovery & Development,https://www.drugdiscoverytrends.com,"Explore the transformative potential of generative AI in drug development, as highlighted in a McKinsey report and from Verseon's CEO.",N/A,"Explore the transformative potential of generative AI in drug development, as highlighted in a McKinsey report and from Verseon's CEO.",N/A,N/A,N/A,"Generative AI could boost biopharma R&D productivity by billions, according to McKinsey
By Brian Buntz | June 16, 2023FacebookXLinkedInShare[Image credit: Seventyfour/Adobe Stock]Generative AI stands to add trillions of dollars of value to the world economy, according to a recent McKinsey report. The consultancy noted that about three-quarters of the value of generative AI spans four areas — customer operations, marketing and sales, software engineering and R&D. The latter could see a 12% annual lift in global functional spending as a result of generative AI, representing an approximately $328 billion windfall annually.
An evolution or revolution: UBS and McKinsey’s take on generative AI in biopharma
The investment bank UBS recently reached more muted conclusions, noting that generative AI would represent more of an evolution than a revolution for biopharma.
Conversely, McKinsey bets the technology could deliver productivity gains that account for 10% to 15% of overall R&D costs. This potential largely stems from the application of generative AI foundation models in what is known as generative design.
In the face of such perspectives, Adityo Prakash, CEO of Verseon, agrees with the transformative potential of AI but cautions against oversimplification. He underscores the need for a holistic approach to AI, taking into account the limitations of data. He points out a critical example in the conversion of chemical structure data. “If a lot of this data is just 2D chemical structures for a small molecule structure, what you’re supposed to do is turn that into 3D using tools that can generate a realistic 3D representation,” Prakash said. “The problem is that many people in this space often miss the details required for deploying AI.”
Beyond drug development: Generative AI’s impact on various industries
Indeed, many of McKinsey’s pronouncements extend beyond the pharma sector. The firm, for instance, projects the technology could automate tasks that now occupy about 60% to 70% of employees’ time across various industries. Ultimately, McKinsey estimates that “half of today’s work activities could be automated between 2030 and 2060,” roughly a decade earlier than in its earlier models suggested.
Prakash stressed that solving thorny drug development hurdles will require a cross-disciplinary approach. “To really solve the problem well, you need people who speak all of these languages fluently,” he said, referring to the various domains of expertise required in drug development – including data science, biology, chemistry, and AI. He suggests that a team combining a physicist, a mathematician and other backgrounds can potentially solve the problem better than siloed teams.
The aim is to expand what Lilly refers to as its “digital worker-equivalent workforce,” an idea intended to measure the time saved by employing technology in place of human labor. In an interview with Insider, Lilly CEO David Ricks stated that its initiatives, initiated in 2022 and encompassing more than 100 projects, are comparable to nearly 1.4 million hours of human effort, or roughly 160 years of round-the-clock work.
In response to the pharma giants’ embrace of AI, Prakash suggested that while these steps are commendable, it’s vital not to underestimate the challenges ahead or overstate the capabilities of AI alone. “We need to get there, and it’s a completely non-trivial task. AI is only one of many tools that are going to help,” Prakash said. “Just chanting ‘AI’ doesn’t get you there,” he stated.
Filed Under: Data science, Drug Discovery and Development, Industry 4.0, machine learning and AITagged With: ai challenges, AI in Pharma, digital workforce, drug development, generative AI, mckinsey report, productivity gains, Verseon ",https://schema.org,,,,,,,,,,,,,,,,,,,"[{'@type': 'Article', '@id': 'https://www.drugdiscoverytrends.com/generative-ai-drug-development-insights/#article', 'isPartOf': {'@id': 'https://www.drugdiscoverytrends.com/generative-ai-drug-development-insights/'}, 'author': {'name': 'Brian Buntz', '@id': 'https://www.drugdiscoverytrends.com/#/schema/person/a6946518fe4467543e9b244e10826fe1'}, 'headline': 'Generative AI could boost biopharma R&#038;D productivity by billions, according to McKinsey', 'datePublished': '2023-06-16T23:27:59+00:00', 'dateModified': '2023-06-16T23:27:59+00:00', 'mainEntityOfPage': {'@id': 'https://www.drugdiscoverytrends.com/generative-ai-drug-development-insights/'}, 'wordCount': 550, 'commentCount': 0, 'publisher': {'@id': 'https://www.drugdiscoverytrends.com/#organization'}, 'image': {'@id': 'https://www.drugdiscoverytrends.com/generative-ai-drug-development-insights/#primaryimage'}, 'thumbnailUrl': 'https://www.drugdiscoverytrends.com/wp-content/uploads/2023/05/scientific-research.jpeg', 'keywords': ['ai challenges', 'AI in Pharma', 'digital workforce', 'drug development', 'generative AI', 'mckinsey report', 'productivity gains', 'Verseon'], 'articleSection': ['Data science', 'Drug Discovery and Development', 'Industry 4.0', 'machine learning and AI'], 'inLanguage': 'en-US', 'potentialAction': [{'@type': 'CommentAction', 'name': 'Comment', 'target': ['https://www.drugdiscoverytrends.com/generative-ai-drug-development-insights/#respond']}]}, {'@type': 'WebPage', '@id': 'https://www.drugdiscoverytrends.com/generative-ai-drug-development-insights/', 'url': 'https://www.drugdiscoverytrends.com/generative-ai-drug-development-insights/', 'name': 'Exploring role of generative AI in reshaping drug development', 'isPartOf': {'@id': 'https://www.drugdiscoverytrends.com/#website'}, 'primaryImageOfPage': {'@id': 'https://www.drugdiscoverytrends.com/generative-ai-drug-development-insights/#primaryimage'}, 'image': {'@id': 'https://www.drugdiscoverytrends.com/generative-ai-drug-development-insights/#primaryimage'}, 'thumbnailUrl': 'https://www.drugdiscoverytrends.com/wp-content/uploads/2023/05/scientific-research.jpeg', 'datePublished': '2023-06-16T23:27:59+00:00', 'dateModified': '2023-06-16T23:27:59+00:00', 'description': ""Explore the transformative potential of generative AI in drug development, as highlighted in a McKinsey report and from Verseon's CEO."", 'breadcrumb': {'@id': 'https://www.drugdiscoverytrends.com/generative-ai-drug-development-insights/#breadcrumb'}, 'inLanguage': 'en-US', 'potentialAction': [{'@type': 'ReadAction', 'target': ['https://www.drugdiscoverytrends.com/generative-ai-drug-development-insights/']}]}, {'@type': 'ImageObject', 'inLanguage': 'en-US', '@id': 'https://www.drugdiscoverytrends.com/generative-ai-drug-development-insights/#primaryimage', 'url': 'https://www.drugdiscoverytrends.com/wp-content/uploads/2023/05/scientific-research.jpeg', 'contentUrl': 'https://www.drugdiscoverytrends.com/wp-content/uploads/2023/05/scientific-research.jpeg', 'width': 7360, 'height': 4912, 'caption': '[Image credit: Seventyfour/Adobe Stock]'}, {'@type': 'BreadcrumbList', '@id': 'https://www.drugdiscoverytrends.com/generative-ai-drug-development-insights/#breadcrumb', 'itemListElement': [{'@type': 'ListItem', 'position': 1, 'name': 'Home', 'item': 'https://www.drugdiscoverytrends.com/'}, {'@type': 'ListItem', 'position': 2, 'name': 'Drug Discovery and Development', 'item': 'https://www.drugdiscoverytrends.com/drug-discovery-and-development/'}, {'@type': 'ListItem', 'position': 3, 'name': 'Generative AI could boost biopharma R&#038;D productivity by billions, according to McKinsey'}]}, {'@type': 'WebSite', '@id': 'https://www.drugdiscoverytrends.com/#website', 'url': 'https://www.drugdiscoverytrends.com/', 'name': 'Drug Discovery and Development', 'description': 'Strategies &amp; Technologies Driving Drug Discovery to Market', 'publisher': {'@id': 'https://www.drugdiscoverytrends.com/#organization'}, 'potentialAction': [{'@type': 'SearchAction', 'target': {'@type': 'EntryPoint', 'urlTemplate': 'https://www.drugdiscoverytrends.com/?s={search_term_string}'}, 'query-input': 'required name=search_term_string'}], 'inLanguage': 'en-US'}, {'@type': 'Organization', '@id': 'https://www.drugdiscoverytrends.com/#organization', 'name': 'WTWH Media', 'url': 'https://www.drugdiscoverytrends.com/', 'logo': {'@type': 'ImageObject', 'inLanguage': 'en-US', '@id': 'https://www.drugdiscoverytrends.com/#/schema/logo/image/', 'url': 'https://www.drugdiscoverytrends.com/wp-content/uploads/2024/05/ddd-logo.png', 'contentUrl': 'https://www.drugdiscoverytrends.com/wp-content/uploads/2024/05/ddd-logo.png', 'width': 538, 'height': 162, 'caption': 'WTWH Media'}, 'image': {'@id': 'https://www.drugdiscoverytrends.com/#/schema/logo/image/'}, 'sameAs': ['https://www.facebook.com/DrugDiscoveryDev/', 'https://x.com/DrugDiscoverDev', 'https://www.linkedin.com/company/drug-discovery-&-development']}, {'@type': 'Person', '@id': 'https://www.drugdiscoverytrends.com/#/schema/person/a6946518fe4467543e9b244e10826fe1', 'name': 'Brian Buntz', 'image': {'@type': 'ImageObject', 'inLanguage': 'en-US', '@id': 'https://www.drugdiscoverytrends.com/#/schema/person/image/', 'url': 'https://secure.gravatar.com/avatar/c46f07975579d6ea44d09cc4b8f2adb3?s=96&d=mm&r=g', 'contentUrl': 'https://secure.gravatar.com/avatar/c46f07975579d6ea44d09cc4b8f2adb3?s=96&d=mm&r=g', 'caption': 'Brian Buntz'}, 'description': 'As the pharma and biotech editor at WTWH Media, Brian has almost two decades of experience in B2B media, with a focus on healthcare and technology. While he has long maintained a keen interest in AI, more recently Brian has made making data analysis a central focus, and is exploring tools ranging from NLP and clustering to predictive analytics. Throughout his 18-year tenure, Brian has covered an array of life science topics, including clinical trials, medical devices, and drug discovery and development. Prior to WTWH, he held the title of content director at Informa, where he focused on topics such as connected devices, cybersecurity, AI and Industry 4.0. A dedicated decade at UBM saw Brian providing in-depth coverage of the medical device sector. Engage with Brian on LinkedIn or drop him an email at bbuntz@wtwhmedia.com.', 'sameAs': ['https://www.linkedin.com/in/brianbuntz/'], 'url': 'https://www.drugdiscoverytrends.com/author/bbuntz/'}]",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
https://news.google.com/rss/articles/CBMiWGh0dHBzOi8vY29pbmdlZWsuY29tL2dlbmVyYXRpdmUtYWktdG8tYWRkLTQtNC10cmlsbGlvbi1hbm51YWxseS10by1nbG9iYWwtZWNvbm9teS1zdHVkeS_SAQA?oc=5,Generative AI to add $4.4 trillion annually to global economy: study - CoinGeek,2023-06-20,CoinGeek,https://coingeek.com,"Generative artificial intelligence (AI) will automate 50% of the work done today by 2045, but it’s those with higher-wage knowledge and skills that are likely to lose their jobs to AI, according to a McKinsey study.",N/A,"Generative artificial intelligence (AI) will automate 50% of the work done today by 2045, but it’s those with higher-wage knowledge and skills that are likely to lose their jobs to AI, according to a McKinsey study.",N/A,N/A,N/A,"Generative AI to add $4.4 trillion annually to global economy: study Business   20 June 2023    Steve Kaaru    Getting your Trinity Audio player ready...Generative artificial intelligence (AI) will automate over half of all work done today by 2045, according to a new study by McKinsey, noting that the technology would add over $4.4 trillion to the global economy annually.Generative AI produces various types of content, from text to imagery and audio output, in response to prompts. OpenAI’s ChatGPT has popularized the technology, making it one of the fastest-growing industries globally.According to McKinsey, the AI era is just beginning.What’s the value and impact of #generativeAI? Companies across countless industries are already experimenting with its applications. Our new research has found that the value at stake is huge–potentially $2.6 to $4.4 trillion in #productivity annually➡ https://t.co/pY5ACuvoL1 pic.twitter.com/ecZ0RvtzHl— McKinsey & Company (@McKinsey) June 14, 2023In its report, the management consulting giant estimated that generative AI would add between $2.6 trillion to $4.4 trillion annually. These numbers could double if the technology is embedded into software used for other tasks beyond the studied use cases, it added.The technology will impact all industries, but banking and life sciences will see the most disruption. By integrating the technology, banking alone could record $340 billion in added value annually.Generative AI will transform the workspace, with McKinsey estimating it will automate over half of today’s work by 2045. This prediction has been reduced by nearly a decade from the 2016 estimate by the rapid growth in usage and investment in the technology over the past few years.AI has previously been touted to be more detrimental to low-level workers whose output can easily be automated. However, according to McKinsey, those in the higher ranks will face the most disruption. The company predicts that “knowledge work associated with occupations that have higher wages and educational requirements” will see the most impact.McKinsey joins other global institutions that predict a big shift in work as we integrate generative AI. Goldman Sachs (NASDAQ: GS) predicted that over 300 million workers could lose their jobs to AI-powered automation, while the World Economic Forum (WEF) projected 83 million jobs would be lost to AI in the next five years. Already, AI was blamed for 4,000 job losses in the U.S. in May.Some are still skeptical of the impact generative AI will have. David Autor, an economics professor at the Massachusetts Institute of Technology (MIT), says the technology is “not going to be as miraculous as people claim.”Watch: Does AI know what it’s doing? width=""562"" height=""315"" frameborder=""0"" allowfullscreen=""allowfullscreen"">New to blockchain? Check out CoinGeek’s Blockchain for Beginners section, the ultimate resource guide to learn more about blockchain technology.  TaggedAIartificial intelligenceGenerative AIMcKinsey",https://schema.org,,,,,,,,,,,,,,,,,,,"[{'@type': 'Article', '@id': 'https://coingeek.com/generative-ai-to-add-4-4-trillion-annually-to-global-economy-study/#article', 'isPartOf': {'@id': 'https://coingeek.com/generative-ai-to-add-4-4-trillion-annually-to-global-economy-study/'}, 'author': {'name': 'Steve Kaaru', '@id': 'https://coingeek.com/#/schema/person/87c4b825dc267bec53579a0786a74591'}, 'headline': 'Generative AI to add $4.4 trillion annually to global economy: study', 'datePublished': '2023-06-20T09:00:16+00:00', 'dateModified': '2023-06-19T09:51:18+00:00', 'mainEntityOfPage': {'@id': 'https://coingeek.com/generative-ai-to-add-4-4-trillion-annually-to-global-economy-study/'}, 'wordCount': 369, 'publisher': {'@id': 'https://coingeek.com/#organization'}, 'image': {'@id': 'https://coingeek.com/generative-ai-to-add-4-4-trillion-annually-to-global-economy-study/#primaryimage'}, 'thumbnailUrl': 'https://coingeek.com/wp-content/uploads/2023/06/Artificial-Intelligence-jpg.webp', 'keywords': ['AI', 'artificial intelligence', 'Generative AI', 'McKinsey'], 'articleSection': ['Business'], 'inLanguage': 'en-US', 'copyrightYear': '2023', 'copyrightHolder': {'@id': 'https://coingeek.com/#organization'}, 'video': [{'@id': 'https://coingeek.com/generative-ai-to-add-4-4-trillion-annually-to-global-economy-study/#video'}]}, {'@type': 'WebPage', '@id': 'https://coingeek.com/generative-ai-to-add-4-4-trillion-annually-to-global-economy-study/', 'url': 'https://coingeek.com/generative-ai-to-add-4-4-trillion-annually-to-global-economy-study/', 'name': 'Generative AI to add $4.4 trillion annually to global economy: study - CoinGeek', 'isPartOf': {'@id': 'https://coingeek.com/#website'}, 'primaryImageOfPage': {'@id': 'https://coingeek.com/generative-ai-to-add-4-4-trillion-annually-to-global-economy-study/#primaryimage'}, 'image': {'@id': 'https://coingeek.com/generative-ai-to-add-4-4-trillion-annually-to-global-economy-study/#primaryimage'}, 'thumbnailUrl': 'https://coingeek.com/wp-content/uploads/2023/06/Artificial-Intelligence-jpg.webp', 'datePublished': '2023-06-20T09:00:16+00:00', 'dateModified': '2023-06-19T09:51:18+00:00', 'description': 'Generative artificial intelligence (AI) will automate 50% of the work done today by 2045, but it’s those with higher-wage knowledge and skills that are likely to lose their jobs to AI, according to a McKinsey study.', 'breadcrumb': {'@id': 'https://coingeek.com/generative-ai-to-add-4-4-trillion-annually-to-global-economy-study/#breadcrumb'}, 'inLanguage': 'en-US', 'potentialAction': [{'@type': 'ReadAction', 'target': ['https://coingeek.com/generative-ai-to-add-4-4-trillion-annually-to-global-economy-study/']}]}, {'@type': 'ImageObject', 'inLanguage': 'en-US', '@id': 'https://coingeek.com/generative-ai-to-add-4-4-trillion-annually-to-global-economy-study/#primaryimage', 'url': 'https://coingeek.com/wp-content/uploads/2023/06/Artificial-Intelligence-jpg.webp', 'contentUrl': 'https://coingeek.com/wp-content/uploads/2023/06/Artificial-Intelligence-jpg.webp', 'width': 730, 'height': 360, 'caption': 'Future artificial intelligence and machine learning for AI droid robot or cyborg'}, {'@type': 'BreadcrumbList', '@id': 'https://coingeek.com/generative-ai-to-add-4-4-trillion-annually-to-global-economy-study/#breadcrumb', 'itemListElement': [{'@type': 'ListItem', 'position': 1, 'name': 'Home', 'item': 'https://coingeek.com/'}, {'@type': 'ListItem', 'position': 2, 'name': 'Business', 'item': 'https://coingeek.com/news/category/business/'}, {'@type': 'ListItem', 'position': 3, 'name': 'Generative AI to add $4.4 trillion annually to global economy: study'}]}, {'@type': 'WebSite', '@id': 'https://coingeek.com/#website', 'url': 'https://coingeek.com/', 'name': 'CoinGeek', 'description': 'Blockchain News', 'publisher': {'@id': 'https://coingeek.com/#organization'}, 'potentialAction': [{'@type': 'SearchAction', 'target': {'@type': 'EntryPoint', 'urlTemplate': 'https://coingeek.com/?s={search_term_string}'}, 'query-input': 'required name=search_term_string'}], 'inLanguage': 'en-US'}, {'@type': 'Organization', '@id': 'https://coingeek.com/#organization', 'name': 'CoinGeek', 'url': 'https://coingeek.com/', 'logo': {'@type': 'ImageObject', 'inLanguage': 'en-US', '@id': 'https://coingeek.com/#/schema/logo/image/', 'url': 'https://coingeek.com/wp-content/uploads/2018/11/logo.svg', 'contentUrl': 'https://coingeek.com/wp-content/uploads/2018/11/logo.svg', 'caption': 'CoinGeek'}, 'image': {'@id': 'https://coingeek.com/#/schema/logo/image/'}, 'sameAs': ['https://www.facebook.com/realcoingeek/', 'https://x.com/realcoingeek', 'https://www.instagram.com/coingeek_official/', 'https://www.linkedin.com/company/coingeek', 'https://www.youtube.com/channel/UC95_Nqes9m5arhoT1lt1SFg']}, {'@type': 'Person', '@id': 'https://coingeek.com/#/schema/person/87c4b825dc267bec53579a0786a74591', 'name': 'Steve Kaaru', 'image': {'@type': 'ImageObject', 'inLanguage': 'en-US', '@id': 'https://coingeek.com/#/schema/person/image/', 'url': 'https://coingeek.com/wp-content/uploads/2021/08/Steve-Kaaru-180x180-1-96x96.png', 'contentUrl': 'https://coingeek.com/wp-content/uploads/2021/08/Steve-Kaaru-180x180-1-96x96.png', 'caption': 'Steve Kaaru'}, 'url': 'https://coingeek.com/author/steve-kaaru/'}, {'@type': 'VideoObject', '@id': 'https://coingeek.com/generative-ai-to-add-4-4-trillion-annually-to-global-economy-study/#video', 'name': 'Generative AI to add $4.4 trillion annually to global economy: study - CoinGeek', 'isPartOf': {'@id': 'https://coingeek.com/generative-ai-to-add-4-4-trillion-annually-to-global-economy-study/#article'}, 'thumbnailUrl': 'https://coingeek.com/wp-content/uploads/2023/06/6pd0jw0sjoi-jpg.webp', 'description': 'Generative artificial intelligence (AI) will automate 50% of the work done today by 2045, but it’s those with higher-wage knowledge and skills that are likely to lose their jobs to AI, according to a McKinsey study.', 'uploadDate': '2023-06-20', 'width': 480, 'height': 270, 'embedUrl': 'https://www.youtube.com/embed/6PD0jw0sjOI', 'duration': 'PT28M9S', 'isFamilyFriendly': True, 'inLanguage': 'en-US'}]",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
https://news.google.com/rss/articles/CBMiWGh0dHBzOi8vd3d3LnRlY2h0YXJnZXQuY29tL3NlYXJjaGVudGVycHJpc2VhaS90aXAvVG9wLWFkdmFudGFnZXMtYW5kLWRpc2FkdmFudGFnZXMtb2YtQUnSAQA?oc=5,Top advantages and disadvantages of AI - TechTarget,2023-06-16,TechTarget,https://www.techtarget.com,"Please see our updated video for AI to account for the generative AI boom and other AI developments: https://youtu.be/WP6z_X5d-Rw 

Subscribe to Eye on Tech: https://www.youtube.com/EyeOnTech 
Stay up to date on the latest enterprise AI news: https://www.techtarget.com/searchenterpriseai/
Follow us on Twitter: https://twitter.com/TTBusinessTech
Like us on LinkedIn: https://www.linkedin.com/showcase/techtarget-business-technology/
Like us on Facebook: https://www.facebook.com/TechTargetBusinessTechnology/",N/A,Explore the advantages and disadvantages of AI and how the technology might affect the future of business and society.,Explore the advantages and disadvantages of AI and how the technology might affect the future of business and society.,N/A,N/A,"





Tech Accelerator
A guide to artificial intelligence in the enterprise 


Prev
Next
sentiment analysis
What is trustworthy AI and why is it important?
Download this guide1









Tip


Top advantages and disadvantages of AI


Is AI good or bad? Many experts worry about unchecked use of the technology, while others believe AI could benefit society with the correct guidelines in place.





Share this item with your network:

















































By


Mary K. Pratt



Published: 16 Jun 2023


 
Alarm over AI has been growing, with leaders from various sectors voicing concerns about both the increasing power of AI and its role in society.







Thousands of CEOs, technologists, researchers, academics and others signed an open letter in early 2023 calling for a pause in AI deployments, even as millions of people start using ChatGPT and other generative AI systems.
More specifically, they called on ""all AI labs to immediately pause for at least 6 months the training of AI systems more powerful than GPT-4.""
The March letter starts by calling out AI's ""profound risks to society and humanity"" and chastising AI labs for engaging in ""an out-of-control race to develop and deploy ever more powerful digital minds that no one -- not even their creators -- can understand, predict, or reliably control.""
They're not the only ones worried about AI: Forty-six percent of respondents to a February 2023 Monmouth University poll said AI would do equal amounts of harm and good, while 41% believe the technology would do more harm. Only 9% of respondents believe computer scientists can develop AI that would benefit society.



This article is part of
A guide to artificial intelligence in the enterprise 

Which also includes:
10 top AI and machine learning trends for 2024
10 top artificial intelligence certifications and courses for 2024
The future of AI: What to expect in the next 5 years




The reality is that AI has many potential advantages and disadvantages. In fact, the open letter signatories acknowledged both the technology's negatives and positives, stating that ""Humanity can enjoy a flourishing future with AI.""




Top 5 advantages of AI
The benefits of AI include the following:
1. 24/7 availability
One of AI's biggest, and most cited, advantages is its 24/7 availability. Other computer technologies operate around the clock, and companies have benefited from the high availability of such systems -- but only insomuch as humans have been available to work with them. AI's ability to make decisions and take actions independent of human involvement in many business circumstances means the technology can work independently, ensuring continuous operations, said Jordan Rae Kelly, senior managing director and head of cybersecurity for the Americas at FTI Consulting.
2. Scalability
AI not only works continuously, it scales almost infinitely, said Sreekar Krishna, principal and national leader for AI at KPMG US. He cited the personalized recommendations companies such as Amazon and Netflix offer to their customers. While a salesclerk who works often enough with a customer might be able to extend such services to that same individual after enough interactions, AI can do so for hundreds of thousands of customers at the same time. AI similarly demonstrates this scalability in the financial industry, where institutions use the technology to instantly verify and validate millions of transactions and monitor for potential fraud every day. ""You can't scale to that degree with humans alone. You need automation, and AI is integral to that automation,"" Krishna said.
3. Improved accuracy and reduced rate of error
Unlike humans, AI systems don't get tired or become distracted. They're able to process infinitely more information, and consistently follow the rules to analyze data and make decisions -- all of which make them far more likely to deliver accurate results nearly all the time. ""That's not to say these platforms are perfect,"" Kelly warned. To deliver such accuracy, AI models must be built on good algorithms that are free from unintended bias, trained on enough high-quality data and monitored to prevent drift.



Forty-six percent of respondents to a February 2023 Monmouth University poll said AI would do equal amounts of harm and good, while 41% believe the technology would do more harm.




4. Enhanced safety
An example of AI's ability to improve safety is General Motors' Super Cruise feature that ensures a driver pays attention to the road. According to information on the company's website, ""When it is engaged, Super Cruise uses a Driver Attention System that monitors the system status and works to detect your head and eye positioning, reminding you to pay attention to the road and steer manually when needed."" Other automotive makers also offer AI-powered capabilities, such as lane-departure warnings, aimed at boosting driver safety.
But AI's safety contributions extend beyond the roadways. It's also used in manufacturing production lines to keep workers safe by, for example, stopping machinery when they get too close to certain areas. And it's used within robots to handle dangerous tasks ranging from defusing bombs to accessing burning buildings, sparing humans from performing those life-threatening jobs.
5. Performs mundane and repetitive tasks
Experts also credit AI for handling repetitive tasks for humans -- both in their jobs and in their personal lives. ""It unburdens the grunt work that humans have had to do,"" Krishna said. As more and more computer systems incorporate AI into their operations, they can perform an increasing amount of lower-level and often boring jobs that can bite into individual's time. Everyday examples of AI's handling of mundane work includes robotic vacuums in the home and data collection in the office. That, in turn, leaves humans with more time for higher-value tasks.


Top 5 disadvantages of AI
Frequently cited drawbacks of AI include the following:
1. A lack of creativity
Although AI has been tasked with creating everything from computer code to visual art, it lacks original thought. ""It can only know what it knows. It can't think outside the box, no pun intended,"" Kelly said. ""It's limited by what it can ingest.""
AI essentially makes predictions based on algorithms and the training data it has been fed; and although machine learning algorithms help the machine learn over time, it doesn't have the capacity humans have for creativity, inspiration and new ways of thinking. ""It's not going to replace critical thinking; it's just going to be another arrow in our quiver,"" said Chaim Mazal, chief security officer at Gigamon, a maker of cybersecurity technology. A Feb. 2023 report from the World Economic Forum states that even though AI can support and enable human creativity, the ""leading opinion is that AI cannot generate fundamentally new ideas on its own."" Whether AI could develop those capabilities is a subject of discussion and debate, even as Microsoft researchers in an April 2023 paper assert that AI has evolved to reason like humans.
2. The absence of empathy
AI can be taught to recognize human emotions such as frustration, but a machine cannot empathize and has no ability to feel. Humans can, giving them a huge advantage over unfeeling AI systems in many areas, including the workplace. Consider the fact that the service sector dominates the U.S. economy, with the Brookings Institute calculating that in 2023 ""four out of five American workers in the private sector are employed in the service economy, doing everything from delivering care in hospitals and nursing homes to making and serving food to ensuring products make it from ports to store shelves and into consumers' hands."" Although some positions -- and aspects of others -- can be automated using AI, Krishna said many of those roles ""require empathy and touchpoints.""
3. Skill loss in humans
Although experts typically list AI's ability to free people from repetitive and mundane tasks as a positive, some believe this particular benefit comes with a downside: a loss of skills in people. People often advance their knowledge, as well as their personal and professional crafts, by first learning and mastering easy repetitive tasks, allowing them to understand how those tasks fit into the bigger chunks of work they must accomplish to complete an objective. But as AI takes over those entry-level jobs, some have voiced concerns that people could lose their ability to know and understand how to perform those tasks. That could stymie their ability to truly master a profession or trade; it could also leave them without the necessary capabilities to step in and perform the work should the AI fail.
4. Possible overreliance on the technology and increased laziness in humans
Similarly, a contingent of thought leaders have said they fear AI could enable laziness in humans. ""We're all concerned about whether it will make us less mindful or thoughtful or thinking,"" said Bill Wong, principal research director at Info-Tech Research Group. He and others noted that some users seem to use AI without double-checking the results, assuming the technology works flawlessly when it does not. AI is far from perfect, with the online site AI Incident Database ""indexing the collective history of harms or near harms realized in the real world by the deployment of artificial intelligence systems.""
5. Job loss and displacement
The equivalent of 300 million full-time jobs could be lost to automation, according to an April 2023 report from Goldman Sachs Research. The authors also estimated ""that roughly two-thirds of U.S. occupations are exposed to some degree of automation by AI."" The story is complicated, though. Economists and researchers have said many jobs will be eliminated by AI, but they've also predicted that AI will shift some workers to higher-value tasks and generate new types of work. Existing and upcoming workers will need to prepare by learning new skills, including the ability to use AI to complement their human capabilities, experts said. ""Although the impact of AI on the labor market is likely to be significant, most jobs and industries are only partially exposed to automation and are thus more likely to be complemented rather than substituted by AI,"" wrote the Goldman Sachs Research authors.


Examples of good AI use cases
AI has enabled significant advances in many areas of society, according to experts. The following use cases illustrate the positive side of this technology:

Newer model cars use AI-enabled systems to ensure safety on the road by monitoring blind spots, alerting drivers when their attention wanes and taking preventative measures such as braking automatically to avoid crashes.
Swiss researchers announced in spring 2023 that they used AI as part of a medical treatment plan to help a paralyzed man walk for the first time in 12 years.
Scientists have always used the latest tools to help them advance their research, and that was certainly the case during the COVID-19 pandemic. Case in point: Researchers created an AI model to help them predict which COVID variants would become dominant, as well as when and where surges in cases would occur.



Examples of bad AI use cases
Although AI itself is a neutral entity, its use in some circumstances demonstrates its limits and potential to harm others. These real-world examples demonstrate how AI can be inappropriately used:

In late spring 2023, a New York lawyer faced judicial scrutiny for submitting court filings citing fictious cases that had been made up by ChatGPT. The lawyer acknowledged using ChatGPT to draft the document and told a federal judge that he didn't realize the tool could make such an error.
In 2019, a video of an apparently drunk Nancy Pelosi, a California Democrat who was then U.S. House Speaker, circulated online. The video was a deepfake, a form of media that has been altered using AI. The believability of that Pelosi video, and others that followed, set off alarms about how AI-generated content could be used to distort truth and spread misinformation.
Another well-publicized example of a poorly executed AI use case happened in 2016, when Microsoft released a chatbot on Twitter. Microsoft engineers designed the bot to act like a female teenager and expected Tay -- the name given to the bot -- to learn to be more like other teens as she engaged online. However, Tay apparently did not have guardrails to block racist, misogynistic and antisemitic language and it became an offensive and hostile bot that Microsoft had to shut down.



Next Steps
Will AI replace jobs? 9 job types that might be affected
What is trustworthy AI and why is it important?
Steps to achieve AI implementation in your business
AI regulation: What businesses need to know
AI transparency: What is it and why do we need it?





Dig Deeper on AI business strategies



Will AI replace jobs? 9 job types that might be affected




By: Ben Lutkevich




IBM boss discusses long-term VM migration opportunity




By: Cliff Saran




Watsonx AI bots assist IBM Consulting in client GenAI projects




By: Don Fluckinger




At Davos, a warning that AI is coming for white-collar jobs




By: Patrick Thibodeau







Sponsored News


Power Your Generative AI Initiatives With High-Performance, Reliable, ...
–Dell Technologies and Intel


A Generative AI Use Case Brought to Life with Solutions from Dell Technologies
–Dell Technologies and Intel


What to Look for in a Server Vendor in 2024
–Dell Technologies and Intel

See More





Related Content


IBM seeks bigger role in HR tech with Watson ...
– HR Software


IBM hybrid cloud, AI offerings ease data integration
– Cloud Computing


Deep learning and neural networks gain commercial ...
– Enterprise AI








",https://schema.org,VideoObject,Top advantages and disadvantages of AI,2023-06-16T08:17Z,,False,,,https://cdn.ttgtmedia.com/rms/onlineimages/competition_a237411574.jpg,"[{'name': 'Mary K. Pratt', '@type': 'Person'}]",,,"{'name': 'TechTarget', 'logo': {'url': 'https://cdn.ttgtmedia.com/rms/amp/amp_teal_logo_115_60.png', 'height': 60, 'width': 115, '@type': 'ImageObject'}, '@type': 'Organization'}",,What is AI (Artificial Intelligence)?,,,https://i.ytimg.com/vi/0oRVLf16CMU/mqdefault.jpg,"{'@type': 'WebPage', '@id': 'https://www.techtarget.com/searchenterpriseai/tip/Top-advantages-and-disadvantages-of-AI'}",,,,"{'cssSelector': '.paywall', '@type': 'WebPageElement', 'isAccessibleForFree': False}",,,PT2M18S,,,,,,,,,,,,,,,,2019-12-21T10:00Z,https://www.youtube.com/embed/0oRVLf16CMU,,,,,,,,,,,,,
https://news.google.com/rss/articles/CBMiP2h0dHBzOi8vd3d3LmZ0LmNvbS9jb250ZW50Lzk4ZTVmNDdhLTdkMGQtNGU2My05YTYzLWZmMzZkNjI3ODJiONIBAA?oc=5,AI in recruitment: the death knell of the CV? - Financial Times,2023-06-17,Financial Times,https://www.ft.com,Generative technology is rebalancing the power dynamic towards applicants,N/A,Generative technology is rebalancing the power dynamic towards applicants,N/A,N/A,N/A,"Jobseekers are increasingly using generative AI to boost their chances of success, from writing CVs and covering letters to predicting possible interview questions  © FT montage/DreamstimeAI in recruitment: the death knell of the CV? on x (opens in a new window)AI in recruitment: the death knell of the CV? on facebook (opens in a new window)AI in recruitment: the death knell of the CV? on linkedin (opens in a new window)AI in recruitment: the death knell of the CV? on whatsapp (opens in a new window)



Save

current progress 0%AI in recruitment: the death knell of the CV? on x (opens in a new window)AI in recruitment: the death knell of the CV? on facebook (opens in a new window)AI in recruitment: the death knell of the CV? on linkedin (opens in a new window)AI in recruitment: the death knell of the CV? on whatsapp (opens in a new window)



Save

Madhumita Murgia and Anjli RavalJune 18 2023162Print this pageStay informed with free updatesSimply sign up to the Artificial intelligence myFT Digest -- delivered directly to your inbox.Students applying for graduate jobs this summer can take advantage of a new personal interview coach. If they send over a specific job description they can receive tailored interview questions and answers — and feedback on their own responses — all for free.The coach, offered by the job search engine Adzuna, is not human but an artificial intelligence bot known as Prepper. It can generate interview questions for more than 1mn live roles at large companies, in industries ranging from technology and financial services to manufacturing and retail.For a graduate job in PwC’s actuarial practice, the chatbot spits out questions such as: “What skills do you think an actuarial consultant should have?” and “How would you explain actuarial concepts to a client who is not from a finance background?”. When a user answers a question, Prepper generates a score out of 100, and tells them which parts worked well and what was missing.Prepper is part of a new wave of chatbots powered by generative AI — from ChatGPT to Bard and Claude. Chatbots are trained on large swaths of text drawn from the internet, including from books, newspapers, blogs, videos and image captions. They can produce plausible and sophisticated text that is largely indistinguishable from human writing.“In the recent 12-18 months, it’s gone bananas,” says Andrew Hunter, co-founder of Adzuna. “It’s of course very hyped at the moment, but there are lots of clever tools [to aid] recruitment, and help people find jobs more easily.”AI is not a new tool in hiring and job-seeking. Over the past decade, it has been used primarily to make processes more efficient and cheaper for employers — from searching for key words in CVs, to filtering video interviews of candidates.But generative AI tools are rebalancing the power dynamic towards applicants. “A lot of the recent improvements we have seen in AI are on the candidate’s side,” says Tomas Chamorro-Premuzic, an organisational psychologist and expert in hiring technologies. “A few years ago, hirers were pretending to use AI to look cool even if they weren’t. Now they are pretending not to use AI.”When Chamorro-Premuzic recently tried to hire for a role, he asked a candidate if they had experimented with generative AI. “They said, ‘If it wasn’t for ChatGPT, I wouldn’t be sat in front of you right now.’” Their CV, cover letter and application had all been written by AI.These systems are powerful, but can also be wrong. How can we implement it with care and an ethical focus?Lindsey Zuloaga, chief data officer, HireVueChamorro-Premuzic, who respected the honesty and decided it was worth taking on someone who was technologically savvy, hired the person. Others are less enthused, warning AI may signal an end to the traditional job application process.“Generative AI can create very good profiles — there may be a few mistakes but only the individual will recognise them, not the employer,” says Matt Jones, from the recruitment technology company Cielo. “This raises the question about the relevance of reviewing CVs, cover letters and applications, particularly at the early career stage. I wonder if this is the death knell of the CV.”For graduates in an increasingly competitive job market, chatbots are a way to cope with a potentially overwhelming process. Ayushman Nath, a second-year undergraduate at the University of Cambridge, says many of his peers have played with ChatGPT, the public chatbot released by the Microsoft-backed OpenAI, asking it to write cover letters for specific companies. He knows people who have advanced through early rounds or secured internships using ChatGPT-written cover letters and applications.“From what I’ve experienced, it’s good at jumping through the initial barriers. The initial filtering rounds are unpersonalised, they feel very remote and dehumanised. Everything is so automated,” Nath says of today’s recruitment processes.Nath and his peers have also been subject to automated video interviews run by recruitment technology providers such as HireVue, which records applicants answering pre-determined questions, usually with a time limit for each answer. The recordings are sometimes watched by the employer’s hiring managers; or the platform’s AI algorithms will assess each candidate’s performance, looking for various keywords from the job description.The company has not launched any generative AI products yet, but its chief data scientist, Lindsey Zuloaga, says her team is testing tools such as interview prep chatbots and new ways to draw information from video interviews. “These systems are powerful, but can also be wrong. How can we implement it with care and an ethical focus?” she says.Grace Lordan, an economist at the London School of Economics and director of The Inclusion Initiative, which studies diversity in corporate settings, says companies, particularly technology groups, are experimenting with generative AI to conduct initial interviews.Grace Lordan, economist at the London School of Economics, believes AI-conducted interviews could help remove bias  © Charlie Bibby/FT“One of the biggest areas of bias is actually the interview,” she says. “This is when people’s affinity bias, or representative bias, which means choosing people who look like others in the organisation, comes in.”AI-conducted interviews could go some way to removing that bias, she says. “Generative AI is quite convincing as an avatar. Using AI as another serious data point will allow pushback from the machines [against human bias].”More employers are also using new assessment methods to broaden the pool of candidates they hire from, amid a global skills and labour shortage and as they push to improve diversity. Automated systems designed for hiring a more diverse workforce can find candidates who may otherwise be overlooked due to health issues, gaps in employment or because they lack a degree or are from a non-traditional background.But although ChatGPT is a useful starting point for a cover letter or for learning the background of a potential employer, recruiters say it is not a replacement for writing an application yourself.RecommendedFT SeriesAI in the workplaceNath, the Cambridge university student, says: “Companies are looking for a relationship with people there, like reaching out to somebody at the firm or a nugget of information that isn’t on the website. And these things can only be cultivated by personal interactions, not AI models.”Hunter, of Adzuna, agrees: “The caution I would give to jobseekers is that AI can act as a good co-pilot but don’t let the tech try and do it all for you . . . It’s very nascent tech, it will spit out cookie-cutter answers. If you let the initial interactions with the employer be fully run by AI, then you aren’t going to be able to do the job.”Copyright The Financial Times Limited 2024. All rights reserved.Reuse this content (opens in new window) CommentsJump to comments section








Promoted ContentExplore the seriesREAD MOREArtificial intelligenceGenerative AI will upend the professionsCurrently reading:AI in recruitment: the death knell of the CV?AI shakes up way we work in three key industriesGenerative AI will upend the professionsBored at work? How AI could come to the rescueWill generative AI boost productivity?

					Follow the topics in this article
			



						Technology sector
					



Add to myFT




						Artificial intelligence
					



Add to myFT




						OpenAI
					



Add to myFT




						Madhumita Murgia
					



Add to myFT




						Anjli Raval
					



Add to myFT



Comments






",http://schema.org,WebSite,AI in recruitment: the death knell of the CV?,2023-06-18T04:00:59.204Z,2023-06-18T04:00:59.204Z,False,"{'@type': ['CreativeWork', 'Product'], 'name': 'Financial Times', 'productID': 'ft.com:subscribed'}",AI in recruitment: the death knell of the CV?,"{'@type': 'ImageObject', '@context': 'http://schema.org', 'url': 'https://www.ft.com/__origami/service/image/v2/images/raw/https%3A%2F%2Fd1e00ek4ebabms.cloudfront.net%2Fproduction%2Fa997c59d-3954-4483-bd65-ce28e400d58f.jpg?source=next-article&fit=scale-down&quality=highest&width=700&dpr=1', 'width': 2048, 'height': 1152}","[{'@type': 'Person', '@context': 'http://schema.org', 'name': 'Madhumita Murgia', 'url': 'https://www.ft.com/madhumita-murgia', 'worksFor': {'@type': 'Organization', '@context': 'http://schema.org', 'name': 'Financial Times', 'legalName': 'The Financial Times Ltd.', 'logo': {'@type': 'ImageObject', '@context': 'http://schema.org', 'url': 'https://im.ft-static.com/m/img/masthead_main.jpg', 'width': 435, 'height': 36}, 'url': 'https://www.ft.com', 'sameAs': ['https://www.twitter.com/FT', 'https://www.facebook.com/financialtimes', 'https://www.linkedin.com/company/financial-times', 'https://www.youtube.com/user/FinancialTimesVideos', 'https://www.instagram.com/financialtimes']}}, {'@type': 'Person', '@context': 'http://schema.org', 'name': 'Anjli Raval', 'url': 'https://www.ft.com/anjli-raval', 'worksFor': {'@type': 'Organization', '@context': 'http://schema.org', 'name': 'Financial Times', 'legalName': 'The Financial Times Ltd.', 'logo': {'@type': 'ImageObject', '@context': 'http://schema.org', 'url': 'https://im.ft-static.com/m/img/masthead_main.jpg', 'width': 435, 'height': 36}, 'url': 'https://www.ft.com', 'sameAs': ['https://www.twitter.com/FT', 'https://www.facebook.com/financialtimes', 'https://www.linkedin.com/company/financial-times', 'https://www.youtube.com/user/FinancialTimesVideos', 'https://www.instagram.com/financialtimes']}}]","Students applying for graduate jobs this summer can take advantage of a new personal interview coach. If they send over a specific job description they can receive tailored interview questions and answers — and feedback on their own responses — all for free.

The coach, offered by the job search engine Adzuna, is not human but an artificial intelligence bot known as Prepper. It can generate interview questions for more than 1mn live roles at large companies, in industries ranging from technology and financial services to manufacturing and retail.

For a graduate job in PwC’s actuarial practice, the chatbot spits out questions such as: “What skills do you think an actuarial consultant should have?” and “How would you explain actuarial concepts to a client who is not from a finance background?”. When a user answers a question, Prepper generates a score out of 100, and tells them which parts worked well and what was missing.

Prepper is part of a new wave of chatbots powered by generative AI — from ChatGPT to Bard and Claude. Chatbots are trained on large swaths of text drawn from the internet, including from books, newspapers, blogs, videos and image captions. They can produce plausible and sophisticated text that is largely indistinguishable from human writing.

“In the recent 12-18 months, it’s gone bananas,” says Andrew Hunter, co-founder of Adzuna. “It’s of course very hyped at the moment, but there are lots of clever tools [to aid] recruitment, and help people find jobs more easily.”

AI is not a new tool in hiring and job-seeking. Over the past decade, it has been used primarily to make processes more efficient and cheaper for employers — from searching for key words in CVs, to filtering video interviews of candidates.

But generative AI tools are rebalancing the power dynamic towards applicants. “A lot of the recent improvements we have seen in AI are on the candidate’s side,” says Tomas Chamorro-Premuzic, an organisational psychologist and expert in hiring technologies. “A few years ago, hirers were pretending to use AI to look cool even if they weren’t. Now they are pretending not to use AI.”

When Chamorro-Premuzic recently tried to hire for a role, he asked a candidate if they had experimented with generative AI. “They said, ‘If it wasn’t for ChatGPT, I wouldn’t be sat in front of you right now.’” Their CV, cover letter and application had all been written by AI.

Chamorro-Premuzic, who respected the honesty and decided it was worth taking on someone who was technologically savvy, hired the person. Others are less enthused, warning AI may signal an end to the traditional job application process.

“Generative AI can create very good profiles — there may be a few mistakes but only the individual will recognise them, not the employer,” says Matt Jones, from the recruitment technology company Cielo. “This raises the question about the relevance of reviewing CVs, cover letters and applications, particularly at the early career stage. I wonder if this is the death knell of the CV.”

For graduates in an increasingly competitive job market, chatbots are a way to cope with a potentially overwhelming process. Ayushman Nath, a second-year undergraduate at the University of Cambridge, says many of his peers have played with ChatGPT, the public chatbot released by the Microsoft-backed OpenAI, asking it to write cover letters for specific companies. He knows people who have advanced through early rounds or secured internships using ChatGPT-written cover letters and applications.

“From what I’ve experienced, it’s good at jumping through the initial barriers. The initial filtering rounds are unpersonalised, they feel very remote and dehumanised. Everything is so automated,” Nath says of today’s recruitment processes.

Nath and his peers have also been subject to automated video interviews run by recruitment technology providers such as HireVue, which records applicants answering pre-determined questions, usually with a time limit for each answer. The recordings are sometimes watched by the employer’s hiring managers; or the platform’s AI algorithms will assess each candidate’s performance, looking for various keywords from the job description.

The company has not launched any generative AI products yet, but its chief data scientist, Lindsey Zuloaga, says her team is testing tools such as interview prep chatbots and new ways to draw information from video interviews. “These systems are powerful, but can also be wrong. How can we implement it with care and an ethical focus?” she says.

Grace Lordan, an economist at the London School of Economics and director of The Inclusion Initiative, which studies diversity in corporate settings, says companies, particularly technology groups, are experimenting with generative AI to conduct initial interviews.

“One of the biggest areas of bias is actually the interview,” she says. “This is when people’s affinity bias, or representative bias, which means choosing people who look like others in the organisation, comes in.”

AI-conducted interviews could go some way to removing that bias, she says. “Generative AI is quite convincing as an avatar. Using AI as another serious data point will allow pushback from the machines [against human bias].”

More employers are also using new assessment methods to broaden the pool of candidates they hire from, amid a global skills and labour shortage and as they push to improve diversity. Automated systems designed for hiring a more diverse workforce can find candidates who may otherwise be overlooked due to health issues, gaps in employment or because they lack a degree or are from a non-traditional background.

But although ChatGPT is a useful starting point for a cover letter or for learning the background of a potential employer, recruiters say it is not a replacement for writing an application yourself.

Nath, the Cambridge university student, says: “Companies are looking for a relationship with people there, like reaching out to somebody at the firm or a nugget of information that isn’t on the website. And these things can only be cultivated by personal interactions, not AI models.”

Hunter, of Adzuna, agrees: “The caution I would give to jobseekers is that AI can act as a good co-pilot but don’t let the tech try and do it all for you . . . It’s very nascent tech, it will spit out cookie-cutter answers. If you let the initial interactions with the employer be fully run by AI, then you aren’t going to be able to do the job.”",1078,"{'@type': 'Organization', '@context': 'http://schema.org', 'name': 'Financial Times', 'legalName': 'The Financial Times Ltd.', 'logo': {'@type': 'ImageObject', '@context': 'http://schema.org', 'url': 'https://im.ft-static.com/m/img/masthead_main.jpg', 'width': 435, 'height': 36}, 'url': 'https://www.ft.com', 'sameAs': ['https://www.twitter.com/FT', 'https://www.facebook.com/financialtimes', 'https://www.linkedin.com/company/financial-times', 'https://www.youtube.com/user/FinancialTimesVideos', 'https://www.instagram.com/financialtimes']}","[{'@type': 'ListItem', 'position': 1, 'name': 'Companies', 'item': 'https://www.ft.com/companies'}, {'@type': 'ListItem', 'position': 2, 'name': 'Technology', 'item': 'https://www.ft.com/technology'}, {'@type': 'ListItem', 'position': 3, 'name': 'Artificial intelligence', 'item': 'https://www.ft.com/artificial-intelligence'}]",Financial Times,FT.com,http://www.ft.com,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
https://news.google.com/rss/articles/CBMif2h0dHBzOi8vd3d3LmZhc3Rjb21wYW55LmNvbS85MDkwOTk0MC9zcGVhay1saXN0ZW4tZG8taG93LWdlbmVyYXRpdmUtYWktYW5kLXZvaWNlLXRlY2hub2xvZ3ktd2lsbC10cmFuc2Zvcm0taG93LXdlLWxpdmUtYW5kLXdvcmvSAQA?oc=5,"Speak, listen, do: how generative AI and voice technology will transform how we live and work - Fast Company",2023-06-20,Fast Company,https://www.fastcompany.com,N/A,N/A,N/A,N/A,N/A,N/A,N/A,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
https://news.google.com/rss/articles/CBMiYGh0dHBzOi8vd3d3LmRoYWthdHJpYnVuZS5jb20vb3Bpbmlvbi9vcC1lZC8zMTM2MDAvYXJ0aWZpY2lhbC1pbnRlbGxpZ2VuY2UtaXMtY29taW5nLWZvci15b3VyLWpvYtIBZGh0dHBzOi8vd3d3LmRoYWthdHJpYnVuZS5jb20vYW1wL29waW5pb24vb3AtZWQvMzEzNjAwL2FydGlmaWNpYWwtaW50ZWxsaWdlbmNlLWlzLWNvbWluZy1mb3IteW91ci1qb2I?oc=5,Artificial intelligence is coming for your job - Dhaka Tribune,2023-06-16,Dhaka Tribune,https://www.dhakatribune.com,N/A,N/A,N/A,N/A,N/A,N/A,N/A,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
https://news.google.com/rss/articles/CBMiiQFodHRwczovL2ZpbmFuY2UueWFob28uY29tL25ld3MvaW52ZXN0b3ItYW5kLW11c2ljaWFuLXdpbGxpYW0tZ2VuZXJhdGl2ZS1haS1pcy1hLWpvYi1jcmVhdG9yLWFuZC13aWxsLWhlbHAtYXZvaWQtbWVkaW9jcml0eS0xOTQxMDMzMDYuaHRtbNIBAA?oc=5,Investor and musician will.i.am: Generative AI is 'a job creator' and will help avoid mediocrity - Yahoo Finance,2023-06-20,Yahoo Finance,https://finance.yahoo.com,"Investor, businessman, and musician will.i.am chats about his next big ideas in AI and investing with Yahoo Finance Live at Cannes Lions.","['generative AI', 'Cannes Lions Festival', 'Brad Smith', 'CANNES, France', 'Brian Sozzi', 'jobs of the future']","Investor, businessman, and musician will.i.am chats about his next big ideas in AI and investing with Yahoo Finance Live at Cannes Lions.","Investor, businessman, and musician will.i.am chats about his next big ideas in AI and investing with Yahoo Finance Live at Cannes Lions.",N/A,N/A,"Read full articleYahoo FinanceInvestor and musician will.i.am: Generative AI is 'a job creator' and will help avoid mediocrityBrian Sozzi·Executive EditorUpdated Tue, Jun 20, 20233 min readLink Copied41In this article: IBM
            +0.38% CRM
            +2.89% AAPL
            +0.49% INTC
            +0.52% CANNES, France — Musician, futurist, and well-connected investor will.i.am suggested the talk about generative AI crushing jobs may be on the overdone side.In his eyes, working closely with the new tech may prove to be job enhancing over time.""If you are a creator and you see this tool, then it's a job creator,"" the entrepreneur told Yahoo Finance Live at the Cannes Lions Festival of Creativity on Monday. ""If you are tied to yesterday and just comfortable with mediocrity, then it's a job [destroyer].""The debate on how AI will shape the jobs of the future and the economy remains a hot topic in markets and economists' circles.Yahoo Finance's Brian Sozzi and Brad Smith speak with investor and musician will.i.am on all things AI at the Cannes Lions Festival of Creativity. (Yahoo Finance)A positive spin on the impact comes out of a new McKinsey study last week. The study identified 63 generative AI use cases spanning 16 business functions that could unleash between $2.6 trillion and $4.4 trillion in economic benefits annually.However, dark cloud takes aren't hard to find either.OpenAI's chief operating officer Brad Lightcap told a crowd at a WSJ Cannes event on Monday that AI could be a job eliminator.""Every large company has an army of people that read and review contracts for revenue recognition purposes, for example,"" Lightcap said at the gathering. ""You may not have that job. That may not be a job of the future.""Goldman Sachs recently estimated that generative AI could expose the equivalent of 300 million jobs globally to automation over the next decade. That's a nice way of saying a person may lose their job to a robot.""What I love about it [generative AI] is that everyone now has the ability to create, because now you have a partner to be able to push it,"" will.i.am added. ""It's not just for songs. It's not just for poetry. It's not just for writing emails. It's not just for marketing strategies. Use it to solve problems, and then by that problem that you solve, it will create jobs.""Will.i.am speaks about how AI will affect creators in Cannes, France. (Yahoo Finance)Will.i.am's FYI, IBM team up on AIBorn William Adams in Los Angeles in 1975, the naturally curious will.i.am didn't exactly run in tech circles. But today, will.i.am is using his investing acumen, brand, and access to top tech leaders such as Salesforce CEO Marc Benioff to invest in new AI ventures.He rose to fame in the late 1990s and early 2000s as a member of the Black Eyed Peas, a band that has sold more than 58 million singles worldwide. The group is still putting out music, minus longtime front-person Fergie, who has retired to spend more time with her family.Will.i.am was an early investor in headphone maker Beats, netting him an undisclosed amount when Apple (AAPL) purchased the company for $3 billion in 2014, and he also struck a partnership deal with Intel (INTC) to promote various hardware.Story continuesHis latest venture is a generative AI messaging and video creation app called FYI. At Cannes, will.i.am revealed a new tie-up with IBM that will weave Watsonx AI technology into the FYI platform.The musician-turned-businessman thinks global businesses are on the cusp of radical transformation in the next decade at the hands of AI.""There's still a lot of folks that don't understand how it's going to transform everything,"" the investor added.Brian Sozzi is Yahoo Finance's Executive Editor. Follow Sozzi on Twitter @BrianSozzi and on LinkedIn. Tips on the banking crisis? Email brian.sozzi@yahoofinance.comClick here for the latest stock market news and in-depth analysis, including events that move stocksRead the latest financial and business news from Yahoo Finance",http://schema.org,NewsArticle,Investor and musician will.i.am: Generative AI is 'a job creator' and will help avoid mediocrity,2023-06-20T19:41:03.000Z,2023-06-20T19:41:03.000Z,,,,"{'@type': 'ImageObject', 'url': 'https://s.yimg.com/ny/api/res/1.2/5cscFKl5anhjaKFir7rdtg--/YXBwaWQ9aGlnaGxhbmRlcjt3PTEyMDA7aD04MDA7Y2Y9d2VicA--/https://s.yimg.com/os/creatr-uploaded-images/2023-06/a6bda980-0f72-11ee-aef8-ede31fd61cea', 'width': 1200, 'height': 800}","{'@type': 'Person', 'name': 'Brian Sozzi', 'url': 'https://www.yahoo.com/author/brian-sozzi/', 'jobTitle': 'Executive Editor'}",,,"{'@type': 'Organization', 'name': 'Yahoo Finance', 'logo': {'@type': 'ImageObject', 'url': 'https://s.yimg.com/rz/p/yahoo_finance_en-US_h_p_finance_2.png', 'width': 354, 'height': 50}, 'url': 'https://finance.yahoo.com/'}",,,,,https://s.yimg.com/ny/api/res/1.2/5cscFKl5anhjaKFir7rdtg--/YXBwaWQ9aGlnaGxhbmRlcjt3PTEyMDA7aD04MDA7Y2Y9d2VicA--/https://s.yimg.com/os/creatr-uploaded-images/2023-06/a6bda980-0f72-11ee-aef8-ede31fd61cea,https://finance.yahoo.com/news/investor-and-musician-william-generative-ai-is-a-job-creator-and-will-help-avoid-mediocrity-194103306.html,,,,,,,,,"{'@context': 'https://schema.org', '@type': 'VideoObject', 'name': 'Watch what happens at the Cannes Lions festival', 'description': 'Yahoo Finance takes you inside the 2023 Cannes Lions International Festival of Creativity. Held annually, the event draws thousands of professionals from the global ad business, and they have one mission in mind: how best to target you. We’ll be there interviewing the movers and shakers in the world of marketing, advertising, sports, and media. This year’s event comes at a pivotal point in the advertising business. <a data-i13n=""cpos:1;pos:1"" href=""https://finance.yahoo.com/video/certainly-recession-nouriel-roubini-143850360.html"">Economic pressures</a> have forced companies to make deep cost cuts with many of those hitting marketing and advertising budgets.</p>\n<p>Some of the big themes we’re covering include how companies are generating demand during a discretionary spending downturn. We’ll also explore how companies are trying to strike the right tone in hopes of broadening their brand appeal. Some companies looking to expand their customer base have suffered backlash amid a polarized society. <a data-i13n=""cpos:2;pos:1"" href=""https://finance.yahoo.com/quote/BUD"">Bud Light</a>, <a data-i13n=""cpos:3;pos:1"" href=""https://finance.yahoo.com/quote/TAP"">Miller Light</a>, and <a data-i13n=""cpos:4;pos:1"" href=""https://finance.yahoo.com/quote/TGT"">Target</a> - all under fire this year.</p>\n<p>Among our special guests, actor and comedian Kevin Hart, recording artist will.i.am, and top executives at leading consumer giants from <a data-i13n=""cpos:5;pos:1"" href=""https://finance.yahoo.com/quote/KO"">Coca-Cola</a> to <a data-i13n=""cpos:6;pos:1"" href=""https://finance.yahoo.com/quote/MA"">Mastercard</a>. We’ll tackle a variety of hot topics including the latest pulse on the health of the broader economy, <a data-i13n=""cpos:7;pos:1"" href=""https://finance.yahoo.com/news/beer-wars-bud-light-loses-top-spot-to-modelo-in-may-144733135.html"">recent controversies surrounding advertising and influencer campaigns by major brands</a>, and <a data-i13n=""cpos:8;pos:1"" href=""https://finance.yahoo.com/news/meta-is-banking-on-ai-to-power-the-future-of-its-ads-business-212132613.html"">how new technology, especially AI, is being used to market to you</a>.</p>\n<p>Our coverage will be led by Yahoo Finance\'s Executive Editor <a data-i13n=""cpos:9;pos:1"" href=""https://www.yahoo.com/author/brian-sozzi/"">Brian Sozzi</a> and Anchor <a data-i13n=""cpos:10;pos:1"" href=""https://www.yahoo.com/author/bradley-smith/"">Brad Smith</a>. Please join us all week June 20th to the 23rd live from Cannes, France.</p>\n<p>Key video moments</p>\n<p>00:00:15 - What happens at Cannes Lions festival 2023</p>\n<p>00:00:55 - big challenges for the biggest brands</p>\n<p>00:01:05 - managing a marketing backlash', 'thumbnailUrl': 'https://s.yimg.com/uu/api/res/1.2/8q0EJNKG6oFiDZBgxr2y4w--~B/aD0xMDgwO3c9MTkyMDthcHBpZD15dGFjaHlvbg--/https://s.yimg.com/os/creatr-uploaded-images/2023-06/815abe00-0b24-11ee-97d3-de3ce8a0c3f6', 'duration': 'PT1M59S', 'contentUrl': 'https://video.media.yql.yahoo.com/v1/video/sapi/hlsstreams/331a4d25-e590-3dcb-988d-c6580e7ed002.m3u8?site=finance&region=US&lang=en-US&devtype=desktop&src=sapi', 'embedUrl': 'https://finance.yahoo.com/video/watch-happens-cannes-lions-festival-100008613.html?format=embed', 'identifier': '331a4d25-e590-3dcb-988d-c6580e7ed002'}",,,,,,,,,,,,,,,,"{'@type': 'Person', 'name': 'Brian Sozzi', 'url': 'https://www.yahoo.com/author/brian-sozzi/', 'jobTitle': 'Executive Editor'}","{'@type': 'Organization', 'name': 'Yahoo Finance', 'url': 'http://finance.yahoo.com/', 'logo': {'@type': 'ImageObject', 'width': 484, 'height': 100, 'url': 'https://s.yimg.com/os/creatr-uploaded-images/2020-12/02246f50-3412-11eb-bfdd-de89f8b3b8b8'}}",,,,,,,,,,,
https://news.google.com/rss/articles/CBMiXGh0dHBzOi8vd3d3LmFkbmV3cy5jb20uYXUvbmV3cy90aGUtam9icy1kb2luZy13ZWxsLWFuZC10aG9zZS1iYWRseS1pbi1haS1wb3dlcmVkLWFkdmVydGlzaW5n0gEA?oc=5,"The jobs doing well, and those badly, in AI-powered advertising - AdNews",2023-06-20,AdNews,https://www.adnews.com.au,"Smaller, yet more capable, agencies.",,"Smaller, yet more capable, agencies.",N/A,N/A,N/A,"



Credit: Joshua Sortino via Unsplash



Automation and generative artificial intelligence (AI) will mean smaller, yet more capable, advertising agencies, according to analysis by global consultancy Forrester.
The disruption to the industry will mean the destruction and rebirth of creativity. 
The Agency AI-Powered Workforce Forecast, 2030 reveals US advertising agencies and related services companies will lose 32,000 jobs to automation.
Creative problem-solving roles will thrive but process-oriented jobs will shrink due to the influence of automation, machine learning and generative AI. 
The global advertising groups are in a frenzy, a form of arms race, to adopt AI (artificial intelligence) in what’s been described as a new industrial revolution.
""The meteoric rise of generative AI marks both a beginning and ending for marketing creativity as we know it,"" says Jay Pattisall, VP, principal analyst at Forrester.
""These technologies bring tremendous computing power, speed, and scale to the human act of creativity and ideation.""AdChoicesADVERTISING
He says the benefits of generative AI to marketing are: Enhancing human intuition with machine intelligence; Amplifying creators’ work; Adding scale and speed to creative quality.
""Yet artificial intelligence is also burdensome,"" he says.
""It forces us to rethink the nonlinear creative process to meet brands’ exponential needs for volumes of efficient, fit-for-format content and advertising.
""It forces us to unlearn and relearn creativity. It presents challenges such as inaccuracy, bias, ethical, and legal liability for both brands and agencies.
""In effect, it’s the destruction and rebirth of creativity — as we know it. When AI is combined with your brand’s creative process, what emerges is intelligent creativity."" 
The latest Forrester report, which focuses on the US market, also says generative AI will both account for nearly a third of automated advertising jobs and increase the productivity of higher-wage skillsets in agencies.
""Forrester assumes job losses from generative AI over the next two years will be modest — until questions around intellectual property rights, copyright, plagiarism, model refresh rate, bias, ethics, and accuracy are resolved,"" the study says.

Forrester also assumes that generative AI job loss potential is low for jobs that require a physical presence, such as a chief executive or manager, even if generative AI influence is high.
""The marketing mindset on AI turns from fear to fascination as the post-pandemic services boom winds down and enthusiasm for generative AI kicks into overdrive,"" says Forrester.
By 2030, agency jobs most at risk from generative AI include clerical, secretarial, and administrative roles (28% of job losses); sales and connected roles (22% of job losses); and market research and connected roles (18% of job losses).
Despite automation potential, the share of agency jobs in management, public relations, creative roles, market research, software (including web and digital interface designers), and data science will grow.
And jobs for clerical, sales, finance, administrative and labor-intensive roles will decline.
Globally, digital marketing and strategy specialists will see more than 20% headcount growth in the next five years.
Fundraising and public relations will grow faster than the job market, and there will be double-digit growth to 2030 for market research and marketing specialists, computer and information system managers, editors and art directors.
Generative AI increases the productivity of higher-wage skill sets. Image generation software add speed and scale to the marketing process to lower the cost of creating content and reconfigure agency skill sets.
Higher-paid jobs most influenced by generative AI technology include editors, writers and authors, technical writers   and programmers.
""This suggests a coming inversion of the agency workforce composition, from legions of less-costly junior talent matched with senior managers to highly paid creator skill sets paired with generative AI assistants,"" says Forrester.
Aaron Kwittken, CEO of PRophet, and AI-driven SaaS platform for the PR community, says the fear and loathing phase has passed into curiosity and adoption. 
According to Forrester’s 2023 data, 56% of US B2C marketing and advertising decision-makers (vice president or above) have already used generative AI in marketing, and another 40% are intrigued or exploring uses.
As a result, advertising and marketing use cases for AI and automation abound with, Forrester says, generative AI turbocharging creators and the creative development process.
The common uses include brainstorming creative concepts, authouring copy for campaigns, SEO keyword optimisation, versioning content designs and production assets, coding and script authouring.
AI-powered intelligence also sharpens media planning and activation.
Agency audience activation platforms, such as DEPT’s Ada, GroupM Nexus, Havas Media Group’s Converged, Omnicom Group’s Omni, Publicis Groupe’s Epsilon PeopleCloud, PMG’s Alli, and Tinuiti’s Bliss Point, each leverage machine learning models and (soon) generative AI authoring and knowledge management to power the audience-intelligence-based approach to media strategy and execution.
 
Have something to say on this? Share your views in the comments section below. Or if you have a news story or tip-off, drop us a line at adnews@yaffa.com.au
Sign up to the AdNews newsletter, like us on Facebook or follow us on Twitter for breaking stories and campaigns throughout the day.
",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
https://news.google.com/rss/articles/CBMiY2h0dHBzOi8vd3d3LmNic25ld3MuY29tL25ld3MvYWktYXJ0aWZpY2lhbC1pbnRlbGxpZ2VuY2Uta25vd2xlZGdlLWJhc2VkLWpvYnMtY291bGQtYmUtbW9zdC1hdC1yaXNrL9IBZ2h0dHBzOi8vd3d3LmNic25ld3MuY29tL2FtcC9uZXdzL2FpLWFydGlmaWNpYWwtaW50ZWxsaWdlbmNlLWtub3dsZWRnZS1iYXNlZC1qb2JzLWNvdWxkLWJlLW1vc3QtYXQtcmlzay8?oc=5,"""Knowledge-based"" jobs could be most at risk from AI boom - CBS News",2023-06-16,CBS News,https://www.cbsnews.com,"The emergence of new forms of AI ""will require reskilling, flexibility and learning how to learn new things,"" expert says.","['Artificial Intelligence', 'AI', 'ChatGPT']","The emergence of new forms of AI ""will require reskilling, flexibility and learning how to learn new things,"" expert says.","The emergence of new forms of AI ""will require reskilling, flexibility and learning how to learn new things,"" expert says.",N/A,N/A,"


MoneyWatch

""Knowledge-based"" jobs could be most at risk from AI boom






    By
                        
              Sanvi Bangalore


    Edited By
                        
                      Aimee Picchi, 
                              
              Alain Sherter


June 16, 2023 / 12:57 PM EDT
          / MoneyWatch
        



















What jobs are safe from AI? 











What jobs are safe from AI?
04:18

The boom in ""generative"" artificial intelligence may usher in the ""next productivity frontier"" in the workplace, but it could also cause job losses and disruption for some knowledge-based workers such as software developers and marketers, according to McKinsey. Integrating generative AI tools into the workplace could theoretically automate as much as 70% of the time an employee spends completing tasks on the job, the consulting firm estimated. That could help many workers save time on routine tasks, which in turn will boost profitability for businesses, McKinsey said in a recent report.For the U.S. economy as a whole, meanwhile, the gains could be considerable, adding $4.4 trillion annually to the nation's GDP. 






But such productivity gains could come with a downside, as some companies may decide to cut jobs since workers won't need as many hours to complete their tasks. Most at risk from advanced forms of AI are knowledge-based workers, who tend to be employed in jobs that traditionally have had higher wages and more job security than blue-collar workers. As a result, most knowledge workers will be changing what they do over time, McKinsey Global Partner Michael Chui told CBS MoneyWatch. 


Generative AI will ""give us superpowers"" by allowing workers to be more productive, but employees will need to adapt, Chui said. This ""will require reskilling, flexibility and learning how to learn new things."" AI could replace half of workers' daily work activities by 2045, which McKinsey said is eight years earlier than it had previously forecast. Where AI will thriveTo be sure, AI won't transform every job, and it could impact some corporate fields more than others. At the top of the list are software development, customer service operations and marketing, according to Rodney Zemmel, a senior partner at McKinsey. Software engineering teams are likely to rely on generative AI to reduce the time they spend generating code. Already, big tech firms are selling AI tools for software engineering, which is being used by 20 million coders, the firm found.


Customer service operations could also undergo a transformation, with AI-powered chatbots creating quick, personalized responses to complex customer questions. Because generative AI can quickly retrieve data for a specific customer, it can reduce the time human sales representatives need to respond. Marketers also could tap AI to help with creating content and assist in interpreting data and with search engine optimization. Workers who are concerned about their jobs should stay on top of emerging technologies like generative AI and understand its place in their respective fields,the McKinsey experts recommended. ""Be on the early edge of adoption"" to stay ahead in the job market, Zemmel advised. 






The ChatGPT Revolution | CBS Reports
22:38

Still, most jobs won't be transformed overnight, Zemmel said.""It's worth remembering in customer service and marketing just how early this technology is and how much work needs to be put in to get it to work safely, reliably, at scale, and the way that most human professional enterprises are going to want to use it,"" he noted. Examining past technological advances provides a hint of how AI is likely to impact workers.


""How many jobs were lost when Google came out?"" Zemmel asked. ""I'm sure the answer wasn't zero, but companies didn't dramatically restructure because of all the work that was no longer needed in document retrieval.""Zemmel said that when he asks corporate managers how they use AI technologies, the common answer is ""writing birthday poems and toasts."" So AI ""still has a way to go before it's really transforming businesses,"" he added.


More from CBS News






 How the rise of AI is straining the U.S. power grid







 Delta cancels more flights Monday as fallout from CrowdStrike outage persists







 Gold prices remain elevated. Should you invest in 1-ounce gold bars now?







 Microsoft outage shuts down Starbucks' mobile ordering app




In:
          Artificial Intelligence
AI
ChatGPT

Sanvi Bangalore


Sanvi Bangalore is a business reporting intern for CBS MoneyWatch. She attends American University in Washington, D.C., and is studying business administration and journalism.



                      Twitter
                    





© 2023 CBS Interactive Inc. All Rights Reserved.

",https://schema.org,BreadcrumbList,"""Knowledge-based"" jobs could be most at risk from AI boom",2023-06-16T12:57:00-0400,2023-07-11T11:39:57-0400,,,,"{'@context': 'https://schema.org', '@type': 'ImageObject', 'height': 630, 'width': 1200, 'url': 'https://assets2.cbsnewsstatic.com/hub/i/r/2023/02/01/3939dccc-c8e0-4217-bd9b-58b1b472fd1e/thumbnail/1200x630/b34c0dff7171d3718ac5cfae64e2bcff/cbsn-fusion-the-rise-of-ai-could-chatgpt-take-your-job-thumbnail-1675345-640x360.jpg?v=e2b758f558b9b19612f3e16bc7fd9fcc'}","[{'@type': 'Person', 'familyName': 'Bangalore', 'givenName': 'Sanvi', 'name': 'Sanvi Bangalore', 'sameAs': 'https://x.com/https://twitter.com/SanviBangalore', 'affiliation': {'@type': 'Organization', 'name': 'CBS News'}, 'worksFor': [{'@type': 'Organization', 'name': 'CBS News'}], 'publishingPrinciples': 'https://www.cbsnews.com/news/cbs-news-publishing-principles/'}]","The boom in ""generative"" artificial intelligence may usher in the ""next productivity frontier"" in the workplace, but it could also cause job losses and disruption for some knowledge-based workers such as software developers and marketers, according to McKinsey. Integrating generative AI tools into the workplace could theoretically automate as much as 70% of the time an employee spends completing tasks on the job, the consulting firm estimated. That could help many workers save time on routine tasks, which in turn will boost profitability for businesses, McKinsey said in a recent report.For the U.S. economy as a whole, meanwhile, the gains could be considerable, adding $4.4 trillion annually to the nation's GDP.But such productivity gains could come with a downside, as some companies may decide to cut jobs since workers won't need as many hours to complete their tasks. Most at risk from advanced forms of AI are knowledge-based workers, who tend to be employed in jobs that traditionally have had higher wages and more job security than blue-collar workers. As a result, most knowledge workers will be changing what they do over time, McKinsey Global Partner Michael Chui told CBS MoneyWatch. Generative AI will ""give us superpowers"" by allowing workers to be more productive, but employees will need to adapt, Chui said. This ""will require reskilling, flexibility and learning how to learn new things."" AI could replace half of workers' daily work activities by 2045, which McKinsey said is eight years earlier than it had previously forecast. Where AI will thriveTo be sure, AI won't transform every job, and it could impact some corporate fields more than others. At the top of the list are software development, customer service operations and marketing, according to Rodney Zemmel, a senior partner at McKinsey. Software engineering teams are likely to rely on generative AI to reduce the time they spend generating code. Already, big tech firms are selling AI tools for software engineering, which is being used by 20 million coders, the firm found.Customer service operations could also undergo a transformation, with AI-powered chatbots creating quick, personalized responses to complex customer questions. Because generative AI can quickly retrieve data for a specific customer, it can reduce the time human sales representatives need to respond. Marketers also could tap AI to help with creating content and assist in interpreting data and with search engine optimization. Workers who are concerned about their jobs should stay on top of emerging technologies like generative AI and understand its place in their respective fields,the McKinsey experts recommended. ""Be on the early edge of adoption"" to stay ahead in the job market, Zemmel advised. Still, most jobs won't be transformed overnight, Zemmel said.""It's worth remembering in customer service and marketing just how early this technology is and how much work needs to be put in to get it to work safely, reliably, at scale, and the way that most human professional enterprises are going to want to use it,"" he noted. Examining past technological advances provides a hint of how AI is likely to impact workers.""How many jobs were lost when Google came out?"" Zemmel asked. ""I'm sure the answer wasn't zero, but companies didn't dramatically restructure because of all the work that was no longer needed in document retrieval.""Zemmel said that when he asks corporate managers how they use AI technologies, the common answer is ""writing birthday poems and toasts."" So AI ""still has a way to go before it's really transforming businesses,"" he added.",,"{'@context': 'https://schema.org', '@type': 'NewsMediaOrganization', '@id': 'https://www.cbsnews.com/', 'name': 'CBS News', 'foundingDate': '1927-09-18', 'sameAs': ['https://www.cbsnews.com/', 'https://www.facebook.com/CBSNews/', 'https://instagram.com/cbsnews/', 'https://twitter.com/CBSNews', 'https://www.youtube.com/CBSNews', 'https://en.wikipedia.org/wiki/CBS_News'], 'logo': [{'@context': 'https://schema.org', '@type': 'ImageObject', 'height': 60, 'width': 600, 'url': 'https://www.cbsnews.com/assets/standalone/cbsnews-logo-white-600x60.png'}], 'url': 'https://www.cbsnews.com/', 'parentOrganization': {'@type': 'Organization', 'name': 'Paramount Global', '@id': 'https://www.paramount.com/', 'sameAs': 'https://www.paramount.com/', 'legalName': 'Paramount Global'}, 'actionableFeedbackPolicy': 'https://www.cbsnews.com/news/cbs-news-publishing-principles/#1d4ed2b9-ade8-4203-a4e4-115dd34c0735', 'correctionsPolicy': 'https://www.cbsnews.com/news/cbs-news-publishing-principles/#751608ae-9468-457c-9dbe-1f9400a7f428', 'ethicsPolicy': 'https://www.cbsnews.com/news/cbs-news-publishing-principles/#a0060f90-73b0-4a57-b756-ca7a7f26cc7d', 'Masthead': 'https://www.cbsnews.com/news/cbs-news-publishing-principles/#5fd9a80d-2c6c-4d38-8b1e-4144650d5963', 'missionCoveragePrioritiesPolicy': 'https://www.cbsnews.com/news/cbs-news-publishing-principles/#4ffda755-6b47-49e1-b98c-24b737906aca', 'ownershipFundingInfo': 'https://www.paramount.com/company-history', 'unnamedSourcesPolicy': 'https://www.cbsnews.com/news/cbs-news-publishing-principles/#de41886e-07ed-4887-ad05-4b2c79edf857', 'publishingPrinciples': 'https://www.cbsnews.com/news/cbs-news-publishing-principles/'}","[{'@type': 'ListItem', 'position': 1, 'item': {'@id': 'https://www.cbsnews.com/', '@type': 'WebPage', '@name': 'CBSNews.com'}}, {'@type': 'ListItem', 'position': 2, 'name': 'MoneyWatch', 'item': {'@id': 'https://www.cbsnews.com/moneywatch', '@type': 'CollectionPage', '@name': 'MoneyWatch'}}, {'@type': 'ListItem', 'position': 3, 'name': '""Knowledge-based"" jobs could be most at risk from AI boom', 'item': {'@id': 'https://www.cbsnews.com/news/ai-artificial-intelligence-knowledge-based-jobs-could-be-most-at-risk/', '@name': '""Knowledge-based"" jobs could be most at risk from AI boom'}}]","""Knowledge-based"" jobs could be most at risk from AI boom",,https://www.cbsnews.com/news/ai-artificial-intelligence-knowledge-based-jobs-could-be-most-at-risk/,https://assets2.cbsnewsstatic.com/hub/i/r/2023/02/01/3939dccc-c8e0-4217-bd9b-58b1b472fd1e/thumbnail/1200x630/b34c0dff7171d3718ac5cfae64e2bcff/cbsn-fusion-the-rise-of-ai-could-chatgpt-take-your-job-thumbnail-1675345-640x360.jpg?v=e2b758f558b9b19612f3e16bc7fd9fcc,"{'@type': 'WebPage', '@id': 'https://www.cbsnews.com/news/ai-artificial-intelligence-knowledge-based-jobs-could-be-most-at-risk/'}",,"[{'@type': 'Person', 'familyName': 'Picchi', 'givenName': 'Aimee', 'name': 'Aimee Picchi'}, {'@type': 'Person', 'familyName': 'Sherter', 'givenName': 'Alain', 'name': 'Alain Sherter'}]",['MoneyWatch'],,,,,"{'@context': 'https://schema.org', '@type': 'ImageObject', 'height': 630, 'width': 1200, 'url': 'https://assets2.cbsnewsstatic.com/hub/i/r/2023/02/01/3939dccc-c8e0-4217-bd9b-58b1b472fd1e/thumbnail/1200x630/b34c0dff7171d3718ac5cfae64e2bcff/cbsn-fusion-the-rise-of-ai-could-chatgpt-take-your-job-thumbnail-1675345-640x360.jpg?v=e2b758f558b9b19612f3e16bc7fd9fcc'}","{'@context': 'https://schema.org', '@type': 'VideoObject', 'mainEntityOfPage': {'@type': 'WebPage', '@id': 'https://www.cbsnews.com/video/what-jobs-are-safe-from-ai/'}, 'name': 'What jobs are safe from AI?', 'description': ""Artificial intelligence will likely remake the workplace. A recent analysis from Goldman Sachs looked at the global impact, and found that AI could replace 300 million full-time jobs. Futurist Martin Ford joined CBS News to discuss the jobs he believes AI likely won't take, and what you can do if you're concerned your job may be replaced."", 'thumbnail': {'@context': 'https://schema.org', '@type': 'ImageObject', 'height': 630, 'width': 1200, 'url': 'https://assets3.cbsnewsstatic.com/hub/i/r/2023/06/03/2b776595-e67f-4de4-9b4e-f74ea75f8b29/thumbnail/1200x630/42501db08cdbaa4430758c0ede209ba0/ai-work.jpg?v=e2b758f558b9b19612f3e16bc7fd9fcc'}, 'thumbnailUrl': 'https://assets3.cbsnewsstatic.com/hub/i/r/2023/06/03/2b776595-e67f-4de4-9b4e-f74ea75f8b29/thumbnail/1200x630/42501db08cdbaa4430758c0ede209ba0/ai-work.jpg?v=e2b758f558b9b19612f3e16bc7fd9fcc', 'uploadDate': '2023-06-02T23:00:00-0400', 'contentUrl': 'https://prod.vodvideo.cbsnews.com/cbsnews/vr/hls/2020091_hls/master.m3u8', 'publisher': {'@context': 'https://schema.org', '@type': 'NewsMediaOrganization', '@id': 'https://www.cbsnews.com/', 'name': 'CBS News', 'foundingDate': '1927-09-18', 'sameAs': ['https://www.cbsnews.com/', 'https://www.facebook.com/CBSNews/', 'https://instagram.com/cbsnews/', 'https://twitter.com/CBSNews', 'https://www.youtube.com/CBSNews', 'https://en.wikipedia.org/wiki/CBS_News'], 'logo': [{'@context': 'https://schema.org', '@type': 'ImageObject', 'height': 60, 'width': 600, 'url': 'https://www.cbsnews.com/assets/standalone/cbsnews-logo-white-600x60.png'}], 'url': 'https://www.cbsnews.com/', 'parentOrganization': {'@type': 'Organization', 'name': 'Paramount Global', '@id': 'https://www.paramount.com/', 'sameAs': 'https://www.paramount.com/', 'legalName': 'Paramount Global'}, 'actionableFeedbackPolicy': 'https://www.cbsnews.com/news/cbs-news-publishing-principles/#1d4ed2b9-ade8-4203-a4e4-115dd34c0735', 'correctionsPolicy': 'https://www.cbsnews.com/news/cbs-news-publishing-principles/#751608ae-9468-457c-9dbe-1f9400a7f428', 'ethicsPolicy': 'https://www.cbsnews.com/news/cbs-news-publishing-principles/#a0060f90-73b0-4a57-b756-ca7a7f26cc7d', 'Masthead': 'https://www.cbsnews.com/news/cbs-news-publishing-principles/#5fd9a80d-2c6c-4d38-8b1e-4144650d5963', 'missionCoveragePrioritiesPolicy': 'https://www.cbsnews.com/news/cbs-news-publishing-principles/#4ffda755-6b47-49e1-b98c-24b737906aca', 'ownershipFundingInfo': 'https://www.paramount.com/company-history', 'unnamedSourcesPolicy': 'https://www.cbsnews.com/news/cbs-news-publishing-principles/#de41886e-07ed-4887-ad05-4b2c79edf857', 'publishingPrinciples': 'https://www.cbsnews.com/news/cbs-news-publishing-principles/'}, 'duration': 'PT0H04M18S', 'embedUrl': 'https://www.cbsnews.com/video/what-jobs-are-safe-from-ai/?embed=1'}",https://www.cbsnews.com/,1927-09-18,"['https://www.cbsnews.com/', 'https://www.facebook.com/CBSNews/', 'https://instagram.com/cbsnews/', 'https://twitter.com/CBSNews', 'https://www.youtube.com/CBSNews', 'https://en.wikipedia.org/wiki/CBS_News']","[{'@context': 'https://schema.org', '@type': 'ImageObject', 'height': 60, 'width': 600, 'url': 'https://www.cbsnews.com/assets/standalone/cbsnews-logo-white-600x60.png'}]","{'@type': 'Organization', 'name': 'Paramount Global', '@id': 'https://www.paramount.com/', 'sameAs': 'https://www.paramount.com/', 'legalName': 'Paramount Global'}",https://www.cbsnews.com/news/cbs-news-publishing-principles/#1d4ed2b9-ade8-4203-a4e4-115dd34c0735,https://www.cbsnews.com/news/cbs-news-publishing-principles/#751608ae-9468-457c-9dbe-1f9400a7f428,https://www.cbsnews.com/news/cbs-news-publishing-principles/#a0060f90-73b0-4a57-b756-ca7a7f26cc7d,https://www.cbsnews.com/news/cbs-news-publishing-principles/#5fd9a80d-2c6c-4d38-8b1e-4144650d5963,https://www.cbsnews.com/news/cbs-news-publishing-principles/#4ffda755-6b47-49e1-b98c-24b737906aca,https://www.paramount.com/company-history,https://www.cbsnews.com/news/cbs-news-publishing-principles/#de41886e-07ed-4887-ad05-4b2c79edf857,https://www.cbsnews.com/news/cbs-news-publishing-principles/,,,,,,,,,,,,,,,
https://news.google.com/rss/articles/CBMizAFodHRwczovL2Npb3NlYS5lY29ub21pY3RpbWVzLmluZGlhdGltZXMuY29tL25ld3MvbmV4dC1nZW4tdGVjaG5vbG9naWVzLzktaW4tMTAtc2luZ2Fwb3JlLXJlc3BvbmRlbnRzLXNheS1nZW5lcmF0aXZlLWFpLWlzLWltcG9ydGFudC10by1kYWlseS13b3JrLWJ1dC1rbm93bGVkZ2UtZ2Fwcy1oaW5kZXItZnVsbC1wb3RlbnRpYWwtaHVic3BvdC8xMDExMDYxODDSAQA?oc=5,9 in 10 Singapore respondents say Generative AI is important to daily work but knowledge gaps hinder full potential ... - ETCIO South East Asia,2023-06-20,ETCIO South East Asia,https://ciosea.economictimes.indiatimes.com,ETCIOSEA An initiative of The Economic Times,"['Next-Gen Technologies', 'Hubspot', 'Generative Ai', 'Asia Pacific', 'Yougov', 'Ai', 'Singapore']",Hubspot: The survey results showed that 66% of total respondents and 71% in small and medium businesses (SMBs) are already using generative AI tools in their role.,Hubspot: The survey results showed that 66% of total respondents and 71% in small and medium businesses (SMBs) are already using generative AI tools in their role.,N/A,N/A,N/A,http://schema.org,WebSite,9 in 10 Singapore respondents say Generative AI is important to daily work but knowledge gaps hinder full po..,2023-06-20T05:00:00+05:30,2023-06-20T05:00:00+05:30,,,,"[{'@type': 'ImageObject', 'url': 'https://etimg.etb2bimg.com/thumb/msid-101106180,width-1200,height-900,resizemode-4/.jpg', 'width': 1200, 'height': 900}]","[{'@type': 'Thing', 'name': 'ET CIO SEA', 'url': 'https://ciosea.economictimes.indiatimes.com'}]","HubSpot, the customer relationship management (CRM) platform for scaling companies, announced the findings of a survey conducted by YouGov, on the usage and attitudes around generative Artificial Intelligence (AI).Despite Singapore&rsquo;s robust technology infrastructure, skilled workforce, and progressive culture of innovation, the survey results have shown that more awareness and training are necessary when it comes to the application of disruptive technologies such as gen AI in sales and marketing. From content creation to customer engagement through chatbots, generative AI tools help businesses deepen customer connections while dramatically reducing the time for marketing research, data analysis, and reporting. Three in five (61%) sales professionals and marketers in Singapore say their organisation has invested in generative AI tools and they plan to continue investing (46%). The survey results showed that 66% of total respondents and 71% in small and medium businesses (SMBs) are already using generative AI tools in their role. Although productivity benefits of generative AI are being realised in sales and marketing roles, respondents also expressed a clear sentiment of responsible use. Over seven in ten (72%) said people should use generative AI tools in their jobs, including one in seven (14%) saying people should leverage gen AI as much as possible and nearly three in five (58%) saying people should use gen AI, but avoid becoming overly reliant on them. With spending on AI in Asia Pacific expected to grow rapidly, Singapore is striding ahead in its advancement of transparency and governance in AI, as well as the application of disruptive technologies across industries. Amongst the respondents who adopt generative AI tools for their role, over nine in ten (92%) say that these are important for their day-to-day work &mdash;but gaps in knowledge (60%) are creating challenges to unleashing their full potential.The shortfall in awareness was revealed by 35% of respondents who face the challenge of not knowing where to begin with generative AI tools and require education and training to realise the value of the technology. For over two-fifths (42%) of respondents, inaccurate information from generative AI poses a concern, while 31% say the content produced by generative AI is too surface-level or vague. 28% of respondents also believe that generative AI cannot create truly unique or original content; this was followed by 36% saying the content generative AI produces isn't always relevant to their desired goal, while nearly the same number (35%) find it difficult to know how to prompt generative AI tools to achieve desired results.&ldquo;Today&rsquo;s customers are increasingly desensitised with templated marketing and sales outreach and are looking for the next level of relevance and personalisation. Businesses must rise to meet these expectations by changing tactics to engage customers more effectively. That's where generative AI comes in; enabling businesses to focus on quality connections over quantity,&rdquo; said Dan Bognar, Vice President &amp; Managing Director, JAPAC, at HubSpot.&ldquo;At a time when budgets are under greater scrutiny, generative AI is transforming work for Singaporean organisations across both sales and marketing functions&mdash; from conducting customer research to prospecting more effectively, generative AI is redefining productivity. We are moving away from getting the same outcome for less to getting even better results, with less. However, for businesses to fully benefit from this technology, improving literacy and empowering employees to use generative AI effectively and responsibly is essential to unlock its potential,&rdquo; he added.Also, AI is proving to be the slingshot for growth and success for SMBs to compete against large enterprises without the need for bigger budgets or teams. AI is levelling the playing field for SMBs to compete like never before. It&rsquo;s helping to drive marketing efforts through smarter ways of working, so sales and marketing teams can focus efforts on more strategic and creative outcomes. In fact, three in five (61%) survey respondents believe that generative AI tools will boost the creativity of those who use them. Survey results showed that smaller businesses are indeed more receptive to AI-enabled innovation and transformation of work processes through generative AI: 71% of sales professionals and marketers in SMBs say they are using generative AI tools in their role, compared to 57% in large enterprises.Further, respondents from businesses with a lower turnover (&ldquo;The old formula for achieving business growth was to increase headcount or add more tools to drive productivity,&rdquo; said Bognar. &ldquo;In the age of AI disruption, activities that once required substantial time and resources no longer will, opening up new pathways for growth and improving customer experiences for SMBs.&rdquo;",,"{'@type': 'NewsMediaOrganization', 'name': 'Agencies', 'logo': {'@type': 'ImageObject', 'url': 'https://img.etb2bimg.com/files/cp/upload-1679574459-cio-sea-light-theme.png', 'width': 600, 'height': 60}}","[{'@type': 'ListItem', 'position': 1, 'item': {'@id': 'https://ciosea.economictimes.indiatimes.com', 'name': 'Home'}}, {'@type': 'ListItem', 'position': 2, 'item': {'@id': 'https://ciosea.economictimes.indiatimes.com/news', 'name': 'News'}}, {'@type': 'ListItem', 'position': 3, 'item': {'@id': 'https://ciosea.economictimes.indiatimes.com/news/next-gen-technologies', 'name': 'Next-Gen Technologies'}}, {'@type': 'ListItem', 'position': 4, 'item': {'@id': 'https://ciosea.economictimes.indiatimes.com/news/next-gen-technologies/9-in-10-singapore-respondents-say-generative-ai-is-important-to-daily-work-but-knowledge-gaps-hinder-full-potential-hubspot/101106180', 'name': '9 in 10 Singapore respondents say Generative AI is important to daily work but knowledge gaps hinder full potential: HubSpot'}}]",ETCIOSEA,,https://ciosea.economictimes.indiatimes.com,,"{'@type': 'WebPage', '@id': 'https://ciosea.economictimes.indiatimes.com/news/next-gen-technologies/9-in-10-singapore-respondents-say-generative-ai-is-important-to-daily-work-but-knowledge-gaps-hinder-full-potential-hubspot/101106180'}",,,Next-Gen Technologies,,,,,,,,,,"{'@type': 'ImageObject', 'url': 'https://img.etb2bimg.com/files/cp/upload-1679574459-cio-sea-light-theme.png', 'width': 600, 'height': 60}",,,,,,,,,,,,,,"{'@type': 'Place', 'address': 'Times Internet Limited (Times Center), FC - 6, Sector 16 A, Film City, Noida - 201301 Uttar Pradesh, India'}",contactus@etcio.com,"{'@type': 'SearchAction', 'target': 'https://ciosea.economictimes.indiatimes.com/search/{query}', 'query-input': 'required name=query'}",,,,,,,,
https://news.google.com/rss/articles/CBMia2h0dHBzOi8vd3d3LmVkd2Vlay5vcmcvdGVjaG5vbG9neS9vcGluaW9uLWhlcmVzLXdoYXQtc3R1ZGVudHMtdGhpbmstYWJvdXQtdXNpbmctYWktaW4tdGhlLWNsYXNzcm9vbS8yMDIzLzA20gEA?oc=5,Here's What Students Think About Using AI in the Classroom (Opinion) - Education Week,2023-06-19,Education Week,https://www.edweek.org,"As much as teens are wed to technology, these high schoolers recognize its limitations. ","Classroom Technology,Technology,Artificial Intelligence","As much as teens are wed to technology, these high schoolers recognize its limitations.","As much as teens are wed to technology, these high schoolers recognize its limitations.","Technology, Classroom Technology",N/A,N/A,http://schema.org,NewsArticle,Here's What Students Think About Using AI in the Classroom (Opinion),"June 19, 2023","June 20, 2023",,https://www.edweek.org/teaching-learning/classroom-q-a-with-larry-ferlazzo,"Here's What Students Think About Using AI in the Classroom,Here's What Students Think About Using AI in the Classroom","{'@context': 'http://schema.org', '@type': 'ImageObject', 'url': 'https://epe.brightspotcdn.com/9d/52/c85141924761bd40f752b881c901/qanda.jpg'}",Larry Ferlazzo,,1490,"{'@type': 'Organization', 'name': 'Education Week', 'url': 'https://www.edweek.org', 'logo': {'@context': 'http://schema.org', '@type': 'ImageObject', 'url': 'https://epe.brightspotcdn.com/1f/f9/73769e394679ba628e7696bd986e/larry-ferlazzo-blue-new.jpg'}}",,,,https://www.edweek.org/technology/opinion-heres-what-students-think-about-using-ai-in-the-classroom/2023/06,https://epe.brightspotcdn.com/9d/52/c85141924761bd40f752b881c901/qanda.jpg,"{'@type': 'WebPage', '@id': 'https://www.edweek.org/technology/opinion-heres-what-students-think-about-using-ai-in-the-classroom/2023/06'}",,,,,,,,,,,,,,,,,,,,,,https://www.edweek.org/about,,,,,,,,Opinion,"Classroom Technology,Technology,Artificial Intelligence",2023,https://www.edweek.org/technology/opinion-heres-what-students-think-about-using-ai-in-the-classroom/2023/06#comments,en-US,true,"[{'@context': 'http://schema.org', '@type': 'Person', 'affiliation': 'Education Week', 'description': 'Larry Ferlazzo is an English and social studies teacher at Luther Burbank High School in Sacramento, Calif.', 'image': {'@context': 'http://schema.org', '@type': 'ImageObject', 'url': 'https://epe.brightspotcdn.com/1f/f9/73769e394679ba628e7696bd986e/larry-ferlazzo-blue-new.jpg'}, 'jobTitle': 'Opinion Contributor', 'name': 'Larry Ferlazzo', 'url': 'https://www.edweek.org/by/larry-ferlazzo'}]",P7M
https://news.google.com/rss/articles/CBMiY2h0dHBzOi8vd3d3LnRvZGF5b25saW5lLmNvbS9jb21tZW50YXJ5L2NvbW1lbnRhcnktd2h5LWdlbmVyYXRpdmUtYWktbWluZWZpZWxkLWNvcHlyaWdodC1sYXctMjE5NjU4NtIBAA?oc=5,Commentary: Why generative AI is a minefield for copyright law - TODAY,2023-06-20,TODAY,https://www.todayonline.com,"In 2022, an AI-generated work of art won the Colorado State Fair’s art competition. The artist, Jason Allen, had used Midjourney — a generative artificial intelligence (AI) system trained on art scraped from the internet — to create the piece.","art,AI","In 2022, an AI-generated work of art won the Colorado State Fair’s art competition. The artist, Jason Allen, had used Midjourney — a generative artificial intelligence (AI) system trained on art scraped from the internet — to create the piece.","In 2022, an AI-generated work of art won the Colorado State Fair’s art competition. The artist, Jason Allen, had used Midjourney — a generative artificial intelligence (AI) system trained on art scraped from the internet — to create the piece.",N/A,N/A,"




Advertisement




































      Commentary: Why generative AI is a minefield for copyright law
  

In 2022, an AI-generated work of art won the Colorado State Fair’s art competition. The artist, Jason Allen, had used Midjourney — a generative artificial intelligence (AI) system trained on art scraped from the internet — to create the piece.














          AFP
                
        


This picture taken on April 26, 2023 in Toulouse, southwestern France, shows screens displaying the logo of Midjourney an articial intelligence application.




















By 


      Jessica Fjeld
  











By 


      Robert Mahari
  











By 


      Ziv Epstein
  













By 

      Jessica Fjeld
  
                                          , 
      

      Robert Mahari
  
                                           & 
      

      Ziv Epstein
  



Published June 20, 2023
Updated May 6, 2024









    Bookmark
  






    Bookmark
  






    Share
  




 

        WhatsApp
      


 

        Telegram
      


 

        Facebook
      


 

        Twitter
      


 

        Email
      


 

        LinkedIn
      

























In 2022, an artificial intelligence (AI)-generated work of art won the Colorado State Fair’s art competition. The artist, Mr Jason Allen, had used Midjourney — a generative artificial intelligence (AI) system trained on art scraped from the internet — to create the piece.
The process was far from fully automated: Mr Allen went through some 900 iterations over 80 hours to create and refine his submission.Advertisement 












Yet his use of AI to win the art competition triggered a heated backlash online, with one Twitter user claiming, “We’re watching the death of artistry unfold right before our eyes.”
As generative AI art tools like Midjourney and Stable Diffusion have been thrust into the limelight, so too have questions about ownership and authorship.
These tools’ generative ability is the result of training them with scores of prior artworks, from which the AI learns how to create artistic outputs.


      Read also
  






      An AI-generated picture won an art prize. Artists aren’t happy.
  







Should the artists whose art was scraped to train the models be compensated? Who owns the images that AI systems produce? Is the process of fine-tuning prompts for generative AI a form of authentic creative expression?
On one hand, technophiles rave over work like Mr Allen’s. But on the other, many working artists consider the use of their art to train AI to be exploitative.Advertisement 












We’re part of a team of 14 experts across disciplines that just published a paper on generative AI in Science magazine. In it, we explore how advances in AI will affect creative work, aesthetics and the media.
One of the key questions that emerged has to do with United States copyright laws, and whether they can adequately deal with the unique challenges of generative AI.
Copyright laws were created to promote the arts and creative thinking. But the rise of generative AI has complicated existing notions of authorship.
PHOTOGRAPHY SERVES AS A HELPFUL LENS
Generative AI might seem unprecedented, but history can act as a guide.


      Read also
  






      Commentary: Tapping AI tools like ChatGPT for investment decisions? Here are some things to take note of
  







Take the emergence of photography in the 1800s. Before its invention, artists could only try to portray the world through drawing, painting or sculpture. Suddenly, reality could be captured in a flash using a camera and chemicals.Advertisement 












As with generative AI, many argued that photography lacked artistic merit.
In 1884, the US Supreme Court weighed in on the issue and found that cameras served as tools that an artist could use to give an idea visible form; the “masterminds” behind the cameras, the court ruled, should own the photographs they create.
From then on, photography evolved into its own art form and even sparked new abstract artistic movements.
AI CAN NOT OWN OUTPUTS
Unlike inanimate cameras, AI possesses capabilities — like the ability to convert basic instructions into impressive artistic works — that make it prone to anthropomorphisation.
Even the term “artificial intelligence” encourages people to think that these systems have humanlike intent or even self-awareness.Advertisement 














      Read also
  






      AI models like ChatGPT can create new jobs, opportunities, but Govt needs to help workers adapt: Lawrence Wong
  







This led some people to wonder whether AI systems can be “owners”. But the US Copyright Office has stated unequivocally that only humans can hold copyrights.
So who can claim ownership of images produced by AI?
Is it the artists whose images were used to train the systems? The users who type in prompts to create images? Or the people who build the AI systems?
INFRINGEMENT OR FAIR USE?
While artists draw obliquely from past works that have educated and inspired them in order to create, generative AI relies on training data to produce outputs.
This training data consists of prior artworks, many of which are protected by copyright law and which have been collected without artists’ knowledge or consent. Using art in this way might violate copyright law even before the AI generates a new work.
For Mr Allen to create his award-winning art, Midjourney was trained on 100 million prior works.
Was that a form of infringement? Or was it a new form of “fair use”, a legal doctrine that permits the unlicensed use of protected works if they’re sufficiently transformed into something new?
While AI systems do not contain literal copies of the training data, they do sometimes manage to recreate works from the training data, complicating this legal analysis.
Will contemporary copyright law favour end users and companies over the artists whose content is in the training data?
To mitigate this concern, some scholars propose new regulations to protect and compensate artists whose work is used for training.
These proposals include a right for artists to opt out of their data being used for generative AI or a way to automatically compensate artists when their work is used to train an AI.
MUDDLED OWNERSHIP
Training data, however, is only part of the process. Frequently, artists who use generative AI tools go through many rounds of revision to refine their prompts, which suggests a degree of originality.
Answering the question of who should own the outputs requires looking into the contributions of all those involved in the generative AI supply chain.
The legal analysis is easier when an output is different from works in the training data. In this case, whoever prompted the AI to produce the output appears to be the default owner.
However, copyright law requires meaningful creative input — a standard satisfied by clicking the shutter button on a camera. It remains unclear how courts will decide what this means for the use of generative AI. Is composing and refining a prompt enough?
Matters are more complicated when outputs resemble works in the training data. If the resemblance is based only on general style or content, it is unlikely to violate copyright, because style is not copyrightable.
The illustrator Hollie Mengert encountered this issue firsthand when her unique style was mimicked by generative AI engines in a way that did not capture what, in her eyes, made her work unique.
Meanwhile, the singer Grimes embraced the tech, “open-sourcing” her voice and encouraging fans to create songs in her style using generative AI.
If an output contains major elements from a work in the training data, it might infringe on that work’s copyright.
Recently, the Supreme Court ruled that Mr Andy Warhol’s drawing of a photograph was not permitted by fair use.
That means that using AI to just change the style of a work — say, from a photo to an illustration — is not enough to claim ownership over the modified output.
While copyright law tends to favour an all-or-nothing approach, scholars at Harvard Law School have proposed new models of joint ownership that allow artists to gain some rights in outputs that resemble their works.
In many ways, generative AI is yet another creative tool that allows a new group of people access to image-making, just like cameras, paintbrushes or Adobe Photoshop.
But a key difference is this new set of tools relies explicitly on training data, and therefore creative contributions cannot easily be traced back to a single artist.
The ways in which existing laws are interpreted or reformed — and whether generative AI is appropriately treated as the tool it is — will have real consequences for the future of creative expression. THE CONVERSATION

ABOUT THE AUTHORS:
Jessica Fjeld is a lecturer on Law at the Havard Law School, and the assistant director of the Cyberlaw Clinic at the Berkman Klein Center for Internet & Society. Robert Mahari is a JD-PhD student at the Massachusetts Institute of Technology (MIT) Media Lab and at Harvard Law School. Ziv Epstein is a PhD student in the Human Dynamics group at MIT.







      Related topics
  

      art
  

      AI
  




Read more of the latest in


      Commentary
  

      Explore now
  









Advertisement










YOU MIGHT LIKE
TRENDING


      Trending
  









The Big Read: Singaporeans want cheap and good hawker food. Hawkers need to make money. How do we square the circle?












Jollibee reopens in 'bigger and more convenient' spot at Lucky Plaza, giving free mascot Funko Pop for opening day












Ya Kun Kaya Toast and Mister Donut launch kaya cream doughnut and Kopi Pon De Ring for National Day












These blue and white slippers that you wear in the toilet are selling for S$1,600 in Saudi Arabia 







      Popular
  









M’sian MP says 'Singaporeans are not very fluent in English', believes there are more M'sians who are better at the language












Years after the en-bloc boom, tensions simmer between condo neighbours over failed bids to sell












'I have done stupid things that many men do': M’sian comedian Harith Iskander on why he and wife of 14 years are splitting up












'Everything is possible': Jay Chou takes photo with Tom Cruise at Wimbledon










 

Recommended by

 








Advertisement





















      Stay in the know. Anytime. Anywhere.
  







      Subscribe to our newsletter for the top features, insights and must reads delivered straight to your inbox.
  














      By clicking subscribe, I agree for my personal data to be used to send me TODAY newsletters, promotional offers and for research and analysis.
  
























      READ THE FULL STORY
  


",https://schema.org,,,,,,,,,,,,,,,,,,,"[{'@type': 'NewsArticle', 'headline': 'Commentary: Why generative AI is a minefield for copyright law', 'name': 'Commentary: Why generative AI is a minefield for copyright law', 'description': 'In 2022, an AI-generated work of art won the Colorado State Fair’s art competition. The artist, Jason Allen, had used Midjourney — a generative artificial intelligence (AI) system trained on art scraped from the internet — to create the piece.', 'image': {'@type': 'ImageObject', 'url': 'https://onecms-res.cloudinary.com/image/upload/s--HfBfA_ln--/c_fill,g_auto,h_338,w_600/f_auto,q_auto/v1/mediacorp/tdy/image/2023/06/20/20230620_afp_midjourney.jpg?itok=-AuJBKcs', 'width': '100', 'height': '100'}, 'datePublished': '2023-06-20T12:00:00+08:00', 'dateModified': '2024-05-06T17:15:40+08:00', 'author': {'@type': 'Person', '@id': 'https://www.todayonline.com/author/jessica-fjeld', 'name': 'Jessica Fjeld', 'url': 'https://www.todayonline.com/author/jessica-fjeld'}, 'publisher': {'@type': 'Organization', '@id': 'https://www.todayonline.com/', 'name': 'TODAY', 'url': 'https://www.todayonline.com/', 'logo': {'@type': 'ImageObject', 'url': 'https://www.todayonline.com/themes/custom/mc_todayonline_theme/images/logo.svg', 'width': '600', 'height': '60'}}, 'mainEntityOfPage': 'https://www.todayonline.com/commentary/commentary-why-generative-ai-minefield-copyright-law-2196586'}]",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
https://news.google.com/rss/articles/CBMiZWh0dHBzOi8vd3d3LmNic25ld3MuY29tL25ld3MvZ3JhbW15LXJ1bGUtYXJ0aWZpY2lhbC1pbnRlbGxpZ2VuY2Utb25seS1odW1hbi1jcmVhdG9ycy1lbGlnaWJsZS1hd2FyZHMv0gFpaHR0cHM6Ly93d3cuY2JzbmV3cy5jb20vYW1wL25ld3MvZ3JhbW15LXJ1bGUtYXJ0aWZpY2lhbC1pbnRlbGxpZ2VuY2Utb25seS1odW1hbi1jcmVhdG9ycy1lbGlnaWJsZS1hd2FyZHMv?oc=5,"New Grammy rule addresses artificial intelligence, says ""only human creators"" eligible for awards - CBS News",2023-06-17,CBS News,https://www.cbsnews.com,"Under the new rule, works that features elements of AI are still eligible as long as a human creator is responsible for a ""meaningful"" contribution.","['Grammys', 'Grammy Awards', 'Artificial Intelligence']","Under the new rule, works that features elements of AI are still eligible as long as a human creator is responsible for a ""meaningful"" contribution.","Under the new rule, works that features elements of AI are still eligible as long as a human creator is responsible for a ""meaningful"" contribution.",N/A,N/A,"


Entertainment

New Grammy rule addresses artificial intelligence, says ""only human creators"" eligible for awards




June 17, 2023 / 8:57 PM EDT
          / AP
        



















Grammys approve new rules on use of AI 











Grammys approve new rules on use of artificial intelligence
00:20

The Recording Academy are making several changes to the Grammy Awards, including a rule that stipulates ""only human creators"" can win the music industry's highest honor in a decision aimed at the use of artificial intelligence in popular music.""A work that contains no human authorship is not eligible in any category,"" they said, under new ""Artificial Intelligence (AI) Protocols"" released Friday.The rule was set following the semiannual academy's board of trustees meeting last month, where it was determined that work that features elements of AI are eligible, as long as a human creator is responsible for a ""meaningful"" contribution to the music and/or lyrics. 






""The human authorship component of the work submitted must be meaningful,"" the new requirements read in part.The news arrives shortly after Paul McCartney announced on Tuesday that a forthcoming ""last Beatles record"" had been composed using artificial intelligence by extracting John Lennon's voice from an old demo. At the time, he described AI as ""kind of scary but exciting,"" adding: ""We will just have to see where that leads.""


In addition to the AI rule, the Recording Academy announced that there have been swift changes made to other categories: now, to win a nomination for the album of the year category, a music creator has to account for at least 20% of the work. That includes all credited artists, featured artists, songwriters, producers, engineers, mixers and mastering engineers, and differs from a decision made in 2021, which allowed anyone who worked on the album to receive a nomination.The number of those eligible in the ""Big Four"" categories — best new artists as well as album, song, and record of the year — has been decreased from 10 to eight nominees.Previously, to be nominated for the ""best music film"" category, 50% of the documentary footage had to be performance based. The Recording Academy has lifted that requirement.The change better reflects the evolution of the music doc format, often a collection of verité and archival footage, like Apple TV's ""Billie Eilish: The World's a Little Blurry"". Biopics and dramatic feature films are still ineligible.


Also eligible: ""Music-focused and individual music videos that together create a visual album (if videos are packaged and entered together as one cohesive film),"" evidence of a trend spearheaded by Beyoncé's 2016 ""Lemonade"" film, and explored across genres, like in Halsey's 2021 ""If I Can't Have Love, I Want Power.""The Recording Academy also announced that the best improvised jazz solo award has been renamed best jazz performance, and best regional Mexican music album (including Tejano) has been renamed best música Mexicana album (including Tejano). To qualify in the latter category, 50% of the lyrics must be sung in Spanish, or the majority of the musical content must reflect a traditional style of Mexican music, like banda, norteño, corridos, gruperos, mariachi, rancheros, sierreño, jarocho, huasteco and huapango.Those changes follow the addition of three new categories, announced on Tuesday: best pop dance recording, best African music performance, and best alternative jazz album.


AI: Artificial Intelligence

              More
              






Software developers want AI to give medical advice. But how accurate is it?







AI-powered mental health bots developed as a therapy support tool







ChatGPT gives incorrect answers to questions about how to vote







A real photo took two honors in an AI competition. Here's the inside story.







Apple just made a big AI announcement. Here's what to know.





            More
            
In:
          Grammys
Grammy Awards
Artificial Intelligence

© 2023 The Associated Press. All Rights Reserved. This material may not be published, broadcast, rewritten, or redistributed.

",https://schema.org,BreadcrumbList,"New Grammy rule addresses artificial intelligence, says ""only human creators"" eligible for awards",2023-06-17T20:57:01-0400,2024-05-11T15:19:30-0400,,,"New Grammy rule addresses AI, says ""only human creators"" eligible for awards","{'@context': 'https://schema.org', '@type': 'ImageObject', 'height': 630, 'width': 1200, 'url': 'https://assets3.cbsnewsstatic.com/hub/i/r/2023/02/18/f4f3411f-2e77-4f5c-8640-534c45a5a95c/thumbnail/1200x630/4112747c3e4074d6199680dc2f0bdb8c/grammy.jpg?v=e2b758f558b9b19612f3e16bc7fd9fcc'}",,"The Recording Academy are making several changes to the Grammy Awards, including a rule that stipulates ""only human creators"" can win the music industry's highest honor in a decision aimed at the use of artificial intelligence in popular music.""A work that contains no human authorship is not eligible in any category,"" they said, under new ""Artificial Intelligence (AI) Protocols"" released Friday.The rule was set following the semiannual academy's board of trustees meeting last month, where it was determined that work that features elements of AI are eligible, as long as a human creator is responsible for a ""meaningful"" contribution to the music and/or lyrics.""The human authorship component of the work submitted must be meaningful,"" the new requirements read in part.The news arrives shortly after Paul McCartney announced on Tuesday that a forthcoming ""last Beatles record"" had been composed using artificial intelligence by extracting John Lennon's voice from an old demo. At the time, he described AI as ""kind of scary but exciting,"" adding: ""We will just have to see where that leads.""In addition to the AI rule, the Recording Academy announced that there have been swift changes made to other categories: now, to win a nomination for the album of the year category, a music creator has to account for at least 20% of the work. That includes all credited artists, featured artists, songwriters, producers, engineers, mixers and mastering engineers, and differs from a decision made in 2021, which allowed anyone who worked on the album to receive a nomination.The number of those eligible in the ""Big Four"" categories — best new artists as well as album, song, and record of the year — has been decreased from 10 to eight nominees.Previously, to be nominated for the ""best music film"" category, 50% of the documentary footage had to be performance based. The Recording Academy has lifted that requirement.The change better reflects the evolution of the music doc format, often a collection of verité and archival footage, like Apple TV's ""Billie Eilish: The World's a Little Blurry"". Biopics and dramatic feature films are still ineligible.Also eligible: ""Music-focused and individual music videos that together create a visual album (if videos are packaged and entered together as one cohesive film),"" evidence of a trend spearheaded by Beyoncé's 2016 ""Lemonade"" film, and explored across genres, like in Halsey's 2021 ""If I Can't Have Love, I Want Power.""The Recording Academy also announced that the best improvised jazz solo award has been renamed best jazz performance, and best regional Mexican music album (including Tejano) has been renamed best música Mexicana album (including Tejano). To qualify in the latter category, 50% of the lyrics must be sung in Spanish, or the majority of the musical content must reflect a traditional style of Mexican music, like banda, norteño, corridos, gruperos, mariachi, rancheros, sierreño, jarocho, huasteco and huapango.Those changes follow the addition of three new categories, announced on Tuesday: best pop dance recording, best African music performance, and best alternative jazz album.",,"{'@context': 'https://schema.org', '@type': 'NewsMediaOrganization', '@id': 'https://www.cbsnews.com/', 'name': 'CBS News', 'foundingDate': '1927-09-18', 'sameAs': ['https://www.cbsnews.com/', 'https://www.facebook.com/CBSNews/', 'https://instagram.com/cbsnews/', 'https://twitter.com/CBSNews', 'https://www.youtube.com/CBSNews', 'https://en.wikipedia.org/wiki/CBS_News'], 'logo': [{'@context': 'https://schema.org', '@type': 'ImageObject', 'height': 60, 'width': 600, 'url': 'https://www.cbsnews.com/assets/standalone/cbsnews-logo-white-600x60.png'}], 'url': 'https://www.cbsnews.com/', 'parentOrganization': {'@type': 'Organization', 'name': 'Paramount Global', '@id': 'https://www.paramount.com/', 'sameAs': 'https://www.paramount.com/', 'legalName': 'Paramount Global'}, 'actionableFeedbackPolicy': 'https://www.cbsnews.com/news/cbs-news-publishing-principles/#1d4ed2b9-ade8-4203-a4e4-115dd34c0735', 'correctionsPolicy': 'https://www.cbsnews.com/news/cbs-news-publishing-principles/#751608ae-9468-457c-9dbe-1f9400a7f428', 'ethicsPolicy': 'https://www.cbsnews.com/news/cbs-news-publishing-principles/#a0060f90-73b0-4a57-b756-ca7a7f26cc7d', 'Masthead': 'https://www.cbsnews.com/news/cbs-news-publishing-principles/#5fd9a80d-2c6c-4d38-8b1e-4144650d5963', 'missionCoveragePrioritiesPolicy': 'https://www.cbsnews.com/news/cbs-news-publishing-principles/#4ffda755-6b47-49e1-b98c-24b737906aca', 'ownershipFundingInfo': 'https://www.paramount.com/company-history', 'unnamedSourcesPolicy': 'https://www.cbsnews.com/news/cbs-news-publishing-principles/#de41886e-07ed-4887-ad05-4b2c79edf857', 'publishingPrinciples': 'https://www.cbsnews.com/news/cbs-news-publishing-principles/'}","[{'@type': 'ListItem', 'position': 1, 'item': {'@id': 'https://www.cbsnews.com/', '@type': 'WebPage', '@name': 'CBSNews.com'}}, {'@type': 'ListItem', 'position': 2, 'name': 'Entertainment', 'item': {'@id': 'https://www.cbsnews.com/entertainment', '@type': 'CollectionPage', '@name': 'Entertainment'}}, {'@type': 'ListItem', 'position': 3, 'name': 'New Grammy rule addresses AI, says ""only human creators"" eligible for awards', 'item': {'@id': 'https://www.cbsnews.com/news/grammy-rule-artificial-intelligence-only-human-creators-eligible-awards/', '@name': 'New Grammy rule addresses AI, says ""only human creators"" eligible for awards'}}]","New Grammy rule addresses artificial intelligence, says ""only human creators"" eligible for awards",,https://www.cbsnews.com/news/grammy-rule-artificial-intelligence-only-human-creators-eligible-awards/,https://assets3.cbsnewsstatic.com/hub/i/r/2023/02/18/f4f3411f-2e77-4f5c-8640-534c45a5a95c/thumbnail/1200x630/4112747c3e4074d6199680dc2f0bdb8c/grammy.jpg?v=e2b758f558b9b19612f3e16bc7fd9fcc,"{'@type': 'WebPage', '@id': 'https://www.cbsnews.com/news/grammy-rule-artificial-intelligence-only-human-creators-eligible-awards/'}",,,['Entertainment'],,,,,"{'@context': 'https://schema.org', '@type': 'ImageObject', 'height': 630, 'width': 1200, 'url': 'https://assets3.cbsnewsstatic.com/hub/i/r/2023/02/18/f4f3411f-2e77-4f5c-8640-534c45a5a95c/thumbnail/1200x630/4112747c3e4074d6199680dc2f0bdb8c/grammy.jpg?v=e2b758f558b9b19612f3e16bc7fd9fcc'}","{'@context': 'https://schema.org', '@type': 'VideoObject', 'mainEntityOfPage': {'@type': 'WebPage', '@id': 'https://www.cbsnews.com/video/grammys-approve-new-rules-on-use-of-artificial-intelligence/'}, 'name': 'Grammys approve new rules on use of artificial intelligence', 'description': 'The Recording Academy announced Friday new rules which stipulate that ""only human creators are eligible"" for Grammy awards, a response to the growing use of artificial intelligence. However, the academy noted that AI is not completely banned, musicians are still allowed to utilize it to create their work.', 'thumbnail': {'@context': 'https://schema.org', '@type': 'ImageObject', 'height': 630, 'width': 1200, 'url': 'https://assets3.cbsnewsstatic.com/hub/i/r/2023/06/17/7ebbfd4d-36be-4475-bf6d-27e82da372c1/thumbnail/1200x630/d556ed87e3757efbe8367b501b69dea9/cbsn-fusion-grammys-approve-new-rules-on-use-of-artificial-intelligence-thumbnail-2059061-640x360.jpg?v=e2b758f558b9b19612f3e16bc7fd9fcc'}, 'thumbnailUrl': 'https://assets3.cbsnewsstatic.com/hub/i/r/2023/06/17/7ebbfd4d-36be-4475-bf6d-27e82da372c1/thumbnail/1200x630/d556ed87e3757efbe8367b501b69dea9/cbsn-fusion-grammys-approve-new-rules-on-use-of-artificial-intelligence-thumbnail-2059061-640x360.jpg?v=e2b758f558b9b19612f3e16bc7fd9fcc', 'uploadDate': '2023-06-17T18:53:25-0400', 'contentUrl': 'https://prod.vodvideo.cbsnews.com/cbsnews/vr/hls/2023/06/17/2229367363820/2059059_hls/master.m3u8', 'publisher': {'@context': 'https://schema.org', '@type': 'NewsMediaOrganization', '@id': 'https://www.cbsnews.com/', 'name': 'CBS News', 'foundingDate': '1927-09-18', 'sameAs': ['https://www.cbsnews.com/', 'https://www.facebook.com/CBSNews/', 'https://instagram.com/cbsnews/', 'https://twitter.com/CBSNews', 'https://www.youtube.com/CBSNews', 'https://en.wikipedia.org/wiki/CBS_News'], 'logo': [{'@context': 'https://schema.org', '@type': 'ImageObject', 'height': 60, 'width': 600, 'url': 'https://www.cbsnews.com/assets/standalone/cbsnews-logo-white-600x60.png'}], 'url': 'https://www.cbsnews.com/', 'parentOrganization': {'@type': 'Organization', 'name': 'Paramount Global', '@id': 'https://www.paramount.com/', 'sameAs': 'https://www.paramount.com/', 'legalName': 'Paramount Global'}, 'actionableFeedbackPolicy': 'https://www.cbsnews.com/news/cbs-news-publishing-principles/#1d4ed2b9-ade8-4203-a4e4-115dd34c0735', 'correctionsPolicy': 'https://www.cbsnews.com/news/cbs-news-publishing-principles/#751608ae-9468-457c-9dbe-1f9400a7f428', 'ethicsPolicy': 'https://www.cbsnews.com/news/cbs-news-publishing-principles/#a0060f90-73b0-4a57-b756-ca7a7f26cc7d', 'Masthead': 'https://www.cbsnews.com/news/cbs-news-publishing-principles/#5fd9a80d-2c6c-4d38-8b1e-4144650d5963', 'missionCoveragePrioritiesPolicy': 'https://www.cbsnews.com/news/cbs-news-publishing-principles/#4ffda755-6b47-49e1-b98c-24b737906aca', 'ownershipFundingInfo': 'https://www.paramount.com/company-history', 'unnamedSourcesPolicy': 'https://www.cbsnews.com/news/cbs-news-publishing-principles/#de41886e-07ed-4887-ad05-4b2c79edf857', 'publishingPrinciples': 'https://www.cbsnews.com/news/cbs-news-publishing-principles/'}, 'duration': 'PT0H00M20S', 'embedUrl': 'https://www.cbsnews.com/video/grammys-approve-new-rules-on-use-of-artificial-intelligence/?embed=1'}",https://www.cbsnews.com/,1927-09-18,"['https://www.cbsnews.com/', 'https://www.facebook.com/CBSNews/', 'https://instagram.com/cbsnews/', 'https://twitter.com/CBSNews', 'https://www.youtube.com/CBSNews', 'https://en.wikipedia.org/wiki/CBS_News']","[{'@context': 'https://schema.org', '@type': 'ImageObject', 'height': 60, 'width': 600, 'url': 'https://www.cbsnews.com/assets/standalone/cbsnews-logo-white-600x60.png'}]","{'@type': 'Organization', 'name': 'Paramount Global', '@id': 'https://www.paramount.com/', 'sameAs': 'https://www.paramount.com/', 'legalName': 'Paramount Global'}",https://www.cbsnews.com/news/cbs-news-publishing-principles/#1d4ed2b9-ade8-4203-a4e4-115dd34c0735,https://www.cbsnews.com/news/cbs-news-publishing-principles/#751608ae-9468-457c-9dbe-1f9400a7f428,https://www.cbsnews.com/news/cbs-news-publishing-principles/#a0060f90-73b0-4a57-b756-ca7a7f26cc7d,https://www.cbsnews.com/news/cbs-news-publishing-principles/#5fd9a80d-2c6c-4d38-8b1e-4144650d5963,https://www.cbsnews.com/news/cbs-news-publishing-principles/#4ffda755-6b47-49e1-b98c-24b737906aca,https://www.paramount.com/company-history,https://www.cbsnews.com/news/cbs-news-publishing-principles/#de41886e-07ed-4887-ad05-4b2c79edf857,https://www.cbsnews.com/news/cbs-news-publishing-principles/,,,,,,,,,,,,,,,
